<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>无锁队列的几种实现及其性能对比</title>
      <link href="/posts/d6459a58/"/>
      <url>/posts/d6459a58/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>作者：juliatliu，腾讯 PCG 运营开发工程师</p><h3 id="一、无锁队列用在什么样的场景？"><a href="#一、无锁队列用在什么样的场景？" class="headerlink" title="一、无锁队列用在什么样的场景？"></a>一、无锁队列用在什么样的场景？</h3><p>当需要处理的数据非常多，比如行情数据，一秒处理非常多的数据的时候，可以考虑用无锁队列。但是如果一秒只需要处理几百或者几千的数据，是没有必要考虑用无锁队列的。用互斥锁就能解决问题，数据量相对少的时候互斥锁与无锁队列之间差别并不是很明显。</p><h3 id="二、为什么要用无锁队列？"><a href="#二、为什么要用无锁队列？" class="headerlink" title="二、为什么要用无锁队列？"></a>二、为什么要用无锁队列？</h3><p>有锁队列会有哪些问题？</p><p><strong>1、Cache 的损坏，在线程间频繁切换的时候会导致 Cache 中数据的丢失；</strong></p><p>CPU 的运行速度比主存快 N 倍，所以大量的处理器时间被浪费在处理器与主存的数据传输上，这就是在处理器与主存之间引入 Cache 的原因。Cache 是一种速度更快但容量更小的内存，当处理器要访问主存中的数据时，这些数据首先要被拷贝到 Cache 中，因为这些数据在不久的将来可能又会被处理器访问。Cache misses 对性能有非常大的影响，因为处理器访问 Cache 中的数据将比直接访问主存快得多。</p><p>线程被频繁抢占产生的 Cache 损坏将导致应用程序性能下降。</p><p><strong>2、在同步机制上争抢队列；</strong></p><p>CPU 会将大量的时间浪费在保护队列数据的互斥锁，而不是处理队列中的数据。</p><p>然后非阻塞的机制使用了 CAS 的特殊操作，使得任务之间可以不争抢任何资源，然后在队列中预定的位置上，插入或者提取数据。</p><p><strong>3、多线程动态内存分配性能下降；</strong></p><p>多线程同时分配内存时，会涉及到线程分配同一块相同地址内存的问题，这个时候会用锁来进行同步。显然频繁分配内存会导致应用程序性能下降。</p><h3 id="三、无锁队列的实现"><a href="#三、无锁队列的实现" class="headerlink" title="三、无锁队列的实现"></a>三、无锁队列的实现</h3><h4 id="3-1-一读一写的无锁队列"><a href="#3-1-一读一写的无锁队列" class="headerlink" title="3.1 一读一写的无锁队列"></a>3.1 一读一写的无锁队列</h4><p>yqueue 是用来设计队列，ypipe 用来设计队列的写入时机、回滚以及 flush，首先我们来看 yqueue 的设计。</p><h5 id="3-1-1-yqueue——无锁队列"><a href="#3-1-1-yqueue——无锁队列" class="headerlink" title="3.1.1 yqueue——无锁队列"></a>3.1.1 yqueue——无锁队列</h5><p><strong>1、内存分配</strong></p><p>首先我们需要考虑队列的内存分配，yqueue 中的数据结构使用的 chunk 块机制，每次批量分配一批元素，这样可以减少内存的分配和释放：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">template&lt;typename T, <span class="type">int</span> N&gt;  </span><br><span class="line">    <span class="comment">// 链表结点称之为chunk_t  </span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">chunk_t</span>  </span></span><br><span class="line"><span class="class">    &#123;</span>  </span><br><span class="line">        T values[N]; <span class="comment">//每个chunk_t可以容纳N个T类型的元素，以后就以一个chunk_t为单位申请内存  </span></span><br><span class="line">        <span class="type">chunk_t</span> *prev;  </span><br><span class="line">        <span class="type">chunk_t</span> *next;  </span><br><span class="line">    &#125;;  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/74a3fd96f4b8ba476cdd2d8dfc2ba91a.jpeg" alt=""></p><p>当队列不足的时候每次分配一个 chunk_t，每个 chunk_t 能存储 N 个元素。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//  Adds an element to the back end of the queue.  </span></span><br><span class="line"><span class="keyword">inline</span> <span class="type">void</span> <span class="title function_">push</span><span class="params">()</span>  </span><br><span class="line">&#123;  </span><br><span class="line">    back_chunk = end_chunk;  </span><br><span class="line">    back_pos = end_pos; <span class="comment">//  </span></span><br><span class="line">    <span class="keyword">if</span> (++end_pos != N) <span class="comment">//end_pos!=N表明这个chunk节点还没有满  </span></span><br><span class="line">         <span class="keyword">return</span>;  </span><br><span class="line">    </span><br><span class="line">     <span class="type">chunk_t</span> *sc = spare_chunk.xchg(<span class="literal">NULL</span>); <span class="comment">// 为什么设置为NULL？ 因为如果把之前值取出来了则没有spare chunk了，所以设置为NULL  </span></span><br><span class="line">     <span class="keyword">if</span> (sc)                               <span class="comment">// 如果有spare chunk则继续复用它  </span></span><br><span class="line">     &#123;  </span><br><span class="line">         end_chunk-&gt;next = sc;  </span><br><span class="line">         sc-&gt;prev = end_chunk;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="keyword">else</span> <span class="comment">// 没有则重新分配  </span></span><br><span class="line">     &#123;  </span><br><span class="line">         <span class="comment">// static int s_cout = 0;  </span></span><br><span class="line">         <span class="comment">// printf(&quot;s_cout:%d\n&quot;, ++s_cout);  </span></span><br><span class="line">         end_chunk-&gt;next = (<span class="type">chunk_t</span> *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">chunk_t</span>)); <span class="comment">// 分配一个chunk  </span></span><br><span class="line">         alloc_assert(end_chunk-&gt;next);  </span><br><span class="line">         end_chunk-&gt;next-&gt;prev = end_chunk;  </span><br><span class="line">     &#125;  </span><br><span class="line">     end_chunk = end_chunk-&gt;next;  </span><br><span class="line">     end_pos = <span class="number">0</span>;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>可以看到 112 行，在要 push 一个元素的时候，首先看最后一个 chunk，也就是 back_chunk 的 back_pos 是不是该 chunk 的最后一个元素，如果是，则重新分配一个 chunk，将这个 chunk 加到 chunk 链表的下一个节点。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/0082c810c4aa7a3307f6a62fd39d6086.jpeg" alt=""></p><p>这个逻辑相对来说还是比较简单的。唯一需要关注的，就是：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">chunk_t</span> *sc = spare_chunk.xchg(<span class="literal">NULL</span>);  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这一行，这个 spare_chunk 是怎么来的？</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//  Removes an element from the front end of the queue.  </span></span><br><span class="line"><span class="keyword">inline</span> <span class="type">void</span> <span class="title function_">pop</span><span class="params">()</span> &#123;  </span><br><span class="line">    <span class="keyword">if</span> (++begin_pos == N) <span class="comment">// 删除满一个chunk才回收chunk  </span></span><br><span class="line">    &#123;  </span><br><span class="line">        <span class="type">chunk_t</span> *o = begin_chunk;  </span><br><span class="line">        begin_chunk = begin_chunk-&gt;next;  </span><br><span class="line">        begin_chunk-&gt;prev = <span class="literal">NULL</span>;  </span><br><span class="line">        begin_pos = <span class="number">0</span>;  </span><br><span class="line"></span><br><span class="line">        <span class="comment">//  &#x27;o&#x27; has been more recently used than spare_chunk,  </span></span><br><span class="line">        <span class="comment">//  so for cache reasons we&#x27;ll get rid of the spare and  </span></span><br><span class="line">        <span class="comment">//  use &#x27;o&#x27; as the spare.  </span></span><br><span class="line">        <span class="type">chunk_t</span> *cs = spare_chunk.xchg(o); <span class="comment">//由于局部性原理，总是保存最新的空闲块而释放先前的空闲快  </span></span><br><span class="line">        <span class="built_in">free</span>(cs);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>当 pop 的时候，如果删除一个 chunk 里面没有元素了，这个时候会需要将这个 chunk 所开辟的空间释放掉，但是这里使用了一个技巧即：将这个 chunk 先不释放，先放到 spare_chunk 里面，等到下次需要开辟新的空间的时候再把这个 spare_chunk 拿来用。</p><p>我们再来看 ypipe。</p><h5 id="3-1-2-ypipe——yqueue-的封装"><a href="#3-1-2-ypipe——yqueue-的封装" class="headerlink" title="3.1.2 ypipe——yqueue 的封装"></a>3.1.2 ypipe——yqueue 的封装</h5><p>yqueue 负责元素内存的分配与释放，入队以及出队列；ypipe 负责 yqueue 读写指针的变化。</p><p>ypipe 是在 yqueue_t 的基础上再构建一个单读单写的无锁队列。</p><p>这里有三个指针：</p><ul><li><p>T* w:指向第一个未刷新的元素，只被写线程使用；</p></li><li><p>T* r:指向第一个没有被预提取的元素，只被读线程使用；</p></li><li><p>T*f:指向下一轮要被刷新的一批元素的第一个。</p></li></ul><p>ypipe 的定义：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//  Initialises the pipe.  </span></span><br><span class="line"><span class="keyword">inline</span> <span class="title function_">ypipe_t</span><span class="params">()</span>  </span><br><span class="line"><span class="comment">//  The destructor doesn&#x27;t have to be virtual. It is mad virtual  </span></span><br><span class="line"><span class="comment">//  just to keep ICC and code checking tools from complaining.  </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> virtual ~<span class="title function_">ypipe_t</span><span class="params">()</span>&#123;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入数据，incomplete参数表示写入是否还没完成，在没完成的时候不会修改flush指针，即这部分数据不会让读线程看到。  </span></span><br><span class="line"><span class="keyword">inline</span> <span class="type">void</span> <span class="title function_">write</span><span class="params">(<span class="type">const</span> T &amp;value_, <span class="type">bool</span> incomplete_)</span>;  </span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> <span class="type">bool</span> <span class="title function_">unwrite</span><span class="params">(T *value_)</span>;  </span><br><span class="line"></span><br><span class="line"><span class="comment">// 刷新所有已经完成的数据到管道，返回false意味着读线程在休眠，在这种情况下调用者需要唤醒读线程。  </span></span><br><span class="line"><span class="comment">// 批量刷新的机制， 写入批量后唤醒读线程；  </span></span><br><span class="line"><span class="comment">// 反悔机制 unwrite  </span></span><br><span class="line"><span class="keyword">inline</span> <span class="type">bool</span> <span class="title function_">flush</span><span class="params">()</span>;  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//  Check whether item is available for reading.  </span></span><br><span class="line"><span class="comment">// 这里面有两个点，一个是检查是否有数据可读，一个是预取  </span></span><br><span class="line"><span class="keyword">inline</span> <span class="type">bool</span> <span class="title function_">check_read</span><span class="params">()</span>;  </span><br><span class="line"><span class="comment">//  Reads an item from the pipe. Returns false if there is no value.  </span></span><br><span class="line"><span class="comment">//  available.  </span></span><br><span class="line"><span class="keyword">inline</span> <span class="type">bool</span> <span class="title function_">read</span><span class="params">(T *value_)</span>  </span><br><span class="line"><span class="comment">//  Applies the function fn to the first elemenent in the pipe  </span></span><br><span class="line"><span class="comment">//  and returns the value returned by the fn.  </span></span><br><span class="line"><span class="comment">//  The pipe mustn&#x27;t be empty or the function crashes.  </span></span><br><span class="line"><span class="keyword">inline</span> <span class="type">bool</span> <span class="title function_">probe</span><span class="params">(<span class="type">bool</span> (*fn)(T &amp;))</span>  </span><br><span class="line">protected:  </span><br><span class="line">    <span class="comment">//  Allocation-efficient queue to store pipe items.  </span></span><br><span class="line">    <span class="comment">//  Front of the queue points to the first prefetched item, back of  </span></span><br><span class="line">    <span class="comment">//  the pipe points to last un-flushed item. Front is used only by  </span></span><br><span class="line">    <span class="comment">//  reader thread, while back is used only by writer thread.  </span></span><br><span class="line">    <span class="type">yqueue_t</span>&lt;T, N&gt; <span class="built_in">queue</span>;  </span><br><span class="line"></span><br><span class="line">    <span class="comment">//  Points to the first un-flushed item. This variable is used  </span></span><br><span class="line">    <span class="comment">//  exclusively by writer thread.  </span></span><br><span class="line">    T *w; <span class="comment">//指向第一个未刷新的元素,只被写线程使用  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//  Points to the first un-prefetched item. This variable is used  </span></span><br><span class="line">    <span class="comment">//  exclusively by reader thread.  </span></span><br><span class="line">    T *r; <span class="comment">//指向第一个还没预提取的元素，只被读线程使用  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//  Points to the first item to be flushed in the future.  </span></span><br><span class="line">    T *f; <span class="comment">//指向下一轮要被刷新的一批元素中的第一个  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//  The single point of contention between writer and reader thread.  </span></span><br><span class="line">    <span class="comment">//  Points past the last flushed item. If it is NULL,  </span></span><br><span class="line">    <span class="comment">//  reader is asleep. This pointer should be always accessed using  </span></span><br><span class="line">    <span class="comment">//  atomic operations.  </span></span><br><span class="line">    <span class="type">atomic_ptr_t</span>&lt;T&gt; c; <span class="comment">//读写线程共享的指针，指向每一轮刷新的起点（看代码的时候会详细说）。当c为空时，表示读线程睡眠（只会在读线程中被设置为空）  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//  Disable copying of ypipe object.  </span></span><br><span class="line">    <span class="type">ypipe_t</span>(<span class="type">const</span> <span class="type">ypipe_t</span> &amp;);  </span><br><span class="line">    <span class="type">const</span> <span class="type">ypipe_t</span> &amp;operator=(<span class="type">const</span> <span class="type">ypipe_t</span> &amp;);  </span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="3-1-3-ypipe-设计的目的"><a href="#3-1-3-ypipe-设计的目的" class="headerlink" title="3.1.3 ypipe 设计的目的"></a>3.1.3 ypipe 设计的目的</h5><p>为了批量读写，即用户可以自主的决定写了多少数据之后开启读。那因为有了生产者和消费者，就会涉及到同步的问题，ypipe 这里测试发现，用锁和条件变量性能最佳。</p><p>我们来分两种情况看一下读写的具体步骤。第一种情况：批量写，第一轮写：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/25f2df0f3e89ab7fb54b72dded3d477a.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/74a3fd96f4b8ba476cdd2d8dfc2ba91a.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/744db6107fb85f6bb3b5717cfe656c2b.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/01d3f4e079cfd35f8d96baf3064ca0f3.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/aa8a11244103b5c76e97978a0c41573a.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/f313bdad477455e3022a0dfb81ff8b08.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/0ee654722a652bce8e2ca2201f275367.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/bbffe5af3c1a786398b3c37b1fb6229d.jpeg" alt=""></p><p>在这个时候才能开始读数据：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/150f0a35e7c019e9cef60bdbbd7fb0a7.jpeg" alt=""></p><p>img</p><p>第二种方式：条件变量+互斥锁：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/7098a73568197431ecff5e7fea721c5e.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/c5ec6c74192109b4df1ed106348c105f.jpeg" alt=""></p><p><strong>flush 函数</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//  Flush all the completed items into the pipe. Returns false if  </span></span><br><span class="line"><span class="comment">//  the reader thread is sleeping. In that case, caller is obliged to  </span></span><br><span class="line"><span class="comment">//  wake the reader up before using the pipe again.  </span></span><br><span class="line"><span class="comment">// 刷新所有已经完成的数据到管道，返回false意味着读线程在休眠，在这种情况下调用者需要唤醒读线程。  </span></span><br><span class="line"><span class="comment">// 批量刷新的机制， 写入批量后唤醒读线程；  </span></span><br><span class="line"><span class="comment">// 反悔机制 unwrite  </span></span><br><span class="line"><span class="keyword">inline</span> <span class="type">bool</span> <span class="title function_">flush</span><span class="params">()</span> &#123;  </span><br><span class="line">    <span class="comment">//  If there are no un-flushed items, do nothing.  </span></span><br><span class="line">    <span class="keyword">if</span> (w == f) <span class="comment">// 不需要刷新，即是还没有新元素加入  </span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;  </span><br><span class="line"></span><br><span class="line">    <span class="comment">//  Try to set &#x27;c&#x27; to &#x27;f&#x27;.  </span></span><br><span class="line">    <span class="comment">// read时如果没有数据可以读取则c的值会被置为NULL  </span></span><br><span class="line">    <span class="keyword">if</span> (c.cas(w, f) != w) <span class="comment">// 尝试将c设置为f，即是准备更新w的位置  </span></span><br><span class="line">    &#123;  </span><br><span class="line"></span><br><span class="line">        <span class="comment">//  Compare-and-swap was unseccessful because &#x27;c&#x27; is NULL.  </span></span><br><span class="line">        <span class="comment">//  This means that the reader is asleep. Therefore we don&#x27;t  </span></span><br><span class="line">        <span class="comment">//  care about thread-safeness and update c in non-atomic  </span></span><br><span class="line">        <span class="comment">//  manner. We&#x27;ll return false to let the caller know  </span></span><br><span class="line">        <span class="comment">//  that reader is sleeping.  </span></span><br><span class="line">        c.<span class="built_in">set</span>(f); <span class="comment">// 更新为新的f位置  </span></span><br><span class="line">        w = f;  </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">//线程看到flush返回false之后会发送一个消息给读线程，这需要写业务去做处理  </span></span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">else</span>  <span class="comment">// 读端还有数据可读取  </span></span><br><span class="line">    &#123;  </span><br><span class="line">        <span class="comment">//  Reader is alive. Nothing special to do now. Just move  </span></span><br><span class="line">        <span class="comment">//  the &#x27;first un-flushed item&#x27; pointer to &#x27;f&#x27;.  </span></span><br><span class="line">        w = f;             <span class="comment">// 更新f的位置  </span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>flush 的目的就是将改变 w 的值，同时改变 c 的值，这里有两种情况：</p><p>1、c 的值与 w 的值相等</p><p>说明队列的 w 值没有更新，不对队列的数据进行读取：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/2bc149fdcf4f068ab53d9ce99eac0461.jpeg" alt=""></p><p>这发生在 flush 第一次发生的时候以及 w 的值还未更新时，此时返回 true，表示队列不可读。</p><p>2、c 的值与 w 的值不相等</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/f93d96825f2aca4d148699608d9277a7.jpeg" alt=""></p><p>这发生在 c 在 w 位置后面，此时更新 c 与 w 的值，并返回 false，表示队列可读。</p><p><strong>write 函数</strong></p><p>write 函数相对简单:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//  Write an item to the pipe.  Don&#x27;t flush it yet. If incomplete is  </span></span><br><span class="line"><span class="comment">//  set to true the item is assumed to be continued by items  </span></span><br><span class="line"><span class="comment">//  subsequently written to the pipe. Incomplete items are neverflushed down the stream.  </span></span><br><span class="line"><span class="comment">// 写入数据，incomplete参数表示写入是否还没完成，在没完成的时候不会修改flush指针，即这部分数据不会让读线程看到。  </span></span><br><span class="line"><span class="keyword">inline</span> <span class="type">void</span> <span class="title function_">write</span><span class="params">(<span class="type">const</span> T &amp;value_, <span class="type">bool</span> incomplete_)</span> &#123;  </span><br><span class="line">    <span class="comment">//  Place the value to the queue, add new terminator element.  </span></span><br><span class="line">    <span class="built_in">queue</span>.back() = value_;  </span><br><span class="line">    <span class="built_in">queue</span>.push();  </span><br><span class="line"></span><br><span class="line">    <span class="comment">//  Move the &quot;flush up to here&quot; poiter.  </span></span><br><span class="line">    <span class="keyword">if</span> (!incomplete_)  </span><br><span class="line">    &#123;  </span><br><span class="line">        f = &amp;<span class="built_in">queue</span>.back(); <span class="comment">// 记录要刷新的位置  </span></span><br><span class="line">        <span class="comment">// printf(&quot;1 f:%p, w:%p\n&quot;, f, w);  </span></span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">else</span>  </span><br><span class="line">    &#123;  </span><br><span class="line">        <span class="comment">//  printf(&quot;0 f:%p, w:%p\n&quot;, f, w);  </span></span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>write 只更新 f 的位置。write 并不能决定该队列是否能读，因为 write 并不能改变 w 指针，如果要队列能读，需要 w 指针改变位置才行。</p><p>从 write 和 flush 可以看出，在更新 w 和 f 的时候并没有互斥的保护，所以该无锁队列的设计并不适合多线程场景。</p><p><strong>read 函数</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">inline</span> <span class="type">bool</span> <span class="title function_">check_read</span><span class="params">()</span> &#123;  </span><br><span class="line">     <span class="comment">//  Was the value prefetched already? If so, return.  </span></span><br><span class="line">     <span class="keyword">if</span> (&amp;<span class="built_in">queue</span>.front() != r &amp;&amp; r) <span class="comment">//判断是否在前几次调用read函数时已经预取数据了return true;  </span></span><br><span class="line">         <span class="keyword">return</span> <span class="literal">true</span>;  </span><br><span class="line"></span><br><span class="line">     <span class="comment">//  There&#x27;s no prefetched value, so let us prefetch more values.  </span></span><br><span class="line">     <span class="comment">//  Prefetching is to simply retrieve the  </span></span><br><span class="line">     <span class="comment">//  pointer from c in atomic fashion. If there are no  </span></span><br><span class="line">     <span class="comment">//  items to prefetch, set c to NULL (using compare-and-swap).  </span></span><br><span class="line">     <span class="comment">// 两种情况  </span></span><br><span class="line">     <span class="comment">// 1. 如果c值和queue.front()， 返回c值并将c值置为NULL，此时没有数据可读  </span></span><br><span class="line">     <span class="comment">// 2. 如果c值和queue.front()， 返回c值，此时可能有数据度的去  </span></span><br><span class="line">     r = c.cas(&amp;<span class="built_in">queue</span>.front(), <span class="literal">NULL</span>); <span class="comment">//尝试预取数据  </span></span><br><span class="line"></span><br><span class="line">     <span class="comment">//  If there are no elements prefetched, exit.  </span></span><br><span class="line">     <span class="comment">//  During pipe&#x27;s lifetime r should never be NULL, however,  </span></span><br><span class="line">     <span class="comment">//  it can happen during pipe shutdown when items are being deallocated.  </span></span><br><span class="line">     <span class="keyword">if</span> (&amp;<span class="built_in">queue</span>.front() == r || !r) <span class="comment">//判断是否成功预取数据  </span></span><br><span class="line">         <span class="keyword">return</span> <span class="literal">false</span>;  </span><br><span class="line"></span><br><span class="line">     <span class="comment">//  There was at least one value prefetched.  </span></span><br><span class="line">     <span class="keyword">return</span> <span class="literal">true</span>;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"> <span class="comment">//  Reads an item from the pipe. Returns false if there is no value.  </span></span><br><span class="line"> <span class="comment">//  available.  </span></span><br><span class="line"> <span class="keyword">inline</span> <span class="type">bool</span> <span class="title function_">read</span><span class="params">(T *value_)</span> &#123;  </span><br><span class="line">     <span class="comment">//  Try to prefetch a value.  </span></span><br><span class="line">     <span class="keyword">if</span> (!check_read())  </span><br><span class="line">         <span class="keyword">return</span> <span class="literal">false</span>;  </span><br><span class="line"></span><br><span class="line">     <span class="comment">//  There was at least one value prefetched.  </span></span><br><span class="line">     <span class="comment">//  Return it to the caller.  </span></span><br><span class="line">     *value_ = <span class="built_in">queue</span>.front();  </span><br><span class="line">     <span class="built_in">queue</span>.pop();  </span><br><span class="line">     <span class="keyword">return</span> <span class="literal">true</span>;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里也是有两种情况：</p><p>1、r 不为空且 r 不等于&amp;queue.front()</p><p>说明此时队列中有可读数据，直接读取即可。</p><p>2、r 指针指向队头元素(r==&amp;queue.front())或者 r 为空</p><p>说明队列中并没有可读的数据，此时将 r 指针更新成 c 的值，这个过程我们叫做预取。预取的指令就是:</p><p>r=c;</p><p>c 在 flush 的时候会被设置为 w。而 w 与&amp;queue.front()之间都是有距离的。这一段距离中间的数据就是预取数据，所以每次 read 都能取出一段数据。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9986ba9fe095d4ceb31db780acfdc8eb.jpeg" alt=""></p><p>当&amp;queue.front() == c 时，代表数据被取完了，这时把 c 指向 NULL，接着读线程会睡眠，这也是给写线程检查读线程是否睡眠的标志。</p><p>我们可以测试一下结果，对一个数据加 200 万次，分别用环形数组、链表、互斥锁、ypipe 队列分别是什么样的性能。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/37503aef6f9421eab6798158fbb3185a.jpeg" alt=""></p><p>通过测试发现在一读一写的情况下，ypipe 的优势是非常大的。</p><p>那多读多写的场景呢？</p><h3 id="四、多读多写的无锁队列实现"><a href="#四、多读多写的无锁队列实现" class="headerlink" title="四、多读多写的无锁队列实现"></a><strong>四、多读多写的无锁队列实现</strong></h3><p>上面我们介绍的是一读一写的场景，用 ypipe 的方式会性能比较快，但是 ypipe 不适用于多读多写的场景，因为在读的时候是没有对 r 指针加锁，在写的时候也没有对 w 指针加锁。</p><p>多读多写的线程安全队列有以下几种实现方式：</p><p>1、互斥锁</p><p>2、互斥锁+条件变量：BlockQueue</p><p>3、内存屏障：SimpleLockFreeQueue</p><p>4、CAS 原子操作：ArrayLockFreeQueue（也可以理解成 RingBuffer）</p><p>其中互斥锁的性能是几种方式里面性能最低的，没什么讲的必要，这里就不对比这种实现方式了。</p><h4 id="4-1-RingBuffer-ArrayLockFreeQueue"><a href="#4-1-RingBuffer-ArrayLockFreeQueue" class="headerlink" title="4.1 RingBuffer(ArrayLockFreeQueue)"></a>4.1 RingBuffer(ArrayLockFreeQueue)</h4><p>下面我们来看基于循环数组的无锁队列，也就是 RingBuffer 如何解决多线程竞争的问题。</p><p>首先看下 RingBuffer 的数据结构如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">template &lt;typename ELEM_T, QUEUE_INT Q_SIZE = ARRAY_LOCK_FREE_Q_DEFAULT_SIZE&gt;  </span><br><span class="line">class ArrayLockFreeQueue &#123;  </span><br><span class="line">public:  </span><br><span class="line"> </span><br><span class="line">    ArrayLockFreeQueue();  </span><br><span class="line">    virtual ~ArrayLockFreeQueue();  </span><br><span class="line"> </span><br><span class="line">    QUEUE_INT <span class="title function_">size</span><span class="params">()</span>;  </span><br><span class="line"> </span><br><span class="line">    <span class="type">bool</span> <span class="title function_">enqueue</span><span class="params">(<span class="type">const</span> ELEM_T &amp;a_data)</span>;<span class="comment">//入队列  </span></span><br><span class="line"> </span><br><span class="line">    <span class="type">bool</span> <span class="title function_">dequeue</span><span class="params">(ELEM_T &amp;a_data)</span>;<span class="comment">//出队列  </span></span><br><span class="line"> </span><br><span class="line">    <span class="type">bool</span> <span class="title function_">try_dequeue</span><span class="params">(ELEM_T &amp;a_data)</span>;  </span><br><span class="line"> </span><br><span class="line">private:  </span><br><span class="line"> </span><br><span class="line">    ELEM_T m_thequeue[Q_SIZE];  </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">volatile</span> QUEUE_INT m_count;  </span><br><span class="line">    <span class="keyword">volatile</span> QUEUE_INT m_writeIndex;  </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">volatile</span> QUEUE_INT m_readIndex;  </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">volatile</span> QUEUE_INT m_maximumReadIndex;  </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">inline</span> QUEUE_INT <span class="title function_">countToIndex</span><span class="params">(QUEUE_INT a_count)</span>;  </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>m_count: // 队列的元素个数</p><p>我们先来看三种不同的下标：</p><ul><li><p>m_writeIndex: // 新元素入队列时存放位置在数组中的下标；</p></li><li><p>m_readIndex: // 下一个出列的元素在数组中的下标；</p></li><li><p>m_maximumReadIndex: // 这个值非常关键，表示最后一个已经完成入队列操作的元素在数组中的下标。如果它的值跟 m_writeIndex 不一致，表明有写请求尚未完成。这意味着，有写请求成功申请了空间但数据还没完全写进队列。所以如果有线程要读取，必须要等到写线程将数据完全写入到队列之后。</p></li></ul><p>以上三种不同的下标都是必须的，因为队列允许任意数量的生产者和消费者围绕着它工作。已经存在一种基于循环数组的无锁队列，使得唯一的生产者和唯一的消费者可以良好的工作。它的实现相当简洁非常值得阅读。该程序使用 gcc 内置的__sync_bool_compare_and_swap，但重新做了宏定义封装。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> CAS(a_ptr, a_oldVal, a_newVal) __sync_bool_compare_and_swap(a_ptr, a_oldVal, a_newVal)  </span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/d8950b94a92bcf233f29192e4c4d306c.jpeg" alt=""></p><p>队列已满判断：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(m_writeIndex+<span class="number">1</span>) % Q_SIZE == m_readIndex  </span><br></pre></td></tr></table></figure><p>对应代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">countToIndex(currentWriteIndex + <span class="number">1</span>) == countToIndex(currentReadIndex)  </span><br></pre></td></tr></table></figure><p>队列为空判断：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">m_readIndex == m_maximumReadIndex</span><br></pre></td></tr></table></figure><p>该 RingBuffer 的重点主要是以下四个方面的问题：</p><p>1、多线程写入的时候，m_writeIndex 如何更新?</p><p>2、m_maximumReadIndex 这个变量为什么会需要？它有什么作用？</p><p>3、多线程读的恶时候，m_readIndex 如何更新？</p><p>4、m_maximumReadIndex 在什么时候改变？</p><h5 id="4-2-enqueue-入队列"><a href="#4-2-enqueue-入队列" class="headerlink" title="4.2 enqueue 入队列"></a>4.2 enqueue 入队列</h5><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">template &lt;typename ELEM_T, QUEUE_INT Q_SIZE&gt;  </span><br><span class="line"><span class="type">bool</span> ArrayLockFreeQueue&lt;ELEM_T, Q_SIZE&gt;::enqueue(<span class="type">const</span> ELEM_T &amp;a_data) &#123;  </span><br><span class="line">    QUEUE_INT currentWriteIndex;        <span class="comment">// 获取写指针的位置  </span></span><br><span class="line">    QUEUE_INT currentReadIndex;  </span><br><span class="line">    <span class="comment">// 1. 获取可写入的位置  </span></span><br><span class="line">    <span class="keyword">do</span>  </span><br><span class="line">    &#123;  </span><br><span class="line">        currentWriteIndex = m_writeIndex;  </span><br><span class="line">        currentReadIndex = m_readIndex;  </span><br><span class="line">        <span class="keyword">if</span>(countToIndex(currentWriteIndex + <span class="number">1</span>) ==  </span><br><span class="line">            countToIndex(currentReadIndex))  </span><br><span class="line">        &#123;  </span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;   <span class="comment">// 队列已经满了  </span></span><br><span class="line">        &#125;  </span><br><span class="line">        <span class="comment">// 目的是为了获取一个能写入的位置  </span></span><br><span class="line">    &#125; <span class="keyword">while</span>(!CAS(&amp;m_writeIndex, currentWriteIndex, (currentWriteIndex+<span class="number">1</span>)));  </span><br><span class="line">    <span class="comment">// 获取写入位置后 currentWriteIndex 是一个临时变量，保存我们写入的位置  </span></span><br><span class="line">    <span class="comment">// We know now that this index is reserved for us. Use it to save the data  </span></span><br><span class="line">    m_thequeue[countToIndex(currentWriteIndex)] = a_data;  <span class="comment">// 把数据更新到对应的位置  </span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 2. 更新可读的位置，按着m_maximumReadIndex+1的操作  </span></span><br><span class="line">    <span class="comment">// update the maximum read index after saving the data. It wouldn&#x27;t fail if there is only one thread  </span></span><br><span class="line">    <span class="comment">// inserting in the queue. It might fail if there are more than 1 producer threads because this  </span></span><br><span class="line">    <span class="comment">// operation has to be done in the same order as the previous CAS  </span></span><br><span class="line">    <span class="keyword">while</span>(!CAS(&amp;m_maximumReadIndex, currentWriteIndex, (currentWriteIndex + <span class="number">1</span>)))  </span><br><span class="line">    &#123;  </span><br><span class="line">         <span class="comment">// this is a good place to yield the thread in case there are more  </span></span><br><span class="line">        <span class="comment">// software threads than hardware processors and you have more  </span></span><br><span class="line">        <span class="comment">// than 1 producer thread  </span></span><br><span class="line">        <span class="comment">// have a look at sched_yield (POSIX.1b)  </span></span><br><span class="line">        sched_yield();      <span class="comment">// 当线程超过cpu核数的时候如果不让出cpu导致一直循环在此。  </span></span><br><span class="line">    &#125;  </span><br><span class="line"> </span><br><span class="line">    AtomicAdd(&amp;m_count, <span class="number">1</span>);  </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;  </span><br><span class="line"> </span><br><span class="line">&#125;  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>图示（非常重要）：</p><p>以下插图展示了对队列执行操作时各个下标时如何变化的。如果一个位置被标记为 X，表示这个位置里面存放了数据。空白表示位置是空的。对于下图的情况，队列中存放了两个元素。WriteIndex 指示的位置是新元素将会被插入的位置。ReadIndex 指向的位置中的元素将会在下一次 pop 操作中被弹出。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/598e27110c2d1c56f1c2b2e4447e442d.jpeg" alt=""></p><p>当生产者准备将数据插入到队列中时，它首先通过增加 WriteIndex 的值来申请空间。MaximumReadIndex 指向最后一个存放有效数据的位置（也就是实际的读的队列尾）。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/1e59f606860004f76521a2e09505d888.jpeg" alt=""></p><p>一旦空间的申请完成，生产者就可以将数据拷贝到刚刚申请的位置中。完成之后增加 MaximumReadIndex 使得它与 WriteIndex 一致。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/93825b87f77c8c20cd58f0044080309a.jpeg" alt=""></p><p>现在队列中有 3 个元素，接着又有一个生产者尝试向队列中插入元素。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/eb677ecad74451051f93e3cac0255580.jpeg" alt=""></p><p>在第一个生产者完成数据拷贝之前，又有另外一个生产者申请了一个新的空间准备拷贝元素。现在有两个生产者同时向队列插入数据。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/822881ff0e0f71ae00f1dd7e3c51d138.jpeg" alt=""></p><p>现在生产者开始拷贝数据，在完成拷贝之后，对 MaximumReadIndex 的递增操作必须严格遵循一个顺序：第一个生产者线程首先递增 MaximumReadIndex，接着才轮到第二个生产者。这个顺序必须被严格遵守的原因是，我们必须保证数据被完全拷贝到队列之后才允许消费者线程将其出列。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">while(!CAS(&amp;m_maximumReadIndex, currentWriteIndex, (currentWriteIndex + 1))&#123;  </span><br><span class="line">sched_yield();      // 当线程超过cpu核数的时候如果不让出cpu导致一直循环在此。  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/dfc114a5343019f9c7e9f593818e5d6b.jpeg" alt=""></p><p>第一个生产者完成了数据拷贝，并对 MaximumReadIndex 完成了递增，现在第二个生产者可以递增 MaximumReadIndex 了。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/b389235fe59539b240294fceb22c0ea1.jpeg" alt=""></p><p>第二个生产者完成了对 MaximumReadIndex 的递增，现在队列中有 5 个元素。</p><h5 id="4-3-dequeue-出队列"><a href="#4-3-dequeue-出队列" class="headerlink" title="4.3 dequeue 出队列"></a>4.3 dequeue 出队列</h5><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">template &lt;typename ELEM_T, QUEUE_INT Q_SIZE&gt;  </span><br><span class="line"><span class="type">bool</span> ArrayLockFreeQueue&lt;ELEM_T, Q_SIZE&gt;::dequeue(ELEM_T &amp;a_data) &#123;  </span><br><span class="line">    QUEUE_INT currentMaximumReadIndex;  </span><br><span class="line">    QUEUE_INT currentReadIndex;  </span><br><span class="line">   </span><br><span class="line">    <span class="keyword">do</span>  </span><br><span class="line">    &#123;  </span><br><span class="line">         <span class="comment">// to ensure thread-safety when there is more than 1 producer thread  </span></span><br><span class="line">        <span class="comment">// a second index is defined (m_maximumReadIndex)  </span></span><br><span class="line">        currentReadIndex = m_readIndex;  </span><br><span class="line">        currentMaximumReadIndex = m_maximumReadIndex;  </span><br><span class="line">   </span><br><span class="line">        <span class="keyword">if</span>(countToIndex(currentReadIndex) ==  </span><br><span class="line">            countToIndex(currentMaximumReadIndex))      <span class="comment">// 如果不为空，获取到读索引的位置  </span></span><br><span class="line">        &#123;  </span><br><span class="line">            <span class="comment">// the queue is empty or  </span></span><br><span class="line">            <span class="comment">// a producer thread has allocate space in the queue but is  </span></span><br><span class="line">            <span class="comment">// waiting to commit the data into it  </span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;  </span><br><span class="line">        &#125;  </span><br><span class="line">        <span class="comment">// retrieve the data from the queue  </span></span><br><span class="line">        a_data = m_thequeue[countToIndex(currentReadIndex)]; <span class="comment">// 从临时位置读取的  </span></span><br><span class="line">   </span><br><span class="line">        <span class="comment">// try to perfrom now the CAS operation on the read index. If we succeed  </span></span><br><span class="line">        <span class="comment">// a_data already contains what m_readIndex pointed to before we  </span></span><br><span class="line">        <span class="comment">// increased it  </span></span><br><span class="line">        <span class="keyword">if</span>(CAS(&amp;m_readIndex, currentReadIndex, (currentReadIndex + <span class="number">1</span>)))  </span><br><span class="line">        &#123;  </span><br><span class="line">            AtomicSub(&amp;m_count, <span class="number">1</span>); <span class="comment">// 真正读取到了数据，元素-1  </span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125; <span class="keyword">while</span>(<span class="literal">true</span>);  </span><br><span class="line">   </span><br><span class="line">    assert(<span class="number">0</span>);  </span><br><span class="line">     <span class="comment">// Add this return statement to avoid compiler warnings  </span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;  </span><br><span class="line"></span><br><span class="line">&#125;  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>以下插入展示了元素出列的时候各种下标是如何变化的，队列中初始有 2 个元素。WriteIndex 指示的位置是新元素将会被插入的位置。ReadIndex 指向的位置中的元素将会在下一次 pop 操作中被弹出。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9ce2f3c4508a2d2e911f83bdae754d00.jpeg" alt=""></p><p>消费者线程拷贝数组 ReadIndex 位置的元素，然后尝试 CAS 操作将 ReadIndex 加 1.如果操作成功消费者成功地将数据出列。因为 CAS 操作是原子的，所以只有唯一的线程可以在同一时刻更新 ReadIndex 的值。</p><p>如果操作失败，读取新的 ReadIndex 的值，重复以上操作(copy 数据，CAS)。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/29fd7cb51d74d66bf56136f01ba6b265.jpeg" alt=""></p><p>现在又有一个消费者将元素出列，队列变成空。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/733a4637cd48fb05bd7a415e06af8837.jpeg" alt=""></p><p>现在有一个生产者正在向队列中添加元素。它已经成功的申请了空间，但尚未完成数据拷贝。任何其他企图从队列中移除元素的消费者都会发现队列非空(因为 writeIndex 不等于 readIndex)。但它不能读取 readIndex 所指向位置中的数据，因为 readIndex 与 MaximumReadIndex 相等。这个时候读数据失败，需要等到生产者完成数据拷贝增加 MaximumReadIndex 的值才可以读。</p><p>当生产者完成数据拷贝，队列的大小是 1，消费者线程就可以读取这个数据了。</p><h5 id="4-4-yielding-处理器的必要性"><a href="#4-4-yielding-处理器的必要性" class="headerlink" title="4.4 yielding 处理器的必要性"></a>4.4 yielding 处理器的必要性</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">while(!CAS(&amp;m_maximumReadIndex, currentWriteIndex, (currentWriteIndex + 1))) &#123;  </span><br><span class="line">    // this is a good place to yield the thread in case there are more  </span><br><span class="line">    // software threads than hardware processors and you have more  </span><br><span class="line">    // than 1 producer thread  </span><br><span class="line">    // have a look at sched_yield (POSIX.1b)  </span><br><span class="line">    sched_yield();      // 当线程超过cpu核数的时候如果不让出cpu导致一直循环在此。  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 enqueue 的第二个 CAS 里面有一个 sched_yield()来主动让出处理器的操作，对于一个声称无锁的算法而言，这个调用看起来有点儿奇怪。多线程环境下影响性能的其中一个因素就是 Cache 损坏。而产生 Cache 损坏的一种情况就是一个线程被抢占，操作系统需要保存被抢占线程的上下文，然后被选中作为下一个调度线程的上下文载入。此时 Cache 中缓存的数据都会失效，因为它是被抢占线程的数据而不是新线程的数据。</p><p>无锁算法和通过阻塞机制同步的算法的一个主要区别在于无锁算法不会阻塞在线程同步上。那这里的让出 CPU，与阻塞在线程同步上有啥区别？为什么不直接自旋？</p><p>首先说下 sched_yield 的必要性：sched_yield 的调用与有多少个生产者线程在并发地往队列中存放数据有关：每个生产者线程所执行的 CAS 操作都必须严格遵循 FIFO 次序,一个用于申请空间,另一个用于通知消费者数据已经写入完成可以被读取了.如果我们的应用程序只有唯一的生产者这个操作队列，sched_yield 将永远没有机会被调用，因为 enqueue 的第二个 CAS 操作永远不会失败。因为一个生产者的情况下没人能破坏生产者执行这两个 CAS 操作的 FIFO 顺序。</p><p>而对于多个生产者线程往队列中存放数据的时候，问题就出现了。概括来说，一个生产者通过第 1 个 CAS 操作申请空间,然后将数据写入到申请到的空间中,然后执行第 2 个 CAS 操作通知消费者数据准备完毕可供读取了.这第 2 个 CAS 操作必须遵循 FIFO 顺序,也就是说,如果 A 线程第首先执行完第一个 CAS 操作,那么它也要第 1 个执行完第 2 个 CAS 操作,如果 A 线程在执行完第一个 CAS 操作之后停止,然后 B 线程执行完第 1 个 CAS 操作,那么 B 线程将无法完成第 2 个 CAS 操作,因为它要等待 A 先完成第 2 个 CAS 操作.而这就是问题产生的根源.让我们考虑如下场景,3 个消费者线程和 1 个消费者线程:</p><ol><li><p>线程 1,2,3 按顺序调用第 1 个 CAS 操作申请了空间.那么它们完成第 2 个 CAS 操作的顺序也应该与这个顺序一致,1,2,3；</p></li><li><p>线程 2 首先尝试执行第 2 个 CAS,但它会失败,因为线程 1 还没完成它的第 2 此 CAS 操作呢.同样对于线程 3 也是一样的；</p></li><li><p>线程 2 和 3 将会不断的调用它们的第 2 个 CAS 操作,直到线程 1 完成它的第 2 个 CAS 操作为止；</p></li><li><p>线程 1 最终完成了它的第 2 个 CAS,现在线程 3 必须等线程 2 先完成它的第 2 个 CAS；</p></li><li><p>线程 2 也完成了,最终线程 3 也完成。</p></li></ol><p>在上面的场景中,生产者可能会在第 2 个 CAS 操作上自旋一段时间,用于等待先于它执行第 1 个 CAS 操作的线程完成它的第 2 次 CAS 操作.在一个物理处理器数量大于操作队列线程数量的系统上,这不会有太严重的问题:因为每个线程都可以分配在自己的处理器上执行,它们最终都会很快完成各自的第 2 次 CAS 操作.虽然算法导致线程处理忙等状态,但这正是我们所期望的,因为这使得操作更快的完成.也就是说在这种情况下我们是不需要 sche_yield()的,它完全可以从代码中删除。</p><p>但是,在一个物理处理器数量少于线程数量的系统上,sche_yield()就变得至关重要了.让我们再次考查上面 3 个线程的场景,当线程 3 准备向队列中插入数据:如果线程 1 在执行完第 1 个 CAS 操作,在执行第 2 个 CAS 操作之前被抢占,那么线程 2,3 就会一直在它们的第 2 个 CAS 操作上忙等(它们忙等,不让出处理器,线程 1 也就没机会执行,它们就只能继续忙等),直到线程 1 重新被唤醒,完成它的第 2 个 CAS 操作。这就是需要 sche_yield()的场合了,操作系统应该避免让线程 2,3 处于忙等状态.它们应该尽快的让出处理器让线程 1 执行,使得线程 1 可以把它的第 2 个 CAS 操作完成.这样线程 2 和 3 才能继续完成它们的操作。</p><p>也就是说，如果不适用 sched_yield，一直自旋，那么可能多个线程同时阻塞在第二个 CAS 那儿。</p><h5 id="4-5-多读多写的-RingBuffer-存在的问题"><a href="#4-5-多读多写的-RingBuffer-存在的问题" class="headerlink" title="4.5 多读多写的 RingBuffer 存在的问题"></a><strong>4.5</strong> 多读多写的 RingBuffer 存在的问题</h5><p>1、多于一个生产者线程性能提升不明显</p><p>如果有多于一个的生产者线程,那么将它们很可能花费大量的时间用于等待更新 MaximumReadIndex(第 2 个 CAS).这个队列最初的设计场景是满足单一消费者,所以不用怀疑在多生产者的情形下会比单一生产者有大幅的性能下降。</p><p>另外如果你只打算将此队列用于单一生产者的场合,那么第 2 个 CAS 操作可以去除.同样 m_maximumReadIndex 也可以一同被移除了,所有对 m_maximumReadIndex 的引用都改成 m_writeIndex.所以,在这样的场合下 push 和 pop 可以被改写如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">template &lt;typename ELEM_T&gt;  </span><br><span class="line"><span class="type">bool</span> ArrayLockFreeQueue&lt;ELEM_T&gt;::push(<span class="type">const</span> ELEM_T &amp;a_data) &#123;  </span><br><span class="line">    <span class="type">uint32_t</span> currentReadIndex;  </span><br><span class="line">    <span class="type">uint32_t</span> currentWriteIndex;  </span><br><span class="line"></span><br><span class="line">    currentWriteIndex = m_writeIndex;  </span><br><span class="line">    currentReadIndex  = m_readIndex;  </span><br><span class="line">    <span class="keyword">if</span> (countToIndex(currentWriteIndex + <span class="number">1</span>) ==  </span><br><span class="line">        countToIndex(currentReadIndex)) &#123;  </span><br><span class="line">        <span class="comment">// the queue is full  </span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line"></span><br><span class="line">    <span class="comment">// save the date into the q  </span></span><br><span class="line">    m_theQueue[countToIndex(currentWriteIndex)] = a_data;  </span><br><span class="line"></span><br><span class="line">    <span class="comment">// increment atomically write index. Now a consumer thread can read  </span></span><br><span class="line">    <span class="comment">// the piece of data that was just stored  </span></span><br><span class="line">    AtomicAdd(&amp;m_writeIndex, <span class="number">1</span>);  </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">template &lt;typename ELEM_T&gt;  </span><br><span class="line"><span class="type">bool</span> ArrayLockFreeQueue&lt;ELEM_T&gt;::pop(ELEM_T &amp;a_data) &#123;  </span><br><span class="line">    <span class="type">uint32_t</span> currentMaximumReadIndex;  </span><br><span class="line">    <span class="type">uint32_t</span> currentReadIndex;  </span><br><span class="line">    <span class="keyword">do</span> &#123;  </span><br><span class="line">        <span class="comment">// m_maximumReadIndex doesn&#x27;t exist when the queue is set up as  </span></span><br><span class="line">        <span class="comment">// single-producer. The maximum read index is described by the current  </span></span><br><span class="line">        <span class="comment">// write index  </span></span><br><span class="line">        currentReadIndex        = m_readIndex;  </span><br><span class="line">        currentMaximumReadIndex = m_writeIndex;  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> (countToIndex(currentReadIndex) ==  </span><br><span class="line">            countToIndex(currentMaximumReadIndex)) &#123;  </span><br><span class="line">            <span class="comment">// the queue is empty or  </span></span><br><span class="line">            <span class="comment">// a producer thread has allocate space in the queue but is  </span></span><br><span class="line">            <span class="comment">// waiting to commit the data into it  </span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">// retrieve the data from the queue  </span></span><br><span class="line">        a_data = m_theQueue[countToIndex(currentReadIndex)];  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">// try to perfrom now the CAS operation on the read index. If we succeed  </span></span><br><span class="line">        <span class="comment">// a_data already contains what m_readIndex pointed to before we  </span></span><br><span class="line">        <span class="comment">// increased it  </span></span><br><span class="line">        <span class="keyword">if</span> (CAS(&amp;m_readIndex, currentReadIndex, (currentReadIndex + <span class="number">1</span>)))  </span><br><span class="line">        &#123;  </span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">// it failed retrieving the element off the queue. Someone else must  </span></span><br><span class="line">        <span class="comment">// have read the element stored at countToIndex(currentReadIndex)  </span></span><br><span class="line">        <span class="comment">// before we could perform the CAS operation  </span></span><br><span class="line">  </span><br><span class="line">    &#125; <span class="keyword">while</span>(<span class="number">1</span>); <span class="comment">// keep looping to try again!  </span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Something went wrong. it shouldn&#x27;t be possible to reach here  </span></span><br><span class="line">    assert(<span class="number">0</span>);  </span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Add this return statement to avoid compiler warnings  </span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>但是如果是单读单写的场景，没有必要用这个无锁队列，可以看以上单读单写的无锁队列。</p><p><strong>2、与智能指针一起使用，内存无法得到释放</strong></p><p>如果你打算用这个队列来存放智能指针对象.需要注意,将一个智能指针存入队列之后,如果它所占用的位置没有被另一个智能指针覆盖,那么它所指向的内存是无法被释放的(因为它的引用计数器无法下降为 0).这对于一个操作频繁的队列来说没有什么问题,但是程序员需要注意的是,一旦队列被填满过一次那么应用程序所占用的内存就不会下降,即使队列被清空.除非自己做改动，每次 pop 手动 delete。</p><p><strong>3、计算队列的大小存在 ABA 问题</strong></p><p>size 函数可能会返回一个不正确的值,size 的实现如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">template &lt;typename ELEM_T&gt;  </span><br><span class="line"><span class="keyword">inline</span> <span class="type">uint32_t</span> ArrayLockFreeQueue&lt;ELEM_T&gt;::size() &#123;  </span><br><span class="line">    <span class="type">uint32_t</span> currentWriteIndex = m_writeIndex;  </span><br><span class="line">    <span class="type">uint32_t</span> currentReadIndex  = m_readIndex;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> (currentWriteIndex &gt;= currentReadIndex) &#123;  </span><br><span class="line">        <span class="keyword">return</span> (currentWriteIndex - currentReadIndex);  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="keyword">else</span> &#123;  </span><br><span class="line">        <span class="keyword">return</span> (m_totalSize + currentWriteIndex - currentReadIndex);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure><p>下面的场景描述了 size 为何会返回一个不正确的值:</p><ol><li><p>当 currentWriteIndex = m_writeIndex 执行之后,m_writeIndex=3,m_readIndex = 2 那么实际 size 是 1；</p></li><li><p>之后操作线程被抢占,且在它停止运行的这段时间内,有 2 个元素被插入和从队列中移除。所以 m_writeIndex=5,m_readIndex = 4,而 size 还是 1；</p></li><li><p>现在被抢占的线程恢复执行,读取 m_readIndex 值,这个时候 currentReadIndex=4,currentWriteIndex=3；</p></li><li><p>currentReadIndex &gt; currentWriteIndex’所以 m_totalSize + currentWriteIndex - currentReadIndex`被返回,这个值意味着队列几乎是满的,而实际上队列几乎是空的。</p></li></ol><p>实际上也就是 ABA 的一个场景。与本文一起上传的代码中包含了处理这个问题的解决方案。</p><p>解决方案：添加一个用于保存队列中元素数量的成员 count.这个成员可以通过 AtomicAdd/AtomicSub 来实现原子的递增和递减。</p><p>但需要注意的是这增加了一定开销,因为原子递增,递减操作比较昂贵也很难被编译器优化。</p><p>例如,在 core 2 duo E6400 2.13 Ghz 的机器上,单生产者单消费者,队列数组的初始大小是 1000,测试执行 10,000k 次的插入,没有 count 成员的版本用时 2.64 秒,而维护了 count 成员的版本用时 3.42 秒.而对于 2 消费者,1 生产者的情况,没有 count 成员的版本用时 3.98 秒,维护 count 的版本用时 5.15 秒。</p><p>这也就是为什么我把是否启用此成员变量的选择交给实际的使用者.使用者可以根据自己的使用场合选择是否承受额外的运行时开销。</p><p>在 array_lock_free_queue.h 中有一个名为 ARRAY_LOCK_FREE_Q_KEEP_REAL_SIZE 的宏变量,如果它被定义那么将启用 count 变量,否则将 size 函数将有可能返回不正确的值。</p><h5 id="4-6-多读多写-RingBuffer-的性能"><a href="#4-6-多读多写-RingBuffer-的性能" class="headerlink" title="4.6 多读多写 RingBuffer 的性能"></a><strong>4.6</strong> 多读多写 RingBuffer 的性能</h5><p><strong>无锁</strong> <strong>vs</strong> <strong>阻塞队列</strong></p><p>并发的插入和移除 100W 元素所花费的时间(越小越好,队列的数组大小初始为 16384)。在单生产者的情况下,无锁队列战胜了阻塞队列.而随着生产者数量的增加,无锁队列的效率迅速下降。因为在多个生产者的情况下，第 2 个 CAS 将对性能产生影响。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/3f29ccc3f38a37b777c2101b5737ae91.jpeg" alt=""></p><p>然后我们来看代码中的情况：</p><p>再来看看消费者线程数量对性能的影响。</p><p>1、一个生产者线程</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/ab7d2f8a751d17975a19d6c6c5d4ba32.jpeg" alt=""></p><p>2、两个生产者</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/efe92c22f2657d0966fc5e413cc49813.jpeg" alt=""></p><p>3、三个生产者</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/684427c77dfd1b078f03c91718b908ba.jpeg" alt=""></p><h5 id="4-7-RingBuffer-结论"><a href="#4-7-RingBuffer-结论" class="headerlink" title="4.7 RingBuffer 结论"></a>4.7 RingBuffer 结论</h5><p>1、CAS 操作是原子的，线程并行执行 push/pop 不会导致死锁；</p><p>2、多生产者同时向队列 push 数据的时候不会将数据写入到同一个位置,产生数据覆盖；</p><p>3、多消费者同时执行 pop 不会导致一个元素被出列多于 1 次；</p><p>4、线程不能将数据 push 进已经满的队列中,不能从空的队列中 pop 元素；</p><p>5、push 和 pop 都没有 ABA 问题。</p><p>但是，虽然这个队列是线程安全的,但是在多生产者线程的环境下它的性能还是不如阻塞队列.因此,在符合下述条件的情况下可以考虑使用这个队列来代替阻塞队列:</p><p>1、只有一个生产者线程；</p><p>2、只有一个频繁操作队列的生产者,但偶尔会有其它生产者向队列 push 数据；</p><p>在 reactor 网络框架中，如果只有一个 reactor 在处理 client 的话，用数组实现的 RingBuffer 来存储消息是比较合适的。</p><h5 id="4-8-四种线程安全队列实现性能对比"><a href="#4-8-四种线程安全队列实现性能对比" class="headerlink" title="4.8 四种线程安全队列实现性能对比"></a>4.8 四种线程安全队列实现性能对比</h5><p>互斥锁队列 vs 互斥锁+条件变量队列 vs 内存屏障链表 vs RingBuffer CAS 实现。</p><h5 id="1、4-写-1-读"><a href="#1、4-写-1-读" class="headerlink" title="1、4 写 1 读"></a>1、4 写 1 读</h5><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/f685973c7103b3f66e733a6d5cfd33df.jpeg" alt=""></p><h5 id="2、4-写-4-读"><a href="#2、4-写-4-读" class="headerlink" title="2、4 写 4 读"></a>2、4 写 4 读</h5><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/d30d3cd79667ed4144867d8a4e02645b.jpeg" alt=""></p><h5 id="3、1-写-4-读"><a href="#3、1-写-4-读" class="headerlink" title="3、1 写 4 读"></a>3、1 写 4 读</h5><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/3564ee3bbb46513d96f9193d55cbf2a9.jpeg" alt=""></p><p>可以发现 RingBuffer 的实现性能在几个场景中都是比较好的，但是相对而言，在 1 写 4 读的场景下性能是最明显的，几乎是内存屏障的 3 倍性能了。</p><p>为什么链表的方式性能相对 BlockQueue 没有很大的提升呢？</p><p>1、链表的方式需要不断的申请和释放元素。当然，用内存池可以适当改善这个影响，但是内存池在分配内存与释放内存的时候也会涉及到线程间的数据竞争，所以用链表的方式性能相对提升不多。</p><p>入队：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">template &lt;typename U&gt;  </span><br><span class="line"><span class="keyword">inline</span> <span class="type">bool</span> <span class="title function_">enqueue</span><span class="params">(U &amp;&amp;item)</span> &#123;  </span><br><span class="line">  <span class="type">idx_t</span> nodeIdx = allocate_node_for(<span class="built_in">std</span>::forward&lt;U&gt;(item));  </span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> tail_ = tail.load(<span class="built_in">std</span>::memory_order_relaxed);  </span><br><span class="line">  <span class="keyword">while</span> (!tail.compare_exchange_weak(tail_, nodeIdx, <span class="built_in">std</span>::memory_order_release, <span class="built_in">std</span>::memory_order_relaxed))  </span><br><span class="line">    <span class="keyword">continue</span>;  </span><br><span class="line">  get_node_at(tail_)-&gt;next.store(nodeIdx, <span class="built_in">std</span>::memory_order_release);  </span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;  </span><br><span class="line">&#125;  </span><br></pre></td></tr></table></figure><p>出队：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="type">bool</span> <span class="title function_">try_dequeue</span><span class="params">(T &amp;item)</span> &#123;  </span><br><span class="line">……</span><br><span class="line">  add_node_to_free_list(head_, headNode);  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>2、链表需要不断地去更新头节点和尾节点指针的位置，在一个 while 循环里面反复去执行：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (!tail.compare_exchange_weak(tail_, nodeIdx, <span class="built_in">std</span>::memory_order_release, <span class="built_in">std</span>::memory_order_relaxed))  </span><br><span class="line">  <span class="keyword">continue</span>;  </span><br></pre></td></tr></table></figure><p>参考：</p><p><a href="https://www.codeproject.com/Articles/43510/Lock-Free-Single-Producer-Single-Consumer-Circular">https://www.codeproject.com/Articles/43510/Lock-Free-Single-Producer-Single-Consumer-Circular</a></p><p><a href="https://zhuanlan.zhihu.com/p/33985732">https://zhuanlan.zhihu.com/p/33985732</a></p><p>本文转自 <a href="https://mp.weixin.qq.com/s/HdP5NcQIdzfznGwcHLTvMw">https://mp.weixin.qq.com/s/HdP5NcQIdzfznGwcHLTvMw</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>异步编程指北</title>
      <link href="/posts/44d9a313/"/>
      <url>/posts/44d9a313/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>作者：michaeywang，腾讯 IEG 运营开发工程师</p><blockquote><p>同步、异步，并发、并行、串行，这些名词在我们的开发中会经常遇到，这里对异步编程做一个详细的归纳总结，希望可以对这方面的开发有一些帮助。</p></blockquote><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/48fb28622736044e7313e0e5f065984b.jpeg" alt=""></p><h3 id="1-几个名词的概念"><a href="#1-几个名词的概念" class="headerlink" title="1 几个名词的概念"></a>1 几个名词的概念</h3><p>多任务的时候，才会遇到的情况，如：同步、异步，并发、并行。</p><h4 id="1-1-理清它们的基本概念"><a href="#1-1-理清它们的基本概念" class="headerlink" title="1.1 理清它们的基本概念"></a>1.1 理清它们的基本概念</h4><p>并发：多个任务在同一个时间段内同时执行，如果是单核心计算机，CPU 会不断地切换任务来完成并发操作。</p><p>并行：多任务在同一个时刻同时执行，计算机需要有多核心，每个核心独立执行一个任务，多个任务同时执行，不需要切换。</p><p>同步：多任务开始执行，任务 A、B、C 全部执行完成后才算是结束。</p><p>异步：多任务开始执行，只需要主任务 A 执行完成就算结束，主任务执行的时候，可以同时执行异步任务 B、C，主任务 A 可以不需要等待异步任务 B、C 的结果。</p><p>并发、并行，是逻辑结构的设计模式。</p><p>同步、异步，是逻辑调用方式。</p><p>串行是同步的一种实现，就是没有并发，所有任务一个一个执行完成。</p><p>并发、并行是异步的 2 种实现方式。</p><h4 id="1-2-举一个例子"><a href="#1-2-举一个例子" class="headerlink" title="1.2 举一个例子"></a>1.2 举一个例子</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9a90183fec78ee962cc64115ab54d5e1.jpeg" alt=""></p><p>你的朋友在广州，但是有 2 辆小汽车在深圳，需要你帮忙把这 2 辆小汽车送到广州去。</p><p>同步的方式，你先开一辆小汽车到广州，然后再坐火车回深圳，再开另外一辆小汽车去广州。这是串行的方法，2 辆车需要的时间也就更长了。</p><p>异步的方式，你开一辆小汽车从深圳去广州，同时请一个代驾把另外一辆小汽车从深圳开去广州。这也就是并行方法，两个人两辆车，可以同时行驶，速度很快。</p><p>并发的方式，你一个人，先开一辆车走 500 米，停车跑回来，再开另外一辆车前行 1000 米，停车再跑回来，循环从深圳往广州开。并发的方式，你可以把 2 辆车一块送到朋友手里，但是过程还是很辛苦的。</p><h4 id="1-3-思考问题"><a href="#1-3-思考问题" class="headerlink" title="1.3 思考问题"></a>1.3 思考问题</h4><p>你找一家汽车托运公司，把 2 辆车一起托运到广州。这种方式是同步、异步，并发、并行的哪种情况呢？</p><h3 id="2-并发-并行执行会遇到的问题"><a href="#2-并发-并行执行会遇到的问题" class="headerlink" title="2 并发/并行执行会遇到的问题"></a>2 并发/并行执行会遇到的问题</h3><h4 id="2-1-问题-1：并发的任务数量控制"><a href="#2-1-问题-1：并发的任务数量控制" class="headerlink" title="2.1 问题 1：并发的任务数量控制"></a>2.1 问题 1：并发的任务数量控制</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/2924a498e6072c453ef153b3b3fcf59f.jpeg" alt=""></p><p>假设：某个接口的并发请求会达到 1 万的 qps，所以对接口的性能、响应时长都要求很高。</p><p>接口内部又有大量 redis、mysql 数据读写，程序中还有很多处理逻辑。如果接口内的所有逻辑处理、数据调用都是串行化，那么单个请求耗时可能会超过 100ms，为了性能优化，就会把数据读取的部分与逻辑计算的部分分开来考虑和实现，能够独立的部分单独剥离出来作为异步任务来执行，这样就把串行化的耗时优化为并发执行，充分利用多核计算机的性能，减少单个接口请求的耗时。</p><p>假设的数据具体化，如：这个接口的数据全部是可以独立获取(支持并发)，需要读取来自不同数据结构的 redis 共 10 个，读取不同数据表的数据共 10 个。那么一次请求，数据获取就会启动 10 个 redis 读取任务，10 个 mysql 读取任务。每秒钟 1 万接口请求，会有 10 万个 redis 读取任务和 10 万个 mysql 读取任务。这 21 万的并发任务，在一秒钟内由 16/32 核的后端部署单机来完成，虽然在同一时刻的任务数量不一定会是 21 万(速度快的话会少于 21 万，如果处理速度慢，出现请求积压拥堵，会超过 21 万)。</p><p>这时候，会遇到的瓶颈。</p><p><strong>内存，如果每个任务需要 500k 内存，那么 210k*0.5M=210*0.5G=105G.</strong></p><p>CPU，任务调度，像 golang 的协程可能开销还小一些，如果是 java 的线程调度，操作系统会因为调度而空转。</p><p>网络，每次数据读取 5k，那么 200k_5k=200_5M=1G.</p><p><strong>端口，端口号最多能分配出来 65536 个，明显不够用了。</strong></p><p><strong>数据源，redis 可以支持 10 万 qps 的请求，但是 mysql 就难以支持 10 万 qps 了。</strong></p><p>上面可能出现的瓶颈中，通过计算机资源扩容可以解决大部分问题，比如：部署 50 个后端实例，每个实例只需要应对 200 的 qps，压力就小了很多。对于数据源，mysql 可以有多个 slave 来支持只读的请求。</p><p>但是，如果接口的并发量更大呢？或者某个/某些数据源读取出现异常，需要重试，或者出现拥堵，接口响应变慢，任务数量也就会出现暴增，后端服务的各方面瓶颈又会随之出现。</p><p>所以，我们需要特别注意和关心后端开启的异步任务数量，要做好异常情况的防范，及时中断掉拥堵/超时的任务，<strong>避免任务暴增导致整个服务不可用</strong>。</p><h4 id="2-2-思考问题"><a href="#2-2-思考问题" class="headerlink" title="2.2 思考问题"></a>2.2 思考问题</h4><p>你要如何应对这类并发任务暴增的情况呢？如何提前预防？如何及时干预呢？</p><h4 id="2-3-问题-2：共享数据的读写顺序和依赖关系"><a href="#2-3-问题-2：共享数据的读写顺序和依赖关系" class="headerlink" title="2.3 问题 2：共享数据的读写顺序和依赖关系"></a>2.3 问题 2：共享数据的读写顺序和依赖关系</h4><p>共享数据的并发读写，是并发编程中的老大难问题，如：读写脏数据，旧数据覆盖新数据等等。</p><p>而数据的依赖关系，也就决定了任务的执行先后顺序。</p><p>为了避免共享数据的竞争读写，为了保证任务的先后关系，就需要用到锁、队列等手段，这时候，并发的过程又被部分的拉平为串行化执行。</p><h4 id="2-4-举个例子"><a href="#2-4-举个例子" class="headerlink" title="2.4 举个例子"></a>2.4 举个例子</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/d3beaa4f4f6ed6b269e6676be3e9c182.jpeg" alt=""></p><p><a href="https://www.ticketmaster.com/eastern-conf-semis-tbd-at-boston-boston-massachusetts/event/01005C6AA5531A90">https://www.ticketmaster.com/eastern-conf-semis-tbd-at-boston-boston-massachusetts/event/01005C6AA5531A90</a></p><p>NBA 季后赛，去现场看球，要抢购球票，体育馆最多容纳 1 万人(1 万张球票)。</p><p>体育馆不同距离、不同位置的票，价格和优惠都不相同。有单人位、有双人位，也有 3、4 人位。你约着朋友共 10 个人去看球，要买票，要选位置。这时候抢票就会很尴尬，因为位置连着的可能会被别人抢走，同时买的票越多，与人冲突的概率就越大，会导致抢票特别困难。</p><p>同时，这个系统的开发也很头大，抢购(秒杀)的并发非常大，预计在开始的一秒钟会超过 10 万人同时进来，再加上刷票的机器人，接口请求量可能瞬间达到 100 万的 QPS。</p><p><strong>较简单的实现方式</strong>，所有的请求都异步执行，订单全部进入消息队列，下单马上响应处理中，请等待。然后，后端程序再从消息队列中串行化处理每一个订单，把出现冲突的订单直接报错，这样，估计 1 秒钟可以处理 1000 个订单，10 秒钟可以处理 1 万个订单。考虑订单的冲突问题，1 万张球票的 9000 张可能在 30 秒内卖出去，此时只处理了 3 万个订单，第一秒钟进来的 100 万订单已经在消息队列中堆积，又有 30 秒钟的新订单进来，需要很久才可以把剩下的 1000 张球票卖出去啊。同理，下单的用户需要等待太久才知道自己的订单结果，这个过程轮询的请求也会很多很多。</p><p><strong>换一种方案，不使用队列串行化处理订单</strong>，直接并发的处理每一个订单。那么处理流程中的数据都需要梳理清楚。</p><p>1 针对每一个用户的请求加锁，避免同一个用户的重入；</p><p>2 每一个/组座位预生成一个 key:0，默认 0 说明没有下单；</p><p>3 预估平均每一个订单包含 2 个/组座位，需要更新 2 个座位 key；</p><p>4 下单的时候给座位 key 执行 INCR key 数字递增操作，只有返回 1 的订单才是成功，其他都是失败；</p><p>5 如果同一个订单中的座位 key 有冲突的情况下，需要回滚成功 key(INCR key = 1)重置(SET key 0);</p><p>6 订单成功/失败，处理完成后，去掉用户的请求锁；</p><p>7 订单数据入库到 mysql(消息队列，避免 mysql 成为瓶颈);</p><p>综上，需要用到 1 个锁(2 次操作)，平均 2 个座位 key(每个座位号 1-2 次操作)，这里只有 2 个座位 key 可以并发更新。为了让 redis 不成为数据读写的瓶颈(超过 100w 的 QPS 写操作)，不能使用单实例模式，而要使用 redis 集群，使用由 10-20 个 redis 实例组成的集群，来支持这么高的 redis 数据读写。</p><p>算上 redis 数据读写、参数、异常、逻辑处理，一个请求大概耗时 10ms 左右，单核至少可以支持 100 并发，由于这里有大量 IO 处理，后端服务可以支持的并发可以更高些，预计单核 200 并发，16 核就可以支持 3200 并发。总共需要支持 100 万并发，预计需要 312 台后端服务器。</p><p>这种方案比队列的方案需要的服务器资源更多，但是用户的等待时间很短，体验就好很多。</p><h4 id="2-5-思考问题"><a href="#2-5-思考问题" class="headerlink" title="2.5 思考问题"></a>2.5 思考问题</h4><p>实际情况会是怎样呢？会有 10 万人同时抢票吗？会有 100 万的超高并发吗？订票系统真的会准备 300 多台服务器来应对抢票吗？</p><h3 id="3-状态处理：忽略结果"><a href="#3-状态处理：忽略结果" class="headerlink" title="3 状态处理：忽略结果"></a>3 状态处理：忽略结果</h3><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/aab305517b9d3b77ce7b31a52d1d5f8e.jpeg" alt=""></p><h4 id="3-1-使用场景和案例"><a href="#3-1-使用场景和案例" class="headerlink" title="3.1 使用场景和案例"></a>3.1 使用场景和案例</h4><p>使用场景，主流程之外的异步任务，可能重要程度不高，或者处理的复杂度太高，有时候会忽略异步任务的处理结果。</p><p>案例 1：异步的数据上报、数据存储/计算/统计/分析。</p><p>案例 2：模板化创建服务，有很多个任务，有前后关联任务，也有相互独立任务，有些执行速度很慢，有些任务失败后也可以手动重试来修复。</p><p>忽略结果的情况，就会遇到下面的问题。</p><h4 id="3-2-问题-1：数据一致性"><a href="#3-2-问题-1：数据一致性" class="headerlink" title="3.2 问题 1：数据一致性"></a>3.2 问题 1：数据一致性</h4><p>看下案例 1 的情况。</p><p>异步的日志上报，是否成功发送到服务端呢？</p><p>异步的指标数据上报，是否正确汇总统计和发送到服务端呢？</p><p>异步的任务，数据发送到消息队列，是否被后端应用程序消费呢？</p><p>服务端是否正常存储和处理完成呢？</p><p>如果因为网络原因，因为并发量太大导致服务负载问题，因为程序 bug 的原因，导致数据没能正确上报和处理，这时候的数据不一致、丢失的问题，就会难以及时排查和事后补发。</p><p>如果在本地完整记录一份数据，以备数据审查，又要考虑高并发高性能的瓶颈，毕竟本地日志读写性能受到磁盘速度的影响，性能会很差。</p><h4 id="3-3-问题-2：功能可靠性"><a href="#3-3-问题-2：功能可靠性" class="headerlink" title="3.3 问题 2：功能可靠性"></a>3.3 问题 2：功能可靠性</h4><p>看下案例 2 的情况。</p><p>创建服务的过程中，有创建代码仓库、开启日志采集和自定义镜像中心，CI/CD 等耗时很长的任务。这里开启日志采集和自定义镜像中心如果出现异常，对整个服务的运行没有影响，而且开发者发现问题后也可以自己手动操作下，再次开启日志采集和自定义镜像功能。所以在模板化处理中，这些异步处理任务就没有关注任务的状态。</p><p>那么问题就很明显，模板化创建服务的过程中，是不能保证全部功能都正常执行完成的，会有部分功能可能有异常，而且也没有提示和后续指引。</p><p>当然模板化创建服务的程序，也可以把全部任务的状态都检查结果，只是会增加一些处理的复杂度和难度。</p><h4 id="3-4-思考问题"><a href="#3-4-思考问题" class="headerlink" title="3.4 思考问题"></a>3.4 思考问题</h4><p>实际开发中，有遇到类似上面的两个案例吗？你会如何处理呢？所有的异步任务，都会检查状态结果吗？为什么呢？</p><h3 id="4-状态处理：结果返回"><a href="#4-状态处理：结果返回" class="headerlink" title="4 状态处理：结果返回"></a>4 状态处理：结果返回</h3><h4 id="4-1-使用场景和案例"><a href="#4-1-使用场景和案例" class="headerlink" title="4.1 使用场景和案例"></a>4.1 使用场景和案例</h4><p>大部分的异步任务对于状态结果还是很关注的，比如：后续的处理逻辑或者任务依赖某个异步任务，或者异步任务非常重要，需要把结果返回给请求方。</p><p>案例 1：模板化创建服务的过程中，需要异步创建服务的 git 代码仓库，还要给仓库添加成员、webhook、初始化代码等。整个过程全部串行化作为一个任务的话，耗时会比较长。可以把创建服务的 git 代码仓库作为一个异步任务，然后得到成功的结果后再异步的发起添加成员、加 webhook、初始化代码等任务。同时，这里的 CI/CD 有配置相关，有执行相关，整个过程也很长，CD 部署成功之后才可以开启日志采集等配置，所以也需要关注 CD 部署的结果。</p><p>案例 2：各种 webhook、callback 接口和方法，就是基于回调的方式，如：golang 中的 channel 通知，工蜂中的代码 push 等 webhook，监控告警中的 callback 等。</p><p>案例 3：发布订阅模式，如引入消息队列服务，主程序把数据发送给消息队列，异步任务订阅相应的主题然后处理。处理完成后也可以把结果再发送给消息队列，或者把结果发送给主调程序的接口，或者等待主调程序来查询结果，当然也可能是上面的忽略结果的情况。</p><p>从上可以总结出来，对于异步任务的状态处理，需要关注结果的话，有两种主要的方法，分别是：轮询查询和等待回调。</p><h4 id="4-2-方法-1：轮询查询"><a href="#4-2-方法-1：轮询查询" class="headerlink" title="4.2 方法 1：轮询查询"></a>4.2 方法 1：轮询查询</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/f4c4e677e34758ad92cd7ddecc635d1e.jpeg" alt=""></p><p>上面的案例 1 中，模板化创建服务的过程很慢，所以整个功能都是异步的，用户大概要等待 10s 左右才知道最后的结果。所以，用户在创建服务之后，浏览器会不断轮询服务端接口，看看创建服务的结果，各个步骤的处理结果，服务配置是否都成功完成了。</p><p>类似的功能实现应该有很多，比如：服务构建、部署、创建镜像仓库、抢购买票等，把任务执行和任务结果通过异步的方式强制分离开，用户可以等待，但是不用停留在当前任务中持续等待，而是可以去做别的事情，随时回来关注下这个任务的处理结果就好了。大部分执行时间很长的任务都会放到异步线程中执行，用户关注结果的话，就可以通过查询的方式来获取结果，程序自动来返回结果的话，就可以用到轮询查询了。</p><p><strong>局限性 1：频率和实时性</strong></p><p>轮询的方式延时可能会比较高，因为跟定时器的间隔时间有关系。</p><p><strong>局限性 2：增加请求压力</strong></p><p>因为轮询，要不断地请求服务端，所以对后端的请求压力也会比较大。</p><h4 id="4-3-方法-2：通知回调"><a href="#4-3-方法-2：通知回调" class="headerlink" title="4.3 方法 2：通知回调"></a>4.3 方法 2：通知回调</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/829ea8572a79aeae4d63f56c8665104a.jpeg" alt=""></p><p>等待回调几乎是实时的，处理有结果返回就马上通过回调通知到主程序/用户，那么效率和体验上就会好很多。</p><p>但是这里也有一个前提要求，回调的时候，主程序必须还在运行，否则回调也就没有了主体，也就无效了。所以要求主程序需要持续等待异步任务的回调，不能过早的退出。</p><p>一般程序中使用异步任务，需要得到任务状态的结果，使用等待回调的情况更多一些。</p><p><strong>特别注意 1：等待超时</strong></p><p>等待的时间，一般不能是无限长，这样容易造成某些异常情况下的任务爆炸，内存泄露。所以需要对异步任务设置一个等待超时，过期后就要中断任务了，也就不能通过回调来得到结果了，直接认为是任务异常了。</p><p><strong>特别注意 2：异常情况</strong></p><p>当主程序在等待异步任务的回调时，如果异步任务自身有异常，无法成功执行，也无法完成回调的操作，那么主程序也就无法得到想要的结果，也不知道任务状态的结果是成功还是失败，这时候也就会遇到上面等待超时的情况了。</p><p><strong>特别注意 3：回调地狱</strong></p><p>使用 nodejs 异步编程的时候，所有的 io 操作都是异步回调，于是就很容易陷入 N 层的回调，代码就会变得异常丑陋和难以维护。于是就出现了很多的异步编程框架/模式，像：Promise,Generator,async/await 等。这里不做过多讲解。</p><h4 id="4-4-思考问题"><a href="#4-4-思考问题" class="headerlink" title="4.4 思考问题"></a>4.4 思考问题</h4><p>实际工作中，还有哪些地方需要处理异步任务的状态结果返回呢？除了轮询和回调，还有其他的方法吗？</p><h3 id="5-异常处理"><a href="#5-异常处理" class="headerlink" title="5 异常处理"></a>5 异常处理</h3><p>同步的程序，处理异常情况，在 java 中只需要一个 try catch 就可以捕获到全部的异常。</p><h4 id="5-1-重点-1：分别做异常处理"><a href="#5-1-重点-1：分别做异常处理" class="headerlink" title="5.1 重点 1：分别做异常处理"></a>5.1 重点 1：分别做异常处理</h4><p>异步的程序，try catch 只能捕获到当前主程序的异常，主程序中的异步线程是无法被捕获的。这时候，就需要针对异步线程中的异步任务也要单独进行 try catch 捕获异常。</p><p>在 golang 中，开启协程，还是需要在异步任务的 defer 方法中，加入一个 recover() ，以避免没有处理的异常导致整个进程的 panic。</p><h4 id="5-2-重点-2：异常结果的记录，查询或者回调"><a href="#5-2-重点-2：异常结果的记录，查询或者回调" class="headerlink" title="5.2 重点 2：异常结果的记录，查询或者回调"></a>5.2 重点 2：异常结果的记录，查询或者回调</h4><p>当我们把异步任务中的异常情况都处理好了，不会导致异步线程把整个进程整奔溃了，那么还有问题，怎么把异常的结果返回给主进程。这就涉及到上面的状态处理了。</p><p>如果可以忽略结果，那么只需要写一下错误日志就好了。</p><p>如果需要处理状态，那就要记录下异常信息或者通知回调给到主进程。</p><h4 id="5-3-思考问题"><a href="#5-3-思考问题" class="headerlink" title="5.3 思考问题"></a>5.3 思考问题</h4><p>实际工作中，你会对所有的可能异常情况都做相应的处理吗？异常结果，都是怎么处理的呢？</p><h3 id="6-典型场景和思考"><a href="#6-典型场景和思考" class="headerlink" title="6 典型场景和思考"></a>6 典型场景和思考</h3><p>前面已经讲到一些案例，总结下来的典型场景有如下几种</p><p>6.1 订阅发布模式，消息队列</p><p>6.2 慢请求，耗时长的任务</p><p>6.3 高并发、高性能要求时的多任务处理</p><p>6.4 不确定执行的时间点，触发器</p><p>人脑(单核)不擅长异步思考，电脑(多核)却更适合。</p><p><strong>编程的时候，是人脑适配电脑，还是电脑服务人脑？</strong></p><p>在大部分的编程中，大家都只需要考虑同步的方式来写代码逻辑。少部分时候，就要考虑使用异步的方式。而且，有很多的开发框架、类库已经把异步处理封装，可以简化异步任务的开发和调试工作。</p><p>所以，对于开发者来说，默认还是同步方式思考和开发，当不得不使用异步的时候，才会考虑异步的方式。毕竟让人脑适配电脑，这个过程还是有些困难的。</p><p>本文转自 <a href="https://mp.weixin.qq.com/s/TvHY2i1FX1zS_WHdCvK-wA">https://mp.weixin.qq.com/s/TvHY2i1FX1zS_WHdCvK-wA</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>从 SVN 到 Git 开发实用命令总结</title>
      <link href="/posts/5244d648/"/>
      <url>/posts/5244d648/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>作者：ronhu，腾讯 IEG 客户端开发工程师</p><blockquote><p>本文从 Git 与 SVN 的对比入手，介绍如何通过 Git-SVN 开始使用 Git，并总结平时工作高频率使用到的 Git 常用命令。</p></blockquote><h3 id="一、Git-vs-SVN"><a href="#一、Git-vs-SVN" class="headerlink" title="一、Git vs SVN"></a>一、Git vs SVN</h3><blockquote><p>Git 和 SVN 孰优孰好，每个人有不同的体验。</p></blockquote><h4 id="Git-是分布式的，SVN-是集中式的"><a href="#Git-是分布式的，SVN-是集中式的" class="headerlink" title="Git 是分布式的，SVN 是集中式的"></a>Git 是分布式的，SVN 是集中式的</h4><p>这是 Git 和 SVN 最大的区别。若能掌握这个概念，两者区别基本搞懂大半。因为 Git 是分布式的，所以 Git 支持离线工作，在本地可以进行很多操作，包括接下来将要重磅推出的分支功能。而 SVN 必须联网才能正常工作。</p><h4 id="Git-复杂概念多，SVN-简单易上手"><a href="#Git-复杂概念多，SVN-简单易上手" class="headerlink" title="Git 复杂概念多，SVN 简单易上手"></a>Git 复杂概念多，SVN 简单易上手</h4><p>所有同时掌握 Git 和 SVN 的开发者都必须承认，Git 的命令实在太多了，日常工作需要掌握<code>add</code>,<code>commit</code>,<code>status</code>,<code>fetch</code>,<code>push</code>,<code>rebase</code>等，若要熟练掌握，还必须掌握<code>rebase</code>和<code>merge</code>的区别，<code>fetch</code>和<code>pull</code>的区别等，除此之外，还有<code>cherry-pick</code>，<code>submodule</code>，<code>stash</code>等功能，仅是这些名词听着都很绕。</p><p>在易用性这方面，SVN 会好得多，简单易上手，对新手很友好。但是从另外一方面看，Git 命令多意味着功能多，若我们能掌握大部分 Git 的功能，体会到其中的奥妙，会发现再也回不去 SVN 的时代了。</p><h4 id="Git-分支廉价，SVN-分支昂贵"><a href="#Git-分支廉价，SVN-分支昂贵" class="headerlink" title="Git 分支廉价，SVN 分支昂贵"></a>Git 分支廉价，SVN 分支昂贵</h4><p>在版本管理里，分支是很常使用的功能。在发布版本前，需要发布分支，进行大需求开发，需要 feature 分支，大团队还会有开发分支，稳定分支等。在大团队开发过程中，常常存在创建分支，切换分支的需求。</p><p>Git 分支是指针指向某次提交，而 SVN 分支是拷贝的目录。这个特性使 Git 的分支切换非常迅速，且创建成本非常低。</p><p>而且 Git 有本地分支，SVN 无本地分支。在实际开发过程中，经常会遇到有些代码没写完，但是需紧急处理其他问题，若我们使用 Git，便可以创建本地分支存储没写完的代码，待问题处理完后，再回到本地分支继续完成代码。</p><h3 id="二、Git-核心概念"><a href="#二、Git-核心概念" class="headerlink" title="二、Git 核心概念"></a>二、Git 核心概念</h3><p>Git 最核心的一个概念就是工作流。</p><ul><li><p>工作区(Workspace)是电脑中实际的目录。</p></li><li><p>暂存区(Index)类似于缓存区域，临时保存你的改动。</p></li><li><p>仓库区(Repository)，分为本地仓库和远程仓库。</p></li></ul><p>从 SVN 切换到 Git，最难理解并且最不能理解的是暂存区和本地仓库。熟练使用 Git 后，会发现这简直是神设计，由于这两者的存在，使许多工作变得易管理。</p><p>通常提交代码分为几步：</p><ol><li><p><code>git add</code>从工作区提交到暂存区</p></li><li><p><code>git commit</code>从暂存区提交到本地仓库</p></li><li><p><code>git push</code>或<code>git svn dcommit</code>从本地仓库提交到远程仓库</p></li></ol><p>一般来说，记住以下命令，便可进行日常工作了（图片来源于网络）：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/cadd895211836de09ceefe6cb6d98ec6.jpeg" alt=""></p><p>Git命令</p><h3 id="三、Git-SVN-常用命令"><a href="#三、Git-SVN-常用命令" class="headerlink" title="三、Git-SVN 常用命令"></a>三、Git-SVN 常用命令</h3><blockquote><p>本节命令针对使用 Git-SVN 的开发者，请务必掌握。</p></blockquote><p>若服务器使用的 SVN，但是本地想要体验 Git 的本地分支，离线操作等功能，可以使用 <code>Git-SVN</code>功能。</p><p>常用操作如下（图片来源于网络）：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/35713aa91b0d6641881718de02880dc9.jpeg" alt=""></p><p>Git-SVN</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 下载一个 SVN 项目和它的整个代码历史，并初始化为 Git 代码库  </span><br><span class="line">$ git svn clone -s [repository]  </span><br><span class="line">  </span><br><span class="line"># 查看当前版本库情况  </span><br><span class="line">$ git svn info  </span><br><span class="line">  </span><br><span class="line"># 取回远程仓库所有分支的变化  </span><br><span class="line">$ git svn fetch  </span><br><span class="line">  </span><br><span class="line"># 取回远程仓库当前分支的变化，并与本地分支变基合并  </span><br><span class="line">$ git svn rebase  </span><br><span class="line">  </span><br><span class="line"># 上传当前分支的本地仓库到远程仓库  </span><br><span class="line">$ git svn dcommit  </span><br><span class="line">  </span><br><span class="line"># 拉取新分支，并提交到远程仓库  </span><br><span class="line">$ svn copy [remote_branch] [new_remote_branch] -m [message]  </span><br><span class="line">  </span><br><span class="line"># 创建远程分支对应的本地分支  </span><br><span class="line">$ git checkout -b [local_branch] [remote_branch]  </span><br><span class="line">  </span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="四、初始化"><a href="#四、初始化" class="headerlink" title="四、初始化"></a>四、初始化</h3><blockquote><p>从本节开始，除特殊说明，以下命令均适用于 Git 与 <code>Git-SVN</code>。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 在当前目录新建一个Git代码库  </span><br><span class="line">$ git init  </span><br><span class="line">  </span><br><span class="line"># 下载一个项目和它的整个代码历史 [Git only]  </span><br><span class="line">$ git clone [url]  </span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="五、配置"><a href="#五、配置" class="headerlink" title="五、配置"></a>五、配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 列举所有配置  </span><br><span class="line">$ git config -l  </span><br><span class="line">  </span><br><span class="line"># 为命令配置别名  </span><br><span class="line">$ git config --global alias.co checkout  </span><br><span class="line">$ git config --global alias.ci commit  </span><br><span class="line">$ git config --global alias.st status  </span><br><span class="line">$ git config --global alias.br branch  </span><br><span class="line">  </span><br><span class="line"># 设置提交代码时的用户信息  </span><br><span class="line">$ git config [--global] user.name &quot;[name]&quot;  </span><br><span class="line">$ git config [--global] user.email &quot;[email address]&quot;  </span><br><span class="line">  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Git 用户的配置文件位于 <code>~/.gitconfig</code></p><p>Git 单个仓库的配置文件位于 <code>~/$PROJECT_PATH/.git/config</code></p><h3 id="六、增删文件"><a href="#六、增删文件" class="headerlink" title="六、增删文件"></a>六、增删文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 添加当前目录的所有文件到暂存区  </span><br><span class="line">$ git add .  </span><br><span class="line">  </span><br><span class="line"># 添加指定文件到暂存区  </span><br><span class="line">$ git add &lt;file1&gt; &lt;file2&gt; ...  </span><br><span class="line">  </span><br><span class="line"># 添加指定目录到暂存区，包括其子目录  </span><br><span class="line">$ git add &lt;dir&gt;  </span><br><span class="line">  </span><br><span class="line"># 删除工作区文件，并且将这次删除放入暂存区  </span><br><span class="line">$ git rm [file1] [file2] ...  </span><br><span class="line">  </span><br><span class="line"># 停止追踪指定文件，但该文件会保留在工作区  </span><br><span class="line">$ git rm --cached [file]  </span><br><span class="line">  </span><br><span class="line"># 改名文件，并且将这个改名放入暂存区  </span><br><span class="line">$ git mv [file-original] [file-renamed]  </span><br><span class="line">  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>把文件名 file1 添加到 .gitignore 文件里，Git 会停止跟踪 file1 的状态。</p><h3 id="七、分支"><a href="#七、分支" class="headerlink" title="七、分支"></a>七、分支</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># 列出所有本地分支  </span><br><span class="line">$ git branch  </span><br><span class="line">  </span><br><span class="line"># 列出所有本地分支和远程分支  </span><br><span class="line">$ git branch -a  </span><br><span class="line">  </span><br><span class="line"># 新建一个分支，但依然停留在当前分支  </span><br><span class="line">$ git branch [branch-name]  </span><br><span class="line">  </span><br><span class="line"># 新建一个分支，并切换到该分支  </span><br><span class="line">$ git checkout -b [new_branch] [remote-branch]  </span><br><span class="line">  </span><br><span class="line"># 切换到指定分支，并更新工作区  </span><br><span class="line">$ git checkout [branch-name]  </span><br><span class="line">  </span><br><span class="line"># 合并指定分支到当前分支  </span><br><span class="line">$ git merge [branch]  </span><br><span class="line">  </span><br><span class="line"># 选择一个 commit，合并进当前分支  </span><br><span class="line">$ git cherry-pick [commit]  </span><br><span class="line">  </span><br><span class="line"># 删除本地分支，-D 参数强制删除分支  </span><br><span class="line">$ git branch -d [branch-name]  </span><br><span class="line">  </span><br><span class="line"># 删除远程分支  </span><br><span class="line">$ git push [remote] :[remote-branch]  </span><br><span class="line">  </span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="八、提交"><a href="#八、提交" class="headerlink" title="八、提交"></a>八、提交</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 提交暂存区到仓库区  </span><br><span class="line">$ git commit -m [message]  </span><br><span class="line">  </span><br><span class="line"># 提交工作区与暂存区的变化直接到仓库区  </span><br><span class="line">$ git commit -a  </span><br><span class="line">  </span><br><span class="line"># 提交时显示所有 diff 信息  </span><br><span class="line">$ git commit -v  </span><br><span class="line">  </span><br><span class="line"># 提交暂存区修改到仓库区，合并到上次修改，并修改上次的提交信息  </span><br><span class="line">$ git commit --amend -m [message]  </span><br><span class="line">  </span><br><span class="line"># 上传本地指定分支到远程仓库  </span><br><span class="line">$ git push [remote] [remote-branch]  </span><br><span class="line">  </span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="九、拉取"><a href="#九、拉取" class="headerlink" title="九、拉取"></a>九、拉取</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 下载远程仓库的所有变动 (Git only)  </span><br><span class="line">$ git fetch [remote]  </span><br><span class="line">  </span><br><span class="line"># 显示所有远程仓库 (Git only)  </span><br><span class="line">$ git remote -v  </span><br><span class="line">  </span><br><span class="line"># 显示某个远程仓库的信息 (Git only)  </span><br><span class="line">$ git remote show [remote]  </span><br><span class="line">  </span><br><span class="line"># 增加一个新的远程仓库，并命名 (Git only)  </span><br><span class="line">$ git remote add [remote-name] [url]  </span><br><span class="line">  </span><br><span class="line"># 取回远程仓库的变化，并与本地分支合并，(Git only), 若使用 Git-SVN，请查看第三节  </span><br><span class="line">$ git pull [remote] [branch]  </span><br><span class="line">  </span><br><span class="line"># 取回远程仓库的变化，并与本地分支变基合并，(Git only), 若使用 Git-SVN，请查看第三节  </span><br><span class="line">$ git pull --rebase [remote] [branch]  </span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="十、撤销"><a href="#十、撤销" class="headerlink" title="十、撤销"></a>十、撤销</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># 恢复暂存区的指定文件到工作区  </span><br><span class="line">$ git checkout [file]  </span><br><span class="line">  </span><br><span class="line"># 恢复暂存区当前目录的所有文件到工作区  </span><br><span class="line">$ git checkout .  </span><br><span class="line">  </span><br><span class="line"># 恢复工作区到指定 commit  </span><br><span class="line">$ git checkout [commit]  </span><br><span class="line">  </span><br><span class="line"># 重置暂存区的指定文件，与上一次 commit 保持一致，但工作区不变  </span><br><span class="line">$ git reset [file]  </span><br><span class="line">  </span><br><span class="line"># 重置暂存区与工作区，与上一次 commit 保持一致  </span><br><span class="line">$ git reset --hard  </span><br><span class="line">  </span><br><span class="line"># 重置当前分支的指针为指定 commit，同时重置暂存区，但工作区不变  </span><br><span class="line">$ git reset [commit]  </span><br><span class="line">  </span><br><span class="line"># 重置当前分支的HEAD为指定 commit，同时重置暂存区和工作区，与指定 commit 一致  </span><br><span class="line">$ git reset --hard [commit]  </span><br><span class="line">  </span><br><span class="line"># 新建一个 commit，用于撤销指定 commit  </span><br><span class="line">$ git revert [commit]  </span><br><span class="line">  </span><br><span class="line"># 将未提交的变化放在储藏区  </span><br><span class="line">$ git stash  </span><br><span class="line">  </span><br><span class="line"># 将储藏区的内容恢复到当前工作区  </span><br><span class="line">$ git stash pop  </span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="十一、查询"><a href="#十一、查询" class="headerlink" title="十一、查询"></a>十一、查询</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 查看工作区文件修改状态  </span><br><span class="line">$ git status  </span><br><span class="line">  </span><br><span class="line"># 查看工作区文件修改具体内容  </span><br><span class="line">$ git diff [file]  </span><br><span class="line">  </span><br><span class="line"># 查看暂存区文件修改内容  </span><br><span class="line">$ git diff --cached [file]  </span><br><span class="line">  </span><br><span class="line"># 查看版本库修改记录  </span><br><span class="line">$ git log  </span><br><span class="line">  </span><br><span class="line"># 查看某人提交记录  </span><br><span class="line">$ git log --author=someone  </span><br><span class="line">  </span><br><span class="line"># 查看某个文件的历史具体修改内容  </span><br><span class="line">$ git log -p [file]  </span><br><span class="line">  </span><br><span class="line"># 查看某次提交具体修改内容  </span><br><span class="line">$ git show [commit]  </span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="写在后面"><a href="#写在后面" class="headerlink" title="写在后面"></a>写在后面</h4><p>从 SVN 到 Git，除本文列举的基础概念和常用命令，包括但不限于<code>如何从 SVN 服务器切换到 Git 服务器</code>，<code>分支模型管理</code>等也非常重要。本文篇幅有限，针对没有介绍到但很重要的知识点会列举到参考资料里，希望作为本文的延伸阅读。</p><p><strong>参考资料</strong></p><ol><li><p><a href="https://git-scm.com/book/zh/v2">Git Pro Books</a> Git 权威指南</p></li><li><p><a href="http://www.worldhello.net/gotgit/04-git-model/070-git-svn.html">Git 和 SVN 协同模型</a> 详细介绍 Git-SVN 协同模型的使用原理与注意点</p></li><li><p><a href="http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html">常用 Git 命令清单</a> 总结得非常详细的清单，与本文部分内容重合并互补</p></li><li><p><a href="https://github.com/xirong/my-git/blob/master/why-git.md">SVN 和 Git 在日常使用中的明显差异</a> 介绍了 Git 和 SVN 的区别，可作为本文的延伸阅读</p></li><li><p><a href="https://www.git-tower.com/learn/git/ebook/cn/command-line/advanced-topics/git-flow">git-flow 的工作流程</a> 通俗易懂的介绍了 git-flow 的基础工作流程</p></li><li><p><a href="https://git-scm.com/book/zh/v2/Git-%E4%B8%8E%E5%85%B6%E4%BB%96%E7%B3%BB%E7%BB%9F-%E8%BF%81%E7%A7%BB%E5%88%B0-Git">SVN 迁移到 Git</a> 服务器从 SVN 迁移到 Git 的具体操作方法</p></li></ol><p>本文转自 <a href="https://mp.weixin.qq.com/s/ApEpvgTujk_aHLeD_2FPFw">https://mp.weixin.qq.com/s/ApEpvgTujk_aHLeD_2FPFw</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> svn </tag>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>探秘 Web 水印技术</title>
      <link href="/posts/21f1f258/"/>
      <url>/posts/21f1f258/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>Web 水印技术</strong>在信息安全和版权保护等领域有着广泛的应用，对防止信息泄露或知识产品被侵犯有重要意义。水印根据可见性可分为可见水印和不可见水印（盲水印），本文将分别予以介绍，带你探秘 web 水印技术。</p><h3 id="可见水印"><a href="#可见水印" class="headerlink" title="可见水印"></a>可见水印</h3><h4 id="最简单的水印"><a href="#最简单的水印" class="headerlink" title="最简单的水印"></a>最简单的水印</h4><p>一种比较常见的简单水印场景是给文章、表格加上 <code>logo</code> 水印，用以申明版权。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/1452006909f9c251a5f800126aaa2cf7.jpeg" alt=""></p><p>这里想要的效果就是一个浅浅的 <code>logo</code> 平铺展示。实现起来也比较简单，只需制作一个半透明的 <code>logo</code> 图片，设为文章或者表格的背景图片即可。仅需一行 <code>CSS</code> 声明。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">background-image</span>:<span class="built_in">url</span>(<span class="string">&quot;./logo.png&quot;</span>);  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>实现图片平铺关键的 <code>CSS</code> 属性是 <code>background-repeat</code>，值为 <code>repeat</code> 时是平铺，这也是它的默认值，所以可以省略。</p><h4 id="全页面水印"><a href="#全页面水印" class="headerlink" title="全页面水印"></a>全页面水印</h4><p>照葫芦画瓢，如果要给整个 <code>Web</code> 页面加上水印，是不是给页面的 <code>body</code> 元素设置背景图片平铺展示就可以了呢？</p><p>然而通常并不会这么处理，因为文章和表格内容多以文本为主，不会明显遮挡水印，而一个完整的页面往往还包含很多其他页面元素，比如图片、视频、控件等等，它们很可能会遮挡住背景图片，从而影响水印效果。</p><p>所以，为了避免被其他元素遮挡，针对页面的水印一般会使用一个层级比较高且覆盖整个页面的元素来承载。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">div</span><span class="selector-class">.watermark</span>&#123;  </span><br><span class="line">  <span class="attribute">position</span>: fixed;  </span><br><span class="line">  <span class="attribute">left</span>:<span class="number">0</span>;  </span><br><span class="line">  <span class="attribute">top</span>:<span class="number">0</span>;  </span><br><span class="line">  <span class="attribute">width</span>: <span class="number">100vw</span>;  </span><br><span class="line">  <span class="attribute">height</span>: <span class="number">100vh</span>;  </span><br><span class="line">  <span class="attribute">background-image</span>:<span class="built_in">url</span>(<span class="string">&quot;./logo.png&quot;</span>);  </span><br><span class="line">  <span class="attribute">opacity</span>: .<span class="number">5</span>;  </span><br><span class="line">  <span class="attribute">z-index</span>: <span class="number">3000</span>;  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这样一来，其他元素就遮挡不住水印了。不过，这个 <code>div</code> 反过来可能会遮挡页面其他元素，影响页面元素操作。还需要一条关键的 <code>CSS</code> 声明来破解这个问题 :</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">pointer-events</span>: none;  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这个 <code>CSS</code> 声明会使该元素“可穿透”，“看得见、摸不着”，不再影响页面操作。</p><h4 id="动态水印"><a href="#动态水印" class="headerlink" title="动态水印"></a>动态水印</h4><p>很多时候，给页面加水印的目的并不是申明版权，而是为了支持溯源。此时水印的内容并不会只是一个 <code>logo</code>，通常会包含用户信息，比如用户名、UID、手机号等等。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/6426b18102827952e9bc497fa6148480.jpeg" alt=""></p><p>这就意味着，每个用户的水印内容是不同的，无法通过提前准备好一张图片来满足了。这种场景往往需要根据用户信息动态生成图片。</p><p>我们来看下几种主流的动态生成水印图片的方式：</p><h5 id="服务端方案"><a href="#服务端方案" class="headerlink" title="服务端方案"></a>服务端方案</h5><p>传统的方式是在服务端生成图片。页面上发起的图片请求中可以附带用户信息，服务端根据这些参数动态生成图片，并将图片数据作为该请求的响应返给页面，页面拿到后将其用作水印。</p><p>这种方式的优点是兼容性好，缺点是需要前后端配合，增加了页面请求和服务端资源开销，防攻击能力也较差。</p><h5 id="Canvas-方案"><a href="#Canvas-方案" class="headerlink" title="Canvas 方案"></a>Canvas 方案</h5><p><code>HTML5</code> 引入 <code>Canvas</code> 特性使得浏览器自身具备了绘图能力。经过多年的发展，主流浏览器基本都已可以提供良好的支持。通过 <code>Canvas</code> 可以轻松绘制图片，并可将图片数据导出，用于页面图片或背景。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> canvasElement = <span class="variable language_">document</span>.<span class="title function_">createElement</span>(<span class="string">&#x27;canvas&#x27;</span>);  </span><br><span class="line"><span class="keyword">const</span> context = canvasElement.<span class="title function_">getContext</span>(<span class="string">&#x27;2d&#x27;</span>);  </span><br><span class="line">canvasElement.<span class="property">width</span> = <span class="number">200</span>;  </span><br><span class="line">canvasElement.<span class="property">height</span> = <span class="number">200</span>;  </span><br><span class="line">context.<span class="title function_">rotate</span>((-<span class="number">30</span> * <span class="title class_">Math</span>.<span class="property">PI</span>) / <span class="number">180</span>);  </span><br><span class="line">context.<span class="property">font</span> = <span class="string">&#x27;400 26px Arial&#x27;</span>;  </span><br><span class="line">context.<span class="property">fillStyle</span> = <span class="string">&#x27;#B9C0CA&#x27;</span>;  </span><br><span class="line">context.<span class="property">textAlign</span> = <span class="string">&#x27;center&#x27;</span>;  </span><br><span class="line">context.<span class="property">textBaseline</span> = <span class="string">&#x27;middle&#x27;</span>;  </span><br><span class="line">context.<span class="title function_">fillText</span>(<span class="string">&#x27;水印文字&#x27;</span>, <span class="number">70</span>, <span class="number">130</span>);  </span><br><span class="line"><span class="keyword">const</span> watermark = canvasElement.<span class="title function_">toDataURL</span>(<span class="string">&#x27;image/png&#x27;</span>);  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>通过上述示例代码可拿到水印图片的 <code>data URI</code> 数据，用作水印承载元素的背景图片平铺展示即可。</p><p>这种方式不需要服务端配合，在前端就可以完成，且有助于减少请求和服务端资源开销。曾经面临的浏览器兼容问题现在也不再是问题，该方案已逐渐流行起来。</p><h5 id="SVG-方案"><a href="#SVG-方案" class="headerlink" title="SVG 方案"></a>SVG 方案</h5><p>对于纯文字的水印来说，有没有办法不生成图片而直接实现平铺呢？</p><p>动态创建大量 <code>DOM</code> 节点，通过 <code>CSS</code> 控制排列当然可以实现，但是繁琐且性能差，优雅更无从谈起。</p><p>不妨换个角度思考，有没有办法让文字不转成图片就可以用作 <code>background-image</code> 属性的值呢？这样就可以利用 <code>background-repeat</code> 实现平铺效果了。</p><p>这时候可以考虑使用 <code>SVG</code>，因为 <code>SVG</code> 具有文本和图像的双重特性。看上去是文本，然而在很多场景可以当做图片使用。</p><p>我们可以通过 <code>SVG</code> 的相关属性精准控制字体位置、大小、颜色、透明度和旋转角度等参数。如：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">svg</span> <span class="attr">width</span>=<span class="string">&quot;200&quot;</span> <span class="attr">height</span>=<span class="string">&quot;200&quot;</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://www.w3.org/2000/svg&quot;</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;<span class="name">text</span> <span class="attr">x</span>=<span class="string">&quot;50%&quot;</span> <span class="attr">y</span>=<span class="string">&quot;50%&quot;</span> <span class="attr">font-size</span>=<span class="string">&quot;30&quot;</span> <span class="attr">fill</span>=<span class="string">&quot;#a2a9b6&quot;</span> <span class="attr">fill-opacity</span>=<span class="string">&quot;0.3&quot;</span> <span class="attr">font-family</span>=<span class="string">&quot;system-ui, sans-serif&quot;</span> <span class="attr">text-anchor</span>=<span class="string">&quot;middle&quot;</span> <span class="attr">dominant-baseline</span>=<span class="string">&quot;middle&quot;</span> <span class="attr">transform</span>=<span class="string">&#x27;rotate(-45, 100 100)&#x27;</span>&gt;</span>水印文字<span class="tag">&lt;/<span class="name">text</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">svg</span>&gt;</span>  </span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p>考虑到浏览器兼容性，用作背景图片时，建议将 <code>SVG</code> 编码为 <code>Base64</code>（或转义特定字符）:</p></blockquote><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">background-image</span>: <span class="built_in">url</span>(<span class="string">&quot;data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjAwIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48dGV4dCB4PSI1MCUiIHk9IjUwJSIgZm9udC1zaXplPSIzMCIgZmlsbD0iI2EyYTliNiIgZmlsbC1vcGFjaXR5PSIwLjMiIGZvbnQtZmFtaWx5PSJzeXN0ZW0tdWksIHNhbnMtc2VyaWYiIHRleHQtYW5jaG9yPSJtaWRkbGUiIGRvbWluYW50LWJhc2VsaW5lPSJtaWRkbGUiIHRyYW5zZm9ybT0ncm90YXRlKC00NSwgMTAwIDEwMCknPuawtOWNsOaWh+WtlzwvdGV4dD48L3N2Zz4=&quot;</span>);  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/c0757a349954269a2d140d98059f6fa8.jpeg" alt=""></p><h4 id="水印安全"><a href="#水印安全" class="headerlink" title="水印安全"></a>水印安全</h4><p>水印是用来保护信息安全的。信息要安全，首先要确保水印自身的安全，提高水印的防攻击（篡改、删除等）能力。</p><p>可见水印大都是基于 <code>DOM</code> 的，找到这个 <code>DOM</code> 节点，通过浏览器插件、抓包工具等在页面上注入一段 <code>JavaScript</code> 或者 <code>CSS</code> 代码对其进行篡改或删除并不困难。</p><p>防止外部代码篡改，一种思路是把水印元素封装起来，与外部环境进行隔离。</p><h5 id="Shadow-DOM"><a href="#Shadow-DOM" class="headerlink" title="Shadow DOM"></a>Shadow DOM</h5><p>在 <code>Chrome</code> 逐步统治浏览器江湖之后，谷歌正野心勃勃的推广 <code>Web Components</code> 技术。该技术允许在 <code>Web</code> 中创建可重用的小部件或组件。组件化开发在前端业界已经流行相当长一段时间了，这主要得益于前端三大框架的推崇，但具体组件标准是由框架各自制定的，而 <code>Web Components</code> 可理解为 <code>Web</code> 标准化的组件。</p><p><code>Web Components</code> 的一个重要特性就是<code>“封装”</code>，即可以将标记结构、样式和行为隐藏起来，并与页面上的其他代码相隔离。比如我们熟悉的 <code>video</code> 元素，它的进度条、按钮等控件都已被封装。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/72c6ffa0d3db1341385fe6aaa5524cd6.jpeg" alt=""></p><p><code>Shadow DOM</code> 接口是<code>“封装”</code>特性的关键所在，它可以将一个隐藏的、独立的 <code>DOM</code> 附加到一个元素上。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/8c3b6ecae517c89f530f1e833546ce40.jpeg" alt=""></p><p>为了提高 <code>web</code> 水印的隐蔽性，同时避免受外部代码影响，从而在一定程度上防止篡改，可以考虑把水印元素放在 <code>Shadow DOM</code> 中。</p><p>来看下 <code>Shadow DOM</code> 的基本用法。使用 <code>Element.attachShadow()</code> 方法来将一个 <code>shadow root</code> 附加到任何一个元素上。它接受一个配置对象作为参数，该对象有一个 <code>mode</code> 属性，值可以是 <code>open</code> 或者 <code>closed</code> 。<code>open</code> 表示可以通过页面内的 <code>JavaScript</code> 方法来获取 <code>Shadow DOM</code>。而 <code>closed</code> 则表示不可以从外部获取 <code>Shadow DOM</code> 。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="title class_">Element</span>.<span class="title function_">attachShadow</span>(&#123;<span class="attr">mode</span>: <span class="string">&#x27;closed&#x27;</span>&#125;);  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/7d4bf4bdf2b80015d10d6c59fb1c15fa.jpeg" alt=""></p><p>样式怎么隔离呢？<code>Shadow DOM</code> 中的样式本身就是隔离的，除非主动使用 <code>CSS</code> 变量、<code>part</code> 属性等暴露，外部样式是不会影响到组件内的。</p><h5 id="Mutation-Observer"><a href="#Mutation-Observer" class="headerlink" title="Mutation Observer"></a>Mutation Observer</h5><p><code>Shadow DOM</code> 提高了水印的隐蔽性，同时可以防止外部代码修改。除此之外，还有一种常见的攻击场景——人为修改，比如在浏览器控制台直接修改或删除对应的 <code>DOM</code> 元素。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/807dd6a11c4156ca585c0231ad9c63d8.jpeg" alt=""></p><p>可以考虑<code>“监听”</code>这种行为，一旦发生就马上修复，比如重新插入一个。那怎么实现这种<code>“监听”</code>呢？现代浏览器中有多种观察者（<code>Observer</code>），比如<code>IntersectionObserver</code>、<code>PerformanceObserver</code>、<code>ResizeObserver</code>、<code>ReportingObserver</code>、<code>MutationObserver</code> 等。其中，<code>MutationObserver</code> 就可以用来监听 <code>DOM</code> 变动，<code>DOM</code> 的任何变动，比如节点的增减、属性的变动、文本内容的变动，通过该 <code>API</code> 都可以得到通知。</p><p>所以可以使用 <code>MutationObserver API</code> 来监听水印元素 <code>DOM</code> 变化，一旦监听到 <code>DOM</code> 元素被修改或者删除，就立即重新插入一个。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/1d01f7edb1fc7955af0cb71381d8ee45.gif" alt=""></p><h3 id="不可见水印（盲水印）"><a href="#不可见水印（盲水印）" class="headerlink" title="不可见水印（盲水印）"></a>不可见水印（盲水印）</h3><p>不可见水印也叫盲水印、隐水印，顾名思义是一种看不到的水印，看不到还要它做什么呢？其实，不可见水印在一些对安全性要求较高的场景意义还是蛮大的。不可见水印通常具有比可见水印更好的隐蔽性和抗攻击性。虽不可见，但通过一定的技术手段是可以将水印信息从其载体上提取出来的，这就使得其载体具备了溯源能力，在关键时刻往往能发挥大作用。</p><p>我总结不可见水印相对可见水印至少有以下三个明显的优势：</p><ul><li><p>更好的观感。可见水印总给人一种“膏药感”，甚至会引起部分人的不适，而不可见水印则不会有这个问题。</p></li><li><p>更佳的隐蔽性。用户基本感知不到水印的存在。</p></li><li><p>更强的抗攻击性。可见水印更容易受到攻击，而不可见水印除了隐蔽性比较强之外，其自身往往还具备比较强的抗攻击能力。</p></li></ul><p>不可见水印（盲水印）属于信息隐匿技术（也叫隐写术），历史悠久，手段繁多。在现代，随着计算机网络技术的发展，数字产品的信息安全和版权保护也已成为信息隐匿技术的一个重要课题。隐写术在数字音频、数字视频和数字图像领域有着非常广泛的应用。</p><p><code>Web</code> 上基于 <code>DOM</code> 的盲水印大都不靠谱，而另一方面数字图像是信息隐藏和数字水印领域研究最多和最早的一种载体，<strong>相较于 Web，数字图像领域有着更为成熟的数字水印算法</strong>。我们不妨先来看下数字图像领域的常见盲水印技术。</p><p>在说数字水印之前，这里介绍一些数字图像的基础知识。</p><p>数字图像（位图）是由像素（<code>pixel</code>）组成。</p><ul><li><p>非黑即白的二值图像，<code>1</code> 个 <code>bit</code> 即可表示 <code>1</code> 个像素（黑白两种状态）。所以 <code>1</code> 个字节（<code>byte</code>）可以表示 <code>8</code> 个像素。</p></li><li><p>灰度图，<code>1</code> 个像素有 <code>256</code> 种状态（<code>2</code> 的 <code>8</code> 次方），需要 <code>8</code> 个 <code>bit</code>，即 <code>1</code> 个字节。</p></li><li><p>彩色的 <code>RGB</code> 图，有 <code>R</code> / <code>G</code> / <code>B</code> 三个通道，每个通道 <code>256</code> 种状态，使用 <code>1</code> 个字节表示，共需 <code>3</code> 个字节表示 <code>1</code> 个像素。</p></li><li><p><code>RGBA</code> 图，在 <code>R</code> / <code>G</code> / <code>B</code> 三个通道基础上增加了一个透明度通道，<code>256</code> 种状态，额外需要 <code>1</code> 个字节，共需要 <code>4</code> 个字节表示一个像素。</p></li></ul><p>通常，考虑到计算速度和性能，图像处理和图像识别大都会将图像转成灰度图或者选择其中一个通道进行。</p><h4 id="LSB-水印"><a href="#LSB-水印" class="headerlink" title="LSB 水印"></a>LSB 水印</h4><p>如上文所述，灰度图像的一个像素有 <code>256</code> 种状态，通常用灰度值（ <code>0-255</code> ）表示，<code>0</code> 表示黑色，<code>255</code> 表示白色，灰度值越大表示亮度越高。</p><p>灰度可用一个字节，即 <code>8</code> 比特二进制数表示，其中最高位对图像的贡献最大，最低位对图像的贡献最小，称为最低比特位（<code>Least Significant Bit</code>，<code>LSB</code>）。</p><p>如果将一个图像所有像素的比特位抽出来，就构成了 <code>8</code> 个不同的位平面，从 <code>LSB</code>（最低有效位 <code>0</code>）到 <code>MSB</code>（最高有效位 <code>7</code>）。位平面从低位到高位，图像的特征逐渐变得复杂，细节不断增加，相邻比特的相关性也越强。而比特位越低包含的图像信息就越少，最低位平面类似于随机噪声。因此，改变低位对图像的成像质量影响不大。</p><p><code>LSB</code> 水印就是利用了这一点，用水印信息替换载体图像的最低比特位，这样原图像的 <code>7</code> 个高位平面就与表示水印信息的最低位平面组成了新的图像。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/0169c9373a631b3e95707fb6441a47f1.jpeg" alt=""></p><p><code>LSB</code> 水印鲁棒性（防攻击性）较差，水印信息容易被抹去。</p><h4 id="频域水印"><a href="#频域水印" class="headerlink" title="频域水印"></a>频域水印</h4><p>将数字图像用一个矩阵来表示，是图像的空间域表示方法，<code>LSB</code> 就是在图像的空间域隐藏信息，鲁棒性较差。而在图像信号的频域（变换域）中隐藏信息要比在空间域中隐藏信息具有更好的鲁棒性。那么如何把图像信号从空间域转换到频域呢？这里就需要用到大名鼎鼎的 <code>傅里叶变换</code> 了。</p><p>法国数学家傅里叶大家一定不陌生，高数里就有傅里叶级数。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/14ad3a3b53bc5b71b25e02a2c6eb920b.jpeg" alt=""></p><p>傅里叶提出的傅里叶变换（<code>Fourier transform</code>）理论，表示能将满足一定条件的某个函数表示成三角函数（正弦和/或余弦函数）或者它们的积分的线性组合，可用于把信号从时间域（或空间域）变换到频率域。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/529260d2d55a6aea24bc66e7299c8f35.jpeg" alt=""></p><p>在此之前人们对信号的分析主要集中在空间域，傅里叶变换的提出为频域分析奠定了基础，有助于解决许多图像的问题。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/397d04d93e4c1aa5b808139b8dc866fe.jpeg" alt=""></p><p>傅里叶变换在数字图像处理领域有着极为重要的应用，图像领域变换的实质是把图像函数展开成具有不同空间频率的正、余弦信号的叠加，也就是说任何图像都可以分解为若干个频率不同的亮度呈正弦变化的图像之和。把图像从空间域变换到频率域后，就能够实现对图像数据进行不同频率成分的提取。对于图像信号来说，可以把灰度（亮度）看做频率，傅里叶变换可作为图像灰度值形成的空间域与其频率域的桥梁。</p><p>在频域中隐藏信息就是傅里叶变换在数字图像处理领域的一个典型应用场景。通常多选择在图像频域的中频部分嵌入信息，因为高频部分易于被各种信号处理方法破坏，而人的视觉又对低频部分比较敏感，容易察觉低频部分的变化。</p><p>在图像频域嵌入水印信息的大致流程为：把原始图像通过离散傅里叶变换转换到频域（变换域），把水印文字信息混入，再经过离散傅里叶变换的逆变换，便得到了载有水印信息的图像。水印信息隐匿性较好。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/a29a6c37f4141251baec7a83ca897e4e.jpeg" alt=""></p><p>光说不练假把式，操练起来。</p><p>下图是我随手拍的鹅厂北京总部大楼一角。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/4259996300d2581a5b5086f80e9d4ae8.jpeg" alt=""></p><p>对上图的一个通道进行离散傅里叶变换，在其变换域（频域）加入水印文字（fransli）后，再进行离散傅里叶变换的逆变换，便得到了下图。怎么样，看不到水印信息吧？</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/b2af0fb0281fee0bb27300b13e5ce110.jpeg" alt=""></p><p>对上图进行离散傅里叶变换，将图片转换到频域（变换域），我们可以清楚的看到嵌入的水印文字（下图）。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/b068cd7fa7976e7977faf37855f64d46.jpeg" alt=""></p><p>频域盲水印具有比较好的防攻击性，我们来测试一下。</p><p>我们截取图像中的一部分并重新采样，然后尝试提取水印信息。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/a838b934315831073c69cf1cbb9597c7.jpeg" alt=""></p><p>可以看到还是有很大概率可以提取到有效水印信息的。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/6389dcb695c80241e433af31f964670d.jpeg" alt=""></p><h4 id="Web-中的数字水印应用"><a href="#Web-中的数字水印应用" class="headerlink" title="Web 中的数字水印应用"></a>Web 中的数字水印应用</h4><p>上面介绍了几种常见的不可见水印（盲水印）实现方式，其中鲁棒性比较好的是基于频域的数字图像盲水印，但这种水印主要是针对数字图像，而 Web 上的内容载体并不一定都是图片，常见的需要加水印的载体除了图片还有文本、表格等，这些场景该如何应用频域盲水印呢？</p><p>或许，<code>Canvas</code> 就是答案。</p><p><strong>Reference</strong></p><ul><li><p><a href="https://developer.mozilla.org/en-US/docs/Web/Web_Components">Web Components</a></p></li><li><p><a href="https://developer.mozilla.org/en-US/docs/Web/Web_Components/Using_shadow_DOM">shadow DOM</a></p></li><li><p><a href="https://www.zhangxinxu.com/wordpress/2020/10/text-as-css-background-image/">如何让文字作为 CSS 背景图片显示？</a></p></li><li><p>《数字图像隐写分析》</p></li><li><p>《数字图像处理原理与实践》</p></li><li><p>《数据隐藏技术揭秘》</p></li></ul><p>本文转自 <a href="https://mp.weixin.qq.com/s/bXpDxN2tTS9FvVQMqLGB2w">https://mp.weixin.qq.com/s/bXpDxN2tTS9FvVQMqLGB2w</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>虚拟内存 &amp; I/O &amp; 零拷贝</title>
      <link href="/posts/8c24d42a/"/>
      <url>/posts/8c24d42a/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h3 id="一、虚拟内存"><a href="#一、虚拟内存" class="headerlink" title="一、虚拟内存"></a>一、虚拟内存</h3><h4 id="1-1-虚拟内存引入"><a href="#1-1-虚拟内存引入" class="headerlink" title="1.1 虚拟内存引入"></a>1.1 虚拟内存引入</h4><p>我们知道计算机由 CPU、存储器、输入/输出设备三大核心部分组成，如下：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/c19e83a348777febc86eecaefecbe446.jpeg" alt=""></p><p>CPU 运行速度很快，在完全理想的状态下，存储器应该要同时具备以下三种特性：</p><ul><li><p>速度足够快：这样 CPU 的效率才不会受限于存储器；</p></li><li><p>容量足够大：容量能够存储计算机所需的全部数据；</p></li><li><p>价格足够便宜：价格低廉，所有类型的计算机都能配备；</p></li></ul><p>然而，出于成本考虑，当前计算机体系中，存储都是采用分层设计的，常见层次如下：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/38bde58134222d4331abbd99fc02c889.jpeg" alt=""></p><p>上图分别为寄存器、高速缓存、主存和磁盘，它们的速度逐级递减、成本逐级递减，在计算机中的容量逐级递增。通常我们所说的物理内存即上文中的主存，常作为操作系统或其他正在运行中的程序的临时资料存储介质。在嵌入式以及一些老的操作系统中，系统直接通过物理寻址方式和主存打交道。然而，随着科技发展，遇到如下窘境：</p><ul><li><p>一台机器可能同时运行多台大型应用程序；</p></li><li><p>每个应用程序都需要在主存存储大量临时数据；</p></li><li><p>早期，单个 CPU 寻址能力 2^32，导致内存最大 4G;</p></li></ul><p>主存成了计算机系统的瓶颈。此时，科学家提出了一个概念：虚拟内存。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/b4a3cb8700d1f5aa8afeccc1064f8e51.jpeg" alt=""></p><p>以 32 位操作系统为例，虚拟内存的引入，使得操作系统可以为每个进程分配大小为 4GB 的虚拟内存空间，而实际上物理内存在需要时才会被加载，有效解决了物理内存有限空间带来的瓶颈。在虚拟内存到物理内存转换的过程中，有很重要的一步就是进行地址翻译，下面介绍。</p><h4 id="1-2-地址翻译"><a href="#1-2-地址翻译" class="headerlink" title="1.2 地址翻译"></a>1.2 地址翻译</h4><p>进程在运行期间产生的内存地址都是虚拟地址，如果计算机没有引入虚拟内存这种存储器抽象技术的话，则 CPU 会把这些地址直接发送到内存地址总线上，然后访问和虚拟地址相同值的物理地址；如果使用虚拟内存技术的话，CPU 则是把这些虚拟地址通过地址总线送到内存管理单元（Memory Management Unit，简称 MMU），MMU 将虚拟地址翻译成物理地址之后再通过内存总线去访问物理内存：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/48e7851b010e6a44fc946e134b26442c.jpeg" alt=""></p><p>虚拟地址（比如 16 位地址 8196=0010 000000000100）分为两部分：虚拟页号（Virtual Page Number，简称 VPN，这里是高 4 位部分）和偏移量（Virtual Page Offset，简称 VPO，这里是低 12 位部分），虚拟地址转换成物理地址是通过页表（page table）来实现的。页表由多个页表项（Page Table Entry, 简称 PTE）组成，一般页表项中都会存储物理页框号、修改位、访问位、保护位和 “在/不在” 位（有效位）等信息。</p><p>这里我们基于一个例子来分析当分析当页面命中时，计算机各个硬件是如何交互的：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/1803e439ed46698530981e6cbacf329e.jpeg" alt=""></p><ul><li><p><strong>第 1 步</strong>：处理器生成一个虚拟地址 VA，通过总线发送到 MMU；</p></li><li><p><strong>第 2 步</strong>：MMU 通过虚拟页号得到页表项的地址 PTEA，通过内存总线从 CPU 高速缓存/主存读取这个页表项 PTE；</p></li><li><p><strong>第 3 步</strong>：CPU 高速缓存或者主存通过内存总线向 MMU 返回页表项 PTE；</p></li><li><p><strong>第 4 步</strong>：MMU 先把页表项中的物理页框号 PPN 复制到寄存器的高三位中，接着把 12 位的偏移量 VPO 复制到寄存器的末 12 位构成 15 位的物理地址，即可以把该寄存器存储的物理内存地址 PA 发送到内存总线，访问高速缓存/主存；</p></li><li><p><strong>第 5 步</strong>：CPU 高速缓存/主存返回该物理地址对应的数据给处理器。</p></li></ul><p>在 MMU 进行地址转换时，如果页表项的有效位是 0，则表示该页面并没有映射到真实的物理页框号 PPN，则会引发一个<strong>缺页中断</strong>，CPU 陷入操作系统内核，接着操作系统就会通过页面置换算法选择一个页面将其换出 (swap)，以便为即将调入的新页面腾出位置，如果要换出的页面的页表项里的修改位已经被设置过，也就是被更新过，则这是一个脏页 (Dirty Page)，需要写回磁盘更新该页面在磁盘上的副本，如果该页面是”干净”的，也就是没有被修改过，则直接用调入的新页面覆盖掉被换出的旧页面即可。缺页中断的具体流程如下：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/fe664c7edae2f76465be6dde8475d473.jpeg" alt=""></p><ul><li><p><strong>第 1 步到第 3 步</strong>：和前面的页面命中的前 3 步是一致的；</p></li><li><p><strong>第 4 步</strong>：检查返回的页表项 PTE 发现其有效位是 0，则 MMU 触发一次缺页中断异常，然后 CPU 转入到操作系统内核中的缺页中断处理器；</p></li><li><p><strong>第 5 步</strong>：缺页中断处理程序检查所需的虚拟地址是否合法，确认合法后系统则检查是否有空闲物理页框号 PPN 可以映射给该缺失的虚拟页面，如果没有空闲页框，则执行页面置换算法寻找一个现有的虚拟页面淘汰，如果该页面已经被修改过，则写回磁盘，更新该页面在磁盘上的副本；</p></li><li><p><strong>第 6 步</strong>：缺页中断处理程序从磁盘调入新的页面到内存，更新页表项 PTE；</p></li><li><p><strong>第 7 步</strong>：缺页中断程序返回到原先的进程，重新执行引起缺页中断的指令，CPU 将引起缺页中断的虚拟地址重新发送给 MMU，此时该虚拟地址已经有了映射的物理页框号 PPN，<strong>因此会按照前面『Page Hit』的流程走一遍</strong>，最后主存把请求的数据返回给处理器。</p></li></ul><h5 id="1-2-1-高速缓存"><a href="#1-2-1-高速缓存" class="headerlink" title="1.2.1 高速缓存"></a>1.2.1 高速缓存</h5><p>前面在分析虚拟内存的工作原理之时，谈到页表的存储位置，为了简化处理，都是默认把主存和高速缓存放在一起，而实际上更详细的流程应该是如下的原理图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/b758d1c66e9d1bd42722c46c18419e58.jpeg" alt=""></p><p>如果一台计算机同时配备了虚拟内存技术和 CPU 高速缓存，那么 MMU 每次都会优先尝试到高速缓存中进行寻址，如果缓存命中则会直接返回，只有当缓存不命中之后才去主存寻址。</p><p>通常来说，大多数系统都会选择利用物理内存地址去访问高速缓存，因为高速缓存相比于主存要小得多，所以使用物理寻址也不会太复杂；另外也因为高速缓存容量很小，所以系统需要尽量在多个进程之间共享数据块，而使用物理地址能够使得多进程同时在高速缓存中存储数据块以及共享来自相同虚拟内存页的数据块变得更加直观。</p><h5 id="1-2-2-加速翻译-amp-优化页表"><a href="#1-2-2-加速翻译-amp-优化页表" class="headerlink" title="1.2.2 加速翻译&amp;优化页表"></a>1.2.2 加速翻译&amp;优化页表</h5><p>虚拟内存这项技术能不能真正地广泛应用到计算机中，还需要解决如下两个问题：</p><ul><li><p>虚拟地址到物理地址的映射过程必须要非常快，地址翻译如何加速。</p></li><li><p>虚拟地址范围的增大必然会导致页表的膨胀，形成大页表。</p></li></ul><p>“<strong>计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决</strong>“。虽然虚拟内存本身就已经是一个中间层了，但是中间层里的问题同样可以通过再引入一个中间层来解决。加速地址翻译过程的方案目前是通过引入页表缓存模块 – TLB，而大页表则是通过实现多级页表或倒排页表来解决。</p><h6 id="1-2-2-1-TLB-加速"><a href="#1-2-2-1-TLB-加速" class="headerlink" title="1.2.2.1 TLB 加速"></a>1.2.2.1 TLB 加速</h6><p><strong>翻译后备缓冲器</strong>（Translation Lookaside Buffer，TLB），也叫快表，是用来加速虚拟地址翻译的，因为虚拟内存的分页机制，页表一般是保存在内存中的一块固定的存储区，而 MMU 每次翻译虚拟地址的时候都需要从页表中匹配一个对应的 PTE，导致进程通过 MMU 访问指定内存数据的时候比没有分页机制的系统多了一次内存访问，一般会多耗费几十到几百个 CPU 时钟周期，性能至少下降一半，如果 PTE 碰巧缓存在 CPU L1 高速缓存中，则开销可以降低到一两个周期，但是我们不能寄希望于每次要匹配的 PTE 都刚好在 L1 中，因此需要引入加速机制，即 TLB 快表。</p><p>TLB 可以简单地理解成页表的高速缓存，保存了最高频被访问的页表项 PTE。由于 TLB 一般是硬件实现的，因此速度极快，MMU 收到虚拟地址时一般会先通过硬件 TLB 并行地在页表中匹配对应的 PTE，若命中且该 PTE 的访问操作不违反保护位（比如尝试写一个只读的内存地址），则直接从 TLB 取出对应的物理页框号 PPN 返回，若不命中则会穿透到主存页表里查询，并且会在查询到最新页表项之后存入 TLB，以备下次缓存命中，如果 TLB 当前的存储空间不足则会替换掉现有的其中一个 PTE。</p><p>下面来具体分析一下 TLB 命中和不命中。</p><p><strong>TLB 命中</strong>：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/0ccb4f35940a1e75b3a54411c01939ce.jpeg" alt=""></p><ul><li><p><strong>第 1 步</strong>：CPU 产生一个虚拟地址 VA；</p></li><li><p><strong>第 2 步和第 3 步</strong>：MMU 从 TLB 中取出对应的 PTE；</p></li><li><p><strong>第 4 步</strong>：MMU 将这个虚拟地址 VA 翻译成一个真实的物理地址 PA，通过地址总线发送到高速缓存/主存中去；</p></li><li><p><strong>第 5 步</strong>：高速缓存/主存将物理地址 PA 上的数据返回给 CPU。</p></li></ul><p><strong>TLB 不命中</strong>：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/c103ce909122cc7de6b8d0f9f5ec44b5.jpeg" alt=""></p><ul><li><p><strong>第 1 步</strong>：CPU 产生一个虚拟地址 VA；</p></li><li><p><strong>第 2 步至第 4 步</strong>：查询 TLB 失败，走正常的主存页表查询流程拿到 PTE，然后把它放入 TLB 缓存，以备下次查询，如果 TLB 此时的存储空间不足，则这个操作会汰换掉 TLB 中另一个已存在的 PTE；</p></li><li><p><strong>第 5 步</strong>：MMU 将这个虚拟地址 VA 翻译成一个真实的物理地址 PA，通过地址总线发送到高速缓存/主存中去；</p></li><li><p><strong>第 6 步</strong>：高速缓存/主存将物理地址 PA 上的数据返回给 CPU。</p></li></ul><h6 id="1-2-2-2-多级页表"><a href="#1-2-2-2-多级页表" class="headerlink" title="1.2.2.2 多级页表"></a>1.2.2.2 多级页表</h6><p>TLB 的引入可以一定程度上解决虚拟地址到物理地址翻译的开销问题，接下来还需要解决另一个问题：大页表。理论上一台 32 位的计算机的寻址空间是 4GB，也就是说每一个运行在该计算机上的进程理论上的虚拟寻址范围是 4GB。到目前为止，我们一直在讨论的都是单页表的情形，如果每一个进程都把理论上可用的内存页都装载进一个页表里，但是实际上进程会真正使用到的内存其实可能只有很小的一部分，而我们也知道页表也是保存在计算机主存中的，那么势必会造成大量的内存浪费，甚至有可能导致计算机物理内存不足从而无法并行地运行更多进程。</p><p>这个问题一般通过<strong>多级页表</strong>（Multi-Level Page Tables）来解决，通过把一个大页表进行拆分，形成多级的页表，我们具体来看一个二级页表应该如何设计：假定一个虚拟地址是 32 位，由 10 位的一级页表索引、10 位的二级页表索引以及 12 位的地址偏移量，则 PTE 是 4 字节，页面 page 大小是 2^12 = 4KB，总共需要 2^20 个 PTE，一级页表中的每个 PTE 负责映射虚拟地址空间中的一个 4MB 的 chunk，每一个 chunk 都由 1024 个连续的页面 Page 组成，如果寻址空间是 4GB，那么一共只需要 1024 个 PTE 就足够覆盖整个进程地址空间。二级页表中的每一个 PTE 都负责映射到一个 4KB 的虚拟内存页面，和单页表的原理是一样的。</p><p>多级页表的关键在于，我们并不需要为一级页表中的每一个 PTE 都分配一个二级页表，而只需要为进程当前使用到的地址做相应的分配和映射。因此，对于大部分进程来说，它们的一级页表中有大量空置的 PTE，那么这部分 PTE 对应的二级页表也将无需存在，这是一个相当可观的内存节约，事实上对于一个典型的程序来说，理论上的 4GB 可用虚拟内存地址空间绝大部分都会处于这样一种未分配的状态；更进一步，在程序运行过程中，只需要把一级页表放在主存中，虚拟内存系统可以在实际需要的时候才去创建、调入和调出二级页表，这样就可以确保只有那些最频繁被使用的二级页表才会常驻在主存中，此举亦极大地缓解了主存的压力。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/bad34c08b01d6c77b76912b26da30d36.jpeg" alt=""></p><h3 id="二、-内核空间-amp-用户空间"><a href="#二、-内核空间-amp-用户空间" class="headerlink" title="二、 内核空间 &amp; 用户空间"></a>二、 内核空间 &amp; 用户空间</h3><p>对 32 位操作系统而言，它的寻址空间（虚拟地址空间，或叫线性地址空间）为 4G（2 的 32 次方）。也就是说一个进程的最大地址空间为 4G。操作系统的核心是内核(kernel)，它独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证内核的安全，现在的操作系统一般都强制用户进程不能直接操作内核。具体的实现方式基本都是由操作系统将虚拟地址空间划分为两部分，一部分为内核空间，另一部分为用户空间。<strong>针对 Linux 操作系统而言，最高的 1G 字节(从虚拟地址 0xC0000000 到 0xFFFFFFFF)由内核使用，称为内核空间。而较低的 3G 字节(从虚拟地址 0x00000000 到 0xBFFFFFFF)由各个进程使用，称为用户空间。</strong></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/effb950b456c010be2c1863838539232.jpeg" alt=""></p><p><strong>为什么需要区分内核空间与用户空间？</strong> 在 CPU 的所有指令中，有些指令是非常危险的，如果错用，将导致系统崩溃，比如清内存、设置时钟等。如果允许所有的程序都可以使用这些指令，那么系统崩溃的概率将大大增加。所以，CPU 将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通应用程序只能使用那些不会造成灾难的指令。区分内核空间和用户空间本质上是要提高操作系统的稳定性及可用性。</p><h4 id="2-1-内核态与用户态"><a href="#2-1-内核态与用户态" class="headerlink" title="2.1 内核态与用户态"></a>2.1 内核态与用户态</h4><p><strong>当进程运行在内核空间时就处于内核态，而进程运行在用户空间时则处于用户态。</strong></p><p>在内核态下，进程运行在内核地址空间中，此时 CPU 可以执行任何指令。运行的代码也不受任何的限制，可以自由地访问任何有效地址，也可以直接进行端口的访问。</p><p>在用户态下，进程运行在用户地址空间中，被执行的代码要受到 CPU 的诸多检查，它们只能访问映射其地址空间的页表项中规定的在用户态下可访问页面的虚拟地址，且只能对任务状态段(TSS)中 I/O 许可位图(I/O Permission Bitmap)中规定的可访问端口进行直接访问。</p><p>对于以前的 DOS 操作系统来说，是没有内核空间、用户空间以及内核态、用户态这些概念的。可以认为所有的代码都是运行在内核态的，因而用户编写的应用程序代码可以很容易的让操作系统崩溃掉。</p><p>对于 Linux 来说，通过区分内核空间和用户空间的设计，隔离了操作系统代码(操作系统的代码要比应用程序的代码健壮很多)与应用程序代码。即便是单个应用程序出现错误也不会影响到操作系统的稳定性，这样其它的程序还可以正常的运行。</p><p><strong>如何从用户空间进入内核空间？</strong></p><p>其实所有的系统资源管理都是在内核空间中完成的。比如读写磁盘文件，分配回收内存，从网络接口读写数据等等。我们的应用程序是无法直接进行这样的操作的。但是我们可以通过内核提供的接口来完成这样的任务。比如应用程序要读取磁盘上的一个文件，它可以向内核发起一个 “系统调用” 告诉内核：“我要读取磁盘上的某某文件”。</p><p>其实就是通过一个特殊的指令让进程从用户态进入到内核态(到了内核空间)，在内核空间中，CPU 可以执行任何的指令，当然也包括从磁盘上读取数据。具体过程是先把数据读取到内核空间中，然后再把数据拷贝到用户空间并从内核态切换到用户态。此时应用程序已经从系统调用中返回并且拿到了想要的数据，可以开开心心的往下执行了。<strong>简单说就是应用程序把高科技的事情(从磁盘读取文件)外包给了系统内核，系统内核做这些事情既专业又高效</strong>。</p><h3 id="三、-IO"><a href="#三、-IO" class="headerlink" title="三、 IO"></a>三、 IO</h3><p>在进行 IO 操作时，通常需要经过如下两个阶段：</p><ul><li><p>数据准备阶段：数据从硬件到内核空间</p></li><li><p>数据拷贝阶段：数据从内核空间到用户空间</p></li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/e2cfee28c5a100ea68a38153dcf9793c.jpeg" alt=""></p><p>通常我们所说的 IO 的阻塞/非阻塞以及同步/异步，和这两个阶段关系密切：</p><ul><li><p>阻塞 IO 和非阻塞 IO 判定标准：数据准备阶段，应用程序是否阻塞等待操作系统将数据从硬件加载到内核空间；</p></li><li><p>同步 IO 和异步 IO 判定标准：数据拷贝阶段，数据是否备好后直接通知应用程序使用，无需等待拷贝；</p></li></ul><h4 id="3-1-同步-阻塞-IO"><a href="#3-1-同步-阻塞-IO" class="headerlink" title="3.1 (同步)阻塞 IO"></a>3.1 (同步)阻塞 IO</h4><p>阻塞 IO ：当用户发生了系统调用后，如果数据未从网卡到达内核态，内核态数据未准备好，此时会一直阻塞。直到数据就绪，然后从内核态拷贝到用户态再返回。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/c0de1da34667e8cbef5594b26dc4ca94.jpeg" alt=""></p><p>阻塞 IO 每个连接一个单独的线程进行处理，通常搭配<strong>多线程</strong>来应对大流量，但是，开辟线程的开销比较大，一个程序可以开辟的线程是有限的，面对百万连接的情况，是无法处理。非阻塞 IO 可以一定程度上解决上述问题。</p><h4 id="3-2-同步-非阻塞-IO"><a href="#3-2-同步-非阻塞-IO" class="headerlink" title="3.2 (同步)非阻塞 IO"></a>3.2 (同步)非阻塞 IO</h4><p>非阻塞 IO ：在第一阶段(网卡-内核态)数据未到达时不等待，然后直接返回。数据就绪后，从内核态拷贝到用户态再返回。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/b34a0a6e68cad5b2c42b7ee91fa66779.jpeg" alt=""></p><p>非阻塞 IO 解决了阻塞 IO<strong>每个连接一个线程处理的问题</strong>，所以其最大的优点就是 <strong>一个线程可以处理多个连接</strong>。然而，非阻塞 IO 需要用户多次发起系统调用。<strong>频繁的系统调用</strong>是比较消耗系统资源的。</p><h4 id="3-3-IO-多路复用"><a href="#3-3-IO-多路复用" class="headerlink" title="3.3 IO 多路复用"></a>3.3 IO 多路复用</h4><p>为了解决非阻塞 IO 存在的频繁的系统调用这个问题，随着内核的发展，出现了 IO 多路复用模型。</p><p><strong>IO 多路复用：通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，就可以返回。</strong></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/998d880ddd9c2d3d701c9bbd954087ff.jpeg" alt=""></p><p>IO 多路复用本质上复用了<strong>系统调用</strong>，使多个文件的状态可以复用一个系统调用获取，有效减少了系统调用。<strong>select、poll、epoll</strong>均是基于 IO 多路复用思想实现的。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9b456c33f6ce4bbae5da46ba95b7b0ac.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/ca0a713be436f72cbdfc8c14823d25f1.jpeg" alt="">select 和 poll 的工作原理比较相似，通过 select()或者 poll()将多个 socket fds 批量通过系统调用传递给内核，由内核进行循环遍历判断哪些 fd 上数据就绪了，然后将就绪的 readyfds 返回给用户。再由用户进行挨个遍历就绪好的 fd，读取或者写入数据。所以通过 IO 多路复用+非阻塞 IO，一方面降低了系统调用次数，另一方面可以用极少的线程来处理多个网络连接。<strong>select 和 poll 的最大区别是：select 默认能处理的最大连接是 1024 个，可以通过修改配置来改变，但终究是有限个；而 poll 理论上可以支持无限个。而 select 和 poll 则面临相似的问题在管理海量的连接时，会频繁的从用户态拷贝到内核态，比较消耗资源。</strong></p><p>epoll 有效规避了将 fd 频繁的从用户态拷贝到内核态，通过使用<strong>红黑树</strong>(RB-tree)<strong>搜索</strong>被监视的<strong>文件描述符</strong>(file descriptor)。在 epoll 实例上<strong>注册事件</strong>时，epoll 会将该<strong>事件添加到</strong> epoll 实例的<strong>红黑树</strong>上并<strong>注册一个回调函数</strong>，当<strong>事件发生时</strong>会将事件<strong>添加到就绪链表</strong>中。</p><h5 id="3-3-1-epoll-数据结构-算法"><a href="#3-3-1-epoll-数据结构-算法" class="headerlink" title="3.3.1 epoll 数据结构 + 算法"></a>3.3.1 epoll 数据结构 + 算法</h5><p>epoll 的核心数据结构是：1 个 <code>红黑树</code> 和 1 个 <code>双向链表</code>，还有 <code>3个核心API</code> 。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/85c388e7f99b46cccf2f2fd2bef2c971.jpeg" alt=""></p><h5 id="3-3-2-监视-socket-索引-红黑树"><a href="#3-3-2-监视-socket-索引-红黑树" class="headerlink" title="3.3.2 监视 socket 索引-红黑树"></a>3.3.2 监视 socket 索引-红黑树</h5><p>为什么采用红黑树呢？因为和 epoll 的工作机制有关。epoll 在添加一个 socket 或者删除一个 socket 或者修改一个 socket 的时候，它需要查询速度更快，操作效率最高，因此需要一个更加优秀的数据结构能够管理这些 socket。我们想到的比如链表，数组，二叉搜索树，B+树等都无法满足要求，</p><ul><li><p>因为链表在查询，删除的时候毫无疑问时间复杂度是 O(n)；</p></li><li><p>数组查询很快，但是删除和新增时间复杂度是 O(n)；</p></li><li><p>二叉搜索树虽然查询效率是 lgn，但是如果不是平衡的，那么就会退化为线性查找，复杂度直接来到 O(n)；</p></li><li><p>B+树是平衡多路查找树，主要是通过降低树的高度来存储上亿级别的数据，但是它的应用场景是内存放不下的时候能够用最少的 IO 访问次数从磁盘获取数据。比如数据库聚簇索引，成百上千万的数据内存无法满足查找就需要到内存查找，而因为 B+树层高很低，只需要几次磁盘 IO 就能获取数据到内存，所以在这种磁盘到内存访问上 B+树更适合。</p></li></ul><p>因为我们处理上万级的 fd，它们本身的存储空间并不会很大，所以倾向于在内存中去实现管理，而红黑树是一种非常优秀的平衡树，它完全是在内存中操作，而且查找，删除和新增时间复杂度都是 lgn，效率非常高，因此选择用红黑树实现 epoll 是最佳的选择。当然不选择用 AVL 树是因为红黑树是不符合 AVL 树的平衡条件的，红黑是用非严格的平衡来换取增删节点时候旋转次数的降低，任何不平衡都会在三次旋转之内解决；而 AVL 树是严格平衡树，在增加或者删除节点的时候，根据不同情况，旋转的次数比红黑树要多。所以红黑树的插入效率更高。</p><h5 id="3-3-2-就绪-socket-列表-双向链表"><a href="#3-3-2-就绪-socket-列表-双向链表" class="headerlink" title="3.3.2 就绪 socket 列表-双向链表"></a>3.3.2 就绪 socket 列表-双向链表</h5><p>就绪列表存储的是就绪的 socket，所以它应能够快速的插入数据。程序可能随时调用 epoll_ctl 添加监视 socket，也可能随时删除。当删除时，若该 socket 已经存放在就绪列表中，它也应该被移除。（事实上，每个 epoll_item 既是红黑树节点，也是链表节点，删除红黑树节点，自然删除了链表节点） 所以就绪列表应是一种能够快速插入和删除的数据结构。双向链表就是这样一种数据结构，epoll 使用 <code>双向链表来实现就绪队列</code> （rdllist）</p><h5 id="3-3-3-三个-API"><a href="#3-3-3-三个-API" class="headerlink" title="3.3.3 三个 API"></a>3.3.3 三个 API</h5><h6 id="3-3-3-1-int-epoll-create-int-size"><a href="#3-3-3-1-int-epoll-create-int-size" class="headerlink" title="3.3.3.1 int epoll_create(int size)"></a>3.3.3.1 int epoll_create(int size)</h6><p>功能：内核会产生一个 epoll 实例数据结构并返回一个文件描述符 epfd，这个特殊的描述符就是 epoll 实例的句柄，后面的两个接口都以它为中心。同时也会创建红黑树和就绪列表，红黑树来管理注册 fd，就绪列表来收集所有就绪 fd。size 参数表示所要监视文件描述符的最大值，不过在后来的 Linux 版本中已经被弃用（同时，size 不要传 0，会报 invalid argument 错误）</p><h6 id="3-3-3-2-int-epoll-ctl-int-epfd，-int-op，-int-fd，-struct-epoll-event-event"><a href="#3-3-3-2-int-epoll-ctl-int-epfd，-int-op，-int-fd，-struct-epoll-event-event" class="headerlink" title="3.3.3.2 int epoll_ctl(int epfd， int op， int fd， struct epoll_event *event)"></a>3.3.3.2 int epoll_ctl(int epfd， int op， int fd， struct epoll_event *event)</h6><p>功能：将被监听的 socket 文件描述符添加到红黑树或从红黑树中删除或者对监听事件进行修改；同时向内核中断处理程序注册一个回调函数，内核在检测到某文件描述符可读/可写时会调用回调函数，该回调函数将文件描述符放在就绪链表中。</p><h6 id="3-3-3-3-int-epoll-wait-int-epfd，-struct-epoll-event-events，-int-maxevents，-int-timeout"><a href="#3-3-3-3-int-epoll-wait-int-epfd，-struct-epoll-event-events，-int-maxevents，-int-timeout" class="headerlink" title="3.3.3.3 int epoll_wait(int epfd， struct epoll_event *events， int maxevents， int timeout);"></a>3.3.3.3 int epoll_wait(int epfd， struct epoll_event *events， int maxevents， int timeout);</h6><p>功能：阻塞等待注册的事件发生，返回事件的数目，并将触发的事件写入 events 数组中。events: 用来记录被触发的 events，其大小应该和 maxevents 一致 maxevents: 返回的 events 的最大个数处于 ready 状态的那些文件描述符会被复制进 ready list 中，epoll_wait 用于向用户进程返回 ready list(就绪列表)。events 和 maxevents 两个参数描述一个由用户分配的 struct epoll event 数组，调用返回时，内核将就绪列表(双向链表)复制到这个数组中，并将实际复制的个数作为返回值。注意，如果就绪列表比 maxevents 长，则只能复制前 maxevents 个成员；反之，则能够完全复制就绪列表。另外，struct epoll event 结构中的 events 域在这里的解释是：<code>在被监测的文件描述符上实际发生的事件</code>。</p><h5 id="3-3-4-工作模式"><a href="#3-3-4-工作模式" class="headerlink" title="3.3.4 工作模式"></a>3.3.4 工作模式</h5><p>epoll 对文件描述符的操作有两种模式：LT（level trigger）和 ET（edge trigger）。</p><ol><li><p>LT 模式 LT(level triggered)是缺省的工作方式，并且同时支持 block 和 no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的 fd 进行 IO 操作。<strong>如果你不作任何操作，内核还是会继续通知你</strong>。</p></li><li><p>ET 模式 ET(edge-triggered)是高速工作方式，只支持 no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过 epoll 告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个 EWOULDBLOCK 错误）。注意，<strong>如果一直不对这个 fd 作 IO 操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)</strong> ET 模式在很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。epoll 工作在 ET 模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。</p></li></ol><h4 id="3-4-网络-IO-模型"><a href="#3-4-网络-IO-模型" class="headerlink" title="3.4 网络 IO 模型"></a>3.4 网络 IO 模型</h4><p>实际的网络模型常结合 I/O 复用和线程池实现，如 Reactor 模式：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/cf90b0dba698dea826fd824fd117b56f.jpeg" alt=""></p><h5 id="3-4-1-单-reactor-单线程模型"><a href="#3-4-1-单-reactor-单线程模型" class="headerlink" title="3.4.1 单 reactor 单线程模型"></a>3.4.1 单 reactor 单线程模型</h5><p>此种模型通常只有一个 epoll 对象，所有的<strong>接收客户端连接</strong>、<strong>客户端读取</strong>、<strong>客户端写入</strong>操作都包含在一个线程内。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/2ed08ede5eaba9a023e05449199526df.jpeg" alt=""></p><blockquote><p>优点：模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成 缺点：单线程无法完全发挥多核 CPU 的性能；I/O 操作和非 I/O 的业务操作在一个 Reactor 线程完成，这可能会大大延迟 I/O 请求的响应；线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障；使用场景：客户端的数量有限，业务处理非常快速，比如 Redis 在业务处理的时间复杂度 O(1) 的情况</p></blockquote><h5 id="3-4-2-单-reactor-多线程模型"><a href="#3-4-2-单-reactor-多线程模型" class="headerlink" title="3.4.2 单 reactor 多线程模型"></a>3.4.2 单 reactor 多线程模型</h5><p>该模型将读写的业务逻辑交给具体的线程池来处理</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/0a1ecbdee77d688e467530b3a6f6adcf.jpeg" alt=""></p><blockquote><p>优点：充分利用多核 cpu 的处理能力，提升 I/O 响应速度；缺点：在该模式中，虽然非 I/O 操作交给了线程池来处理，但是所有的 I/O 操作依然由 Reactor 单线程执行，在高负载、高并发或大数据量的应用场景，依然容易成为瓶颈。</p></blockquote><h5 id="3-4-3-multi-reactor-多线程模型"><a href="#3-4-3-multi-reactor-多线程模型" class="headerlink" title="3.4.3 multi-reactor 多线程模型"></a>3.4.3 multi-reactor 多线程模型</h5><p>在这种模型中，主要分为两个部分：mainReactor、subReactors。mainReactor 主要负责接收客户端的连接，然后将建立的客户端连接通过负载均衡的方式分发给 subReactors，subReactors 来负责具体的每个连接的读写 对于非 IO 的操作，依然交给工作线程池去做。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/5ff32c5eb1a360233d3e85a33b0cdff4.jpeg" alt=""></p><blockquote><p>优点：父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。缺点：编程复杂度较高。</p></blockquote><h5 id="3-4-4-主流的中间件所采用的网络模型"><a href="#3-4-4-主流的中间件所采用的网络模型" class="headerlink" title="3.4.4 主流的中间件所采用的网络模型"></a>3.4.4 主流的中间件所采用的网络模型</h5><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/c68c63136f34cb6adf8a87858ae46ab1.jpeg" alt=""></p><h4 id="3-5-异步-IO"><a href="#3-5-异步-IO" class="headerlink" title="3.5 异步 IO"></a>3.5 异步 IO</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/cbd5a0b719c7a7b38dbf00226f23e455.jpeg" alt=""></p><p>前面介绍的所有网络 IO 都是同步 IO，因为当数据在内核态就绪时，在内核态拷贝用用户态的过程中，仍然会有短暂时间的阻塞等待。而异步 IO 指：<strong>内核态拷贝数据到用户态这种方式也是交给系统线程来实现，不由用户线程完成</strong>，如 windows 的 IOCP ，Linux 的 AIO。</p><h3 id="四、-零拷贝"><a href="#四、-零拷贝" class="headerlink" title="四、 零拷贝"></a>四、 零拷贝</h3><h4 id="4-1-传统-IO-流程"><a href="#4-1-传统-IO-流程" class="headerlink" title="4.1 传统 IO 流程"></a>4.1 传统 IO 流程</h4><p>传统 IO 流程会经过如下两个过程：</p><ul><li><p>数据准备阶段：数据从硬件到内核空间</p></li><li><p>数据拷贝阶段：数据从内核空间到用户空间</p></li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/e2cfee28c5a100ea68a38153dcf9793c.jpeg" alt=""></p><p><strong>零拷贝</strong>：<strong>指数据无需从硬件到内核空间或从内核空间到用户空间</strong>。下面介绍常见的零拷贝实现</p><h4 id="4-2-mmap-write"><a href="#4-2-mmap-write" class="headerlink" title="4.2 mmap + write"></a>4.2 mmap + write</h4><p>mmap 将内核中读缓冲区（read buffer）的地址与用户空间的缓冲区（user buffer）进行映射，从而实现内核缓冲区与应用程序内存的共享，省去了将数据从内核读缓冲区（read buffer）拷贝到用户缓冲区（user buffer）的过程，整个拷贝过程会发生 4 次上下文切换，1 次 CPU 拷贝和 2 次 DMA 拷贝。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/8482fa20e9455550b8e25032cd20ccbf.jpeg" alt=""></p><h4 id="4-3-sendfile"><a href="#4-3-sendfile" class="headerlink" title="4.3 sendfile"></a>4.3 sendfile</h4><p>通过 sendfile 系统调用，数据可以直接在内核空间内部进行 I/O 传输，从而省去了数据在用户空间和内核空间之间的来回拷贝，sendfile 调用中 I/O 数据对用户空间是完全不可见的，整个拷贝过程会发生 2 次上下文切换，1 次 CPU 拷贝和 2 次 DMA 拷贝。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/89f778577f40e19c23748f21c82e2c51.jpeg" alt=""></p><h4 id="4-4-Sendfile-DMA-gather-copy"><a href="#4-4-Sendfile-DMA-gather-copy" class="headerlink" title="4.4 Sendfile + DMA gather copy"></a>4.4 Sendfile + DMA gather copy</h4><p>Linux2.4 引入 ，将内核空间的读缓冲区（read buffer）中对应的数据描述信息（内存地址、地址偏移量）记录到相应的网络缓冲区（socketbuffer）中，由 DMA 根据内存地址、地址偏移量将数据批量地从读缓冲区（read buffer）拷贝到网卡设备中，这样就省去了内核空间中仅剩的 1 次 CPU 拷贝操作，发生 2 次上下文切换、0 次 CPU 拷贝以及 2 次 DMA 拷贝；</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/6cc539da52a0d32f4e36ae89e9b7c1ca.jpeg" alt=""></p><h4 id="4-5-splice"><a href="#4-5-splice" class="headerlink" title="4.5 splice"></a>4.5 splice</h4><p>Linux2.6.17 版本引入，在内核空间的读缓冲区（read buffer）和网络缓冲区（socket buffer）之间建立管道（pipeline），从而避免了两者之间的 CPU 拷贝操作，2 次上下文切换，0 次 CPU 拷贝以及 2 次 DMA 拷贝。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/779b9e255ca08024aded9192cece40a5.jpeg" alt=""></p><h4 id="4-6-写时复制"><a href="#4-6-写时复制" class="headerlink" title="4.6 写时复制"></a>4.6 写时复制</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/6b8ab04aa70093ac436b166c992301d1.jpeg" alt=""></p><p>通过尽量延迟产生私有对象中的副本，写时复制最充分地利用了稀有的物理资源。</p><h4 id="4-7-Java-中零拷贝"><a href="#4-7-Java-中零拷贝" class="headerlink" title="4.7 Java 中零拷贝"></a>4.7 Java 中零拷贝</h4><p>MappedByteBuffer：基于内存映射（mmap）这种零拷贝方式的提供的一种实现。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/5f70d5501ab14bc25a572bdcd130ddc4.jpeg" alt=""></p><p>FileChannel 基于 sendfile 定义了 transferFrom() 和 transferTo() 两个抽象方法，它通过在通道和通道之间建立连接实现数据传输的。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/02948becb7b768ca44258f57ea453984.jpeg" alt=""></p><p><strong>五、参考</strong></p><p><a href="https://mp.weixin.qq.com/s/c81Fvws0J2tHjcdTgxvv6g">https://mp.weixin.qq.com/s/c81Fvws0J2tHjcdTgxvv6g</a></p><p><a href="https://blog.csdn.net/Chasing\_\_Dreams/article/details/106297351">https://blog.csdn.net/Chasing\_\_Dreams/article/details/106297351</a></p><p><a href="https://mp.weixin.qq.com/s/EDzFOo3gcivOe\_RgipkTkQ">https://mp.weixin.qq.com/s/EDzFOo3gcivOe\_RgipkTkQ</a></p><p><a href="https://mp.weixin.qq.com/s/G6TfGbc4U8Zhv30wnN0HIg">https://mp.weixin.qq.com/s/G6TfGbc4U8Zhv30wnN0HIg</a></p><p><a href="https://www.modb.pro/db/189656">https://www.modb.pro/db/189656</a></p><p><a href="https://mp.weixin.qq.com/s/r9RU4RoE-qrzXPAwiej5sw">https://mp.weixin.qq.com/s/r9RU4RoE-qrzXPAwiej5sw</a></p><p>本文转自 <a href="https://mp.weixin.qq.com/s/DMWfSxrbu4kgCh4JCQ4XIQ">https://mp.weixin.qq.com/s/DMWfSxrbu4kgCh4JCQ4XIQ</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CPU 是如何与内存交互的</title>
      <link href="/posts/ae8caf24/"/>
      <url>/posts/ae8caf24/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>这篇文章主要整理了一下计算机中的内存结构，以及 CPU 是如何读写内存中的数据的，如何维护 CPU 缓存中的数据一致性。什么是虚拟内存，以及它存在的必要性。如有不对请多多指教。</p><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>目前在计算机中，主要有两大存储器 SRAM 和 DRAM。主存储器是由 DRAM 实现的，也就是我们常说的内存，在 CPU 里通常会有 L1、L2、L3 这样三层高速缓存是用 SRAM 实现的。</p><p>SRAM 被称为“静态”存储器，是因为只要处在通电状态，里面的数据就可以保持存在。而一旦断电，里面的数据就会丢失了。</p><p>目前 SRAM 主要集成在 CPU 里面，每个 CPU 核心都有一块属于自己的 L1 高速缓存，通常分成指令缓存和数据缓存，分开存放 CPU 使用的指令和数据。L2 的 Cache 同样是每个 CPU 核心都有的，不过它往往不在 CPU 核心的内部。所以，L2 cache 的访问速度会比 L1 稍微慢一些。而 L3 cache ，则通常是多个 CPU 核心共用的。</p><p>在 DRAM 中存储单元使用电容保存电荷的方式来存储数据，电容会不断漏电，所以需要定时刷新充电，才能保持数据不丢失，这也是被称为“动态”存储器的原因。由于存储 DRAM 一个 bit 只需要一个晶体管，所以存储的数据也大很多。</p><p>我们来看一些他们的速度：</p><ul><li><p>• L1 的存取速度：<strong>4 个 CPU 时钟周期</strong></p></li><li><p>• L2 的存取速度：<strong>11 个 CPU 时钟周期</strong></p></li><li><p>• L3 的存取速度：<strong>39 个 CPU 时钟周期</strong></p></li><li><p>• DRAM 内存的存取速度<strong>：107 个 CPU 时钟周期</strong></p></li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/b14b3754d0c03096c5d359883c0ad31b.jpeg" alt=""></p><h3 id="CPU-cache"><a href="#CPU-cache" class="headerlink" title="CPU cache"></a>CPU cache</h3><h4 id="cache-结构"><a href="#cache-结构" class="headerlink" title="cache 结构"></a>cache 结构</h4><p>上面我们说了，对于 CPU 来说，SRAM 被称为 CPU 的 cache，CPU 每次获取数据都会先访问 cache，如果获取不到数据则把数据加载到 cache 中进行访问。因为 cache 的大小是远远小于主存的，所以还需要在 cache 和主存之间维护一个映射关系，这样才能正确找到数据。</p><p>一种简单的方式是<strong>直接映射</strong>，有点像我们把数据找出来，直接放入到 map 中进行存储一样，映射通过地址和 cache 的数量进行取模后获取到 cache 中主存的地址去获取数据。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">（地址）mod（cache 中的块数）  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/5cc0841ec407e3320a93ba8f5bb92f16.jpeg" alt=""></p><p>上图中画了一个地址去找 cache 的情况。对于 cache 来说可以划分为：</p><p>索引：用来取模找到对应的 cache 行；</p><p>有效位：cache 初始值一开始是空的，这个字段标记 cache 行是否有数据；</p><p>标记：用来和地址进行比较是否是对应的数据；</p><p>数据：表示存储的实际的数据，可以通过地址的偏移来获取到对应的数据；</p><p>比如对于这个 cache 有 1024 个字，即 4KB。假设有一个 32 位的地址要去 cache 中查找数据，那么会取地址 10 位进行取模找到对应的 cache 行，然后取出 20 位与 cahce 标记位进行比较，如果相等，并且有效位开启，那么对应请求地址在 cache 中命中。否则，发生缺失。</p><p>由于 CPU 在读取数据的时候，并不是要读取一整个 Block，而是读取一个他需要的数据片段， cache 中命中之后会根据低两位的偏移去数据里面索引到对应的字。</p><p>除了上面说的<strong>直接映射</strong>以外还有<strong>组相联</strong>和<strong>全相联</strong>。</p><p><strong>组相联</strong>就是使用组索引代替了原来的索引，下图中表示每组有 2 行数据，通过组索引找到对应的数据行之后通过有效位和标记对组中每一行进行检索，如果能匹配上就说明命中。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/ee1f8bb11329452752271fa32b4b045d.jpeg" alt=""></p><h4 id="cache-读写操作"><a href="#cache-读写操作" class="headerlink" title="cache 读写操作"></a>cache 读写操作</h4><p>先来看看读操作，cache 在初始状态的时候是空的，这个时候去读数据会产生 <strong>cache 缺失（cache miss）</strong>。cache 控制器会检测到缺失的发生，然后从主存中（或低一级 cache）中取回所需数据。如果命中，那么就会直接使用。</p><p>当 cache 缺失时，对于乱序执行处理器而言依然能执行一些其他指令，但是对于顺序执行处理器，当 cache 缺失时会被阻塞，临时寄存器和程序员可见的寄存器中的内容基本被冻结。</p><p>再来看看写操作，因为 cache 是由多级组成，所以写策略一般而言有两种：<strong>写直达（write-through）</strong>和<strong>写回（write-back）</strong>。通过这两种策略使在 cache 中写入的数据和主存中的数据保持一致。</p><p><strong>写直达</strong>就是在将数据写入 cache 之后同时将这个数据立马写入到主存中，但是由于主存和 cache 本身性能差异，那么每次在写入主存的时候都将花费大量的时间。解决办法就是加一层写缓冲（write buffer），这样 CPU 在将数据写入 cache 和缓冲之后可以继续执行，等到缓冲写入到主存中再释放。</p><p>但是如果写入速度大于缓冲释放速度，那么还是会阻塞 CPU 执行。那么可以考虑一下<strong>写回</strong>策略，这种机制会在每次写入的时候仅将新值写入 cache 中，只有当修改过的块被替换时才需要写到较低层存储结构中。</p><h4 id="一致性与-MESI-协议"><a href="#一致性与-MESI-协议" class="headerlink" title="一致性与 MESI 协议"></a>一致性与 MESI 协议</h4><p>由于现在都是多核 CPU，并且 cache 分了多级，并且数据存在共享的情况，所以需要一种机制保证在不同的核中看到的 cache 数据必须时一致的。最常用来处理多核 CPU 之间的缓存一致性协议就是 <strong>MESI 协议</strong>。</p><p><strong>MESI 协议</strong>，是一种叫作写失效（Write Invalidate）的协议。在写失效协议里，只有一个 CPU 核心负责写入数据，其他的核心，只是同步读取到这个写入。在这个 CPU 核心写入 cache 之后，它会去广播一个“失效”请求告诉所有其他的 CPU 核心。</p><p>MESI 协议对应的四个不同的标记，分别是：</p><ul><li><p>• M：代表已修改（Modified）</p></li><li><p>• E：代表独占（Exclusive）</p></li><li><p>• S：代表共享（Shared）</p></li><li><p>• I：代表已失效（Invalidated）</p></li></ul><p>“已修改”和“已失效”比较容易理解，我们来看看 独占”和“共享” 两个状态。</p><p>在独占状态下，对应的 cache Line 只加载到了当前 CPU 核所拥有的 cache 里。其他的 CPU 核，并没有加载对应的数据到自己的 cache 里。这个时候，如果要向独占的 cache Block 写入数据，我们可以自由地写入数据，而不需要告知其他 CPU 核。</p><p>那么对应的，共享状态就是在多核中同时加载了同一份数据。所以在共享状态下想要修改数据要先向所有的其他 CPU 核心广播一个请求，要求先把其他 CPU 核心里面的 cache ，都变成无效的状态，然后再更新当前 cache 里面的数据。</p><h3 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h3><h4 id="虚拟内存映射"><a href="#虚拟内存映射" class="headerlink" title="虚拟内存映射"></a>虚拟内存映射</h4><p>在我们日常使用的 Linux 或者 Windows 操作系统下，程序并不能直接访问物理内存。程序都是通过虚拟地址 VA（virtual address）用地址转换翻译成 PA 物理地址（physical address）才能获取到数据。也就是说 CPU 操作的实际上是一个虚拟地址 VA。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/bc3d6618bc65dbf51184e23850fad845.jpeg" alt=""></p><p>如上图，CPU 访问主存的时候会将一个虚拟地址（virtual address）被内存管理单元（Memory Management Unint, MMU）进行翻译成物理地址 PA（physical address） 才能访问。</p><p>想要把虚拟内存地址，映射到物理内存地址，最直观的办法，就是来建一张映射表。这个映射表在计算机中叫页表（Page Table）。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/6941e28000f79dc56bb528fe0b1ce7f3.jpeg" alt=""></p><p>在查找页表的时候，会将虚拟地址分成页号（Directory）和偏移量（Offset）两个部分。前面的高位，表示内存地址的页号。后面的低位，表示内存地址里面的偏移量。</p><p>查找方式和上面说的组相联类似，首先使用虚拟页号作为索引去页表中找到对应的物理页号，页表中还会有 1 位表示有效位，如果该位无效就不在主存中，发生一次缺页；如果有效，那么就可以拿到对应的物理页号获取到对应的物理页位置，再根据偏移量得到物理内存地址。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/a7d002f01dfd2d9909f1c38c6eb6b07c.jpeg" alt=""></p><p>如果有效位关闭，那么该页就只存在磁盘上的某个指定的磁盘地址。缺页会触发缺页异常，然后在闪存或磁盘中找到该页，将其放入到主存 DRAM 中。</p><p>如果主存满了，那么会选择一个牺牲页，大多数操作系统会使用 LRU 替换策略来进行页的替换。操作系统会查找最少使用的页，被替换的页会写入磁盘的交换区（swap 分区）。swap 分区通常被称为交换分区，这是一块特殊的硬盘空间，即当实际内存不够用的时候，操作系统会从内存中取出一部分暂时不用的数据，放在交换分区中，从而为当前运行的程序腾出足够的内存空间。</p><p>在下图中假设选择将存放在主存中的 VP6 进行替换，将 VP6 替换为 VP3。如果被替代的 VP6 已经被修改了，那么内核会将它复制回磁盘。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/2ec2784f014c202150119418d021dba2.jpeg" alt=""></p><p>由于局部性（locality）的存在，程序一般而言会在一个较小的活动页面集合上工作，页的切换开销只存在于程序启动时将页面调度到内存中，接下来的程序都会页命中。但是如果代码的工作集太大，超过了物理内存大小，那么页面就会不停地换进换出，产生抖动。</p><h4 id="多级页表"><a href="#多级页表" class="headerlink" title="多级页表"></a>多级页表</h4><p>假设我们现在是一个 32 位的地址空间、4KB 的页面和一个 4 字节的 PTE，那么需要一个 4MB 的页表常驻在内存中，并且这个页表是每个进程都独占一份，所以会造成很大的内存浪费，我们需要一种方式来优化我们的页表空间存储。</p><p>想一下虚拟内存空间结构，整个 4 GB 的空间，操作系统用了 1 GB，从地址 <code>0XC0000000</code> 到 <code>0XFFFFFFFF</code>, 剩余 3 GB 留给用户空间，其实很多程序根本用不到这么大的空间，对于 64 位系统，每个进程都会拥有 256 TiB 的内存空间，那就更加用不上了。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/98b3c392db80b2d72c28c55de0714c05.jpeg" alt=""></p><p>那么对于用不上的空间，我们可以不可以不把它加载到页表里面，等到用这块空间的时候才在页表里面给它分配一个页表项，是不是就可以节省大量空间。</p><p>在程序运行的时候，内存地址从顶部往下，不断分配占用的栈的空间。而堆的空间，内存地址则是从底部往上，是不断分配占用的。所以，在一个实际的程序进程里面，虚拟内存占用的地址空间，通常是两段连续的空间。而多级页表，就特别适合这样的内存地址分布。</p><p>假设 32 位虚拟地址空间被划分位 4KB 每页，每个条目都是 4 字节，那么我们可以让第一级页表中的每个 PTE （页表项 page table entry）负责映射虚拟地址空间中一个 4MB 的片，这个片由 1024 个连续页面组成，表示二级页表。如果地址空间是 4GB，那么 1024 个一级页表项就可以覆盖整个空间。</p><p>如下图所示，内存前 2K 个页面给代码和数据，接下来 6K 个页面未分配，在接下来 1023 个页面也未分配，接下来一个页面分配给用户栈。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/16172e0f3c5c65305f99ea39871e3895.jpeg" alt=""></p><p>这种方法从两个方面减少了内存占用。第一，如果一级页表中的一个 PTE 是空的，那么相应的二级页表就根本不会存在。由于很多程序占用内存实际远小于页表所能表示的大小，所以可以节约很大空间的页表项资源；第二，只有一级页表才需要总是在主存中，二级页表会在需要的时候创建或销毁，只有最经常使用的二级页表才需要缓存在主存中，这就减少了主存的压力。</p><p>Linux 在 2.6.10 中引入了四层的页表辅助虚拟地址的转换：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/b1a1b07ea37f266e39265c841847405b.jpeg" alt=""></p><p>首先会找到 4 级页表里面对应的条目（Entry）。这个条目里存放的是一张 3 级页表所在的位置。4 级页面里面的每一个条目，都对应着一张 3 级页表，所以我们可能有多张 3 级页表。</p><p>找到对应这张 3 级页表之后，我们用 3 级索引去找到对应的 3 级索引的条目。3 级索引的条目再会指向一个 2 级页表。依次拿到 1 级页表里面存储的物理页号，我们同样可以用“页号 + 偏移量”的方式，来获取最终的物理内存地址。</p><h4 id="TLB-加速地址转换"><a href="#TLB-加速地址转换" class="headerlink" title="TLB 加速地址转换"></a>TLB 加速地址转换</h4><p>对于一个页命中的数据获取过程通常来说，如果没有 TLB 加速是这样的：</p><ol><li><p>CPU 生成一个虚拟地址，并把它传给 MMU；</p></li><li><p>MMU 生成页表项地址 PTEA，并从高速缓存/主存请求获取页表项 PTE；</p></li><li><p>高速缓存/主存向 MMU 返回 PTE；</p></li><li><p>MMU 构造物理地址 PA，并把它传给高速缓存/主存；</p></li><li><p>高速缓存/主存返回所请求的数据给 CPU。</p></li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/f5aa98cbf4cdb02f7ab6ff52400c9dec.jpeg" alt=""></p><p>一次简单的数据获取需要多次经过多次与内存的交互，如果是 4 级页表，那么就需要访问 4 次内存才能获取到对应的物理页号。如果是缺页，还需要有一个 PTE 的置换或加载过程。在开头也讲了，访问内存的性能其实很低的，实际上这严重影响了 CPU 处理性能。</p><p>程序所需要使用的指令，都顺序存放在虚拟内存里面。我们执行的指令，也是一条条顺序执行下去的。也就是说，我们对于指令地址的访问，存在前面几讲所说的“空间局部性”和“时间局部性”，而需要访问的数据也是一样的。我们连续执行了 5 条指令。因为内存地址都是连续的，所以我们可以通过加缓存的方法，把之前内存转换的地址缓存下来，减少与内存的交互。</p><p>加的这一层就是<strong>缓存芯片 TLB</strong> （Translation Lookaside Buffer），它里面每一行保存着一个由单个 PTE 组成的块。</p><p>那么查询数据的过程就变成了：</p><ol><li><p>CPU 产生一个虚拟地址；</p></li><li><p>MMU 从 TLB 中取出相应的 PTE；</p></li><li><p>MMU 将这个虚拟地址翻译成一个物理地址，并且将它发送到高速缓存/主存；</p></li><li><p>高速缓存/主存将所请求的数据字返回给 CPU；</p></li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/12fae7e53bca04b943a6f22a467053b9.jpeg" alt=""></p><h4 id="最后来看看为什么需要虚拟内存？"><a href="#最后来看看为什么需要虚拟内存？" class="headerlink" title="最后来看看为什么需要虚拟内存？"></a>最后来看看为什么需要虚拟内存？</h4><p>讲完了什么是虚拟内存，我们最后讲讲虚拟内存的必要性。</p><p>由于操作虚拟内存实际上就是操作页表，从上面讲解我们知道，页表的大小其实和物理内存没有关系，当物理内存不够用时可以通过页缺失来将需要的数据<strong>置换</strong>到内存中，内存中只需要存放众多程序中活跃的那部分，不需要将整个程序加载到内存里面，这可以让小内存的机器也可以运行程序。</p><p>虚拟内存可以为正在运行的进程提供独立的内存空间，制造一种每个进程的内存都是独立的假象。虚拟内存空间只是操作系统中的逻辑结构，通过多层的页表结构来转换虚拟地址，可以让多个进程可以通过虚拟内存<strong>共享物理内存</strong>。</p><p>并且独立的虚拟内存空间也会<strong>简化内存</strong>的分配过程，当用户程序向操作系统申请堆内存时，操作系统可以分配几个连续的虚拟页，但是这些虚拟页可以对应到物理内存中不连续的页中。</p><p>再来就是提供了<strong>内存保护机制</strong>。任何现代计算机系统必须为操作系统提供手段来控制对内存系统的访问。虚拟内存中页表中页存放了读权限、写权限和执行权限。内存管理单元可以决定当前进程是否有权限访问目标的物理内存，这样我们就最终将权限管理的功能全部收敛到虚拟内存系统中，减少了可能出现风险的代码路径。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>从上面我们可以知道 CPU 的缓存结构一般由 L1、L2、L3 三层缓存结构组成，CPU 读取数据只与缓存交互，不会直接访问主存，所以 CPU 缓存和主存之间维护了一套映射关系。当被查找的数据发生缺失时，需要等待数据从主存加载到缓存中，如果缓存满了，那么还需要进行淘汰。如果被淘汰的数据是脏数据，那么还需要写回到主存中，写的策略有写直达（write-through）和写回（write-back）。</p><p>由于现在计算机中的 CPU 都是多核的，并且缓存数据是由多核共享的，所以就有了类似 MESI 这样的协议来维护一个状态机保证数据在多核之间是一致的。</p><p>为了访问数据安全，便捷，迅速所以加了一层虚拟内存，每个程序在启动的时候都会维护一个页表，这个页表维护了一套映射关系。CPU 操作的实际上是虚拟地址，每次需要 MMU 将虚拟地址在页表上映射成物理地址后查找数据。并且为了节省内存所以设计了多级页表，为了从页表中查找数据更快加了一个缓存芯片 TLB。</p><h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h4><p>《深入理解计算机系统》</p><p>《深入浅出计算机组成原理》</p><p>《计算机组成与设计：硬件软件接口》</p><p><a href="https://draveness.me/whys-the-design-os-virtual-memory/">https://draveness.me/whys-the-design-os-virtual-memory/</a></p><p><a href="https://people.freebsd.org/~lstewart/articles/cpumemory.pdf">https://people.freebsd.org/~lstewart/articles/cpumemory.pdf</a></p><p>本文转自 <a href="https://mp.weixin.qq.com/s/SaaHKPnNUSvDkmwKtip3HA">https://mp.weixin.qq.com/s/SaaHKPnNUSvDkmwKtip3HA</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>带你走进 Redis</title>
      <link href="/posts/4bdcd1db/"/>
      <url>/posts/4bdcd1db/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><blockquote><p>本文主要讲述 Redis 的基础知识和常识性内容，帮助大家了解和熟悉 Redis；后续通过阅读源码、实践 Redis 后会总结相关的知识点，再继续分享给大家。</p></blockquote><h3 id="一、什么是-Redis"><a href="#一、什么是-Redis" class="headerlink" title="一、什么是 Redis"></a>一、什么是 Redis</h3><p>Redis 是一个开源、基于内存、使用 C 语言编写的 key-value 数据库，并提供了多种语言的 API。它的数据结构十分丰富，基础数据类型包括：string（字符串）、list（列表，双向链表）、hash（散列，键值对集合）、set（集合，不重复）和 sorted set（有序集合）。主要可以用于数据库、缓存、分布式锁、消息队列等…</p><p>以上的数据类型是 Redis 键值的数据类型，其实就是数据的保存形式，但是数据类型的底层实现是最重要的，底层的数据结构主要分为 6 种，分别是<strong>简单动态字符串</strong>、<strong>双向链表</strong>、<strong>压缩链表</strong>、<strong>哈希表</strong>、<strong>跳表</strong>和<strong>整数数组</strong>。各个数据类型和底层结构的对应关系如下：</p><p>数据类型和底层结构的对应关系</p><table><thead><tr><th>string</th><th>list</th><th>hash</th><th>set</th><th>sorted set</th></tr></thead><tbody><tr><td>简单动态字符串</td><td>双向链表、压缩链表</td><td>压缩链表、哈希表</td><td>压缩链表、整数数组</td><td>压缩链表、跳表</td></tr></tbody></table><p>底层实现的时间复杂度</p><table><thead><tr><th>跳表</th><th>双向链表</th><th>压缩链表</th><th>哈希表</th><th>整数数组</th></tr></thead><tbody><tr><td>O(logN)</td><td>O(N)</td><td>O(N)</td><td>O(1)</td><td>O(N)</td></tr></tbody></table><p>可以看出除了 string 类型的底层实现只有一种数据结构，其他四种均有两种底层实现，这四种类型为集合类型，其中一个键对应了一个集合的数据；</p><h4 id="1-1-Redis-键值是如何保存的呢？"><a href="#1-1-Redis-键值是如何保存的呢？" class="headerlink" title="1.1 Redis 键值是如何保存的呢？"></a>1.1 <strong>Redis 键值是如何保存的呢？</strong></h4><p>Redis 为了快速访问键值对，采用了<strong>哈希表</strong>来保存所有的键值对，一个哈希表对应了多个<strong>哈希桶</strong>，所谓的哈希桶是指哈希表数组中的每一个元素，当然哈希表中保存的不是值本身，是指向值的指针，如下图。</p><p>其中哈希桶中的 entry 元素中保存了_key 和_value 指针，分别指向了实际的键和值。通过 Redis 可以在 O(1)的时间内找到键值对，只需要计算 key 的哈希值就可以定位位置，但从下图可以看出，在 4 号位置出现了冲突，两个 key 映射到了同一个位置，这就产生了哈希冲突，会导致哈希表的操作变慢。虽然 Redis 通过链式冲突解决该问题，但如果数据持续增多，产生的哈希冲突也会越来越多，会加重 Redis 的查询时间；</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/d413243ae164480481917d1ac5c09364.png" alt="">Redis 保存数据示意图</p><p>为了解决上述的哈希冲突问题，Redis 会对哈希表进行<strong>rehash</strong>操作，也就是增加目前的哈希桶数量，使得 key 更加分散，进而减少哈希冲突的问题，主要流程如下：</p><ol><li><p>采用两个 hash 表进行操作，当哈希表 A 需要进行扩容时，给哈希表 B 分配两倍的空间；</p></li><li><p>将哈希表 A 的数据重新映射并拷贝给哈希表 B；</p></li><li><p>释放 A 的空间。</p></li></ol><p>上述的步骤可能会存在一个问题，当哈希表 A 向 B 复制的时候，是需要一定的时间的，可能会造成 Redis 的线程阻塞，就无法服务其他的请求了。</p><p>针对上述问题，Redis 采用了<strong>渐进式 rehash</strong>，主要的流程是：Redis 还是继续处理客户端的请求，每次处理一个请求的时候，就会将该位置所有的 entry 都拷贝到哈希表 B 中，当然也会存在某个位置一直没有被请求。Redis 也考虑了这个问题，通过设置一个定时任务进行 rehash，在一些键值对一直没有操作的时候，会周期性的搬移一些数据到哈希表 B 中，进而缩短 rehash 的过程。</p><h4 id="1-2-Redis-为什么采用单线程呢？"><a href="#1-2-Redis-为什么采用单线程呢？" class="headerlink" title="1.2 Redis 为什么采用单线程呢？"></a><strong>1.2 Redis 为什么采用单线程呢？</strong></h4><p>首先要明确的是 Redis 单线程指的是<strong>网络 IO</strong>和<strong>键值对读写</strong>是由一个线程来完成的，但 Redis 持久化、集群数据等是由额外的线程执行的。了解 Redis 使用单线程之前可以先了解一下多线程的开销。</p><p>通常情况下，使用多线程可以增加系统吞吐率或者可以增加系统扩展性，但多线程通常会存在同时访问某些共享资源，为了保证访问共享资源的正确性，就需要有额外的机制进行保证，这个机制首先会带来一定的开销。其实对于多线程并发访问的控制一直是一个难点问题，如果没有精细的设计，比如说，只是简单地采用一个粗粒度互斥锁，就会出现不理想的结果。即使增加了线程，大部分线程也在等待获取访问共享资源的互斥锁，并行变串行，系统吞吐率并没有随着线程的增加而增加。</p><p>这也是 Redis 使用单线程的主要原因。</p><p><strong>值得注意的是在 Redis6.0 中引入了多线程</strong>。在 Redis6.0 之前，从网络 IO 处理到实际的读写命令处理都是由单个线程完成的，但随着网络硬件的性能提升，Redis 的性能瓶颈有可能会出现在网络 IO 的处理上，也就是说<strong>单个主线程处理网络请求的速度跟不上底层网络硬件的速度</strong>。针对此问题，Redis 采用多个 IO 线程来处理网络请求，提高网络请求处理的并行度，但多 IO 线程只用于处理网络请求，<strong>对于读写命令，Redis 仍然使用单线程处理！</strong></p><h4 id="1-3-Redis-单线程为什么还这么快？"><a href="#1-3-Redis-单线程为什么还这么快？" class="headerlink" title="1.3 Redis 单线程为什么还这么快？"></a><strong>1.3 Redis 单线程为什么还这么快？</strong></h4><p><strong>IO 多路复用机制：使其在网络 IO 操作中能并发处理大量的客户端请求从而实现高吞吐率</strong></p><p>IO 多路复用机制是指一个线程处理多个 IO 流，也就是常说的 select/epoll 机制。在 Redis 运行单线程的情况下，该机制允许内核中同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果，进而提升并发性。</p><p><strong>Redis 是基于内存的，绝大部分请求都是内存操作，十分的迅速；</strong></p><p><strong>Redis 具有高效的底层数据结构，为优化内存，对每种类型基本都有两种底层实现方式；</strong></p><p><strong>主要执行过程是单线程，避免了不必要的上下文切换和资源竞争，不存在多线程导致的 CPU 切换和锁的问题；</strong></p><h3 id="二、Redis-数据丢失问题"><a href="#二、Redis-数据丢失问题" class="headerlink" title="二、Redis 数据丢失问题"></a>二、Redis 数据丢失问题</h3><p>由上一小节我们大概了解了 Redis 的存储和快的主要原因，通常情况下我们会把 Redis 当作缓存使用，将后端数据库中的数据存储在内存中，然后从内存中直接读取数据，响应速度会非常快。但是如果服务器宕机了，内存中的数据也就会丢失，当然我们可以重新从后端数据库中恢复这些缓存数据，但是频繁访问数据库，会给数据库带来一定的压力；另一方面数据是从慢速的数据库中读取的，性能肯定比不上 Redis，也会导致这些数据的应用程序响应变慢。</p><p>所以对 Redis 来说，实现数据的持久化，避免从后端恢复数据是至关重要的，目前 Redis 持久化主要有两大机制，分别是<strong>AOF（Append Only File）日志</strong>和<strong>RDB 快照</strong>。</p><h4 id="2-1-AOF-日志"><a href="#2-1-AOF-日志" class="headerlink" title="2.1 AOF 日志"></a>2.1 AOF 日志</h4><p>AOF 日志是写后日志，也就是 Redis 先执行命令，然后将数据写入内存，最后才记录日志，如下图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/a7f15ebf931c4b74d86195e3de1a25ba.png" alt=""></p><p>Redis AOF 操作过程</p><p>AOF 日志中记录的是 Redis 收到的每一条命令，这些命令都是以文本的形式保存的，例如我们以 Redis 收到 set key value 命令后记录的日志为例，AOF 文件中保存的数据如下图所示，其中*3 代表当前命令分为三部分，每部分都是通过$+数字开头，其中数字表示该部分的命令、键、值一共有多少字节。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/74a85298188ebb94ed28ab26071c4896.jpeg" alt=""></p><p>Redis AOF 日志内容</p><p>AOF 为了避免额外的检查开销，并不会检查命令的正确性，如果先记录日志再执行命令，就有可能记录错误的命令，再通过 AOF 日志恢复数据的时候，就有可能出错，而且在执行完命令后记录日志也不会阻塞当前的写操作。但是 AOF 是存在一定的风险的，首先是如果刚执行一个命令，但是 AOF 文件中还没来得及保存就宕机了，那么这个命令和数据就会有丢失的风险，另外 AOF 虽然可以避免对当前命令的阻塞（因为是先写入再记录日志），但有可能会对下一次操作带来阻塞风险（可能存在写入磁盘较慢的情况）。这两种情况都在于 AOF 什么时候写入磁盘，对于这个问题 AOF 机制提供了三种选择（appendfsync 的三个可选值），分别是<strong>Always、Everysec、No</strong>具体如下：</p><p>AOF 写入磁盘的机制</p><table><thead><tr><th><strong>Always</strong></th><th><strong>同步写回：每个命令执行完立马写入磁盘</strong></th></tr></thead><tbody><tr><td><strong>Everysec</strong></td><td><strong>每秒写回：每个命令执行完，先把日志写入 AOF 文件的缓冲区，每隔一秒把缓冲区的内容写入磁盘</strong></td></tr><tr><td><strong>No</strong></td><td><strong>操作系统的写回：每个命令执行完，先把日志写入 AOF 文件的缓冲区，由操作系统决定何时把缓冲区的内容写入磁盘</strong></td></tr></tbody></table><p>我们可以根据不同的场景来选择不同的方式：</p><ol><li><p>Always 可靠性较高，数据基本不丢失，但是对性能的影响较大；</p></li><li><p>Everysec 性能适中，即使宕机也只会丢失 1 秒的数据；</p></li><li><p>No 性能好，但是如果宕机丢失的数据较多。</p></li></ol><p>虽然有一定的写回策略，但毕竟 AOF 是通过文件的形式记录所有的写命令，但如果指令越来越多的时候，AOF 文件就会越来越大，可能会超出文件大小的限制；另外，如果文件过大再次写入指令的话效率也会变低；如果发生宕机，需要把 AOF 所有的命令重新执行，以用于故障恢复，数据过大的话这个恢复过程越漫长，也会影响 Redis 的使用。</p><p>此时，<strong>AOF 重写机制</strong>就来了：</p><p>AOF 重写就是根据所有的键值对创建一个新的 AOF 文件，可以减少大量的文件空间，减少的原因是：AOF 对于命令的添加是追加的方式，逐一记录命令，但有可能存在某个键值被反复更改，产生了一些冗余数据，这样在重写的时候就可以过滤掉这些指令，从而更新当前的最新状态。</p><p>AOF 重写的过程是通过主线程 fork 后台的 bgrewriteaof 子进程来实现的，可以避免阻塞主进程导致性能下降，整个过程如下：</p><ul><li><p>AOF 每次重写，fork 过程会把主线程的内存拷贝一份 bgrewriteaof 子进程，里面包含了数据库的数据，拷贝的是父进程的页表，可以在不影响主进程的情况下逐一把拷贝的数据记入重写日志；</p></li><li><p>因为主线程没有阻塞，仍然可以处理新来的操作，如果这时候存在写操作，会先把操作先放入缓冲区，对于正在使用的日志，如果宕机了这个日志也是齐全的，可以用于恢复；对于正在更新的日志，也不会丢失新的操作，等到数据拷贝完成，就可以将缓冲区的数据写入到新的文件中，保证数据库的最新状态。</p></li></ul><h4 id="2-2-RDB-快照"><a href="#2-2-RDB-快照" class="headerlink" title="2.2 RDB 快照"></a>2.2 RDB 快照</h4><p>上一小节里了解了避免 Redis 数据丢失的 AOF 方法，这个方法记录的是操作命令，而不是实际的数据，如果日志非常多的话，Redis 恢复的就很缓慢，会影响到正常的使用。</p><p>这一小节主要是讲述的另一种 Redis 数据持久化的方式：<strong>内存快照</strong>。即记录内存中的数据在某一时刻的状态，并以文件的形式写到磁盘上，即使服务器宕机，快照文件也不会丢失，数据的可靠性也就得到了保证，这个文件称为 RDB(Redis DataBase)文件。可以看出 RDB 记录的是某一时刻的数据，和 AOF 不同，所以在数据恢复的时候只需要将 RDB 文件读入到内存，就可以完成数据恢复。但为了 RDB 数据恢复的可靠性，在进行快照的时候是全量快照，会将内存中所有的数据都记录到磁盘中，这就有可能会阻塞主线程的执行。Redis 提供了两个命令来生成 RDB 文件，分别是<strong>save</strong>和<strong>bgsave</strong>：</p><ul><li><p>save：在主线程中执行，会导致阻塞；</p></li><li><p>bgsave：会创建一个子进程，该进程专门用于写入 RDB 文件，可以避免主线程的阻塞，也是默认的方式。</p></li></ul><p>我们可以采用 bgsave 的命令来执行全量快照，提供了数据的可靠性保证，也避免了对 Redis 的性能影响。执行快照期间数据能不能修改呢?如果不能修改，快照过程中如果有新的写操作，数据就会不一致，这肯定是不符合预期的。Redis 借用了操作系统的<strong>写时复制</strong>，在执行快照的期间，正常处理写操作。</p><p>主要流程为：</p><ul><li><p>bgsave 子进程是由主线程 fork 出来的，可以共享主线程的所有内存数据；</p></li><li><p>bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件中；</p></li><li><p>如果主线程对这些数据都是读操作，例如 A，那么主线程和 bgsave 子进程互不影响；</p></li><li><p>如果主线程需要修改一块数据，如 C，这块数据会被复制一份，生成数据的副本，然主线程在这个副本上进行修改；bgsave 子进程可以把原来的数据 C 写入 RDB 文件；</p></li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/41b35009dccf0b5d1a03c18d2c15e18a.jpeg" alt=""></p><p>写时复制机制保证快照期间数据可修改</p><p>通过上述方法就可以保证快照的完整性，也可以允许主线程处理写操作，可以避免对业务的影响。<strong>那多久进行一次快照呢</strong>？</p><p>理论上来说快照时间间隔越短越好，可以减少数据的丢失，毕竟 fork 的子进程不会阻塞主线程，但是频繁的将数据写入磁盘，会给磁盘带来很多压力，也可能会存在多个快照竞争磁盘带宽（当前快照没结束，下一个就开始了）。另一方面，虽然 fork 出的子进程不会阻塞，但 fork 这个创建过程是会阻塞主线程的，当主线程需要的内存越大，阻塞时间越长；</p><p>针对上面的问题，Redis 采用了<strong>增量快照</strong>，在做一次全量快照后，后续的快照只对修改的数据进行记录，需要记住哪些数据被修改了，可以避免全量快照带来的开销。</p><h4 id="2-3-混合使用-AOF-日志和-RDB-快照"><a href="#2-3-混合使用-AOF-日志和-RDB-快照" class="headerlink" title="2.3 混合使用 AOF 日志和 RDB 快照"></a>2.3 混合使用 AOF 日志和 RDB 快照</h4><p>虽然跟 AOF 相比，RDB 快照的恢复速度快，但快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又会产生额外开销，那么，还有什么方法既能利用 RDB 的快速恢复，又能以较小的开销做到尽量少丢数据呢？</p><p>在 Redis4.0 提出了<strong>混合使用 AOF 和 RDB 快照</strong>的方法，也就是两次 RDB 快照期间的所有命令操作由 AOF 日志文件进行记录。这样的好处是 RDB 快照不需要很频繁的执行，可以避免频繁 fork 对主线程的影响，而且 AOF 日志也只记录两次快照期间的操作，不用记录所有操作，也不会出现文件过大的情况，避免了重写开销。</p><p>通过上述方法既可以享受 RDB 快速恢复的好处，也可以享受 AOF 记录简单命令的优势。</p><p><strong>对于 AOF 和 RDB 的选择问题：</strong></p><ul><li><p><strong>数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；</strong></p></li><li><p><strong>如果允许分钟级别的数据丢失，可以只使用 RDB；</strong></p></li><li><p><strong>如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。</strong></p></li></ul><h3 id="三、Redis-数据同步"><a href="#三、Redis-数据同步" class="headerlink" title="三、Redis 数据同步"></a>三、Redis 数据同步</h3><p>当 Redis 发生宕机的时候，可以通过 AOF 和 RDB 文件的方式恢复数据，从而保证数据的丢失从而提高稳定性。但如果 Redis 实例宕机了，在恢复期间就无法服务新来的数据请求；AOF 和 RDB 虽然可以保证数据尽量的少丢失，但无法保证服务尽量少中断，这就会影响业务的使用，不能保证 Redis 的高可靠性。</p><p>Redis 其实采用了主从库的模式，以保证数据副本的一致性，主从库采用读写分离的方式：从库和主库都可以接受读操作；对于写操作，首先要到主库执行，然后主库再将写操作同步到从库；</p><p>只有主库接收写操作可以避免客户端将数据修改到不同的 Redis 实例上，其他客户端进行读取时可能就会读取到旧的值；当然，如果非要所有的库都可以进行写操作，就要涉及到锁、实例间协商是否完成修改等一系列操作，会带来额外的开销；</p><h4 id="3-1-主从库如何进行第一次数据同步"><a href="#3-1-主从库如何进行第一次数据同步" class="headerlink" title="3.1 主从库如何进行第一次数据同步"></a>3.1 主从库如何进行第一次数据同步</h4><p>当存在多个 Redis 实例的时候，可以通过 replicaof 命令形成主库和从库的关系，在从库中输入：<strong>replicaof 主库 ip 6379</strong> 就可以在主库中复制数据，具体有三个阶段：</p><ul><li><p>首先是主从库建立连接、协商同步的过程，具体的从库向主库发送 psync 命令，代表要进行数据同步；psync 中包含了主库的 runID（Redis 启动时生成的随机 ID，初始值为：？）和复制进度 offset（设为-1，代表第一次复制）两个参数，主库接收到 psync 命令会，会用 FULLRESYNC 命令返回给从库，包含两个参数：主库 runID 和复制进度 offset；其中 FULLRESYNC 代表的全量复制，会将主库所有的数据都复制给从库；</p></li><li><p>待从库接收到数据后，在本地完成数据加载，具体的主库执行 bgsave 命令，生成 RDB 文件，然后将文件发给从库，从库接收到 RDB 文件后，首先清空当前数据，然后再加载 RDB 文件；这个过程主库不会被阻塞，仍然可以接受请求，如果存在写操作，刚刚生成的 RDB 文件中是不包含这些新数据的，此时主库会在内存中用专门的 replication buffer 记录 RDB 文件生成后所有的写操作；</p></li><li><p>最后，主库会把 replication buffer 中的修改操作发给从库，从库重新执行这些操作，就可以实现主从库同步了。</p></li></ul><p>如果从库的实例过多，对于主库来说有一定的压力，主库会频繁 fork 子进程以生成 RDB 文件，fork 这个操作会阻塞主线程处理正常请求，导致响应变慢，Redis 采用了主-从-从的模式，可以手动选择一个从库，用来同步其他从库的数据，以减少主库生成 RDB 文件和传输 RDB 文件的压力；如下图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/40c6f80af461b226e412db9b48ed91b9.jpeg" alt=""></p><p>级联的“主-从-从”模式</p><p>这样从库就可以知道在进行数据同步的时候，不需要和主库直接交互，只需要和选择的从库进行写操作同步就可以了，从而减少主库的压力。</p><h4 id="3-2-主库如果挂了呢？"><a href="#3-2-主库如果挂了呢？" class="headerlink" title="3.2 主库如果挂了呢？"></a>3.2 主库如果挂了呢？</h4><p>Redis 采用主从库的模式保证数据副本的一致性，在这个模式下如果从库发生故障，客户端可以向其他主库或者从库发送请求，但如果主库挂了，客户端就没法进行写操作了，也无法对从库进行相应的数据复制操作；</p><p>不管是写服务中断还是从库无法进行数据同步，都是不能接受的，所以当主库挂了以后，需要一个新的主库来代替挂掉的主库，这样就就会产生三个问题：</p><ol><li><p>怎么判断主库是真的挂了，而不是网络异常？</p></li><li><p>主库如果挂了，该选择哪个从库作为新的主库？</p></li><li><p>怎么把新主库的相关信息通知给从库和客户端？</p></li></ol><p>Redis 采用了<strong>哨兵机制</strong>应对这些问题，哨兵机制是实现主从库自动切换的关键机制，在主从库运行的同时，它也在进行<strong>监控、选择主库和通知</strong>的操作；</p><ul><li><p><strong>监控</strong>。哨兵在运行时，周期性的给所有的主从库发送 PING 命令，检测是否仍在运行。如果从库没有响应哨兵的 PING 命令，哨兵就会将它标记为下线状态；如果主库没有在规定时间内响应哨兵的 PING 命令，哨兵也会判断主库下限，然后开始自动切换主库的流程。</p></li><li><p><strong>选主</strong>。主库挂了之后，哨兵需要按照一定的规则选择一个从库，并将他作为新的主库。</p></li><li><p><strong>通知</strong>。选取了新的主库后，哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令和新主库建立连接，并进行数据复制；同时哨兵也会将新主库的消息发给客户端；</p></li></ul><p>下图展示了哨兵的几个操作的任务：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/43e40c16bca4d293d3b014684654938b.jpeg" alt=""></p><p>哨兵机制的三项任务与目标</p><p><strong>但这样也会存在一个问题，哨兵判断主从库是否下线如果出现失误呢？</strong></p><p>对于从库，下线影响不大，集群的对外服务也不会间断。但是如果哨兵误判主库下线，可能是因为网络拥塞或者主库压力大的情况，这时候也就需要进行选主并让从库和新的主库进行数据同步，这个过程是有一定的开销的，所以我们要尽可能的避免误判的情况。哨兵机制也考虑了这一点，<strong>它通常采用多实例组成的集群模式进行部署，也被称为哨兵集群</strong>；通过引入多个哨兵实例一起判断，就可以尽可能的避免单个哨兵产生的误判问题。这时候判断主库是否下线不是由一个哨兵决定的，只有大多数哨兵认为该主库下线，主库才会标记为“客观下线”。</p><p>简单的来说”客观下线“的标准是当 N 个哨兵实例，<strong>有 N/2 + 1 个实例认为该主库为下线状态，该主库就会被认定为“客观下线”</strong>。这样就可以尽量的避免单个哨兵产生的误判问题（N/2 + 1 这个值也可以通过参数改变）；</p><p><strong>如果判断了主库为主观下线，怎么选取新的主库呢？</strong></p><p>上面有说道，这一部分也是由哨兵机制来完成的，选取主库的过程分为<strong>“筛选 和 打分”</strong>。主要是按照一定的规则过滤掉不符合的从库，再按照一定的规则给其余的从库打分，将最高分的从库作为新的主库。</p><ul><li><p><strong>筛选</strong>。首先从库一定是正在运行的，还要判断从库之前的网络连接状态，如果总是断连并且超过了一定的阈值，哨兵会认为该从库的网络不好，也会将其筛掉。</p></li><li><p><strong>打分</strong>。哨兵机制根据三个规则依次进行打分：从库优先级、从库复制进度以及从库 ID 号。在某一轮有从库得分最高，那么它就是新的主库了，选主过程结束。如果该轮没有出现最高的，继续下一轮。</p></li></ul><ol><li><p>优先级最高的从库。用户可以通过 slave-priority 配置项，给不同的从库设置优先级。选主库的时候哨兵会给优先级高的从库打高分，如果一个从库优先级高，那么就是新主库；</p></li><li><p>从库复制进度最接近。主库的 slave_repl_offset 和从库 master_repl_offset 越接近，得分越高；</p></li><li><p>ID 小的从库得分高。如果上面两轮也没有选出新主库，就会根据从库实例的 ID 来判断，ID 越小的从库得分越高。</p></li></ol><p>由此哨兵可以选择出一个新的主库。</p><p><strong>由哪个哨兵来执行主从库切换呢？</strong></p><p>这个过程和判断主库“客观下线”类似，也是一个投票的过程。如果某个哨兵判断了主库为下线状态，就会给其他的哨兵实例发送<strong>is-master-down-by-addr</strong>的命令，其他实例会根据自己和主库的连接状态作出 Y 或 N 的响应，Y 相当于赞成票，N 为反对票。一个哨兵获得一定的票数后，就可以标记主库为“客观下线”，这个票数是由参数 quorum 设置的。如下图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/4830716e7f46fe58c8a49f0f107f2252.jpeg" alt=""></p><p>例如：现在有 3 个哨兵，quorum 配置的是 2，那么，一个哨兵需要 2 张赞成票，就可以标记主库为“客观下线”了。这 2 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。</p><p>这个时候哨兵就可以给其他哨兵发送消息，表示希望自己来执行主从切换，并让所有的哨兵进行投票，这个过程称为“Leader 选举”，进行主从切换的哨兵称为 Leader。任何一个想成为 Leader 的哨兵都需要满足两个条件：</p><ul><li><p>拿到半数以上的哨兵赞成票；</p></li><li><p>拿到的票数需要大于等于 quorum 的值。</p></li></ul><p>以上就可以选出 Leader 然后进行主从库切换了。</p><h3 id="四、Redis-集群"><a href="#四、Redis-集群" class="headerlink" title="四、Redis 集群"></a>四、Redis 集群</h3><h4 id="数据量过多如何处理？"><a href="#数据量过多如何处理？" class="headerlink" title="数据量过多如何处理？"></a>数据量过多如何处理？</h4><p>当数据量过多的情况下，一种简单的方式是升级 Redis 实例的资源配置，包括增加内存容量、磁盘容量、更好配置的 CPU 等，但这种情况下 Redis 使用 RDB 进行持久化的时候响应会变慢，Redis 通过 fork 子进程来完成数据持久化，但 fork 在执行时会阻塞主线程，数据量越大，fork 的阻塞时间就越长，从而导致 Redis 响应变慢。</p><p><strong>Redis 的切片集群</strong>可以解决这个问题，也就是启动多个 Redis 实例来组成一个集群，再按照一定的规则把数据划分为多份，每一份用一个实例来保存，这样客户端只需要访问对应的实例就可以获取数据。在这种情况下 fork 子进程一般不会给主线程带来较长时间的阻塞，如下图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/4b6961e60c8cf4cc70dafdc02690480a.jpeg" alt=""></p><p>切片集群架构图</p><p>将 20GB 的数据分为 4 分，每份包含 5GB 数据，客户端只需要找到对应的实例就可以获取数据，从而减少主线程阻塞的时间。</p><p>当数据量过多的时候，可以通过升级 Redis 实例的资源配置或者通过切片集群的方式。前者实现起来简单粗暴，但这数据量增加的时候，需要的内存也在不断增加，主线程 fork 子进程就有可能会阻塞，而且该方案受到硬件和成本的限制。相比之下第二种方案是一种扩展性更好的方案，如果想保存更多的数据，仅需要增加 Redis 实例的个数，不用担心单个实例的硬件和成本限制。<strong>在面向百万、千万级别的用户规模时，横向扩展的 Redis 切片集群会是一个非常好的选择。</strong></p><p>选择切片集群也是需要解决一些问题的：</p><ul><li><p>数据切片后，在多个实例之间怎么分布？</p></li><li><p>客户端怎么确定想要访问的实例是哪一个？</p></li></ul><p>Redis 采用了 Redis Cluster 的方案来实现切片集群，具体的 Redis Cluster 采用了哈希槽（Hash Slot）来处理数据和实例之间的映射关系。在 Redis Cluster 中，一个切片集群共有 16384 个哈希槽（<a href="https://www.cnblogs.com/rjzheng/p/11430592.html">为什么 Hash Slot 的个数是 16384</a>），这些哈希槽类似于数据的分区，每个键值对都会根据自己的 key 被影射到一个哈希槽中，映射步骤如下：</p><ul><li><p>根据键值对 key，按照 CRC16 算法计算一个 16bit 的值；</p></li><li><p>用计算的值对 16384 取模，得到 0 ～ 16383 范围内的模数，每个模数对应一个哈希槽。</p></li></ul><p>这时候可以得到一个 key 对应的哈希槽了，哈希槽又是如何找到对应的实例的呢？</p><p>在部署 Redis Cluster 的时候，可以通过 cluster create 命令创建集群，此时 Redis 会自动把这些槽分布在集群实例上，例如一共有 N 个实例，那么每个实例包含的槽个数就为 16384/N。当然可能存在 Redis 实例中内存大小配置不一的问题，内存大的实例具有更大的容量。这种情况下可以通过 cluster addslots 命令手动分配哈希槽。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 33.33.33.3 –p 6379 cluster addslots 0,1  </span><br><span class="line">redis-cli -h 33.33.33.4 –p 6379 cluster addslots 2,3  </span><br><span class="line">redis-cli -h 33.33.33.5 –p 6379 cluster addslots 4  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>要注意的是，如果采用 cluster addslots 的方式手动分配哈希槽，需要将 16384 个槽全部分配完，否则 Redis 集群无法正常工作。现在通过哈希槽，切片集群就实现了数据到哈希槽、哈希槽到实例的对应关系，那么客户端如何确定需要访问的实例是哪一个呢？</p><p><strong>客户端定位集群中的数据</strong></p><p>客户端请求的 key 可以通过 CRC16 算法计算得到，但客户端还需要知道哈希槽分布在哪个实例上。在最开始客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端，实例之间会把自己的哈希槽信息发给和它相连的实例，完成哈希槽的扩散。这样客户端访问任何一个实例的时候，都能获取所有的哈希槽信息。当客户端收到哈希槽的信息后会把哈希槽对应的信息缓存在本地，当客户端发送请求的时候，会先找到 key 对应的哈希槽，然后就可以给对应的实例发送请求了。</p><p>但是，哈希槽和实例的对应关系不是一成不变的，可能会存在新增或者删除的情况，这时候就需要重新分配哈希槽；也可能为了负载均衡，Redis 需要把所有的实例重新分布。</p><p>虽然实例之间可以互相传递消息以获取最新的哈希槽分配信息，但是客户端无法感知这个变化，就会导致客户端访问的实例可能不是自己所需要的了。</p><p>Redis Cluster 提供了重定向的机制，当客户端给实例发送数据读写操作的时候，如果这个实例上没有找到对应的数据，此时这个实例就会给客户端返回 MOVED 命令的相应结果，这个结果中包含了新实例的访问地址，此时客户端需要再给新实例发送操作命令以进行读写操作，MOVED 命令如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">GET hello:key  </span><br><span class="line">(error) MOVED 3333 33.33.33.33:6379  </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>返回的信息代表客户端请求的 key 所在的哈希槽为 3333，实际是在 33.33.33.33 这个实例上，此时客户端只需要向 33.33.33.33 这个实例发送请求就可以了。</p><p>此时也存在一个小问题，哈希槽中对应的数据过多，导致还没有迁移到其他实例，此时客户端就发起了请求，在这种情况下，客户端就对实例发起了请求，如果数据还在对应的实例中，会给客户端返回数据；如果请求的数据已经被转移到其他实例上，客户端就会收到实例返回的 ASK 命令，该命令表示：哈希槽中数据还在前一种、ASK 命令把客户端需要访问的新实例返回了。此时客户端需要给新实例发送 ASKING 命令以进行请求操作；</p><p>值得注意的是 ASK 信息和 MOVED 信息不一样，<strong>ASK 信息并不会更新客户端本地的缓存的哈希槽分配信息</strong>，也就是说如果客户端再次访问该哈希槽还是会请求之前的实例，直到数据迁移完成。</p><p>以上就是 Redis 基础篇的全部内容~</p><p><strong>参考</strong></p><p><a href="https://km.tencent.com/pkm/articles/515629">https://km.tencent.com/pkm/articles/515629</a></p><p><a href="https://time.geekbang.org/column/intro/100056701">https://time.geekbang.org/column/intro/100056701</a></p><p>本文转自 <a href="https://mp.weixin.qq.com/s/4bAPVdUr_XbIw9xFCtWhfw">https://mp.weixin.qq.com/s/4bAPVdUr_XbIw9xFCtWhfw</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes原理与架构初探</title>
      <link href="/posts/a414d800/"/>
      <url>/posts/a414d800/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><blockquote><p>本文将从一个普通开发者的角度去探索Kubernetes，从应用部署方式的演变方式说起，再到搭建一个简易的K8s集群，去了解它的资源管理方式，然后再去实战。当对K8s有了一定了解后，再将其中的核心组件的原理进行剖析，从而深入理解Kubernetes的原理与架构。相信可以在读完本文后对Kubernetes有一个初步认识。</p></blockquote><h2 id="kubernetes介绍"><a href="#kubernetes介绍" class="headerlink" title="kubernetes介绍"></a>kubernetes介绍</h2><p>本章节主要介绍应用程序在服务器上部署方式演变以及kubernetes的概念、组件和工作原理。</p><h3 id="应用部署方式演变"><a href="#应用部署方式演变" class="headerlink" title="应用部署方式演变"></a>应用部署方式演变</h3><p>在部署应用程序的方式上，主要经历了三个时代：</p><ul><li>传统部署：互联网早期，会直接将应用程序部署在物理机上</li><li>优点：简单，不需要其它技术的参与。  </li><li>缺点：不能为应用程序定义资源使用边界，很难合理地分配计算资源，而且程序之间容易产生影响。</li><li>虚拟化部署：可以在一台物理机上运行多个虚拟机，每个虚拟机都是独立的一个环境  </li><li>优点：程序环境不会相互产生影响，提供了一定程度的安全性。</li><li>缺点：增加了操作系统，浪费了部分资源。</li><li>容器化部署：与虚拟化类似，但是共享了操作系统  </li><li>优点：</li><li>可以保证每个容器拥有自己的文件系统、CPU、内存、进程空间等。</li><li>运行应用程序所需要的资源都被容器包装，并和底层基础架构解耦。</li><li>容器化的应用程序可以跨云服务商、跨Linux操作系统发行版进行部署。</li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/02b66194a82688df97916856c3832384.png" alt=""></p><p>容器化部署方式给带来很多的便利，但是也会出现一些问题，比如说：</p><ul><li>一个容器故障停机了，怎么样让另外一个容器立刻启动去替补停机的容器。</li><li>当并发访问量变大的时候，怎么样做到横向扩展容器数量。</li></ul><p>这些容器管理的问题统称为容器编排问题，为了解决这些容器编排问题，就产生了一些容器编排的软件：</p><ul><li>Swarm：Docker自己的容器编排工具。</li><li>Mesos：Apache的一个资源统一管控的工具，需要和Marathon结合使用。</li><li>Kubernetes：Google开源的的容器编排工具。</li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/614611420eae4ec820b38ad6a8569b43.png" alt=""></p><h3 id="kubernetes简介"><a href="#kubernetes简介" class="headerlink" title="kubernetes简介"></a>kubernetes简介</h3><p>kubernetes，是一个全新的基于容器技术的分布式架构领先方案，是谷歌严格保密十几年的秘密武器—-Borg系统的一个开源版本，于2014年9月发布第一个版本，2015年7月发布第一个正式版本。</p><p>kubernetes的本质是<strong>一组服务器集群</strong>，它可以在集群的每个节点上运行特定的程序，来对节点中的容器进行管理。目的是实现资源管理的自动化，主要提供了如下的主要功能：</p><ul><li>自我修复：一旦某一个容器崩溃，能够在1秒中左右迅速启动新的容器。</li><li>弹性伸缩：可以根据需要，自动对集群中正在运行的容器数量进行调整。</li><li>服务发现：服务可以通过自动发现的形式找到它所依赖的服务。</li><li>负载均衡：如果一个服务起动了多个容器，能够自动实现请求的负载均衡。</li><li>版本回退：如果发现新发布的程序版本有问题，可以立即回退到原来的版本。</li><li>存储编排：可以根据容器自身的需求自动创建存储卷。</li></ul><h3 id="kubernetes组件"><a href="#kubernetes组件" class="headerlink" title="kubernetes组件"></a>kubernetes组件</h3><p>一个kubernetes集群主要是由控制节点(master)、工作节点(node)构成，每个节点上都会安装不同的组件。master：集群的控制平面，负责集群的决策 ( 管理 )</p><ul><li>ApiServer : 资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制。</li><li>Scheduler : 负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上ControllerManager: 负责维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等 </li><li>Etcd ：负责存储集群中各种资源对象的信息。</li><li>node：集群的数据平面，负责为容器提供运行环境 ( 干活 )。</li><li>Kubelet : 负责维护容器的生命周期，即通过控制docker，来创建、更新、销毁容器。</li><li>KubeProxy : 负责提供集群内部的服务发现和负载均衡 Docker : 负责节点上容器的各种操作。</li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/152cfe57e845b0251eaa60ee3660709f.png" alt=""></p><p>下面，以部署一个nginx服务来说明kubernetes系统各个组件调用关系：</p><ul><li>首先要明确，一旦kubernetes环境启动之后，master和node都会将自身的信息存储到etcd数据库中。</li><li>一个nginx服务的安装请求会首先被发送到master节点的apiServer组件。</li><li>apiServer组件会调用scheduler组件来决定到底应该把这个服务安装到哪个node节点上。</li><li>在此时，它会从etcd中读取各个node节点的信息，然后按照一定的算法进行选择，并将结果告知apiServer。</li><li>apiServer调用controller-manager去调度Node节点安装nginx服务。</li><li>kubelet接收到指令后，会通知docker，然后由docker来启动一个nginx的pod，pod是kubernetes的最小操作单元，容器必须跑在pod中。</li><li>至此，一个nginx服务就运行了，如果需要访问nginx，就需要通过kube-proxy来对pod产生访问的代理。<br>这样，外界用户就可以访问集群中的nginx服务了。</li></ul><h3 id="kubernetes概念"><a href="#kubernetes概念" class="headerlink" title="kubernetes概念"></a>kubernetes概念</h3><ul><li>Master：集群控制节点，每个集群需要至少一个master节点来负责集群的管控。</li><li>Node：工作负载节点，由master分配容器到这些node工作节点上，然后node节点上的docker负责容器的运行。</li><li>Pod：kubernetes的最小控制单元，容器都是运行在pod中的，一个pod中可以有1个或者多个容器。</li><li>Controller：控制器，通过它来实现对pod的管理，比如启动pod、停止pod、伸缩pod的数量等等。 </li><li>Service：pod对外服务的统一入口，下面可以维护者同一类的多个pod。 </li><li>Label：标签，用于对pod进行分类，同一类pod会拥有相同的标签。 </li><li>NameSpace：命名空间，用来隔离pod的运行环境。</li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/74ed8ee0ae2e234a030ea7a0006e8a11.png" alt=""></p><h2 id="集群环境搭建"><a href="#集群环境搭建" class="headerlink" title="集群环境搭建"></a>集群环境搭建</h2><p>本章节主要介绍如何搭建kubernetes的集群环境。</p><h3 id="环境规划"><a href="#环境规划" class="headerlink" title="环境规划"></a>环境规划</h3><h4 id="集群类型"><a href="#集群类型" class="headerlink" title="集群类型"></a>集群类型</h4><p>kubernetes集群大体上分为两类：一主多从和多主多从。</p><ul><li>一主多从：一台Master节点和多台Node节点，搭建简单，但是有单机故障风险，适合用于测试环境。</li><li>多主多从：多台Master节点和多台Node节点，搭建麻烦，安全性高，适合用于生产环境。</li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/5152628e5aec98bd6b2dd8d089cb2636.png" alt=""></p><p>说明：为了测试简单，本次搭建的是一主两从类型的集群。</p><h4 id="安装方式"><a href="#安装方式" class="headerlink" title="安装方式"></a>安装方式</h4><p>kubernetes有多种部署方式，目前主流的方式有kubeadm、minikube、二进制包</p><ul><li>minikube：一个用于快速搭建单节点kubernetes的工具。</li><li>kubeadm：一个用于快速搭建kubernetes集群的工具。</li><li>二进制包 ：从官网下载每个组件的二进制包，依次去安装，此方式对于理解kubernetes组件更加有效。</li></ul><p>说明：现在需要安装kubernetes的集群环境，但是又不想过于麻烦，所以选择使用kubeadm方式。</p><h4 id="主机规划"><a href="#主机规划" class="headerlink" title="主机规划"></a>主机规划</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/1ee75f09bc7b00c2523ee5eb34f52439.png" alt=""></p><h3 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h3><p>本次环境搭建需要安装三台Centos服务器（一主二从），然后在每台服务器中分别安装docker（18.06.3），kubeadm（1.17.4）、kubelet（1.17.4）、kubectl（1.17.4）程序。</p><h4 id="主机安装"><a href="#主机安装" class="headerlink" title="主机安装"></a>主机安装</h4><p>安装虚拟机过程中注意下面选项的设置：</p><ul><li>操作系统环境：CPU（2C） 内存（2G） 硬盘（50G） </li><li>语言选择：中文简体。</li><li>软件选择：基础设施服务器。</li><li>分区选择：自动分区。</li><li>网络配置：按照下面配置网路地址信息。</li></ul><p>网络地址：192.168.109.100  （每台主机都不一样  分别为100、101、102）<br>子网掩码：255.255.255.0<br>默认网关：192.168.109.2<br>DNS：223.5.5.5</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/87333a4dc834044085a0b0f124bb1f4d.png" alt=""></p><p>主机名设置：按照下面信息设置主机名</p><ul><li>master节点：master</li><li>node节点：node1</li><li>node节点：node2</li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/506c1e7a22f31bd82a83111d29b4f43f.png" alt=""></p><h4 id="环境初始化"><a href="#环境初始化" class="headerlink" title="环境初始化"></a>环境初始化</h4><p>1）检查操作系统的版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 此方式下安装kubernetes集群要求Centos版本要在7.5或之上</span></span><br><span class="line">[root@master ~]# cat /etc/redhat-release</span><br><span class="line">CentOS Linux release 7.5.1804 (Core)</span><br></pre></td></tr></table></figure><p>2）主机名解析，为了方便后面集群节点间的直接调用，在这配置一下主机名解析，企业中推荐使用内部DNS服务器。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 主机名成解析 编辑三台服务器的/etc/hosts文件，添加下面内容</span></span><br><span class="line">192.168.109.100  master</span><br><span class="line">192.168.109.101  node1</span><br><span class="line">192.168.109.102  node2</span><br></pre></td></tr></table></figure><p>3）时间同步，kubernetes要求集群中的节点时间必须精确一致，这里直接使用chronyd服务从网络同步时间。企业中建议配置内部的时间同步服务器。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动chronyd服务</span></span><br><span class="line">[root@master ~]# systemctl start chronyd</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置chronyd服务开机自启</span></span><br><span class="line">[root@master ~]# systemctl enable chronyd</span><br><span class="line"><span class="meta">#</span><span class="bash"> chronyd服务启动稍等几秒钟，就可以使用date命令验证时间了</span></span><br><span class="line">[root@master ~]# date</span><br></pre></td></tr></table></figure><p>4）禁用iptables和firewalld服务，kubernetes和docker在运行中会产生大量的iptables规则，为了不让系统规则跟它们混淆，直接关闭系统的规则。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1 关闭firewalld服务</span></span><br><span class="line">[root@master ~]# systemctl stop firewalld</span><br><span class="line">[root@master ~]# systemctl disable firewalld</span><br><span class="line"><span class="meta">#</span><span class="bash"> 2 关闭iptables服务</span></span><br><span class="line">[root@master ~]# systemctl stop iptables</span><br><span class="line">[root@master ~]# systemctl disable iptables</span><br></pre></td></tr></table></figure><p>5）禁用selinux，selinux是linux系统下的一个安全服务，如果不关闭它，在安装集群中会产生各种各样的奇葩问题。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 编辑 /etc/selinux/config 文件，修改SELINUX的值为disabled</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 注意修改完毕之后需要重启linux服务</span></span><br><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure><p>6）禁用swap分区，swap分区指的是虚拟内存分区，它的作用是在物理内存使用完之后，将磁盘空间虚拟成内存来使用 启用swap设备会对系统的性能产生非常负面的影响，因此kubernetes要求每个节点都要禁用swap设备 但是如果因为某些原因确实不能关闭swap分区，就需要在集群安装过程中通过明确的参数进行配置说明。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 编辑分区配置文件/etc/fstab，注释掉swap分区一行</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 注意修改完毕之后需要重启linux服务</span></span><br><span class="line">UUID=455cc753-7a60-4c17-a424-7741728c44a1 /boot    xfs     defaults        0 0</span><br><span class="line">/dev/mapper/centos-home                   /home    xfs     defaults        0 0</span><br><span class="line"><span class="meta">#</span><span class="bash"> /dev/mapper/centos-swap swap                     swap    defaults        0 0</span></span><br></pre></td></tr></table></figure><p>7）修改linux的内核参数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 修改linux的内核参数，添加网桥过滤和地址转发功能</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 编辑/etc/sysctl.d/kubernetes.conf文件，添加如下配置:</span></span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重新加载配置</span></span><br><span class="line">[root@master ~]# sysctl -p</span><br><span class="line"><span class="meta">#</span><span class="bash"> 加载网桥过滤模块</span></span><br><span class="line">[root@master ~]# modprobe br_netfilter</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看网桥过滤模块是否加载成功</span></span><br><span class="line">[root@master ~]# lsmod | grep br_netfilter</span><br></pre></td></tr></table></figure><p>80配置ipvs功能，使用ipvs的话，需要关闭flannel的数据包校验。</p><p><a href="https://blog.csdn.net/woshizhangliang999/article/details/108478319?spm=1001.2101.3001.6650.5&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-5.pc_relevant_paycolumn_v2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-5.pc_relevant_paycolumn_v2&utm_relevant_index=9）" target="_blank" rel="noopener">《Kubernetes K8S在IPVS代理模式下Service服务的ClusterIP类型访问失败处理》</a></p><p>在kubernetes中service有两种代理模型，一种是基于iptables的，一种是基于ipvs的两者比较的话，ipvs的性能明显要高一些，但是如果要使用它，需要手动载入ipvs模块。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1 安装ipset和ipvsadm</span></span><br><span class="line">[root@master ~]# yum install ipset ipvsadm -y</span><br><span class="line"><span class="meta">#</span><span class="bash"> 2 添加需要加载的模块写入脚本文件</span></span><br><span class="line">[root@master ~]# cat &lt;&lt;EOF &gt;  /etc/sysconfig/modules/ipvs.modules</span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">modprobe -- ip_vs</span><br><span class="line">modprobe -- ip_vs_rr</span><br><span class="line">modprobe -- ip_vs_wrr</span><br><span class="line">modprobe -- ip_vs_sh</span><br><span class="line">modprobe -- nf_conntrack_ipv4</span><br><span class="line">EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 3 为脚本文件添加执行权限</span></span><br><span class="line">[root@master ~]# chmod +x /etc/sysconfig/modules/ipvs.modules</span><br><span class="line"><span class="meta">#</span><span class="bash"> 4 执行脚本文件</span></span><br><span class="line">[root@master ~]# /bin/bash /etc/sysconfig/modules/ipvs.modules</span><br><span class="line"><span class="meta">#</span><span class="bash"> 5 查看对应的模块是否加载成功</span></span><br><span class="line">[root@master ~]# lsmod | grep -e ip_vs -e nf_conntrack_ipv4</span><br></pre></td></tr></table></figure><p>9）重启服务器，上面步骤完成之后，需要重新启动linux系统</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# reboot</span><br></pre></td></tr></table></figure><h4 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 1 切换镜像源</span></span><br><span class="line">[root@master ~]# wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2 查看当前镜像源中支持的docker版本</span></span><br><span class="line">[root@master ~]# yum list docker-ce --showduplicates</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 3 安装特定版本的docker-ce</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 必须指定--<span class="built_in">setopt</span>=obsoletes=0，否则yum会自动安装更高版本</span></span><br><span class="line">[root@master ~]# yum install --setopt=obsoletes=0 docker-ce-18.06.3.ce-3.el7 -y</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4 添加一个配置文件</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Docker在默认情况下使用的Cgroup Driver为cgroupfs，而kubernetes推荐使用systemd来代替cgroupfs</span></span><br><span class="line">[root@master ~]# mkdir /etc/docker</span><br><span class="line">[root@master ~]# cat &lt;&lt;EOF &gt;  /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">"exec-opts": ["native.cgroupdriver=systemd"],</span><br><span class="line">"registry-mirrors": ["https://kn0t2bca.mirror.aliyuncs.com"]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 5 启动docker</span></span><br><span class="line">[root@master ~]# systemctl restart docker</span><br><span class="line">[root@master ~]# systemctl enable docker</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 6 检查docker状态和版本</span></span><br><span class="line">[root@master ~]# docker version</span><br></pre></td></tr></table></figure><h4 id="安装kubernetes组件"><a href="#安装kubernetes组件" class="headerlink" title="安装kubernetes组件"></a>安装kubernetes组件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 由于kubernetes的镜像源在国外，速度比较慢，这里切换成国内的镜像源</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 编辑/etc/yum.repos.d/kubernetes.repo，添加下面的配置 </span></span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg</span><br><span class="line">       http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装kubeadm、kubelet和kubectl</span></span><br><span class="line">[root@master ~]# yum install kubeadm-1.17.4 kubelet-1.17.4 kubectl-1.17.4 -y</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置kubelet的cgroup</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 编辑/etc/sysconfig/kubelet，添加下面的配置</span></span><br><span class="line">KUBELET_CGROUP_ARGS="--cgroup-driver=systemd"</span><br><span class="line">KUBE_PROXY_MODE="ipvs"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4 设置kubelet开机自启</span></span><br><span class="line">[root@master ~]# systemctl enable kubelet</span><br></pre></td></tr></table></figure><h4 id="准备集群镜像"><a href="#准备集群镜像" class="headerlink" title="准备集群镜像"></a>准备集群镜像</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在安装kubernetes集群之前，必须要提前准备好集群需要的镜像，所需镜像可以通过下面命令查看</span></span><br><span class="line">[root@master ~]# kubeadm config images list</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 下载镜像</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 此镜像在kubernetes的仓库中,由于网络原因,无法连接，下面提供了一种替代方案</span></span><br><span class="line">images=(</span><br><span class="line">    kube-apiserver:v1.17.4</span><br><span class="line">    kube-controller-manager:v1.17.4</span><br><span class="line">    kube-scheduler:v1.17.4</span><br><span class="line">    kube-proxy:v1.17.4</span><br><span class="line">    pause:3.1</span><br><span class="line">    etcd:3.4.3-0</span><br><span class="line">    coredns:1.6.5</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">for imageName in $&#123;images[@]&#125; ; do</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName</span><br><span class="line">docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName</span><br><span class="line">docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$imageName</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h4 id="集群初始化"><a href="#集群初始化" class="headerlink" title="集群初始化"></a>集群初始化</h4><p>下面开始对集群进行初始化，并将node节点加入到集群中<br>下面的操作只需要在master节点上执行即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建集群</span></span><br><span class="line">[root@master ~]# kubeadm init \</span><br><span class="line">--kubernetes-version=v1.17.4 \</span><br><span class="line">    --pod-network-cidr=10.244.0.0/16 \</span><br><span class="line">    --service-cidr=10.96.0.0/12 \</span><br><span class="line">    --apiserver-advertise-address=192.168.109.100</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建必要文件</span></span><br><span class="line">[root@master ~]# mkdir -p $HOME/.kube</span><br><span class="line">[root@master ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">[root@master ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure><p>下面的操作只需要在node节点上执行即可</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 将node节点加入集群</span></span><br><span class="line">[root@master ~]# kubeadm join 192.168.109.100:6443 \</span><br><span class="line">--token 8507uc.o0knircuri8etnw2 \</span><br><span class="line">--discovery-token-ca-cert-hash \</span><br><span class="line">sha256:acc37967fb5b0acf39d7598f8a439cc7dc88f439a3f4d0c9cae88e7901b9d3f</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看集群状态 此时的集群状态为NotReady，这是因为还没有配置网络插件</span></span><br><span class="line">[root@master ~]# kubectl get nodes</span><br><span class="line">NAME     STATUS     ROLES    AGE     VERSION</span><br><span class="line">master   NotReady   master   6m43s   v1.17.4</span><br><span class="line">node1    NotReady   &lt;none&gt;   22s     v1.17.4</span><br><span class="line">node2    NotReady   &lt;none&gt;   19s     v1.17.4</span><br></pre></td></tr></table></figure><h4 id="安装网络插件"><a href="#安装网络插件" class="headerlink" title="安装网络插件"></a>安装网络插件</h4><p>kubernetes支持多种网络插件，比如flannel、calico、canal等等，任选一种使用即可，本次选择flannel。<br>下面操作依旧只在master节点执行即可，插件使用的是DaemonSet的控制器，它会在每个节点上都运行。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 获取fannel的配置文件</span></span><br><span class="line">[root@master ~]# wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改文件中quay.io仓库为quay-mirror.qiniu.com</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用配置文件启动fannel</span></span><br><span class="line">[root@master ~]# kubectl apply -f kube-flannel.yml</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 稍等片刻，再次查看集群节点的状态</span></span><br><span class="line">[root@master ~]# kubectl get nodes</span><br><span class="line">NAME     STATUS   ROLES    AGE     VERSION</span><br><span class="line">master   Ready    master   15m     v1.17.4</span><br><span class="line">node1    Ready    &lt;none&gt;   8m53s   v1.17.4</span><br><span class="line">node2    Ready    &lt;none&gt;   8m50s   v1.17.4</span><br></pre></td></tr></table></figure><p>至此，kubernetes的集群环境搭建完成。</p><h3 id="服务部署"><a href="#服务部署" class="headerlink" title="服务部署"></a>服务部署</h3><p>接下来在kubernetes集群中部署一个nginx程序，测试下集群是否在正常工作。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 部署nginx</span></span><br><span class="line">[root@master ~]# kubectl create deployment nginx --image=nginx:1.14-alpine</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 暴露 80 端口，指的是暴露容器内部的 80 端口</span></span><br><span class="line">[root@master ~]# kubectl expose deployment nginx --port=80 --type=NodePort</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看服务状态</span></span><br><span class="line">[root@master ~]# kubectl get pods,service</span><br><span class="line">NAME                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginx-86c57db685-fdc2k   1/1     Running   0          18m</span><br><span class="line"></span><br><span class="line">NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">service/kubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP        82m</span><br><span class="line">service/nginx        NodePort    10.104.121.45   &lt;none&gt;        80:30073/TCP   17m</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4最后在电脑上访问下部署的nginx服务，master节点的IP + service暴露给外界的端口(30073)</span></span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/bf4df91920c7e996684aaa9a7470e55a.png" alt=""></p><h2 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h2><p>本章节主要介绍yaml语法和kubernetes的资源管理方式。</p><h3 id="资源管理介绍"><a href="#资源管理介绍" class="headerlink" title="资源管理介绍"></a>资源管理介绍</h3><p>在kubernetes中，所有的内容都抽象为资源，用户需要通过操作资源来管理kubernetes。</p><p>kubernetes的本质上就是一个集群系统，用户可以在集群中部署各种服务，所谓的部署服务，其实就是在kubernetes集群中运行一个个的容器，并将指定的程序跑在容器中。</p><p>kubernetes的最小管理单元是pod而不是容器，所以只能将容器放在Pod中，而kubernetes一般也不会直接管理Pod，而是通过Pod控制器来管理Pod的。</p><p>Pod可以提供服务之后，就要考虑如何访问Pod中服务，kubernetes提供了Service资源实现这个功能。</p><p>当然，如果Pod中程序的数据需要持久化，kubernetes还提供了各种存储系统。</p><p>学习kubernetes的核心，就是学习如何对集群上的Pod、Pod控制器、Service、存储等各种资源进行操作</p><h3 id="YAML语言介绍"><a href="#YAML语言介绍" class="headerlink" title="YAML语言介绍"></a>YAML语言介绍</h3><p>YAML是一个类似XML、JSON的标记性语言。它强调以<strong>数据</strong>为中心，并不是以标识语言为重点。因而YAML本身的定义比较简单，号称“一种人性化的数据格式语言”。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">heima</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">age</span>&gt;</span>15<span class="tag">&lt;/<span class="name">age</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">address</span>&gt;</span>Beijing<span class="tag">&lt;/<span class="name">address</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">heima</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">heima:</span></span><br><span class="line">    <span class="attr">age:</span> <span class="number">15</span></span><br><span class="line">    <span class="attr">address:</span> <span class="string">Beijing</span></span><br></pre></td></tr></table></figure><p>YAML的语法比较简单，主要有下面几个：</p><ul><li>大小写敏感。</li><li>使用缩进表示层级关系。</li><li>缩进不允许使用tab，只允许空格( 低版本限制 )</li><li>缩进的空格数不重要，只要相同层级的元素左对齐即可。</li><li>‘#’表示注释。</li></ul><p>YAML支持以下几种数据类型：</p><ul><li>纯量：单个的、不可再分的值。</li><li>对象：键值对的集合，又称为映射（mapping）/哈希（hash）/字典（dictionary）</li><li>数组：一组按次序排列的值，又称为序列（sequence）/列表（list）</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 纯量, 就是指的一个简单的值，字符串、布尔值、整数、浮点数、Null、时间、日期</span></span><br><span class="line"><span class="comment"># 1 布尔类型</span></span><br><span class="line"><span class="attr">c1:</span> <span class="literal">true</span> <span class="string">(或者True)</span></span><br><span class="line"><span class="comment"># 2 整型</span></span><br><span class="line"><span class="attr">c2:</span> <span class="number">234</span></span><br><span class="line"><span class="comment"># 3 浮点型</span></span><br><span class="line"><span class="attr">c3:</span> <span class="number">3.14</span></span><br><span class="line"><span class="comment"># 4 null类型 </span></span><br><span class="line"><span class="attr">c4:</span> <span class="string">~</span>  <span class="comment"># 使用~表示null</span></span><br><span class="line"><span class="comment"># 5 日期类型</span></span><br><span class="line"><span class="attr">c5:</span> <span class="number">2018</span><span class="number">-02</span><span class="number">-17</span>    <span class="comment"># 日期必须使用ISO 8601格式，即yyyy-MM-dd</span></span><br><span class="line"><span class="comment"># 6 时间类型</span></span><br><span class="line"><span class="attr">c6:</span> <span class="number">2018</span><span class="number">-02</span><span class="string">-17T15:02:31+08:00</span>  <span class="comment"># 时间使用ISO 8601格式，时间和日期之间使用T连接，最后使用+代表时区</span></span><br><span class="line"><span class="comment"># 7 字符串类型</span></span><br><span class="line"><span class="attr">c7:</span> <span class="string">heima</span>     <span class="comment"># 简单写法，直接写值 , 如果字符串中间有特殊字符，必须使用双引号或者单引号包裹 </span></span><br><span class="line"><span class="attr">c8:</span> <span class="string">line1</span></span><br><span class="line">    <span class="string">line2</span>     <span class="comment"># 字符串过多的情况可以拆成多行，每一行会被转化成一个空格</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对象</span></span><br><span class="line"><span class="comment"># 形式一(推荐):</span></span><br><span class="line"><span class="attr">heima:</span></span><br><span class="line">  <span class="attr">age:</span> <span class="number">15</span></span><br><span class="line">  <span class="attr">address:</span> <span class="string">Beijing</span></span><br><span class="line"><span class="comment"># 形式二(了解):</span></span><br><span class="line"><span class="attr">heima:</span> <span class="string">&#123;age:</span> <span class="number">15</span><span class="string">,address:</span> <span class="string">Beijing&#125;</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数组</span></span><br><span class="line"><span class="comment"># 形式一(推荐):</span></span><br><span class="line"><span class="attr">address:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">顺义</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">昌平</span></span><br><span class="line"><span class="comment"># 形式二(了解):</span></span><br><span class="line"><span class="attr">address:</span> <span class="string">[顺义,昌平]</span></span><br></pre></td></tr></table></figure><p>小提示：  </p><ul><li>书写yaml切记 : 后面要加一个空格</li><li>如果需要将多段yaml配置放在一个文件中，中间要使用 — 分隔  </li><li>下面是一个yaml转json的网站，可以通过它验证yaml是否书写正确：<br>  <a href="https://www.json2yaml.com/convert-yaml-to-json" target="_blank" rel="noopener">https://www.json2yaml.com/convert-yaml-to-json</a></li></ul><h3 id="资源管理方式"><a href="#资源管理方式" class="headerlink" title="资源管理方式"></a>资源管理方式</h3><ul><li>命令式对象管理：直接使用命令去操作kubernetes资源<br>  <code>kubectl run nginx-pod --image=nginx:1.17.1 --port=80</code></li><li>命令式对象配置：通过命令配置和配置文件去操作kubernetes资源<br>  <code>kubectl create/patch -f nginx-pod.yaml</code></li><li>声明式对象配置：通过apply命令和配置文件去操作kubernetes资源<br>  <code>kubectl apply -f nginx-pod.yaml</code></li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/110a43b3e57e2b92235d461c85a71832.png" alt=""></p><h4 id="命令式对象管理"><a href="#命令式对象管理" class="headerlink" title="命令式对象管理"></a>命令式对象管理</h4><p>kubectl命令</p><p>kubectl是kubernetes集群的命令行工具，通过它能够对集群本身进行管理，并能够在集群上进行容器化应用的安装部署。kubectl命令的语法如下： <code>kubectl [command] [type] [name] [flags]</code></p><ul><li>comand：指定要对资源执行的操作，例如create、get、delete。</li><li>type：指定资源类型，比如deployment、pod、service。 </li><li>name：指定资源的名称，名称大小写敏感。</li><li>flags：指定额外的可选参数。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看所有pod</span></span><br><span class="line">kubectl get pod</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看某个pod</span></span><br><span class="line">kubectl get pod pod_name</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看某个pod,以yaml格式展示结果</span></span><br><span class="line">kubectl get pod pod_name -o yaml</span><br></pre></td></tr></table></figure><p>资源类型，kubernetes中所有的内容都抽象为资源，可以通过下面的命令进行查看: kubectl api-resources经常使用的资源有下面这些：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/53418416160551dac1564b321f706859.png" alt=""></p><p>操作，kubernetes允许对资源进行多种操作，可以通过–help查看详细的操作命令kubectl –help经常使用的操作有下面这些：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/a86cb48a5f218c3e6365f7271276c792.png" alt=""></p><p>下面以一个namespace/pod的创建和删除简单演示下命令的使用：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建一个namespace</span></span><br><span class="line">[root@master ~]# kubectl create namespace dev</span><br><span class="line">namespace/dev created</span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取namespace</span></span><br><span class="line">[root@master ~]# kubectl get ns</span><br><span class="line">NAME              STATUS   AGE</span><br><span class="line">default           Active   21h</span><br><span class="line">dev               Active   21s</span><br><span class="line">kube-node-lease   Active   21h</span><br><span class="line">kube-public       Active   21h</span><br><span class="line">kube-system       Active   21h</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在此namespace下创建并运行一个nginx的Pod</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用 kubectl run NAME 会创建一个 deployment 控制器，通过控制器创建 Pod（k8s低版本）。</span></span><br><span class="line">[root@master ~]# kubectl run pod --image=nginx -n dev</span><br><span class="line">kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.</span><br><span class="line">deployment.apps/pod created</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看新创建的pod</span></span><br><span class="line">[root@master ~]# kubectl get pod -n dev</span><br><span class="line">NAME                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod-864f9875b9-pcw7x   1/1     Running   0          21s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除指定的pod</span></span><br><span class="line">[root@master ~]# kubectl delete pod pod-864f9875b9-pcw7x -n dev</span><br><span class="line">pod "pod-864f9875b9-pcw7x" deleted</span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除指定的namespace</span></span><br><span class="line">[root@master ~]# kubectl delete ns dev</span><br><span class="line">namespace "dev" deleted</span><br></pre></td></tr></table></figure><h4 id="命令式对象配置"><a href="#命令式对象配置" class="headerlink" title="命令式对象配置"></a>命令式对象配置</h4><p>命令式对象配置就是使用命令配合配置文件一起来操作kubernetes资源。</p><ol><li>创建一个nginxpod.yaml，内容如下：</li></ol><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dev</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginxpod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">dev</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-containers</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx:1.17.1</span></span><br></pre></td></tr></table></figure><ol start="2"><li>执行create命令，创建资源：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl create -f nginxpod.yaml</span><br><span class="line">namespace/dev created</span><br><span class="line">pod/nginxpod created</span><br></pre></td></tr></table></figure><p>此时发现创建了两个资源对象，分别是namespace和pod。</p><ol start="3"><li>执行get命令，查看资源：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]#  kubectl get -f nginxpod.yaml</span><br><span class="line">NAME            STATUS   AGE</span><br><span class="line">namespace/dev   Active   18s</span><br><span class="line">NAME            READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/nginxpod    1/1     Running   0          17s</span><br></pre></td></tr></table></figure><p>这样就显示了两个资源对象的信息。</p><ol start="4"><li>执行delete命令，删除资源：</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl delete -f nginxpod.yaml</span><br><span class="line">namespace "dev" deleted</span><br><span class="line">pod "nginxpod" deleted</span><br></pre></td></tr></table></figure><p>此时发现两个资源对象被删除了。</p><blockquote><p>命令式对象配置的方式操作资源，可以简单的认为：命令+yaml配置文件（里面是命令需要的各种参数）</p></blockquote><h4 id="声明式对象配置"><a href="#声明式对象配置" class="headerlink" title="声明式对象配置"></a>声明式对象配置</h4><p>声明式对象配置跟命令式对象配置很相似，但是它只有一个命令apply。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 首先执行一次kubectl apply -f yaml文件，发现创建了资源</span></span><br><span class="line">[root@master ~]#  kubectl apply -f nginxpod.yaml</span><br><span class="line">namespace/dev created</span><br><span class="line">pod/nginxpod created</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 再次执行一次kubectl apply -f yaml文件，发现说资源没有变动</span></span><br><span class="line">[root@master ~]#  kubectl apply -f nginxpod.yaml</span><br><span class="line">namespace/dev unchanged</span><br><span class="line">pod/nginxpod unchanged</span><br></pre></td></tr></table></figure><blockquote><p>其实声明式对象配置就是使用apply描述一个资源最终的状态（在yaml中定义状态）<br>使用apply操作资源： </p><ul><li>如果资源不存在，就创建，相当于 kubectl create</li><li>如果资源已存在，就更新，相当于 kubectl patch</li></ul></blockquote><p>扩展：kubectl可以在node节点上运行吗?</p><p>kubectl的运行是需要进行配置的，它的配置文件是$HOME/.kube，如果想要在node节点运行此命令，需要将master上的.kube文件复制到node节点上，即在master节点上执行下面操作：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r HOME/.kube node1: HOME/</span><br></pre></td></tr></table></figure><p>使用推荐: 三种方式应该怎么用 ?</p><ul><li>创建/更新资源 使用声明式对象配置 <code>kubectl apply -f XXX.yaml</code></li><li>删除资源 使用命令式对象配置 <code>kubectl delete -f XXX.yaml</code></li><li>查询资源 使用命令式对象管理 <code>kubectl get(describe) 资源名称</code></li></ul><p>本文转自 <a href="https://mp.weixin.qq.com/s/Q0vxASPNiACd_gCl-rq-2Q" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/Q0vxASPNiACd_gCl-rq-2Q</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Firewalld 防火墙示例，完整的入门指南</title>
      <link href="/posts/6cf05f2f/"/>
      <url>/posts/6cf05f2f/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>本指南将教您开始使用 firewalld 以添加、更改和删除防火墙区域中的规则所需的所有知识。</strong></p><p>如今，必须为服务器和网络配置和实现可靠的防火墙。没有它，问题不再是恶意攻击是否会伤害你，而是何时会伤害你。不幸的是，这些在互联网上很常见。</p><p>这就是 Firewalld 发挥作用的地方。Firewalld 是 Red Hat Enterprise Linux、Fedora、Oracle Linux、openSUSE、AlmaLinux、Rocky Linux 等 Linux 发行版中的默认防火墙，可提供保护服务器和网络所需的所有保护。但在我们进入如何使用它之前，让我们先解释一下它是什么。</p><h2 id="什么是-Firewalld？"><a href="#什么是-Firewalld？" class="headerlink" title="什么是 Firewalld？"></a>什么是 Firewalld？</h2><p>Firewalld 是一个基于区域的防火墙管理工具，它提供动态管理的防火墙，支持定义网络连接或接口的信任级别的网络区域。</p><p>此外，它还充当 Linux 内核的 Netfilter 框架的前端，提供防火墙功能。</p><p>与 iptables 链不同，它使用区域和服务管理防火墙规则。这些规则用于对传入流量进行排序并确定是否应该阻止或允许它。</p><h2 id="如何使用-Firewalld-管理防火墙规则"><a href="#如何使用-Firewalld-管理防火墙规则" class="headerlink" title="如何使用 Firewalld 管理防火墙规则"></a>如何使用 Firewalld 管理防火墙规则</h2><p>管理 Firewalld 规则的主要工具是<code>firewall-cmd</code>. 它是一个命令行工具，为管理 Firewalld 的运行时和永久配置提供了一个界面。使用时，更改立即生效，无需重启服务。</p><h3 id="检查-Firewalld-状态"><a href="#检查-Firewalld-状态" class="headerlink" title="检查 Firewalld 状态"></a>检查 Firewalld 状态</h3><p>运行以下命令以查看您的 Firewalld 是否处于活动状态：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[linuxmi@fedora www.linuxmi.com]$ sudo firewall-cmd --state</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/64232c407cea8fb849e612b404f1a68d.png" alt=""></p><p>此外，要查看 Firewalld 服务的状态，请运行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[linuxmi@fedora www.linuxmi.com]$ sudo systemctl status firewalld</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/b951794a0b8597fadf589b8ba6431a23.png" alt=""></p><p>如果服务由于某种原因没有启动，您可以启动它并将其设置为在系统启动时自动启动运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[linuxmi@fedora www.linuxmi.com]$ sudo systemctl start firewalld </span><br><span class="line">[linuxmi@fedora www.linuxmi.com]$ sudo systemctl enable firewalld</span><br></pre></td></tr></table></figure><p>同样，您可以通过执行以下操作来停止和禁用 Firewalld 服务的自动启动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[linuxmi@fedora www.linuxmi.com]$ sudo systemctl stop firewalld </span><br><span class="line">[linuxmi@fedora www.linuxmi.com]$ sudo systemctl disable firewalld</span><br></pre></td></tr></table></figure><h3 id="区域和接口"><a href="#区域和接口" class="headerlink" title="区域和接口"></a>区域和接口</h3><p>如前所述，Firewalld 是基于区域 zone 的防火墙。但这究竟是什么意思，什么是区域？</p><p>简而言之，它们是 Firewalld 组织的顶级组件。因此，区域可以为不同的连接区域提供不同级别的安全性。这个想法是为不同的网络区域制定单独的安全措施。</p><p>每个区域至少连接到一个网络接口——硬件或虚拟网络适配器。获取预配置 Firewalld 区域的列表很简单。键入命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[linuxmi@fedora www.linuxmi.com]$ sudo firewall-cmd --get-zones</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/c1d82c2b972e1c08af3082f87554be2a.png" alt=""></p><p>如您所见，默认列出的区域是：</p><ul><li><p><strong>block</strong>：传入的网络连接被拒绝，并带有 icmp-host-prohibited 消息。仅允许由该系统发起的网络连接。</p></li><li><p><strong>dmz</strong>：适用于非军事区内可公开访问的计算机，但对内部网络的访问受限。仅接受某些入站连接。</p></li><li><p><strong>drop</strong>：任何传入的网络连接都被丢弃，并且不发送任何响应。只允许传出网络连接。</p></li><li><p><strong>external</strong>：用于启用伪装的外部网络，主要是路由器。您不相信网络上的其他计算机不会伤害您的计算机。仅接受某些类型的入站连接。</p></li><li><p><strong>home</strong>：用于在家中使用。您通常相信网络上的其他计算机不会损害您的计算机。仅接受某些类型的传入连接。</p></li><li><p><strong>internal</strong>：用于内部网络。您通常相信网络上的其他计算机不会损害您的计算机。仅接受某些入站连接。</p></li><li><p><strong>public</strong>：用于外部网络。您不相信网络上的其他计算机不会伤害您的计算机。仅接受某些类型的入站连接。</p></li><li><p><strong>trusted</strong>：允许任何网络连接。</p></li><li><p><strong>work</strong>：用于工作场所。您通常相信网络上的其他计算机不会损害您的计算机。仅接受某些入站连接。</p></li></ul><p>如果您没有进行任何其他更改，Firewalld 的默认区域设置为“<code>public</code>”。检查默认区域：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --get-default-zone</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/952d5da59fa44b235f1a2b5d2e87fe5e.png" alt=""></p><p>要更改默认区域，例如“home”，请键入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --set-default-zone&#x3D;home</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9aeef901ea643092ff5222d4b5408be7.png" alt=""></p><p>要列出活动区域和分配给它们的网络接口，请运行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --get-active-zones</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/441447f5439dcc0b43d51a24891f718a.png" alt=""></p><p>要将网络接口（在我们的示例中为 enp1s0）分配给另一个区域，例如“home”，请键入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;home --change-interface&#x3D;enp1s0</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/a878f12acd638d21ae97daa57cd58fa3.png" alt=""></p><p>请记住，如果您的系统上只有一个网络接口并将其分配给另一个区域，则默认情况下该区域将变为活动状态。</p><p>要获取特定区域的所有配置，例如“public”，请运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --list-all</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/e04cadcc3ae702a5e611e456a674df1c.png" alt=""></p><p>同样，要一次获取所有区域的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --list-all-zones</span><br></pre></td></tr></table></figure><h3 id="按服务名称允许和拒绝"><a href="#按服务名称允许和拒绝" class="headerlink" title="按服务名称允许和拒绝"></a>按服务名称允许和拒绝</h3><p>Firewalld 可以根据预定义的规则允许特定网络服务的流量。最简单的方法是将您需要允许的服务添加到您正在使用的区域。</p><p>当然，您首先应该知道服务的名称。但是很难记住所有服务的名称，即使它们符合预期。因此，使用以下命令，我们可以查看所有可用预定义的名称。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --get-services</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/d5e143ad8ac8bf785c8c1428465f13af.png" alt=""></p><p>您可以在services 目录中的相关<code>.xml</code>文件中找到有关这些服务的更多详细信息。<code>/usr/lib/firewalld/</code>例如 MySQL 服务定义如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat &#x2F;usr&#x2F;lib&#x2F;firewalld&#x2F;services&#x2F;mysql.xml</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/a479e43e55edb5c2c713e3df260fbd28.png" alt=""></p><p>假设我们要启用 MySQL 服务。为此，我们<code>--add-service=</code>在<code>firewalld-cmd</code>命令后添加服务名称，并使用<code>--zone=</code>选项指定分配服务的区域。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --add-service&#x3D;mysql</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/f4eb0ba2199d59473a90569aa9d7fb90.png" alt=""></p><p>现在让我们重新检查“<code>public</code>”区域的详细信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --list-all</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/eae06d674eca4d68c3980261fffcab45.png" alt=""></p><p>OK。我们添加了一个防火墙规则，允许传入连接到 MySQL 服务器。然而，这个规则是暂时的。这意味着该规则在系统重新启动期间将无法生存。</p><p>为了确保规则的持久性，我们必须<code>--permanent</code>在命令中添加选项。这样，即使在重新启动后，Firewalld 也会自动加载它。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --add-service&#x3D;mysql --permanent</span><br></pre></td></tr></table></figure><p>我们必须注意一个重要细节：添加不带<code>--permanent</code>选项的规则使其立即可用并生效。但是，<code>--permanent</code>在系统重新启动之前，使用将不起作用。</p><p>因此，为了使我们的新永久规则立即生效，我们需要重新加载 Firewalld，执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --reload</span><br></pre></td></tr></table></figure><p>这样，我们在保留状态信息的同时重新加载防火墙规则。换句话说，当前的永久配置将成为新的运行时配置。</p><p>现在让我们看看如何从防火墙中删除规则。该过程几乎与添加相同，但这次<code>--remove-service</code>使用了该选项。</p><p>例如，要删除 MySQL 服务，我们必须发出以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --remove-service&#x3D;mysql</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/ef5d250d960f29b81ff89eb23e6bc1ad.png" alt=""></p><p>同样，要永久删除访问权限，我们需要添加<code>--permanent</code>选项，然后重新加载规则以使更改立即生效。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --remove-service&#x3D;mysql --permanent</span><br><span class="line">sudo firewall-cmd --reload</span><br></pre></td></tr></table></figure><h3 id="按端口号允许和拒绝"><a href="#按端口号允许和拒绝" class="headerlink" title="按端口号允许和拒绝"></a>按端口号允许和拒绝</h3><p>但是，有时我们必须通过指定<a href="https://linuxiac.com/common-network-ports/" target="_blank" rel="noopener">端口号</a>来允许访问。例如，假设您有一个服务在非标准 TCP 端口 10069 上进行侦听。因此，我们需要的不是按名称预定义服务。</p><p>幸运的是，Firewalld 提供了一种允许通过端口和协议进行访问的方法，该方法与服务名称完全相同。例如，要允许流量到 TCP 上的端口 10069，请运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --add-port&#x3D;10069&#x2F;tcp</span><br></pre></td></tr></table></figure><p>我们检查允许的端口，执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --list-ports</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/5660c77cc54a3164754768db9ffe4fe3.png" alt=""></p><p>当然，我们也可以通过熟悉的方式对整个区域的大图进行概览：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --list-all</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/d60fa9ab1d79ad975b5d45684eb0b9ae.png" alt=""></p><p>与使用服务名称时相同的持久性规则在这里适用。因此，为了确保我们的防火墙规则在重新启动之间仍然存在，我们需要执行以下操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --add-port&#x3D;10069&#x2F;tcp --permanent</span><br><span class="line">sudo firewall-cmd --reload</span><br></pre></td></tr></table></figure><p>此外，如果您要启用的端口使用 UDP 协议而不是 TCP，则必须在该行<code>tcp</code>替换为。<code>udp``firewall-cmd</code></p><p>从规则列表中删除端口的方法是相同的，唯一的区别是替换为<code>--add-port=</code>选项<code>--remove-port=</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --remove-port&#x3D;10069&#x2F;tcp --permanent</span><br><span class="line">sudo firewall-cmd --reload</span><br></pre></td></tr></table></figure><h3 id="防火墙丰富的规则"><a href="#防火墙丰富的规则" class="headerlink" title="防火墙丰富的规则"></a>防火墙丰富的规则</h3><p>熟悉 iptables 的人会轻松使用 firewalld 丰富的规则。顾名思义，它们使您能够构建具有多个标准的复杂规则，而这些标准是使用名称或基于端口的规则无法实现的。</p><p>换句话说，防火墙丰富的规则通过更自定义的粒度选项提供了更高级别的控制。此外，他们还可以配置日志记录、伪装、端口转发和速率限制。</p><p>它们的使用可以有无数种变化，所以如果你想了解更多关于它们的信息，你应该查阅<a href="https://firewalld.org/documentation/man-pages/firewalld.richlanguage.html" target="_blank" rel="noopener">官方文档</a>。在这里，我们将提供一些简化的示例，让您了解如何使用 Firewalld 丰富的规则。</p><p>例如，假设我们要允许访问 MySQL 服务器，正如我们所知，该服务器从 IP 地址 192.168.1.69 侦听端口 3306。规则如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --add-rich-rule &#39;rule family&#x3D;&quot;ipv4&quot; source address&#x3D;&quot;192.168.1.69&quot; port port&#x3D;3306 protocol&#x3D;tcp accept&#39;</span><br></pre></td></tr></table></figure><p>与基于名称和端口的规则一样，Firewalld 的丰富规则不是持久的，除非<code>--permanent</code>指定了标志。</p><p>删除此规则的命令与上述命令相同，只是该<code>--add-rich-rule</code>选项应替换为<code>--remove-rich-rule</code>.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --remove-rich-rule &#39;rule family&#x3D;&quot;ipv4&quot; source address&#x3D;&quot;192.168.1.69&quot; port port&#x3D;&quot;3306&quot; protocol&#x3D;&quot;tcp&quot; accept&#39;</span><br></pre></td></tr></table></figure><p>如果我们想要做相反的事情并阻止从 IP 地址 192.168.1.69 访问 MySQL 服务器，我们的规则是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --add-rich-rule &#39;rule family&#x3D;&quot;ipv4&quot; source address&#x3D;&quot;192.168.1.69&quot; port port&#x3D;&quot;3306&quot; protocol&#x3D;&quot;tcp&quot; reject&#39;</span><br></pre></td></tr></table></figure><p>作为最后一个示例，我们希望将所有入站流量从端口 80 重定向到主机 192.168.1.200 上的端口 8080，我们已经安装了<a href="https://linuxiac.com/install-apache-tomcat-on-almalinux-9-rocky-linux-9/" target="_blank" rel="noopener">Tomcat 服务器</a>。为了实现这一点，我们的 Firewalld 丰富规则应该是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --add-rich-rule &#39;rule family&#x3D;ipv4 forward-port port&#x3D;80 protocol&#x3D;tcp to-port&#x3D;8080 to-addr&#x3D;192.168.1.200&#39;</span><br></pre></td></tr></table></figure><p>您可以通过运行以下命令来查看丰富的规则：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone&#x3D;public --list-rich-rules</span><br></pre></td></tr></table></figure><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/5699912701a1f9f33a0af1b6b4473c3b.png" alt=""></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>我们的指南到此结束。我希望你觉得它有帮助。您现在应该很好地了解 Firewalld 是什么以及如何使用它来保护您的计算机和网络。了解它将使您能够使用该工具的灵活性和功能。</p><p>有关 Firewalld 的更深入概述，请访问<a href="https://firewalld.org/documentation/" target="_blank" rel="noopener">官方文档</a>或查看Red Hat 网站上的<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_firewalls_and_packet_filters/using-and-configuring-firewalld_firewall-packet-filters" target="_blank" rel="noopener">这篇文章</a>，他们是 Firewalld 的作者。</p><p>本文转自 <a href="https://www.linuxmi.com/firewalld-guide.html" target="_blank" rel="noopener">https://www.linuxmi.com/firewalld-guide.html</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> firewalld </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes 集群安装记录</title>
      <link href="/posts/cffb64f7/"/>
      <url>/posts/cffb64f7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><blockquote><p>暂先记录命令</p><p>基于CentOS7 进行安装</p></blockquote><h2 id="对系统进行配置"><a href="#对系统进行配置" class="headerlink" title="对系统进行配置"></a>对系统进行配置</h2><h3 id="关闭-firewalld"><a href="#关闭-firewalld" class="headerlink" title="关闭 firewalld"></a>关闭 firewalld</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 临时关闭 firewalld</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line"><span class="meta">#</span><span class="bash"> 关闭 firewalld 开机启动</span></span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure><h3 id="关闭-selinux"><a href="#关闭-selinux" class="headerlink" title="关闭 selinux"></a>关闭 selinux</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 临时关闭 selinux</span></span><br><span class="line">setenforce 0</span><br><span class="line"><span class="meta">#</span><span class="bash"> 关闭 selinux 开机启动</span></span><br><span class="line">sed -i 's/enforcing/disabled/' /etc/selinux/config</span><br></pre></td></tr></table></figure><h3 id="关闭-swap-交换分区"><a href="#关闭-swap-交换分区" class="headerlink" title="关闭 swap 交换分区"></a>关闭 swap 交换分区</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 临时关闭 swap</span></span><br><span class="line">swapoff -a</span><br><span class="line"><span class="meta">#</span><span class="bash"> 禁止开机时开启 swap</span></span><br><span class="line">sed -ri 's/.*swap.*/#&amp;/' /etc/fstab</span><br></pre></td></tr></table></figure><h3 id="将-kubernetes-集群中所有主机添加到-hosts-中"><a href="#将-kubernetes-集群中所有主机添加到-hosts-中" class="headerlink" title="将 kubernetes 集群中所有主机添加到 hosts 中"></a>将 kubernetes 集群中所有主机添加到 hosts 中</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /etc/hosts &lt;&lt; EOF</span><br><span class="line">192.168.233.129 k8s-master</span><br><span class="line">192.168.233.130 k8s-node01</span><br><span class="line">192.168.233.131 k8s-node02</span><br><span class="line">192.168.233.132 k8s-node03</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="配置-iptables-不对-bridge-的数据进行处理"><a href="#配置-iptables-不对-bridge-的数据进行处理" class="headerlink" title="配置 iptables 不对 bridge 的数据进行处理"></a>配置 iptables 不对 bridge 的数据进行处理</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 同步到系统</span></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure><h3 id="安装-NTP-客户端（与互联网同步时间）"><a href="#安装-NTP-客户端（与互联网同步时间）" class="headerlink" title="安装 NTP 客户端（与互联网同步时间）"></a>安装 NTP 客户端（与互联网同步时间）</h3><blockquote><p>此步骤的目的是保持集群中时间保持一致，如果纯内网环境 可自建 NTP 服务器，并将命令中的 公共NTP服务器更换为自建 NTP 服务器</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装 ntpdate 包</span></span><br><span class="line">yum -y install ntpdate</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设定 ntp 服务器为微软公共 NTP 服务器</span></span><br><span class="line">ntpdate time.windows.com</span><br></pre></td></tr></table></figure><h2 id="安装-DockerCE"><a href="#安装-DockerCE" class="headerlink" title="安装 DockerCE"></a>安装 DockerCE</h2><h3 id="安装-wget"><a href="#安装-wget" class="headerlink" title="安装 wget"></a>安装 wget</h3><blockquote><p>最小化安装的 centos 中不包含 wget</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install wget</span><br></pre></td></tr></table></figure><h3 id="保存-aliyun-的docker-ce-库文件"><a href="#保存-aliyun-的docker-ce-库文件" class="headerlink" title="保存 aliyun 的docker-ce 库文件"></a>保存 aliyun 的docker-ce 库文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo</span><br></pre></td></tr></table></figure><h3 id="安装-docker-ce"><a href="#安装-docker-ce" class="headerlink" title="安装 docker-ce"></a>安装 docker-ce</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install docker-ce</span><br></pre></td></tr></table></figure><h3 id="启动-docker-ce"><a href="#启动-docker-ce" class="headerlink" title="启动 docker-ce"></a>启动 docker-ce</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动 docker</span></span><br><span class="line">systemctl start docker</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置 docker 服务开机启动</span></span><br><span class="line">systemctl enable docker</span><br></pre></td></tr></table></figure><h3 id="配置-docker-服务"><a href="#配置-docker-服务" class="headerlink" title="配置 docker 服务"></a>配置 docker 服务</h3><blockquote><p><code>registry-mirrors</code> 配置 docker 镜像仓库</p><p><code>exec-opts</code> 配置参数，这里主要修改 docker 默认的 cgroup 驱动</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/docker/daemon.json</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"registry-mirrors"</span>: [<span class="string">"https://docker.mirrors.ustc.edu.cn/"</span>],</span><br><span class="line">  <span class="attr">"exec-opts"</span>: [<span class="string">"native.cgroupdriver=systemd"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 重启 docker 服务使配置生效</span></span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><h2 id="kubernetes-服务安装"><a href="#kubernetes-服务安装" class="headerlink" title="kubernetes 服务安装"></a>kubernetes 服务安装</h2><h3 id="添加-kubernetes-库文件"><a href="#添加-kubernetes-库文件" class="headerlink" title="添加 kubernetes 库文件"></a>添加 kubernetes 库文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.ustc.edu.cn/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=https://mirrors.ustc.edu.cn/kubernetes/yum/doc/yum-key.gpg https://mirrors.ustc.edu.cn/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="安装相关-kubernetes-包"><a href="#安装相关-kubernetes-包" class="headerlink" title="安装相关 kubernetes 包"></a>安装相关 kubernetes 包</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</span><br></pre></td></tr></table></figure><h3 id="配置-kubelet-开机启动"><a href="#配置-kubelet-开机启动" class="headerlink" title="配置 kubelet 开机启动"></a>配置 kubelet 开机启动</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable kubelet</span><br></pre></td></tr></table></figure><h3 id="下载相关-docker-镜像"><a href="#下载相关-docker-镜像" class="headerlink" title="下载相关 docker 镜像"></a>下载相关 docker 镜像</h3><blockquote><p>因国内网络环境不稳定，所以此处先从 <code>registry.aliyuncs.com</code> 下载相关镜像，再使用 docker tag 命令将这些镜像重命名为标准名称</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载镜像</span></span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/kube-apiserver:v1.25.4</span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/kube-controller-manager:v1.25.4</span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/kube-scheduler:v1.25.4</span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/kube-proxy:v1.25.4</span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/pause:3.8</span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/etcd:3.5.5-0</span><br><span class="line">docker pull registry.aliyuncs.com/google_containers/coredns:v1.9.3</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 重新命名镜像</span></span><br><span class="line">docker tag registry.aliyuncs.com/google_containers/kube-apiserver:v1.25.4 registry.k8s.io/google_containers/kube-apiserver:v1.25.4</span><br><span class="line">docker tag registry.aliyuncs.com/google_containers/kube-controller-manager:v1.25.4 registry.k8s.io/google_containers/kube-controller-manager:v1.25.4</span><br><span class="line">docker tag registry.aliyuncs.com/google_containers/kube-scheduler:v1.25.4 registry.k8s.io/google_containers/kube-scheduler:v1.25.4</span><br><span class="line">docker tag registry.aliyuncs.com/google_containers/kube-proxy:v1.25.4 registry.k8s.io/google_containers/kube-proxy:v1.25.4</span><br><span class="line">docker tag registry.aliyuncs.com/google_containers/pause:3.8 registry.k8s.io/google_containers/pause:3.8</span><br><span class="line">docker tag registry.aliyuncs.com/google_containers/etcd:3.5.5-0 registry.k8s.io/google_containers/etcd:3.5.5-0</span><br><span class="line">docker tag registry.aliyuncs.com/google_containers/coredns:v1.9.3 registry.k8s.io/google_containers/coredns/coredns:v1.9.3</span><br></pre></td></tr></table></figure><h3 id="containerd-相关操作"><a href="#containerd-相关操作" class="headerlink" title="containerd 相关操作"></a>containerd 相关操作</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 删除 containerd 默认配置文件</span></span><br><span class="line">rm /etc/containerd/config.toml</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启 containerd</span></span><br><span class="line">systemctl restart containerd</span><br></pre></td></tr></table></figure><h3 id="使用-kubeadm-下载相关镜像"><a href="#使用-kubeadm-下载相关镜像" class="headerlink" title="使用 kubeadm 下载相关镜像"></a>使用 kubeadm 下载相关镜像</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm config images pull</span><br></pre></td></tr></table></figure><h2 id="启动-kubernetes-服务"><a href="#启动-kubernetes-服务" class="headerlink" title="启动 kubernetes 服务"></a>启动 kubernetes 服务</h2><h3 id="初始化集群（仅在-master-执行）"><a href="#初始化集群（仅在-master-执行）" class="headerlink" title="初始化集群（仅在 master 执行）"></a>初始化集群（仅在 master 执行）</h3><blockquote><p><code>apiserver-advertise-address</code> 集群 master 的IP地址</p><p><code>service-cidr</code> kubernetes 服务的子网</p><p><code>pod-network-cidr</code>  kubernetes pod 网络的子网</p><p><code>ignore-preflight-errors</code>  忽略预检错误</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init \</span><br><span class="line">--apiserver-advertise-address=192.168.233.129 \</span><br><span class="line">--service-cidr=10.96.0.0/12 \</span><br><span class="line">--pod-network-cidr=10.244.0.0/16 \</span><br><span class="line">--ignore-preflight-errors=all</span><br></pre></td></tr></table></figure><p>执行完初始化命令后，如果没有出现错误，则会显示如下命令（需要记下此条命令）。以下token生成结果每个人都不同。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.233.129:6443 --token 1oceiq.4roygoeq52m5x85i \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:a3fba05d4e2bc170e49ebddf11cd779d664a3936ec8502366c6be69fbd96ecde</span><br></pre></td></tr></table></figure><p>此条命令的主要作用是将 kubernetes 节点加入到集群中。默认token有效期为24小时，当过期之后，该token就不可用了。这时就需要重新创建token，可以直接使用命令快捷生成：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm token create --print-join-command</span><br></pre></td></tr></table></figure><h3 id="将节点加入到集群中（仅在-node-执行）"><a href="#将节点加入到集群中（仅在-node-执行）" class="headerlink" title="将节点加入到集群中（仅在 node 执行）"></a>将节点加入到集群中（仅在 node 执行）</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.233.129:6443 --token 1oceiq.4roygoeq52m5x85i \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:a3fba05d4e2bc170e49ebddf11cd779d664a3936ec8502366c6be69fbd96ecde</span><br></pre></td></tr></table></figure><h2 id="部署容器calico网络-（仅在-master-执行）"><a href="#部署容器calico网络-（仅在-master-执行）" class="headerlink" title="部署容器calico网络 （仅在 master 执行）"></a>部署容器calico网络 （仅在 master 执行）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 配置 KUBECONFIG 环境变量</span></span><br><span class="line">echo "export KUBECONFIG=/etc/kubernetes/admin.conf" &gt;&gt; /etc/profile</span><br><span class="line"><span class="meta">#</span><span class="bash"> 同步系统环境变量到当前 shell 中</span></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta">#</span><span class="bash"> 下载相关容器网络配置文件模板</span></span><br><span class="line">wget https://raw.githubusercontent.com/projectcalico/calico/v3.24.5/manifests/tigera-operator.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/projectcalico/calico/v3.24.5/manifests/custom-resources.yaml</span><br></pre></td></tr></table></figure><h3 id="修改容器网络配置文件"><a href="#修改容器网络配置文件" class="headerlink" title="修改容器网络配置文件"></a>修改容器网络配置文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim custom-resources.yaml</span><br></pre></td></tr></table></figure><blockquote><p>修改 custom-resources.yaml IP为 pod-network-cidr。上文中有提到</p></blockquote><h3 id="创建容器网络"><a href="#创建容器网络" class="headerlink" title="创建容器网络"></a>创建容器网络</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f tigera-operator.yaml</span><br><span class="line">kubectl create -f custom-resources.yaml</span><br></pre></td></tr></table></figure><h2 id="部署-kubernetes-Dashboard"><a href="#部署-kubernetes-Dashboard" class="headerlink" title="部署 kubernetes Dashboard"></a>部署 kubernetes Dashboard</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载 kubernetes Dashboard 的编排文件</span></span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml</span><br><span class="line"><span class="meta">#</span><span class="bash"> 编辑上述编排文件</span></span><br><span class="line">vi recommended.yaml</span><br></pre></td></tr></table></figure><blockquote><p>修改Service为NodePort类型，暴露到外部。对照配置文件自行修改，以下为我修改完成的样子：</p></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">8443</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">30001</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br></pre></td></tr></table></figure><h3 id="部署-Dashboard"><a href="#部署-Dashboard" class="headerlink" title="部署 Dashboard"></a>部署 Dashboard</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f recommended.yaml</span><br></pre></td></tr></table></figure><h3 id="创建-Dashboard-用户"><a href="#创建-Dashboard-用户" class="headerlink" title="创建 Dashboard 用户"></a>创建 Dashboard 用户</h3><blockquote><p>用户名为：dashboard-admin，可根据要求自行修改</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create serviceaccount dashboard-admin -n kube-system</span><br></pre></td></tr></table></figure><h3 id="授权"><a href="#授权" class="headerlink" title="授权"></a>授权</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin</span><br></pre></td></tr></table></figure><h3 id="创建-Token"><a href="#创建-Token" class="headerlink" title="创建 Token"></a>创建 Token</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system create token dashboard-admin</span><br></pre></td></tr></table></figure><h3 id="访问-Dashboard"><a href="#访问-Dashboard" class="headerlink" title="访问 Dashboard"></a>访问 Dashboard</h3><p>访问 <a href="https://192.168.233.129:30001/#/login" target="_blank" rel="noopener">https://192.168.233.129:30001/#/login</a> 并使用上一步生成的Token进行登录</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>安装目录：/etc/kubernetes/</p><p>组件配置文件目录：/etc/kubernetes/manifests/</p>]]></content>
      
      
      
        <tags>
            
            <tag> kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从0到1详解ZooKeeper的应用场景及架构</title>
      <link href="/posts/15ab9f73/"/>
      <url>/posts/15ab9f73/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h3 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h3><h4 id="1-后台系统由集中式发展为分布式"><a href="#1-后台系统由集中式发展为分布式" class="headerlink" title="1 后台系统由集中式发展为分布式"></a>1 后台系统由集中式发展为分布式</h4><p>随着计算机系统的规模越来越大，业务量的迅速提升和互联网的爆炸式增长，集中式系统采用大型主机单机部署带来了一系列问题：系统大而复杂、难于维护、发生单点故障引起雪崩、扩展性差等。这些都使业务面临巨大的压力和严重的风险，为了解决集中式系统架构面临的痛点，分布式系统架构逐步走上舞台。分布式系统是一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统，可以很好的解决系统扩容、可用性以及降低成本。</p><h4 id="2-分布式系统架构引入的新问题"><a href="#2-分布式系统架构引入的新问题" class="headerlink" title="2 分布式系统架构引入的新问题"></a>2 分布式系统架构引入的新问题</h4><p><strong>“天下没有免费的午餐”</strong>，分布式系统架构带来了优点的同时，也提出了一系列的挑战：</p><p>（1）由于多节点甚至多地部署，节点之间的数据一致性如何保证？</p><p>（2）在并发场景下如何保证任务只被执行一次？</p><p>（3）一个节点挂掉不能提供服务时如何被集群知晓并由其他节点接替任务？</p><p>（4）存在资源共享时，资源的安全性和互斥性如何保证？</p><p>以上列举了分布式系统中面临的一些挑战，需要一个协调机制来解决分布式集群中的问题，使得开发者更专注于应用本身的逻辑而不是关注分布式系统处理。</p><h4 id="3-分布式协调组件"><a href="#3-分布式协调组件" class="headerlink" title="3 分布式协调组件"></a>3 分布式协调组件</h4><p>为解决分布式系统中面临的这些问题，开发者们通过工程实践创造了很多非常优秀的分布式系统协调组件，这些组件可以在分布式环境下，保证分布式系统的数据一致性和容错性等。其中为我们熟知的有：ZooKeeper、ETCD、Consul 等。ZooKeeper 作为 Apache 的顶级开源项目，基于 Google Chubby 开源实现，在 Hadoop，Hbase，Kafka 等技术中充当核心组件的角色。虽然历史悠久，但就像陈酿一样，其设计思想和实现不论何时还是值得仔细学习和品味。</p><h3 id="二、ZooKeeper"><a href="#二、ZooKeeper" class="headerlink" title="二、ZooKeeper"></a>二、ZooKeeper</h3><h4 id="1-ZooKeeper-是什么"><a href="#1-ZooKeeper-是什么" class="headerlink" title="1 ZooKeeper 是什么"></a>1 ZooKeeper 是什么</h4><p>从理论概念角度解释：ZooKeeper 是一个分布式的，开源的分布式应用程序协调服务，它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。</p><p>从数据读写角度解释：ZooKeeper 是一个分布式的开源协调服务，用于分布式系统。ZooKeeper 允许你读取、写入数据和发现数据更新。数据按层次结构组织在文件系统中，并复制到 ensemble（一个 ZooKeeper 服务器的集合）中所有的 ZooKeeper 服务器。对数据的所有操作都是原子的和顺序一致的。ZooKeeper 通过 Zab 一致性协议在 ensemble 的所有服务器之间复制一个状态机来确保这个特性。</p><h4 id="2-ZooKeeper-的安装与使用"><a href="#2-ZooKeeper-的安装与使用" class="headerlink" title="2 ZooKeeper 的安装与使用"></a>2 ZooKeeper 的安装与使用</h4><p><strong>“纸上得来终觉浅，绝知此事要躬行”</strong>，学习一个新的组件，我们先通过安装使用，对配置、API 等有一个直观的认识，也为后面动手实现一些功能部署好开发环境基础。</p><h5 id="2-1-ZooKeeper-下载与安装"><a href="#2-1-ZooKeeper-下载与安装" class="headerlink" title="2.1 ZooKeeper 下载与安装"></a>2.1 ZooKeeper 下载与安装</h5><p>（1）ZooKeeper 使用 JAVA 语言开发，使用前需要先安装 JDK(读者自行安装)，安装 JDK 后可在终端命令行中使用 java -version 命令查看版本（<strong>注意：本文均在 Linux 环境下指导演示</strong>）。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/74b997e86ccfa87a62892a576bd4b055.jpeg" alt=""></p><p>（2）ZooKeeper 下载：<a href="https://zookeeper.apache.org/releases.html" target="_blank" rel="noopener">https://zookeeper.apache.org/releases.html</a> </p><p>在下载页面分为最新的 Release 版本和最近的稳定 Release 版本，这里生产环境使用推荐稳定版本，点击下载并上传 apache-zookeeper-3.7.0-bin.tar.gz 到 Linux 服务器上。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/ef0cc840032a04db447c94be697e733c.jpeg" alt=""></p><p>（3）ZooKeeper 安装：ZooKeeper 安装分为集群安装和单机安装，生产环境一般为集群安装。此处作为演示，使用一台服务器来做模拟集群，也称伪集群安装(通过三个不同的文件夹 zk1/zk2/zk3，模拟真实环境中的三台服务器实例)。</p><ol><li><p>本篇中我们将要在本地开发机上安装三个 zk 实例（可以认为在生产集群模式中，这是三台不同的服务器），其安装位置分别如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk1  </span><br><span class="line">&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk2  </span><br><span class="line">&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk3</span><br></pre></td></tr></table></figure></li><li><p>将上文中下载的 ZooKeeper 安装包 apache-zookeeper-3.7.0-bin.tar.gz 上传到第一个实例 zk1 文件夹下，并使用如下命令进行解压：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf apache-zookeeper-3.7.0-bin.tar.gz</span><br></pre></td></tr></table></figure></li><li><p>解压完成后在 zk1 文件夹下创建 data 和 log 目录，分别用于存储当前 zk 实例数据和日志：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir data logs</span><br></pre></td></tr></table></figure><p>此时 zk1 文件夹目录结构如下所示：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/576e0389f6a81d2f6b779d270161d3c5.jpeg" alt=""></p></li></ol><ol start="4"><li><p>创建 myid 文件 在 zk1 的 data 目录下，<strong>创建 myid 文件</strong>，此文件记录节点 id，每个 zookeeper 节点都需要一个 myid 文件来记录节点在集群中的 id，此文件中只能有一个数字，这里 zk1 实例 myid 中写入一个 1 即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;1&quot; &gt;&gt; &#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk1&#x2F;data&#x2F;myid  &#x2F;&#x2F; 实例zk1的myid赋值为1  </span><br><span class="line">echo &quot;2&quot; &gt;&gt; &#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk2&#x2F;data&#x2F;myid  &#x2F;&#x2F; 实例zk2的myid赋值为2  </span><br><span class="line">echo &quot;3&quot; &gt;&gt; &#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk3&#x2F;data&#x2F;myid  &#x2F;&#x2F; 实例zk3的myid赋值为3</span><br></pre></td></tr></table></figure></li><li><p>进入 zk1 文件夹下 apache-zookeeper-3.7.0-bin/conf/目录，将配置文件 zoo_sample.cfg 重命名为 zoo.cfg，打开 zoo.cfg 进行配置，具体配置如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tickTime&#x3D;2000  # 单位时间，其他时间都是以这个倍数来表示  </span><br><span class="line">initLimit&#x3D;10   # 节点初始化时间，10倍单位时间(即十倍tickTime)  </span><br><span class="line">syncLimit&#x3D;5    # 心跳最大延迟周期  </span><br><span class="line">dataDir&#x3D;&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk1&#x2F;data     # 该实例对应的数据目录（上文步骤3创建）  </span><br><span class="line">dataLogDir&#x3D;&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk1&#x2F;logs  # 该实例对应的日志目录（上文步骤3创建）  </span><br><span class="line">clientPort&#x3D;2181                              # 端口（每个实例不同）  </span><br><span class="line">&#x2F;&#x2F; 集群配置  </span><br><span class="line">server.1&#x3D;127.0.0.1:8881:7771                 # server.id&#x3D;host:port:port  </span><br><span class="line">server.2&#x3D;127.0.0.1:8882:7772                 # server.id&#x3D;host:port:port  </span><br><span class="line">server.3&#x3D;127.0.0.1:8883:7773                 # server.id&#x3D;host:port:port</span><br></pre></td></tr></table></figure><p>集群配置中模版为 server.id=host:port:port，id 是上面 myid 文件中配置的 id；ip 是节点的 ip，第一个 port 是节点之间通信的端口，第二个 port 用于选举 leader 节点（在真正的集群模式下，不同服务器可以共用同一个 port，这里单机上演示为了避免端口冲突，选择不同的端口）。</p></li></ol><ol start="6"><li><p>zk2 和 zk3 的实例配置与 zk1 类似，为了方便我们可以直接拷贝 zk1 的配置到 zk2 和 zk3 文件夹，然后修改各自的 zoo.cfg 和 data 目录下的 myid 即可。拷贝命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp -R zk1 zk2  </span><br><span class="line">cp -R zk1 zk3</span><br></pre></td></tr></table></figure><p>zk2 对应的 zoo.cfg：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tickTime&#x3D;2000  # 单位时间，其他时间都是以这个倍数来表示  </span><br><span class="line">initLimit&#x3D;10   # 节点初始化时间，10倍单位时间(即十倍tickTime)  </span><br><span class="line">syncLimit&#x3D;5    # 心跳最大延迟周期  </span><br><span class="line">dataDir&#x3D;&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk2&#x2F;data     # 该实例对应的数据目录（上文步骤3创建）  </span><br><span class="line">dataLogDir&#x3D;&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk2&#x2F;logs  # 该实例对应的日志目录（上文步骤3创建）  </span><br><span class="line">clientPort&#x3D;2182                              # 端口（每个实例不同）  </span><br><span class="line">&#x2F;&#x2F; 集群配置  </span><br><span class="line">server.1&#x3D;127.0.0.1:8881:7771                 # server.id&#x3D;host:port:port  </span><br><span class="line">server.2&#x3D;127.0.0.1:8882:7772                 # server.id&#x3D;host:port:port  </span><br><span class="line">server.3&#x3D;127.0.0.1:8883:7773                 # server.id&#x3D;host:port:port</span><br></pre></td></tr></table></figure><p>zk3 对应的 zoo.cfg：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tickTime&#x3D;2000  # 单位时间，其他时间都是以这个倍数来表示  </span><br><span class="line">initLimit&#x3D;10   # 节点初始化时间，10倍单位时间(即十倍tickTime)  </span><br><span class="line">syncLimit&#x3D;5    # 心跳最大延迟周期  </span><br><span class="line">dataDir&#x3D;&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk3&#x2F;data     # 该实例对应的数据目录（上文步骤3创建）  </span><br><span class="line">dataLogDir&#x3D;&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk3&#x2F;logs  # 该实例对应的日志目录（上文步骤3创建）  </span><br><span class="line">clientPort&#x3D;2183                              # 端口（每个实例不同）  </span><br><span class="line">&#x2F;&#x2F; 集群配置  </span><br><span class="line">server.1&#x3D;127.0.0.1:8881:7771                 # server.id&#x3D;host:port:port  </span><br><span class="line">server.2&#x3D;127.0.0.1:8882:7772                 # server.id&#x3D;host:port:port  </span><br><span class="line">server.3&#x3D;127.0.0.1:8883:7773                 # server.id&#x3D;host:port:port</span><br></pre></td></tr></table></figure><p>至此 zk 伪集群模式的安装配置已经完成，整体目录结构纵览如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">.  </span><br><span class="line">├── zk1  </span><br><span class="line">│   ├── data  </span><br><span class="line">│   │     └── myid  </span><br><span class="line">│   ├── logs  </span><br><span class="line">│   └── apache-zookeeper-3.7.0-bin  </span><br><span class="line">├── zk2  </span><br><span class="line">│   ├── data  </span><br><span class="line">│   │     └── myid  </span><br><span class="line">│   ├── logs  </span><br><span class="line">│   └── apache-zookeeper-3.7.0-bin  </span><br><span class="line">└── zk3  </span><br><span class="line">│   ├── data  </span><br><span class="line">│   │     └── myid  </span><br><span class="line">    ├── logs  </span><br><span class="line">    └── apache-zookeeper-3.7.0-bin</span><br></pre></td></tr></table></figure><p>（4）ZooKeeper 实例启动及使用客户端交互：</p></li></ol><ol><li><p>启动刚刚创建的三个 zk 实例 (1) 启动 zk1 实例，命令行运行下面命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 启动命令  </span><br><span class="line">&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk1&#x2F;apache-zookeeper-3.7.0-bin&#x2F;bin&#x2F;zkServer.sh start  </span><br><span class="line">&#x2F;&#x2F; 启动结果  </span><br><span class="line">ZooKeeper JMX enabled by default  </span><br><span class="line">Using config: &#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk1&#x2F;apache-zookeeper-3.7.0-bin&#x2F;bin&#x2F;..&#x2F;conf&#x2F;zoo.cfg  </span><br><span class="line">Starting zookeeper ... STARTED</span><br></pre></td></tr></table></figure><p>(2) 同样启动 zk2 和 zk3 实例，命令行运行下面命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 启动zk2命令  </span><br><span class="line">&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk2&#x2F;apache-zookeeper-3.7.0-bin&#x2F;bin&#x2F;zkServer.sh start  </span><br><span class="line">&#x2F;&#x2F; 启动zk3命令  </span><br><span class="line">&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk3&#x2F;apache-zookeeper-3.7.0-bin&#x2F;bin&#x2F;zkServer.sh start</span><br></pre></td></tr></table></figure></li></ol><ol start="2"><li><p>连接实例 所有实例全部启动过后，选择任一实例进行连接，这里选择实例 zk2，命令行输入如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk2&#x2F;apache-zookeeper-3.7.0-bin&#x2F;bin&#x2F;zkCli.sh -server 127.0.0.1:2182</span><br></pre></td></tr></table></figure></li></ol><ol start="3"><li><p>创建节点 连接之后，可以在当前实例上创建节点，类似于创建一个 kv 值或者文件夹（ZK 的命令和可选参数读者可以自行查看用户手册）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 创建节点 create表示创建命令，&#x2F;zk-demo为节点名称 123为节点值  </span><br><span class="line">[zk: 127.0.0.1:2181(CONNECTED) 1] create &#x2F;zk-demo 123  </span><br><span class="line">Created &#x2F;zk-demo  </span><br><span class="line">&#x2F;&#x2F; 获取节点值 get表示获取 &#x2F;zk-demo为需要获取的节点名称  </span><br><span class="line">[zk: 127.0.0.1:2181(CONNECTED) 2] get &#x2F;zk-demo  </span><br><span class="line">123</span><br></pre></td></tr></table></figure></li></ol><ol start="4"><li><p>在其他实例上获取 zk2 实例创建的节点 由于 zk 会将节点写入的值同步到集群中每个节点，从而保证数据的一致性，那么其他节点理论上也可以访问到刚刚 zk2 创建的值。下面连接 zk1 来验证下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 连接zk1  </span><br><span class="line">&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk1&#x2F;apache-zookeeper-3.7.0-bin&#x2F;bin&#x2F;zkCli.sh -server 127.0.0.1:2181  </span><br><span class="line">&#x2F;&#x2F; 获取zk2上创建的节点&#x2F;zk-demo  </span><br><span class="line">[zk: 127.0.0.1:2183(CONNECTED) 0] get &#x2F;zk-demo  </span><br><span class="line">123</span><br></pre></td></tr></table></figure><p>可以看到，我们成功的在实例 zk1 上获取到了实例 zk2 创建的节点，说明数据写入 zk2 后，在各个节点间同步并实现了一致，zk 的下载、安装和基本命令操作也就讲完了。</p></li></ol><h4 id="3-ZooKeeper-能做什么"><a href="#3-ZooKeeper-能做什么" class="headerlink" title="3 ZooKeeper 能做什么"></a>3 ZooKeeper 能做什么</h4><p>前文中，我们了解了 ZooKeeper 出现的背景，它是分布式系统中非常重要的中间件，分布式应用程序可以基于 ZooKeeper 实现：</p><ul><li><p>数据的发布和订阅</p></li><li><p>服务注册与发现</p></li><li><p>分布式配置中心</p></li><li><p>命名服务</p></li><li><p>分布式锁</p></li><li><p>Master 选举</p></li><li><p>负载均衡</p></li><li><p>分布式队列</p></li></ul><p>可以看到 ZooKeeper 可以实现非常多的功能，之所以能够实现各种不同的能力，源于 ZooKeeper 底层的数据结构和数据模型。</p><h4 id="4-ZooKeeper-的数据结构和数据模型"><a href="#4-ZooKeeper-的数据结构和数据模型" class="headerlink" title="4 ZooKeeper 的数据结构和数据模型"></a>4 ZooKeeper 的数据结构和数据模型</h4><h5 id="1-Znode-数据节点"><a href="#1-Znode-数据节点" class="headerlink" title="1 Znode 数据节点"></a>1 Znode 数据节点</h5><p>ZooKeeper 的数据节点可以视为树状结构，树中的各节点被称为 Znode（即 ZooKeeper node），一个 Znode 可以有多个子节点，ZooKeeper 中的所有存储的数据是由 znode 组成，并以 key/value 形式存储数据。整体结构类似于 linux 文件系统的模式以树形结构存储，其中根路径以 / 开头：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/3dbcb424149f2fd8f32b31a3cf09592b.jpeg" alt=""></p><p>如上图所示，在根目录下我们创建 Dog 和 Cat 两个不同的数据节点，Cat 节点下有 TomCat 这个数据存储节点，整个 ZooKeeper 的树形存储结构就是这样的 Znode 构成，并存储在内存中。</p><p>命令行下使用 ZooKeeper 客户端工具创建节点的过程如下：首先连接一个 zk 实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 连接zk1  </span><br><span class="line">&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk1&#x2F;apache-zookeeper-3.7.0-bin&#x2F;bin&#x2F;zkCli.sh -server 127.0.0.1:2181</span><br></pre></td></tr></table></figure><p>创建节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[zk: 127.0.0.1:2181(CONNECTED) 5] create &#x2F;Dog  </span><br><span class="line">Created &#x2F;Dog  </span><br><span class="line">[zk: 127.0.0.1:2181(CONNECTED) 6] create &#x2F;Cat  </span><br><span class="line">Created &#x2F;Cat  </span><br><span class="line">[zk: 127.0.0.1:2181(CONNECTED) 7] create &#x2F;Cat&#x2F;TomCat  </span><br><span class="line">Created &#x2F;Cat&#x2F;TomCat</span><br></pre></td></tr></table></figure><p>使用 ls 命令查看各个目录下的节点数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[zk: 127.0.0.1:2181(CONNECTED) 8] ls &#x2F;  </span><br><span class="line">[Cat, Dog, zk-demo, zookeeper]  </span><br><span class="line">[zk: 127.0.0.1:2181(CONNECTED) 10] ls &#x2F;Cat  </span><br><span class="line">[TomCat]</span><br></pre></td></tr></table></figure><p>Znode 节点类似于 Unix 文件系统，但也有自己的特性：</p><p>（1）<strong>Znode 兼具文件和目录特点</strong> 既像文件一样维护着数据、信息、时间戳等数据，又像目录一样可以作为路径标识的一部分，并可以具有子 Znode。用户对 Znode 具有增、删、改、查等操作；</p><p>（2）<strong>Znode 具有原子性操作</strong> 读操作将获取与节点相关的所有数据，写操作也将替换掉节点的所有数据；</p><p>（3） <strong>Znode 存储数据大小有限制</strong> 每个 Znode 的数据大小至多 1M，但是常规使用中应该远小于此值；</p><p>（4）<strong>Znode 通过路径引用</strong> 如同 Unix 中的文件路径。路径必须是绝对的，因此他们必须由斜杠字符来开头。除此以外，他们必须是唯一的，也就是说每一个路径只有一个表示，因此这些路径不能改变。</p><h5 id="2-Znode-节点类型"><a href="#2-Znode-节点类型" class="headerlink" title="2 Znode 节点类型"></a>2 Znode 节点类型</h5><p>Znode 有两种，分别为临时节点和永久节点，节点的类型在创建时即被确定，并且不能改变。</p><p>临时节点：该节点的生命周期依赖于创建它们的会话。一旦会话结束，临时节点将被自动删除，当然可以也可以手动删除。临时节点不允许拥有子节点。</p><p>永久节点：该节点的生命周期不依赖于会话，并且只有在客户端显式执行删除操作的时候，才能被删除。</p><p>Znode 还有一个序列化的特性，如果创建的时候指定的话，该 Znode 的名字后面会自动追加一个递增的序列号。序列号对于此节点的父节点来说是唯一的，这样便会记录每个子节点创建的先后顺序。因此组合之后，Znode 有四种节点类型：</p><ul><li><p>PERSISTENT：永久节点</p></li><li><p>EPHEMERAL：临时节点</p></li><li><p>PERSISTENT_SEQUENTIAL：永久顺序节点</p></li><li><p>EPHEMERAL_SEQUENTIAL：临时顺序节点</p></li></ul><p>为了对节点类型有更清楚的认识，在命令行下来模拟创建一个临时节点：（1）首先连接 zk1 实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 连接zk1  </span><br><span class="line">&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk1&#x2F;apache-zookeeper-3.7.0-bin&#x2F;bin&#x2F;zkCli.sh -server 127.0.0.1:2181</span><br></pre></td></tr></table></figure><p>（2）创建一个临时节点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; -e 表示该节点为临时节点  </span><br><span class="line">[zk: 127.0.0.1:2181(CONNECTED) 12] create -e &#x2F;Dog&#x2F;Puppy 123  </span><br><span class="line">Created &#x2F;Dog&#x2F;Puppy</span><br></pre></td></tr></table></figure><p>（3）连接 zk2 实例，查看该临时节点是否同步：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 连接zk2  </span><br><span class="line">&#x2F;Users&#x2F;newboy&#x2F;ZooKeeper&#x2F;zk2&#x2F;apache-zookeeper-3.7.0-bin&#x2F;bin&#x2F;zkCli.sh -server 127.0.0.1:2182  </span><br><span class="line">&#x2F;&#x2F; 查询&#x2F;Dog&#x2F;Puppy节点值  </span><br><span class="line">[zk: 127.0.0.1:2182(CONNECTED) 2] get &#x2F;Dog&#x2F;Puppy  </span><br><span class="line">123</span><br></pre></td></tr></table></figure><p>（4）断开 zk1 实例的会话</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[zk: 127.0.0.1:2181(CONNECTED) 16] quit  </span><br><span class="line">WATCHER::  </span><br><span class="line">WatchedEvent state:Closed type:None path:null  </span><br><span class="line">2022-03-15 15:39:55,807 [myid:] - INFO  [main:ZooKeeper@1232] - Session: 0x1000c3279ae0000 closed  </span><br><span class="line">2022-03-15 15:39:55,807 [myid:] - INFO  [main-EventThread:ClientCnxn$EventThread@570] - EventThread shut down for session: 0x1000c3279ae0000  </span><br><span class="line">2022-03-15 15:39:55,810 [myid:] - ERROR [main:ServiceUtils@42] - Exiting JVM with code 0</span><br></pre></td></tr></table></figure><p>（5）在 zk2 上查看该节点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: 127.0.0.1:2182(CONNECTED) 3] get &#x2F;Dog&#x2F;Puppy  </span><br><span class="line">org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode &#x3D; NoNode for &#x2F;Dog&#x2F;Puppy</span><br></pre></td></tr></table></figure><p>可以看到/Dog/Puppy 临时节点随着 zk1 实例会话的退出消失了，这就是临时节点的特性，zk1 创建的临时节点会随着 zk1 实例连接的退出而消失，永久节点则只能通过 delete /Dog(节点名)删除才会消失。</p><h5 id="3-ZooKeeper-的-Znode-Watcher-机制"><a href="#3-ZooKeeper-的-Znode-Watcher-机制" class="headerlink" title="3 ZooKeeper 的 Znode Watcher 机制"></a>3 ZooKeeper 的 Znode Watcher 机制</h5><p>ZooKeeper 可以用来做数据的发布和订阅，一个典型的发布/订阅模型系统定义了一种一对多的订阅关系，能够让多个订阅者同时监听某一个主题对象，当这个主题对象自身状态变化时，会通知所有订阅者，使它们能够做出相应的处理。在 ZooKeeper 中，引入了<strong>Watcher 机制</strong>来<strong>实现这种分布式的通知功能</strong>。</p><p>ZooKeeper 允许 ZK 客户端向服务端注册一个 Watcher 监听，当服务端的一些指定事件触发了这个 Watcher，那么就会向指定客户端发送一个事件通知。例如 ZK 客户端监听临时节点/Cat,当该临时节点消失时，则会由服务端触发调用客户端 WatchManager，客户端从 WatchManager 中取出对应的 Watcher 对象来进行处理逻辑。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/4ca3c640d7239240d2f3f443a42f3912.jpeg" alt=""></p><p>（1）客户端首先将 Watcher 注册到服务端，同时将 Watcher 对象保存到客户端的 Watch 管理器中；（2）当 ZooKeeper 服务端监听的数据状态发生变化时，服务端会主动通知客户端；（3)接着客户端的 Watch 管理器会触发相关 Watcher 来回调相应处理逻辑，从而完成整体的数据发布/订阅流程。</p><h5 id="4-经典案例：基于-Znode-临时顺序节点-Watcher-机制实现公平分布式锁"><a href="#4-经典案例：基于-Znode-临时顺序节点-Watcher-机制实现公平分布式锁" class="headerlink" title="4 经典案例：基于 Znode 临时顺序节点+Watcher 机制实现公平分布式锁"></a>4 经典案例：基于 Znode 临时顺序节点+Watcher 机制实现公平分布式锁</h5><p>1、临时顺序节点：在介绍 Znode 节点时，我们提到过 Znode 节点有“临时节点”这个类型，它会随着客户端连接的断开而消失，同时节点类型可以选择顺序性，组合起来就是“临时顺序节点”，如下图所示：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/b4c3fbf87c1aff1bb085332adbb3c740.jpeg" alt=""></p><p>在根目录“/”下创建分布式锁“/Lock”节点目录，/Lock 节点本身可以是永久节点，用于存放客户端抢占创建的临时顺序节点。此时假设有两个 ZK 客户端 A 和 B 同时调用 Create 函数，在”/Lock”节点下创建临时顺序节点，A 比 B 网络延时更小，先创建，ZK 分配节点名称为”/Lock/Seq0001”, B 晚于 A 创建成功，ZK 分配节点名为”/Lock/Seq0002”，ZK 负责维护这个递增的顺序节点名。</p><p>2、分布式锁实现的具体流程 （1）如下图，客户端 A、B 同时在”/Lock”节点下创建临时顺序子节点，可以理解为同时抢占分布式锁，A 先于 B 创建成功，此时分配的节点为“/Lock/seq-0000001”，由于 A 创建成功，并且临时顺序节点的顺序值序号最小，代表它是最先获取到该锁，此时加锁成功。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/cb3fb4027e2987df8c338f0be5b22c64.jpeg" alt=""></p><p>（2）如下图，（红色虚线）客户端 B 晚于 A 创建临时顺序节点，此时 ZK 分配的节点顺序值为“/Lock/seq-0000002”，B 创建成功之后，它的顺序值大于 A 的顺序值，不是最小顺序值，此时说明 A 已经抢占到分布式锁，这个时候 B 就使用 Watcher 监听机制，监听次小于自己的临时顺序节点 A 的状态变化。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/95bab22bd322598589fbdc5a85339306.jpeg" alt=""></p><p>（3）如下图，当 A 客户端因宕机或者完成处理逻辑而断开链接时，A 创建的临时顺序节点会随之消失，此时由于客户端 B 已经监听了 A 临时顺序节点的状态变化，当消失事件发生时，Watcher 监听器逻辑会回调客户端 B，B 重新开始获取锁。注意此时不是 B 再次创建节点，而是获取”/Lock”下的临时顺序节点，发现自己的顺序值最小，那么就加锁成功。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/d83a36b96e0631fef84298b9ae88b32d.jpeg" alt=""></p><p>如果有 C、D 甚至更多的客户端同时抢占，原理都是一致的，他们会依次排队，监听自己之前(节点顺序值次小于自己)的节点，等待他们的状态发生变化时，再去重新获取锁。</p><p>这里使用临时顺序节点和 Watcher 机制实现了一个公平分布式锁，还有很多其他用法，如只使用临时节点实现非公平分布式锁，篇幅所限，读者可以自行探索。</p><h3 id="三、深入-ZooKeeper-一致性协议原理"><a href="#三、深入-ZooKeeper-一致性协议原理" class="headerlink" title="三、深入 ZooKeeper 一致性协议原理"></a>三、深入 ZooKeeper 一致性协议原理</h3><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/fcc88028215994f607ac668501d3ee60.jpeg" alt=""></p><p>上图是 ZooKeeper 的整体架构，ZooKeeper Service 是服务端集群，也是整个组件的核心，客户端的读写请求都是它来处理。ZK 下载安装章节模拟的 zk1/zk2/zk3 就可以认为是一个 ZK 服务端集群，我们在 zk2 中写入的节点值，在 zk1 和 zk3 实例中也能读到这个节点值，zk2 会话退出后临时节点在其他服务器上也同样消失了，ZK 服务端是通过什么机制实现数据在各个节点之间的同步，从而保证一致性？当有节点出现故障时又是如何保证正常提供对外服务？这就涉及到 ZooKeeper 的核心-分布式一致性原理。</p><h4 id="1-ZooKeeper-服务端角色"><a href="#1-ZooKeeper-服务端角色" class="headerlink" title="1 ZooKeeper 服务端角色"></a>1 ZooKeeper 服务端角色</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/92961091a46751940bfcf4300cb7fc8a.jpeg" alt=""></p><ul><li><p><strong>Leader</strong> 一个 ZooKeeper 集群同一时间只会有一个实际工作的 Leader，它会发起并维护与各 Follwer 及 Observer 间的心跳。所有的写操作必须要通过 Leader 完成再由 Leader 将写操作广播给其它服务器。</p></li><li><p><strong>Follower</strong> 一个 ZooKeeper 集群可能同时存在多个 Follower，它会响应 Leader 的心跳。Follower 可直接处理并返回客户端的读请求，同时会将写请求转发给 Leader 处理，并且负责在 Leader 处理写请求时对请求进行投票。</p></li><li><p><strong>Observer</strong> 角色与 Follower 类似，但是无投票权。</p></li></ul><p>1、早期的 ZooKeeper 集群服务运行过程中，只有Leader服务器和Follow服务器 2、随着集群规模扩大，follower变多，ZK在创建节点和选主等事务性请求时，需要一半以上节点AC，所以导致性能下降写入操作越来越耗时，follower之间通信越来越耗时 3、为了解决这个问题，就引入了观察者，可以处理读，但是不参与投票。既保证了集群的扩展性，又避免过多服务器参与投票导致的集群处理请求能力下降`</p><h4 id="2-一致性协议-ZAB"><a href="#2-一致性协议-ZAB" class="headerlink" title="2 一致性协议-ZAB"></a>2 一致性协议-ZAB</h4><p>ZooKeeper 为了保证集群中各个节点读写数据的一致性和可用性，设计并实现了 ZAB 协议，ZAB 全称是 ZooKeeper Atomic Broadcast，也就是 ZooKeeper 原子广播协议。这种协议支持崩溃恢复，并基于主从模式，同一时刻只有一个 Leader，所有的写操作都由 Leader 节点主导完成，而读操作可通过任意节点完成，因此 ZooKeeper 读性能远好于写性能，更适合读多写少的场景。</p><p>一旦 Leader 节点宕机，ZAB 协议的崩溃恢复机制能自动从 Follower 节点中重新选出一个合适的替代者，即新的 Leader，该过程即为领导选举。领导选举过程，是 ZAB 协议中最为重要和复杂的过程。</p><h4 id="3-ZAB-协议读写流程"><a href="#3-ZAB-协议读写流程" class="headerlink" title="3. ZAB 协议读写流程"></a>3. ZAB 协议读写流程</h4><h5 id="3-1-ZAB-写流程"><a href="#3-1-ZAB-写流程" class="headerlink" title="3.1 ZAB 写流程"></a>3.1 ZAB 写流程</h5><h6 id="3-1-1-写-Leader"><a href="#3-1-1-写-Leader" class="headerlink" title="3.1.1 写 Leader"></a>3.1.1 写 Leader</h6><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/6e38c236bbc76ec7cdb207df8f8e447a.jpeg" alt=""></p><p>由上图可见，通过 Leader 进行写操作，主要分为五步：</p><ol><li><p>客户端向 Leader 发起写请求</p></li><li><p>Leader 将写请求以 Proposal 的形式发给所有 Follower 并等待 ACK</p></li><li><p>Follower 收到 Leader 的 Proposal 后返回 ACK</p></li><li><p>Leader 得到过半数的 ACK（Leader 对自己默认有一个 ACK）后向所有的 Follower 和 Observer 发送 Commmit</p></li><li><p>Leader 将处理结果返回给客户端</p></li></ol><p><strong>注意</strong>Leader并不需要得到Observer的ACK，即Observer无投票权</p><p>Leader不需要得到所有Follower的ACK，只要收到过半的ACK即可，同时Leader本身对自己有一个ACK。上图中有4个Follower，只需其中两个返回ACK即可，因为(2+1) / (4+1) &gt; 1/2</p><p>Observer虽然无投票权，但仍须同步Leader的数据从而在处理读请求时可以返回尽可能新的数据`</p><h6 id="3-1-2-写-Follower"><a href="#3-1-2-写-Follower" class="headerlink" title="3.1.2 写 Follower"></a>3.1.2 写 Follower</h6><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/eebe06caf1d02daf668806727028417a.jpeg" alt=""></p><p>从上图可见：</p><ul><li><p>Follower 可接受写请求，但不能直接处理，而需要将写请求转发给 Leader 处理</p></li><li><p>Observer 与 Follower 写流程相同</p></li><li><p>除了多了一步请求转发，其它流程与直接写 Leader 无任何区别</p></li></ul><h5 id="3-2-ZAB-读流程"><a href="#3-2-ZAB-读流程" class="headerlink" title="3.2 ZAB 读流程"></a>3.2 ZAB 读流程</h5><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/8f97cff719ce8ae89092fcd44d8a8568.jpeg" alt=""></p><p>Leader/Follower/Observer 都可直接处理读请求，从本地内存中读取数据并返回给客户端即可。由于处理读请求不需要服务器之间的交互，Follower/Observer 越多，整体可处理的读请求量越大，也即读性能越好。<code>ZooKeeper官方文档数据，Client数量1000时，读写性能比10:1</code></p><h4 id="4-ZooKeeper-Leader-选举算法"><a href="#4-ZooKeeper-Leader-选举算法" class="headerlink" title="4 ZooKeeper Leader 选举算法"></a>4 ZooKeeper Leader 选举算法</h4><h5 id="4-1-选举算法"><a href="#4-1-选举算法" class="headerlink" title="4.1 选举算法"></a>4.1 选举算法</h5><p>ZooKeeper 中默认的并建议使用的 Leader 选举算法是：基于 TCP 的 FastLeaderElection，其他选举算法被废弃。集群模式下 zoo.cfg 配置文件中有参数可配选举算法：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/34882fcc47f7983d75b1393f76377d10.jpeg" alt=""></p><h5 id="4-2-FastLeaderElection-选举参数解析"><a href="#4-2-FastLeaderElection-选举参数解析" class="headerlink" title="4.2 FastLeaderElection 选举参数解析"></a>4.2 FastLeaderElection 选举参数解析</h5><p>（1）选举算法参数<strong>myid</strong>：每个 ZooKeeper 服务器，都需要在数据文件夹下创建一个名为 myid 的文件，该文件包含整个 ZooKeeper 集群唯一的 ID（整数）。例如，我们第二章中部署的 zk1/zk2/zk3 三个实例，其 myid 分别为 1、2 和 3，在配置文件中其 ID 与 hostname 必须一一对应，如下所示。在该配置文件中，server.后面的 id 即为 myid。该参数在选举时如果无法通过其他判断条件选择 Leader，那么将该 ID 的大小来确定优先级。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 集群配置  </span><br><span class="line">server.1&#x3D;127.0.0.1:8881:7771                 # server.id&#x3D;host:port:port  </span><br><span class="line">server.2&#x3D;127.0.0.1:8882:7772                 # server.id&#x3D;host:port:port  </span><br><span class="line">server.3&#x3D;127.0.0.1:8883:7773                 # server.id&#x3D;host:port:port</span><br></pre></td></tr></table></figure><p><strong>zxid</strong>：用于标识一次更新操作的 ID。为了保证顺序性，该 zxid 必须单调递增，因此 ZooKeeper 使用一个 64 位的数来表示，高 32 位是 Leader 的 epoch，从 1 开始，每次选出新的 Leader，epoch 加一。低 32 位为该 epoch 内的序号，每次有写操作低 32 位加一，每次 epoch 变化，都将低 32 位的序号重置。这样保证了 zxid 的全局递增性。之前看到过有博主使用中国古代的年号来解释这个字段，非常形象：万历十五年，万历是 epoch，十五年是序号<strong>选票数据结构</strong>，每个服务器在进行选举时，发送的选票包含如下关键信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">struct Vote &#123;  </span><br><span class="line">    logicClock  &#x2F;&#x2F; 逻辑时钟，表示该服务器发起的第多少轮投票  </span><br><span class="line">    state       &#x2F;&#x2F; 当前服务器的状态 （LOOKING-不确定Leader状态 FOLLOWING-跟随者状态 LEADING-领导者状态 OBSERVING-观察者状态）  </span><br><span class="line">    self_myid     &#x2F;&#x2F; 当前服务器的myid  </span><br><span class="line">    self_zxid   &#x2F;&#x2F; 当前服务器上所保存的数据的最大zxid  </span><br><span class="line">    vote_myid     &#x2F;&#x2F; 被推举的服务器的myid  </span><br><span class="line">    vote_zxid   &#x2F;&#x2F; 被推举的服务器上所保存的数据的最大zxid  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>节点服务器状态</strong>，每个服务器所处的状态时下面状态中的一种：</p><ul><li><p><strong>LOOKING</strong> 不确定 Leader 状态。该状态下的服务器认为当前集群中没有 Leader，会发起 Leader 选举。</p></li><li><p><strong>FOLLOWING</strong> 跟随者状态。表明当前服务器角色是 Follower，并且它知道 Leader 是谁。</p></li><li><p><strong>LEADING</strong> 领导者状态。表明当前服务器角色是 Leader，它会维护与 Follower 间的心跳。</p></li><li><p><strong>OBSERVING</strong> 观察者状态。表明当前服务器角色是 Observer，与 Folower 唯一的不同在于不参与选举，也不参与集群写操作时的投票。</p></li></ul><h5 id="4-3-选举投票流程"><a href="#4-3-选举投票流程" class="headerlink" title="4.3 选举投票流程"></a>4.3 选举投票流程</h5><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/e82620b112d6f399ed3748b8ece3efb6.jpeg" alt=""></p><p>每个服务器的一次选举流程：</p><ol><li><p><strong>自增选举轮次</strong>：即 logicClock 加一，ZooKeeper 规定所有有效的投票都必须在同一轮次中。每个服务器在开始新一轮投票时，会先对自己维护的 logicClock 进行自增操作。</p></li><li><p><strong>初始化选票</strong>：每个服务器在开始进行新一轮的投票之前，会将自己的投票箱清空，然后初始化自己的选票。在初始化阶段，每台服务器都会将自己推选为 Leader，也就是将票都投给自己。例如：服务器 1、2、3 都投票给自己(1-&gt;1), (2-&gt;2),(3-&gt;3)。</p></li><li><p><strong>发送初始化选票</strong>：每个服务器通过广播将初始化投给自己的票广播出去，让其他服务器接收。</p></li><li><p><strong>接收外部投票</strong>：服务器会尝试从其它服务器获取投票，并记入自己的投票箱内。如果无法获取任何外部投票，则会确认自己是否与集群中其它服务器保持着有效连接。如果是，则再次发送自己的投票；如果否，则马上与之建立连接。</p></li><li><p><strong>判断选举轮次</strong>：收到外部投票后，首先会根据投票信息中所包含的 logicClock 来进行不同处理。（1）如果大于当前服务的选票中的选举次数，那么则会更新当前服务的 logicClock，并且清空所有收到的选票，再次拿选票和外部投票进行选票的比较，确定是否真的要更改自身的选票，然后重新发送选票信息；（2）如果外部选票的选举次数小于当前服务实例的选举次数，那么直接无视掉这个选票信息，并且继续发送自身的选票出去；（3）如果外部选票和自身服务实例的选举次数一致，那么就需要进入选票之间的比较操作。</p></li><li><p><strong>选票 PK</strong>：选票 PK 是基于(self_myid, self_zxid)与(vote_myid, vote_zxid)的对比。</p><p>（1）外部投票的 logicClock 大于自己的 logicClock，则将自己的 logicClock 及自己的选票的 logicClock 变更为收到的 logicClock；</p><p>（2）若 logicClock 一致，则对比二者的 vote_zxid，若外部投票的 vote_zxid 比较大，则将自己的票中的 vote_zxid 与 vote_myid 更新为收到的票中的 vote_zxid 与 vote_myid 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱。如果票箱内已存在(self_myid, self_zxid)相同的选票，则直接覆盖；</p><p>（3）若二者 vote_zxid 一致，则比较二者的 vote_myid，若外部投票的 vote_myid 比较大，则将自己的票中的 vote_myid 更新为收到的票中的 vote_myid 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱。</p></li><li><p><strong>统计选票</strong>：如果已经确定有过半服务器认可了自己的投票（可能是更新后的投票），则终止投票。否则继续接收其它服务器的投票。</p></li><li><p><strong>更新服务器状态</strong>：投票终止后，服务器开始更新自身状态。若过半的票投给了自己，则将自己的服务器状态更新为 LEADING，否则将自己的状态更新为 FOLLOWING。</p></li></ol><p><strong>同时还需要注意的一点是，即使选票超过半数了，选出 Leader 服务实例了，也不是立刻结束，而是等待 200ms，确保没有丢失其他服务的更优的选票。</strong></p><h4 id="5-ZooKeeper-集群启动选举流程图解"><a href="#5-ZooKeeper-集群启动选举流程图解" class="headerlink" title="5 ZooKeeper 集群启动选举流程图解"></a>5 ZooKeeper 集群启动选举流程图解</h4><h5 id="5-1-集群启动领导选举"><a href="#5-1-集群启动领导选举" class="headerlink" title="5.1 集群启动领导选举"></a>5.1 集群启动领导选举</h5><p>1、<strong>各自推选自己</strong>：ZooKeeper 集群刚启动时，所有服务器的 logicClock 都为 1，zxid 都为 0。各服务器初始化后，先把第一票投给自己并将它存入自己的票箱，同时广播给其他服务器。此时各自的票箱中只有自己投给自己的一票，如下图所示：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/740b3a295950051d313b323243610ff4.jpeg" alt=""></p><p>2、<strong>更新选票</strong>：第一步中各个服务器先投票给自己，并把投给自己的结果广播给集群中的其他服务器，这一步其他服务器接收到广播后开始更新选票操作（如果对此规则不熟悉，可以对照<strong>4.3 选举投票流程</strong>小节），以 Server1 为例流程如下：</p><p>（1）Server1 收到 Server2 和 Server3 的广播选票后，由于 logicClock 和 zxid 都相等，此时就比较 myid；</p><p>（2）Server1 收到的两张选票中 Server3 的 myid 最大，此时 Server1 判断应该遵从 Server3 的投票决定，将自己的票改投给 Server3。接下来 Server1 先清空自己的票箱(票箱中有第一步中投给自己的选票)，然后将自己的新投票(1-&gt;3)和接收到的 Server3 的(3-&gt;3)投票一起存入自己的票箱，再把自己的新投票决定(1-&gt;3)广播出去,此时 Server1 的票箱中有两票：(1-&gt;3),(3-&gt;3)；</p><p>（3）同理，Server2 收到 Server3 的选票后也将自己的选票更新为（2-&gt;3）并存入票箱然后广播。此时 Server2 票箱内的选票为(2-&gt;3)，(3-&gt;3)；</p><p>（4）Server3 根据上述规则，无须更新选票，自身的票箱内选票仍为（3-&gt;3）；</p><p>（5）Server1 与 Server2 重新投给 Server3 的选票广播出去后，由于三个服务器最新选票都相同，最后三者的票箱内都包含三张投给服务器 3 的选票。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9f738562b55067fbd8ba0f524b01be5e.jpeg" alt=""></p><p>3、<strong>根据选票确定角色</strong>：根据上述选票，三个服务器一致认为此时 Server3 应该是 Leader。因此 Server1 和 Server2 都进入 FOLLOWING 状态，而 Server3 进入 LEADING 状态。之后 Leader 发起并维护与 Follower 间的心跳。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/51fabd503490b27fea4c582a08257fc3.jpeg" alt=""></p><h5 id="5-2-Follower-重启选举"><a href="#5-2-Follower-重启选举" class="headerlink" title="5.2 Follower 重启选举"></a>5.2 Follower 重启选举</h5><p>本节讨论 Follower 节点发生故障重启或网络产生分区恢复后如何进行选举。1、<strong>Follower 重启投票给自己</strong>：Follower 重启，或者发生网络分区后找不到 Leader，会进入 LOOKING 状态并发起新的一轮投票。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/120ca77965beb9aed0d1349e510ece78.jpeg" alt=""></p><p>2、<strong>发现已有 Leader 后成为 Follower</strong>：Server3 收到 Server1 的投票后，将自己的状态 LEADING 以及选票返回给 Server1。Server2 收到 Server1 的投票后，将自己的状态 FOLLOWING 及选票返回给 Server1。此时 Server1 知道 Server3 是 Leader，并且通过 Server2 与 Server3 的选票可以确定 Server3 确实得到了超过半数的选票。因此服务器 1 进入 FOLLOWING 状态。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/a7a7ce3f7c12839667f08343490c7271.jpeg" alt=""></p><h5 id="5-3-Leader-宕机重启选举"><a href="#5-3-Leader-宕机重启选举" class="headerlink" title="5.3 Leader 宕机重启选举"></a>5.3 Leader 宕机重启选举</h5><p>1、<strong>Follower 发起新投票</strong>：Leader（Server3）宕机后，Follower（Server1 和 2）发现 Leader 不工作了，因此进入 LOOKING 状态并发起新的一轮投票，并且都将票投给自己，同时将投票结果广播给对方。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/37ef655ad6df3eb9c1fe8fd96d7ae6d9.jpeg" alt=""></p><p>2、<strong>更新选票</strong>：（1）Server1 和 2 根据外部投票确定是否要更新自身的选票，这里跟之前的选票 PK 流程一样，比较的优先级为：logicLock &gt; zxid &gt; myid，这里 Server1 的参数(L=3, M=1, Z=11)和 Server2 的参数(L=3, M=2, Z=10)，logicLock 相等，zxid 服务器 1 大于服务器 2，因此服务器 2 就清空已有票箱，将(1-&gt;1)和(2-&gt;1)两票存入票箱，同时将自己的新投票广播出去 （2）服务器 1 收到 2 的投票后，也将自己的票箱更新。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/3003ef514552a0bc7cd2af4f65ed52bd.jpeg" alt=""></p><p>3、<strong>重新选出 Leader</strong>：此时由于只剩两台服务器，服务器 1 投票给自己，服务器 2 投票给 1，所以 1 当选为新 Leader。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/a83b5eeb822b808e471fdbfb631e4776.jpeg" alt=""></p><p>4、<strong>旧 Leader 恢复发起选举</strong>：之前宕机的旧 Leader 恢复正常后，进入 LOOKING 状态并发起新一轮领导选举，并将选票投给自己。此时服务器 1 会将自己的 LEADING 状态及选票返回给服务器 3，而服务器 2 将自己的 FOLLOWING 状态及选票返回给服务器 3。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/f3600edcf51d8e170aa70a449b2e7368.jpeg" alt=""></p><p>5、<strong>旧 Leader 成为 Follower</strong>：服务器 3 了解到 Leader 为服务器 1，且根据选票了解到服务器 1 确实得到过半服务器的选票，因此自己进入 FOLLOWING 状态。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9000fb3c1e013690352fabd87399753e.jpeg" alt=""></p><h4 id="6-commit-过的数据不丢失"><a href="#6-commit-过的数据不丢失" class="headerlink" title="6 commit 过的数据不丢失"></a>6 commit 过的数据不丢失</h4><p>ZK 的数据写入都是通过 Leader，一条数据写入过程中，ZK 服务集群中只有超过一半的服务器返回给 Leader ACK 后，Leader 服务器才会 Commit 这条消息，同步到每一个节点。已经被过 Leader commit，也就是被过半节点同步过的消息，在 Leader 宕机之后，重新选举出 Leader 这个消息也不会丢失。但是未被 commit 也就是未被过半节点复制到的消息则会丢失。</p><h3 id="四、参考文献-amp-amp-鸣谢"><a href="#四、参考文献-amp-amp-鸣谢" class="headerlink" title="四、参考文献 &amp;&amp; 鸣谢"></a>四、参考文献 &amp;&amp; 鸣谢</h3><ul><li><p><a href="https://forthe77.github.io/2019/03/25/one-zookeeper-deploy/" target="_blank" rel="noopener">https://forthe77.github.io/2019/03/25/one-zookeeper-deploy/</a></p></li><li><p><a href="https://blog.nowcoder.net/n/16f13a7d72b2496c8ff4da080f777a5a" target="_blank" rel="noopener">https://blog.nowcoder.net/n/16f13a7d72b2496c8ff4da080f777a5a</a></p></li><li><p><a href="https://blog.csdn.net/Weixiaohuai/article/details/112788171" target="_blank" rel="noopener">https://blog.csdn.net/Weixiaohuai/article/details/112788171</a></p></li><li><p><a href="https://www.cnblogs.com/IcanFixIt/p/7818592.html" target="_blank" rel="noopener">https://www.cnblogs.com/IcanFixIt/p/7818592.html</a></p></li><li><p><a href="https://www.runoob.com/w3cnote/zookeeper-znode-data-model.html" target="_blank" rel="noopener">https://www.runoob.com/w3cnote/zookeeper-znode-data-model.html</a></p></li><li><p><a href="https://www.cnblogs.com/reycg-blog/p/10208585.html" target="_blank" rel="noopener">https://www.cnblogs.com/reycg-blog/p/10208585.html</a></p></li><li><p><a href="https://dbaplus.cn/news-141-1875-1.html" target="_blank" rel="noopener">https://dbaplus.cn/news-141-1875-1.html</a></p></li><li><p><a href="https://www.infoq.cn/article/us5gjqqz8bmbeha25io0" target="_blank" rel="noopener">https://www.infoq.cn/article/us5gjqqz8bmbeha25io0</a> [<a href="http://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/24%E8%AE%B2%E5%90%83%E9%80%8F%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%AE%8C/20%20%20%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95%EF%BC%9A%E4%B8%80%E6%AC%A1%E6%80%A7%E8%AF%B4%E6%B8%85%E6%A5%9A%20Paxos%E3%80%81Raft%20%E7%AD%89%E7%AE%97%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB.md\]" target="_blank" rel="noopener">http://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/24%E8%AE%B2%E5%90%83%E9%80%8F%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93-%E5%AE%8C/20%20%20%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95%EF%BC%9A%E4%B8%80%E6%AC%A1%E6%80%A7%E8%AF%B4%E6%B8%85%E6%A5%9A%20Paxos%E3%80%81Raft%20%E7%AD%89%E7%AE%97%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB.md\]</a>(<a href="http://learn.lianglianglee.com/专栏/24讲吃透分布式数据库-完/20" target="_blank" rel="noopener">http://learn.lianglianglee.com/专栏/24讲吃透分布式数据库-完/20</a> 共识算法：一次性说清楚 Paxos、Raft 等算法的区别.md)</p></li><li><p><a href="https://juejin.cn/post/6907151199141625870" target="_blank" rel="noopener">https://juejin.cn/post/6907151199141625870</a></p></li><li><p><a href="https://lotabout.me/2019/QQA-What-is-Sequential-Consistency/" target="_blank" rel="noopener">https://lotabout.me/2019/QQA-What-is-Sequential-Consistency/</a></p></li><li><p><a href="http://fishleap.top/pages/a958bc/#_6-%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95" target="_blank" rel="noopener">http://fishleap.top/pages/a958bc/#_6-%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95</a></p></li><li><p><a href="https://developer.aliyun.com/article/768655" target="_blank" rel="noopener">https://developer.aliyun.com/article/768655</a> <a href="https://www.cnblogs.com/aspirant/p/8994227.html" target="_blank" rel="noopener">https://www.cnblogs.com/aspirant/p/8994227.html</a></p></li><li><p><a href="https://blog.xiaohansong.com/lamport-logic-clock.html" target="_blank" rel="noopener">https://blog.xiaohansong.com/lamport-logic-clock.html</a> <a href="http://icyfenix.cn/distribution/consensus/" target="_blank" rel="noopener">http://icyfenix.cn/distribution/consensus/</a></p></li><li><p><a href="https://dbaplus.cn/news-141-2053-1.html" target="_blank" rel="noopener">https://dbaplus.cn/news-141-2053-1.html</a> <a href="https://www.infoq.cn/article/dvaaj71f4fbqsxmgvdce" target="_blank" rel="noopener">https://www.infoq.cn/article/dvaaj71f4fbqsxmgvdce</a></p></li><li><p><a href="https://segmentfault.com/a/1190000039760185[https://blog.csdn.net/chenshijie2011/article/details/118075170?spm=1001.2101.3001.6650.1&amp;utm\_medium=distribute.pc\_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc\_relevant\_default&amp;depth\_1-utm\_source=distribute.pc\_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc\_relevant\_default&amp;utm\_relevant\_index=2](https://blog.csdn.net/chenshijie2011/article/details/118075170?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_default&amp;utm_relevant_index=2)" target="_blank" rel="noopener">https://segmentfault.com/a/1190000039760185[https://blog.csdn.net/chenshijie2011/article/details/118075170?spm=1001.2101.3001.6650.1&amp;utm\_medium=distribute.pc\_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc\_relevant\_default&amp;depth\_1-utm\_source=distribute.pc\_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc\_relevant\_default&amp;utm\_relevant\_index=2](https://blog.csdn.net/chenshijie2011/article/details/118075170?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1.pc_relevant_default&amp;utm_relevant_index=2)</a></p></li><li><p><a href="https://javaedge.blog.csdn.net/article/details/110585930?spm=1001.2101.3001.6650.4&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4.pc_relevant_default&utm_relevant_index=7" target="_blank" rel="noopener">https://javaedge.blog.csdn.net/article/details/110585930?spm=1001.2101.3001.6650.4&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4.pc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4.pc_relevant_default&amp;utm_relevant_index=7</a></p></li></ul><p>本文转自 <a href="https://mp.weixin.qq.com/s/tiAQQXbh7Tj45_1IQmQqZg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/tiAQQXbh7Tj45_1IQmQqZg</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch 基础入门详文</title>
      <link href="/posts/9c1530a2/"/>
      <url>/posts/9c1530a2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>作者：lynneyli，腾讯 IEG 运营开发工程师</p><blockquote><p>Elasticsearch（简称：ES）功能强大，其背后有很多默认值，或者默认操作。这些操作优劣并存，优势在于我们可以迅速上手使用 ES，劣势在于，其实这些默认值的背后涉及到很多底层原理，怎么做更合适，只有数据使用者知道。用 ES 的话来说，你比 ES 更懂你的数据，但一些配置信息、限制信息，还是需要在了解了 ES 的功能之后进行人工限制。</p></blockquote><p>你是否遇到：在使用了一段时间 ES 之后，期望使用 ES 的其他功能，例如聚合、排序，但因为字段类型受限，无奈只能进行reindex等一系列问题？</p><p>题主在遇到一些问题后，发现用 ES 很简单，但是会用 ES 很难。这让我下定决心一定好好了解 ES，也就出现了本文。</p><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>ES（全称 Elastic Search）是一款开源、近实时、高性能的分布式搜索引擎。在近 3 年的热门搜索引擎类数据统计中，ES 都霸居榜首（数据来源：DBRaking），可见的其深受大家的喜爱。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/25d949d7cccc2bd954b8098fb1595594.jpeg" alt=""></p><p>随着 ES 的功能越来越强大，其和数据库的边界也越来越小，除了进行全文检索，ES 也支持聚合/排序。ES 底层基于<strong>Lucene</strong>开发，针对<strong>Lucene</strong>的局限性，ES 提供了 RESTful API 风格的接口、支持分布式、可水平扩展，同时它可以被多种编程语言调用。</p><p>ES 很多基础概念以及底层实现其本质是 Lucene 的概念。</p><p><strong>ps：本文所有的 dsl 查询、结果展示均基于 ES v7.7</strong></p><h3 id="历史背景"><a href="#历史背景" class="headerlink" title="历史背景"></a>历史背景</h3><h4 id="Lucene-的历史背景"><a href="#Lucene-的历史背景" class="headerlink" title="Lucene 的历史背景"></a>Lucene 的历史背景</h4><p>下图这个人叫<strong>Doug Cutting</strong>，他是 Hadoop 语言和 Lucene 工具包的创始人。Doug Cutting 毕业于斯坦福大学，在 Xerox 积累了一定的工作经验后，从 1997 年开始，利用业余时间开发出了 Lucene。Lucene 面世于 1999 年，并于 2005 年成为 Apache 顶级开源项目。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/ff6ae86fa70fb2f9c94d2e06188dc12c.jpeg" alt=""></p><p><strong>Lucene</strong>的特点：</p><ul><li><p><strong>Lucene</strong>是基于 java 编写的，开源的全文检索引擎<strong>工具包</strong>。</p></li><li><p><strong>Lucene</strong>具有高性能：在相同的硬件环境下，基于 Hadoop 的 webmap（Lucene 的第一个应用） 的反应速度是之前系统的 <strong>33 倍</strong>。</p></li></ul><p><strong>Lucene</strong>的局限性：</p><ul><li><p>仅限于 java 开发。</p></li><li><p>类库的接口学习成本高：本质上<strong>Lucene</strong>就是一个编程库,可以按原始接口来调用，但是如果在应用程序中直接使用<strong>Lucene</strong>，需要覆盖大量的集成框架工作。</p></li><li><p>原生并不支持水平扩展，若需实现海量数据的搜索引擎，需在此基础上格外开发以支持分布式。</p></li></ul><h4 id="ES-的历史背景"><a href="#ES-的历史背景" class="headerlink" title="ES 的历史背景"></a>ES 的历史背景</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/6e5d7edf096126d08c36e6eeb3ceeb2e.jpeg" alt=""></p><p>ElasticSearch创始人-Shay Banon</p><ul><li><p>2004 年，Shay Banon 基于 Lucene 开发了 Compass，在考虑 Compass 的第三个版本时，他意识到有必要重写 Compass 的大部分内容，以“创建一个可扩展的搜索解决方案”。因此，他创建了“一个从头构建的分布式解决方案”，并使用了一个公共接口，即 HTTP 上的 JSON，它也适用于 Java 以外的编程语言。</p></li><li><p>2010 年，Shay Banon 在发布了 Elasticsearch 的第一个版本。</p></li></ul><p>ES 多个版本可能出现破坏性变更，例如，在 6.x，ES 不允许一个 Index 中出现多个<strong>Type</strong>。在 ES 的官网，每个版本都对应着一个使用文档。</p><p>在使用 ES 之前，最好先了解 ES 的版本历史。<strong>下面列出一些比较重大的更新版本，可以在了解了基本概念之后再看。</strong></p><ul><li>初始版本 0.7.0 2010 年 5 月 14 日</li></ul><ul><li>Zen Discovery 自动发现模块 - Groovy Client 支持 - 简单的插件管理机制 - 更好支持 ICU 分词器</li></ul><ul><li>1.0.0 2014 年 2 月 14 日</li></ul><ul><li><p><strong>支持聚合分析 Aggregations</strong></p></li><li><p><strong>CAT API 支持</strong></p></li><li><p><strong>Doc values 引入</strong></p></li><li><p>支持联盟查询</p></li><li><p>断路器支持</p></li></ul><ul><li>2.0.0 2015 年 10 月 28 日</li></ul><ul><li><p><strong>query/filter 查询合并，都合并到 query 中，根据不同的 context 执行不同的查询</strong></p></li><li><p>增加了 pipleline Aggregations 在 ES 中，有 Query 和 Filter 两种 Context - Query Context ：相关性算分</p></li><li><p>Filter Context ：不需要算分（YES OR NO）, 可以利用 Cache 获得更好的性能</p></li><li><p>存储压缩可配置</p></li><li><p>Rivers 模块被移除</p></li><li><p>Multicast 组播发现成为组件</p></li></ul><ul><li>5.0.0 2016 年 10 月 26 日</li></ul><ul><li><p><strong>Lucene 6.x 的支持，磁盘空间少一半；索引时间少一半；查询性能提升 25%；支持 IPV6。</strong></p></li><li><p>Internal engine 级别移除了用于避免同一文档并发更新的竞争锁，带来 15%-20%的性能提升</p></li><li><p><strong>Shrink API ，它可将分片数进行收缩成它的因数，如之前你是 15 个分片，你可以收缩成 5 个或者 3 个又或者 1 个，那么我们就可以想象成这样一种场景，在写入压力非常大的收集阶段，设置足够多的索引，充分利用 shard 的并行写能力，索引写完之后收缩成更少的 shard，提高查询性能</strong></p></li><li><p><strong>引入新的字段类型 Text/Keyword 来替换 String</strong></p></li><li><p>提供了 Painless 脚本，代替 Groovy 脚本</p></li><li><p>新增 Sliced Scroll 类型，现在 Scroll 接口可以并发来进行数据遍历了。每个 Scroll 请求，可以分成多个 Slice 请求，可以理解为切片，各 Slice 独立并行，利用 Scroll 重建或者遍历要快很多倍。- 限制索引请求大小，避免大量并发请求压垮 ES</p></li><li><p>限制单个请求的 shards 数量，默认 1000 个</p></li></ul><ul><li>6.0.0 2017 年 8 月 31 日</li></ul><ul><li><p><strong>Index sorting，即索引阶段的排序。</strong></p></li><li><p>顺序号的支持，每个 es 的操作都有一个顺序编号（类似增量设计）</p></li><li><p><strong>无缝滚动升级</strong></p></li><li><p><strong>逐步废弃 type，在 6.0 里面，开始不支持一个 index 里面存在多个 type</strong></p></li><li><p>Index-template inheritance，索引版本的继承，目前索引模板是所有匹配的都会合并，这样会造成索引模板有一些冲突问题， 6.0 将会只匹配一个，索引创建时也会进行验证 - Load aware shard routing， 基于负载的请求路由，目前的搜索请求是全节点轮询，那么性能最慢的节点往往会造成整体的延迟增加，新的实现方式将基于队列的耗费时间自动调节队列长度，负载高的节点的队列长度将减少，让其他节点分摊更多的压力，搜索和索引都将基于这种机制。- 已经关闭的索引将也支持 replica 的自动处理，确保数据可靠。</p></li></ul><ul><li>7.0.0 2019 年 4 月 10 日</li></ul><ul><li><p><strong>集群连接变化：TransportClient 被废弃 以至于，es7 的 java 代码，只能使用 restclient</strong></p></li><li><p><strong>重大改进-正式废除单个索引下多 Type 的支持</strong></p></li><li><p>es6 时，官方就提到了 es7 会删除 type，并且 es6 时已经规定每一个 index 只能有一个 type。<strong>在 es7 中使用默认的_doc 作为 type</strong>，官方说在 8.x 版本会彻底移除 type。api 请求方式也发送变化，如获得某索引的某 ID 的文档：<strong>GET index/_doc/id 其中 index 和 id 为具体的值</strong></p></li><li><p><strong>Lucene9.0</strong> - 引入了真正的内存断路器，它可以更精准地检测出无法处理的请求，并防止它们使单个节点不稳定 - Zen2 是 Elasticsearch 的全新集群协调层，提高了可靠性、性能和用户体验，变得更快、更安全，并更易于使用 - 新功能 - New Cluster coordination - Feature - Complete High Level REST Client - Script Score Query - 性能优化 - Weak-AND 算法提高查询性能</p></li><li><p><strong>默认的 Primary Shared 数从 5 改为 1，避免 Over Sharding</strong></p><p>shard 也是一种资源，shard 过多会影响集群的稳定性。因为 shard 过多，元信息会变多，这些元信息会占用堆内存。shard 过多也会影响读写性能，因为每个读写请求都需要一个线程。所以如果 index 没有很大的数据量，不需要设置很多 shard。</p></li><li><p>更快的前 k 个查询</p></li><li><p>间隔查询(Intervals queries) 某些搜索用例（例如，法律和专利搜索）引入了查找单词或短语彼此相距一定距离的记录的需要。Elasticsearch 7.0 中的间隔查询引入了一种构建此类查询的全新方式，与之前的方法（跨度查询 span queries）相比，使用和定义更加简单。与跨度查询相比，间隔查询对边缘情况的适应性更强。</p></li></ul><h3 id="基础概念介绍"><a href="#基础概念介绍" class="headerlink" title="基础概念介绍"></a>基础概念介绍</h3><p>下图简单概述了 index、type、document 之间的关系，type 在新版本中废弃，所以画图时特殊标识了一下。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/814801c3571b5fcadefc8cc9b1b9e74f.jpeg" alt=""></p><h4 id="index"><a href="#index" class="headerlink" title="index"></a>index</h4><p>Index 翻译过来是索引的意思。在 ES 里，索引有两个含义：</p><ul><li><p>名词：一个索引相当于关系型数据库中的一个表（在 6.x 以前，一个 <code>index</code> 可以被认为是一个数据库）</p></li><li><p>动词：将一份 <code>document</code> 保存在一个 <code>index</code> 里，这个过程也可以称为索引。</p></li></ul><h4 id="type"><a href="#type" class="headerlink" title="type"></a>type</h4><p>在 6.x 之前， <code>index</code> 可以被理解为关系型数据库中的【数据库】，而 <code>type</code> 则可以被认为是【数据库中的表】。使用 <code>type</code> 允许我们在一个 <code>index</code> 里存储多种类型的数据，数据筛选时可以指定 <code>type</code> 。<code>type</code> 的存在从某种程度上可以减少 <code>index</code> 的数量，但是 <code>type</code> 存在以下限制：</p><ul><li><p><strong>不同 type 里的字段需要保持一致</strong>。例如，一个 <code>index</code> 下的不同 <code>type</code> 里有两个名字相同的字段，他们的类型（string, date 等等）和配置也必须相同。</p></li><li><p>只在某个 <code>type</code> 里存在的字段，在其他没有该字段的 type 中也会消耗资源。</p></li><li><p>得分是由 <code>index</code> 内的统计数据来决定的。也就是说，一个 type 中的文档会影响另一个 type 中的文档的得分。</p></li></ul><p>以上限制要求我们，只有同一个 <code>index</code> 的中的 type 都有类似的映射 (mapping) 时，才勉强适用 <code>type</code> 。否则，使用多个 <code>type</code> 可能比使用多个 <code>index</code> 消耗的资源更多。</p><p>这大概也是为什么 ES 决定废弃 type 这个概念，个人感觉 type 的存在，就像是一个语法糖，但是并未带来太大的收益，反而增加了复杂度。</p><h4 id="document"><a href="#document" class="headerlink" title="document"></a>document</h4><p>index 中的单条记录称为 <code>document</code> （文档），可以理解为表中的一行数据。多条 <code>document</code> 组成了一个 <code>index</code> 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&quot;hits&quot; : &#123;  </span><br><span class="line">    &quot;total&quot; : &#123;  </span><br><span class="line">      &quot;value&quot; : 3563,  </span><br><span class="line">      &quot;relation&quot; : &quot;eq&quot;  </span><br><span class="line">    &#125;,  </span><br><span class="line">    &quot;max_score&quot; : 1.0,  </span><br><span class="line">    &quot;hits&quot; : [  </span><br><span class="line">      &#123;  </span><br><span class="line">        &quot;_index&quot; : &quot;test&quot;,  </span><br><span class="line">        &quot;_type&quot; : &quot;_doc&quot;,  </span><br><span class="line">        &quot;_id&quot; : &quot;3073&quot;,  </span><br><span class="line">        &quot;_score&quot; : 1.0,  </span><br><span class="line">        &quot;_source&quot; : &#123;  </span><br><span class="line">   ...  </span><br><span class="line">   &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>上图为 ES 一条文档数据，其中：</p><ul><li><p><code>_index</code> ：文档所属索引名称。</p></li><li><p><code>_type</code> ：文档所属类型名（此处已默认为_doc）。</p></li><li><p><code>_id</code> ：Doc 的主键。在写入的时候，可以指定该 Doc 的 ID 值，如果不指定，则系统自动生成一个唯一的 UUID 值。</p></li><li><p><code>_score</code> ：顾名思义，得分，也可称之为相关性，在查询是 ES 会 根据一些规则计算得分，并根据得分进行倒排。除此之外，ES 支持通过 <code>Function score query</code> 在查询时自定义 score 的计算规则。</p></li><li><p><code>_source</code> ：文档的原始 JSON 数据。</p></li></ul><h4 id="field"><a href="#field" class="headerlink" title="field"></a>field</h4><p>一个 <code>document</code> 会由一个或多个 field 组成，field 是 ES 中数据索引的最小定义单位，下面仅列举部分常用的类型。</p><p>⚠️ 在 ES 中，没有数组类型，<strong>任何字段都可以变成数组。</strong></p><h5 id="string"><a href="#string" class="headerlink" title="string"></a>string</h5><h6 id="text"><a href="#text" class="headerlink" title="text"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/text.html" target="_blank" rel="noopener">text</a></h6><ul><li><p>索引全文值的字段，例如<strong>电子邮件正文</strong>或<strong>产品描述</strong>。</p></li><li><p>如果您需要索引结构化内容，例如电子邮件地址、主机名、状态代码或标签，您可能应该使用 <code>keyword</code> 字段。</p></li><li><p>出于不同目的，我们期望<strong>以不同方式索引同一字段</strong>，这就是 multi-fields 。例如，可以将 <code>string</code> 字段映射为用于全文搜索的 <code>text</code> 字段，并映射为用于排序或聚合的 <code>keyword</code> 字段：</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;mappings&quot;: &#123;  </span><br><span class="line">    &quot;properties&quot;: &#123;  </span><br><span class="line">      &quot;city&quot;: &#123;  </span><br><span class="line">        &quot;type&quot;: &quot;text&quot;,  </span><br><span class="line">        &quot;fields&quot;: &#123;  </span><br><span class="line">          &quot;raw&quot;: &#123;  </span><br><span class="line">            &quot;type&quot;:  &quot;keyword&quot;  </span><br><span class="line">          &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>⚠️<strong>纯 <code>text</code> 字段默认无法进行排序或聚合</strong></p></li><li><p>⚠️ 使用<code>text</code>字段一定要使用合理的<strong>分词器</strong>。</p></li></ul><h6 id="keyword"><a href="#keyword" class="headerlink" title="keyword"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/keyword.html" target="_blank" rel="noopener">keyword</a></h6><ul><li><p>用于索引<strong>结构化内容</strong>的字段，例如 ID、电子邮件地址、主机名、状态代码、邮政编码或标签。如果您需要索引全文内容，例如电子邮件<strong>正文</strong>或产品描述，你应该使用 <code>text</code> 字段。</p></li><li><p>它们通常用于过滤（查找所有发布状态的博客文章）、<strong>排序和聚合</strong>。<code>keyword</code> 字段<strong>只能精确匹配</strong>。</p></li></ul><h5 id="numeric"><a href="#numeric" class="headerlink" title="numeric"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/number.html" target="_blank" rel="noopener">numeric</a></h5><p><code>long, integer, short, byte, double, float, half_float, scaled_float...</code></p><ul><li><p>就整数类型（ <code>byte</code> 、 <code>short</code> 、 <code>integer</code> 和 <code>long</code> ）而言，应该选择足以满足用例的最小类型。</p></li><li><p>对于浮点类型，使用<strong>缩放因子</strong>将浮点数据存储到整数中通常更有效，这就是 <code>scaled_float</code> 类型的实现。</p></li><li><p>下面这个 case， <code>scaling_factor</code> 缩放因子设置为 100，对于所有的 API 来说， price 看起来都像是一个双精度浮点数。但是对于 ES 内部，他其实是一个整数 <code>long</code> 。</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&quot;price&quot;: &#123;  </span><br><span class="line">        &quot;type&quot;: &quot;scaled_float&quot;,  </span><br><span class="line">        &quot;scaling_factor&quot;: 100  </span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><ul><li><p>如果 <code>scaled_float</code> 无法满足精度要求，可以使用 <code>double</code> 、 <code>float</code> 、 <code>half_float</code> 。</p></li><li><p>不是所有的字段都适合存储为 <code>numberic</code> ，<code>numberic</code> 类型更擅长 <code>range</code> 类查询，精确查询可以尝试使用 <code>keyword</code> 。</p></li></ul><h4 id="mapping"><a href="#mapping" class="headerlink" title="mapping"></a>mapping</h4><p><code>mapping</code> 是一个定义 <code>document</code> 结构的过程， <code>mapping</code> 中定义了一个文档所包含的所有 field 信息。</p><p>定义字段索引过多会导致爆炸的映射,这可能会导致内存不足错误和难以恢复的情况， <code>mapping</code> 提供了一些配置对 <code>field</code> 进行限制，下面列举几个可能会比较常见的：</p><ul><li><p><strong>index.mapping.total_fields.limit</strong> 限制 field 的最大数量，默认值是 1000（field 和 object 内的所有字段，都会加入计数）。</p></li><li><p><strong>index.mapping.depth.limit</strong> 限制 object 的最大深度，默认值是 20。</p></li><li><p><strong>index.mapping.field_name_length.limit</strong> 限制中字段名的长度，默认是没有限制。</p></li></ul><h5 id="dynamic-mapping"><a href="#dynamic-mapping" class="headerlink" title="dynamic mapping"></a><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/dynamic-mapping.html" target="_blank" rel="noopener">dynamic mapping</a></h5><p>在索引 document 时，ES 的动态 <code>mapping</code> 会将新增内容中不存在的字段，自动的加入到映射关系中。ES 会自动检测新增字段的逻辑，并赋予其默认值。</p><ul><li><p>One of the most important features of Elasticsearch is that it tries to get out of your way and let you start exploring your data as quickly as possible.</p></li><li><p>You know more about your data than Elasticsearch can guess, so while dynamic mapping can be useful to get started, at some point you will want to specify your own explicit mappings.</p></li></ul><p>截取了部分 ES 官方文档中的话术，ES 认为一些自动化的操作会让新手上手更容易。但是同时，又提出，你肯定比 ES 更了解你的数据，可能刚开始使用起来觉得比较方便，但是最好还是自己明确定义映射关系。</p><p>（🙄️ 个人认为，这些自动操作是在用户对 ES 没有太多了解的情况下进行的，如果刚开始依赖了这些默认的操作，例如：新增字段使用了 ES 赋予的默认值，如果后续有分析、排序、聚合等操作可能会有一定限制）。</p><p>⚠️ 在 ES 中，删除/变更 field 定义，需要进行 <code>reindex</code> ，所以在构建 <code>mapping</code> 结构时记得评估好字段的用途，以使用最合适的字段类型。</p><h4 id="部分查询关键字介绍"><a href="#部分查询关键字介绍" class="headerlink" title="部分查询关键字介绍"></a>部分查询关键字介绍</h4><h5 id="match-amp-match-phrase"><a href="#match-amp-match-phrase" class="headerlink" title="match&amp;match_phrase"></a>match&amp;match_phrase</h5><ul><li><code>match</code> ：用于执行全文查询的标准查询，包括<strong>模糊匹配和短语或接近查询。**</strong>重要参数：控制 Token 之间的布尔关系：operator：or/and**</li></ul><ul><li><code>match_phrase</code> ：与 match 查询类似<strong>但用于匹配确切的短语或单词接近匹配。重要参数：Token 之间的位置距离：slop 参数</strong>，默认为 0</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">GET &#x2F;_analyze  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;text&quot;: [&quot;这是测试&quot;],  </span><br><span class="line">  &quot;analyzer&quot;: &quot;ik_smart&quot;  </span><br><span class="line">&#125;  </span><br><span class="line">&#x2F;&#x2F;Result  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;tokens&quot; : [  </span><br><span class="line">    &#123;  </span><br><span class="line">      &quot;token&quot; : &quot;这是&quot;,  </span><br><span class="line">      &quot;start_offset&quot; : 0,  </span><br><span class="line">      &quot;end_offset&quot; : 2,  </span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,  </span><br><span class="line">      &quot;position&quot; : 0  </span><br><span class="line">    &#125;,  </span><br><span class="line">    &#123;  </span><br><span class="line">      &quot;token&quot; : &quot;测试&quot;,  </span><br><span class="line">      &quot;start_offset&quot; : 2,  </span><br><span class="line">      &quot;end_offset&quot; : 4,  </span><br><span class="line">      &quot;type&quot; : &quot;CN_WORD&quot;,  </span><br><span class="line">      &quot;position&quot; : 1  </span><br><span class="line">    &#125;  </span><br><span class="line">  ]  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">&#x2F;&#x2F;match+analyzer:ik_smart  </span><br><span class="line">&#x2F;&#x2F;可以查询到所有describe中包含【这是测试】、【这是】、【测试】的doc  </span><br><span class="line">GET &#x2F;doraon_recommend_tab_test&#x2F;_search  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;query&quot;: &#123;  </span><br><span class="line">    &quot;match&quot;: &#123;  </span><br><span class="line">      &quot;describe&quot;:&#123;  </span><br><span class="line">      &quot;query&quot;: &quot;这是测试&quot;,  </span><br><span class="line">      &quot;analyzer&quot;: &quot;ik_smart&quot;  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">&#x2F;&#x2F;match_phrase + analyzer:ik_smart + slop&#x3D;0(默认)  </span><br><span class="line">&#x2F;&#x2F;可以查询到所有describe中包含【这是】+【测试】token间隔为0的doc（说人话就是：模糊匹配【这是测试】）  </span><br><span class="line">GET &#x2F;doraon_recommend_tab_test&#x2F;_search  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;_source&quot;: &quot;describe&quot;,  </span><br><span class="line">  &quot;query&quot;: &#123;  </span><br><span class="line">    &quot;match_phrase&quot;: &#123;  </span><br><span class="line">      &quot;describe&quot;: &quot;这是测试&quot;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">&#x2F;&#x2F;match_phrase + analyzer:ik_smart + slop&#x3D;1  </span><br><span class="line">&#x2F;&#x2F;可以查询到所有describe中包含【这是】+【测试】token间隔为1的doc  </span><br><span class="line">&#x2F;&#x2F;例如某个doc中describe为【这是一个测试】，【这是一个测试】分词后的token分别为【这是】【一个】【测试】  </span><br><span class="line">&#x2F;&#x2F;【这是】和【测试】之间间隔了1个token【一个】，所以可以被查询到；同理【这是一个我的测试】查询不到  </span><br><span class="line">GET &#x2F;test&#x2F;_search  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;query&quot;: &#123;  </span><br><span class="line">    &quot;match_phrase&quot;: &#123;  </span><br><span class="line">      &quot;describe&quot;:&#123;  </span><br><span class="line">        &quot;query&quot;: &quot;这是测试&quot;,  </span><br><span class="line">        &quot;analyzer&quot;: &quot;ik_smart&quot;,  </span><br><span class="line">        &quot;slop&quot;: 1  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="term"><a href="#term" class="headerlink" title="term"></a>term</h5><p><code>term</code> 是进行<strong>精确查找</strong>的关键；在 Lucene 中，term 是中索引和搜索的最小单位。一个 field 会由一个或多个 <code>term</code> 组成， <code>term</code> 是由 field 经过 Analyzer（分词）产生。<code>Term Dictionary</code> 即 <code>term</code> 词典，是根据条件查找 <code>term</code> 的基本索引。</p><ul><li><p>避免对 <code>text</code> 字段使用术语查询。默认情况下，ES 会在分析过程中更改文本字段的值。这会使查找 <code>text</code> 字段值的精确匹配变得困难。要搜索 <code>text</code> 字段值，强烈建议改用 <code>match</code> 查询。</p></li><li><p>⚠️<strong>默认分词情况下</strong>，无论是 <code>term</code> 还是 <code>match</code> ，都无法判断<code>text</code> 类型字段是否为空字符串</p></li></ul><p>以上两点均是因为 <code>text</code> 字段存储的是分词结果，如果字段值为空，分词结果将不会存储 <code>term</code> 信息， <code>keyword</code> 字段存储的是原始内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">GET &#x2F;test&#x2F;_termvectors&#x2F;123?fields&#x3D;content  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;_index&quot; : &quot;[your index]&quot;,  </span><br><span class="line">  &quot;_type&quot; : &quot;_doc&quot;,  </span><br><span class="line">  &quot;_id&quot; : &quot;123&quot;,  </span><br><span class="line">  &quot;_version&quot; : 2,  </span><br><span class="line">  &quot;found&quot; : true,  </span><br><span class="line">  &quot;took&quot; : 0,  </span><br><span class="line">  &quot;term_vectors&quot; : &#123; &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">GET &#x2F;test&#x2F;_termvectors&#x2F;234?fields&#x3D;card_pic  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;_index&quot; : &quot;[your index]&quot;,  </span><br><span class="line">  &quot;_type&quot; : &quot;_doc&quot;,  </span><br><span class="line">  &quot;_id&quot; : &quot;234&quot;,  </span><br><span class="line">  &quot;_version&quot; : 1,  </span><br><span class="line">  &quot;found&quot; : true,  </span><br><span class="line">  &quot;took&quot; : 0,  </span><br><span class="line">  &quot;term_vectors&quot; : &#123;  </span><br><span class="line">    &quot;card_pic&quot; : &#123;  </span><br><span class="line">      &quot;field_statistics&quot; : &#123;  </span><br><span class="line">        &quot;sum_doc_freq&quot; : 183252,  </span><br><span class="line">        &quot;doc_count&quot; : 183252,  </span><br><span class="line">        &quot;sum_ttf&quot; : 183252  </span><br><span class="line">      &#125;,  </span><br><span class="line">      &quot;terms&quot; : &#123;  </span><br><span class="line">        &quot;&quot; : &#123;  </span><br><span class="line">          &quot;term_freq&quot; : 1,  </span><br><span class="line">          &quot;tokens&quot; : [  </span><br><span class="line">            &#123;  </span><br><span class="line">              &quot;position&quot; : 0,  </span><br><span class="line">              &quot;start_offset&quot; : 0,  </span><br><span class="line">              &quot;end_offset&quot; : 0  </span><br><span class="line">            &#125;  </span><br><span class="line">          ]  </span><br><span class="line">        &#125;  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="分析器-Analyzer"><a href="#分析器-Analyzer" class="headerlink" title="分析器 Analyzer"></a>分析器 Analyzer</h4><p>在上一篇文章中提到了，针对全文索引类型，一定要选择合适的分析器，现在我们就来了解一下分析器～</p><p>Analyzer 主要是对输入的文本类内容进行分析（通常是分词），将分析结果以 <code>term</code> 的形式进行存储。</p><p>Analyzer 由三个部分组成：<strong>Character Filters</strong>、<strong>Tokenizer</strong>、<strong>Token Filters</strong></p><ul><li><p><strong>Character Filters</strong></p><p>Character Filters 以 characters 流的方式接收原始数据，它可以支持 characters 的增、删、改，通常内置的分析器都没有设置默认的 Character Filters。ES 内置的 Character Filters：</p></li></ul><ul><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/analysis-htmlstrip-charfilter.html" target="_blank" rel="noopener">HTML Strip Character Filter</a>：支持剔除 html 标签，解码</p></li><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/analysis-mapping-charfilter.html" target="_blank" rel="noopener">Mapping Character Filter</a>：支持根据定义的映射进行替换</p></li><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/analysis-pattern-replace-charfilter.html" target="_blank" rel="noopener">Pattern Replace Character Filter</a>：支持根据正则进行替换</p></li></ul><ul><li><p><strong>Tokenizer</strong></p><p>Tokenizer 接收一个字符流，分解成独立的 tokens(通常就是指的分词)，并且输出 tokens。例如,一个 whitespace tokenizer（空格 tokenizer），以空格作为分割词对输入内容进行分词。例如：向 whitespace tokenizer 输入“Quick brown fox!”，将会输出“Quick”、 “brown”、“fox!” 3 个 token。</p></li><li><p><strong>Token Filters</strong></p><p>Token filters 接收 Tokenizer 输出的 token 序列，它可以根据配置进行 token 的增、删、改。例如：指定 synonyms 增加 token、指定 remove stopwords 进行 token 删除，抑或是使用 lowercasing 进行小写转换。</p></li></ul><p>ES 内置的分析器有<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/analysis-standard-analyzer.html" target="_blank" rel="noopener">Standard Analyzer</a>、<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/analysis-simple-analyzer.html" target="_blank" rel="noopener">Simple Analyzer</a>、<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/analysis-whitespace-analyzer.html" target="_blank" rel="noopener">Whitespace Analyzer</a>、<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/analysis-stop-analyzer.html" target="_blank" rel="noopener">Stop Analyzer</a>、<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/analysis-keyword-analyzer.html" target="_blank" rel="noopener">Keyword Analyzer</a>、<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/analysis-pattern-analyzer.html" target="_blank" rel="noopener">Pattern Analyzer</a>、<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/analysis-lang-analyzer.html" target="_blank" rel="noopener">Language Analyzers</a>、<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/analysis-fingerprint-analyzer.html" target="_blank" rel="noopener">Fingerprint Analyzer</a>，并且<strong>支持定制化</strong>。</p><p>这里的内置分词器看起来都比较简单，这里简单介绍一下 Standard Analyzer、Keyword Analyzer，其他的分词器大家感兴趣可以自行查阅。</p><h5 id="text-类型默认-analyzer：Standard-Analyzer"><a href="#text-类型默认-analyzer：Standard-Analyzer" class="headerlink" title="text 类型默认 analyzer：Standard Analyzer"></a>text 类型默认 analyzer：Standard Analyzer</h5><p>Standard Analyzer 的组成部分：</p><ul><li><p>Tokenizer<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/analysis-standard-tokenizer.html" target="_blank" rel="noopener">Standard Tokenizer</a>：基于 Unicode 文本分割算法-<a href="http://unicode.org/reports/tr29/" target="_blank" rel="noopener">Unicode 标准附件# 29</a>，支持使用 <code>max_token_length</code> 参数指定 token 长度，默认为 255。</p></li><li><p>Token Filters</p></li></ul><ul><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/analysis-lowercase-tokenfilter.html" target="_blank" rel="noopener">Lower Case Token Filter</a></p></li><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/analysis-stop-tokenfilter.html" target="_blank" rel="noopener">Stop Token Filter</a> ：<strong>默认没有 stop token/words</strong>，需通过参数 <code>stopwords</code> 或 <code>stopwords_path</code> 进行指定。</p></li></ul><p>如果 text 类型没有指定 Analyzer，Standard Analyzer，前面我们已经了解了 ES 分析器的结构，理解它的分析器应该不在话下。Unicode 文本分割算法依据的标准，给出了文本中词组、单词、句子的默认分割边界。该附件在 notes 中提到，像类似中文这种复杂的语言，并没有明确的分割边界，简而言之就是说，<strong>中文并不适用于这个标准</strong>。</p><p>通常我们的全文检索使用场景都是针对中文的，所以我们在创建我们的映射关系时，一定要指定合适的分析器。</p><h5 id="keyword-类型默认-analyzer：Keyword-Analyzer"><a href="#keyword-类型默认-analyzer：Keyword-Analyzer" class="headerlink" title="keyword 类型默认 analyzer：Keyword Analyzer"></a>keyword 类型默认 analyzer：Keyword Analyzer</h5><p>Keyword Analyzer 本质上就是一个”noop” Analyzer，直接将输入的内容作为一整个 token。</p><h5 id="第三方中文分词器-ik"><a href="#第三方中文分词器-ik" class="headerlink" title="第三方中文分词器 ik"></a>第三方中文分词器 ik</h5><p>github 地址：<a href="https://github.com/medcl/elasticsearch-analysis-ik" target="_blank" rel="noopener">https://github.com/medcl/elasticsearch-analysis-ik</a></p><p>IK Analyzer 是一个开源的，基于 java 语言开发的轻量级的中文分词工具包。从 2006 年 12 月推出 1.0 版开始， IKAnalyzer 已经推出了 4 个大版本。最初，它是以开源项目 Luence 为应用主体的，结合词典分词和文法分析算法的中文分词组件。从 3.0 版本开始，IK 发展为面向 Java 的公用分词组件，独立于 Lucene 项目，同时提供了对 Lucene 的默认优化实现。在 2012 版本中，IK 实现了简单的分词歧义排除算法，标志着 IK 分词器从单纯的词典分词向模拟语义分词衍化。</p><p>使用方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; mapping创建  </span><br><span class="line">PUT &#x2F;[your index]  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;mappings&quot;: &#123;  </span><br><span class="line">    &quot;properties&quot;: &#123;  </span><br><span class="line">      &quot;text_test&quot;:&#123;  </span><br><span class="line">        &quot;type&quot;: &quot;text&quot;,  </span><br><span class="line">        &quot;analyzer&quot;: &quot;ik_smart&quot;  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">&#x2F;&#x2F; 新建document  </span><br><span class="line">POST &#x2F;[your index]&#x2F;_doc  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;text_test&quot;:&quot;我爱中国&quot;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">&#x2F;&#x2F;查看term vector  </span><br><span class="line">GET &#x2F;[your index]&#x2F;_termvectors&#x2F;ste3HYABZRKvoZUCe2oH?fields&#x3D;text_test  </span><br><span class="line">&#x2F;&#x2F;结果包含了 “我”“爱”“中国”</span><br></pre></td></tr></table></figure><h4 id="相似性得分-similarity"><a href="#相似性得分-similarity" class="headerlink" title="相似性得分 similarity"></a>相似性得分 similarity</h4><h5 id="classic：基于-TF-IDF-实现，V7-已禁止使用，V8-彻底废除（仅供了解）"><a href="#classic：基于-TF-IDF-实现，V7-已禁止使用，V8-彻底废除（仅供了解）" class="headerlink" title="classic：基于 TF/IDF 实现，V7 已禁止使用，V8 彻底废除（仅供了解）"></a>classic：基于 TF/IDF 实现，V7 已禁止使用，V8 彻底废除（仅供了解）</h5><p>TF/IDF 介绍文章：<a href="https://zhuanlan.zhihu.com/p/31197209" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31197209</a></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/c24c30f2ad55217d739df48ecb1d50ef.jpeg" alt=""></p><p>TF/IDF 使用逆文档频率作为权重，降低常见词汇带来的相似性得分。从公式中可以看出，这个相似性算法仅与<strong>文档词频</strong>相关，覆盖不够全面。例如：缺少文档长度带来的权重，当其他条件相同，“王者荣耀”这个查询关键字同时出现在短篇文档和长篇文档中时，短篇文档的相似性其实更高。</p><p>在 ESV5 之前，ES 使用的是 Lucene 基于 TF/IDF 自实现的一套相关性得分算法，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">score(q,d)  &#x3D;  </span><br><span class="line">            queryNorm(q)  </span><br><span class="line">          · coord(q,d)  </span><br><span class="line">          · ∑ (  </span><br><span class="line">                tf(t in d)  </span><br><span class="line">              · idf(t)²  </span><br><span class="line">              · t.getBoost()  </span><br><span class="line">              · norm(t,d)  </span><br><span class="line">            ) (t in q)</span><br></pre></td></tr></table></figure><ul><li><p>queryNorm：query normalization factor 查询标准化因子，旨在让<strong>不同查询</strong>之间的相关性结果可以进行比较（实际上 ES 的 tips 中提到，并不推荐大家这样做，不同查询之间的决定性因素是不一样的）</p></li><li><p>coord：coordination factor 协调因子，query 经过分析得到的 terms 在文章中命中的数量越多，coord 值越高。例如：查询“王者荣耀五周年”，terms：“王者”、“荣耀”、“五周年”，同时包含这几个 term 的文档 coord 值越高</p></li><li><p>tf：词频</p></li><li><p>idf：文档逆频率</p></li><li><p>boost：boost 翻译过来是增长推动的意思，这里可以理解为一个支持可配的加权参数。</p></li><li><p>norm：文档长度标准化，内容越长，值越小</p></li></ul><p>Lucene 已经针对 TF/IDF 做了尽可能的优化，但是有一个问题仍然无法避免：</p><ul><li><strong>词频饱和度</strong>问题，如下图所示，TF/IDF 算法的相似性得分会随着词频不断上升。在 Lucene 现有的算法中，如果一个词出现的频率过高，<strong>会直接忽略掉文档长度带来的权重影响</strong>。</li></ul><p>另一条曲线是 BM25 算法相似性得分随词频的关系，<strong>它的结果随词频上升而趋于一个稳定值。</strong></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/b584f07a289d169668eeff6f64e29626.jpeg" alt=""></p><h5 id="BM25：默认"><a href="#BM25：默认" class="headerlink" title="BM25：默认"></a>BM25：默认</h5><p>BM25 介绍文章：<a href="https://en.wikipedia.org/wiki/Okapi\_BM25" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Okapi\_BM25</a> ，对 BM25 的实现细节我们在这里不做过多阐述，主要了解一下 BM25 算法相较于之前的算法有哪些优点：</p><ul><li><p><strong>词频饱和</strong>不同于 TF/IDF，BM25 的实现基于一个重要发现：<strong>“词频和相关性之间的关系是非线性的”</strong>。当词频到达一定阈值后，对相关性得分的影响是<strong>相同的</strong>，此时应该由其他因素的权重决定得分高低，例如之前提到的文档长度。</p></li><li><p><strong>将文档长度加入算法中</strong>相同条件下，短篇文档的权重值会高于长篇文档。</p></li><li><p><strong>提供了可调整的参数</strong></p></li></ul><p>我们在查询过程可以通过设置 <code>&quot;explain&quot;:true</code> 查看相似性得分的具体情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">GET &#x2F;[your index]&#x2F;_search  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;explain&quot;: true,  </span><br><span class="line">  &quot;query&quot;: &#123;  </span><br><span class="line">    &quot;match&quot;: &#123;  </span><br><span class="line">      &quot;describe&quot;: &quot;测试&quot;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">&#x2F;&#x2F;简化版查询结果  </span><br><span class="line">&#123;  </span><br><span class="line">    &quot;_explanation&quot;: &#123;  </span><br><span class="line">        &quot;value&quot;: 0.21110919,  </span><br><span class="line">        &quot;description&quot;: &quot;weight(describe:测试 in 1) [PerFieldSimilarity], result of:&quot;,  </span><br><span class="line">        &quot;details&quot;: [  </span><br><span class="line">            &#123;  </span><br><span class="line">                &quot;value&quot;: 0.21110919,  </span><br><span class="line">                &quot;description&quot;: &quot;score(freq&#x3D;1.0), computed as boost * idf * tf from:&quot;,  </span><br><span class="line">                &quot;details&quot;: [  </span><br><span class="line">                    &#123;  </span><br><span class="line">                        &quot;value&quot;: 2.2,  </span><br><span class="line">                        &quot;description&quot;: &quot;boost&quot;,  </span><br><span class="line">                        &quot;details&quot;: []  </span><br><span class="line">                    &#125;,  </span><br><span class="line">                    &#123;  </span><br><span class="line">                        &quot;value&quot;: 0.18232156,  </span><br><span class="line">                        &quot;description&quot;: &quot;idf, computed as log(1 + (N - n + 0.5) &#x2F; (n + 0.5)) from:&quot;,  </span><br><span class="line">                        &quot;details&quot;: [...]  </span><br><span class="line">                    &#125;,  </span><br><span class="line">                    &#123;  </span><br><span class="line">                        &quot;value&quot;: 0.5263158,  </span><br><span class="line">                        &quot;description&quot;: &quot;tf, computed as freq &#x2F; (freq + k1 * (1 - b + b * dl &#x2F; avgdl)) from:&quot;,  </span><br><span class="line">                        &quot;details&quot;: [...]  </span><br><span class="line">                    &#125;  </span><br><span class="line">                ]  </span><br><span class="line">            &#125;  </span><br><span class="line">        ]  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="boolean"><a href="#boolean" class="headerlink" title="boolean"></a>boolean</h5><p>boolean 相似性非常好理解，只能根据查询条件是否匹配，其最终值其实就是 query boost 值。</p><h4 id="query-and-filter-context"><a href="#query-and-filter-context" class="headerlink" title="query and filter context"></a>query and filter context</h4><ul><li><p>filter <strong>Does</strong> this document match this query clause?</p><p>filter 只关心是/否，根据你过滤条件给你筛选出默认的文档</p></li><li><p>query <strong>how well</strong> does this document match this query clause?</p><p>query 的关注点除了是否之外，还关注这些文档的匹配度有多高</p></li></ul><p>他们本质上的区别是<strong>是否参与相关性得分</strong>。在查询过程中，官方建议可以根据实际使用情况配合使用 <code>filter</code> 和 <code>query</code> 。但是如果你的查询并<strong>不关心相关性得分</strong>，仅关心查询到的结果，其实两者<strong>差别不大</strong>。</p><p>题主本来以为使用 filter 可以节省计算相似性得分的耗时，但是使用 filter 同样会进行相似性得分，只是通过特殊的方式将其 value 置为了 0。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;only query  </span><br><span class="line">GET &#x2F;[your index]&#x2F;_search  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;explain&quot;: true,  </span><br><span class="line">  &quot;query&quot;: &#123;  </span><br><span class="line">    &quot;bool&quot;: &#123;  </span><br><span class="line">      &quot;must&quot;: [  </span><br><span class="line">        &#123;&quot;match&quot;: &#123;&quot;describe&quot;: &quot;测试&quot;&#125;&#125;,  </span><br><span class="line">        &#123;&quot;term&quot;: &#123;&quot;tab_id&quot;: 5&#125;&#125;  </span><br><span class="line">      ]  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">&#x2F;&#x2F;简化_explanation结果  </span><br><span class="line">&#123;  </span><br><span class="line">    &quot;_explanation&quot;: &#123;  </span><br><span class="line">        &quot;value&quot;: 1.2111092,  </span><br><span class="line">        &quot;description&quot;: &quot;sum of:&quot;,  </span><br><span class="line">        &quot;details&quot;: [  </span><br><span class="line">            &#123;  </span><br><span class="line">                &quot;value&quot;: 0.21110919,  </span><br><span class="line">                &quot;description&quot;: &quot;weight(describe:测试 in 1) [PerFieldSimilarity], result of:&quot;  </span><br><span class="line">            &#125;,  </span><br><span class="line">            &#123;  </span><br><span class="line">                &quot;value&quot;: 1,  </span><br><span class="line">                &quot;description&quot;: &quot;tab_id:[5 TO 5]&quot;,  </span><br><span class="line">                &quot;details&quot;: []  </span><br><span class="line">            &#125;  </span><br><span class="line">        ]  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">&#x2F;&#x2F;query+filter  </span><br><span class="line">GET &#x2F;[your index]&#x2F;_search  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;explain&quot;: true,  </span><br><span class="line">  &quot;query&quot;: &#123;  </span><br><span class="line">    &quot;bool&quot;: &#123;  </span><br><span class="line">      &quot;filter&quot;: [  </span><br><span class="line">        &#123;&quot;term&quot;: &#123;&quot;tab_id&quot;: &quot;5&quot;&#125;&#125;  </span><br><span class="line">      ],  </span><br><span class="line">      &quot;must&quot;: [  </span><br><span class="line">        &#123;&quot;match&quot;: &#123;&quot;describe&quot;: &quot;测试&quot;&#125;&#125;  </span><br><span class="line">      ]  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">&#x2F;&#x2F;简化_explanation结果  </span><br><span class="line">&#123;  </span><br><span class="line">    &quot;_explanation&quot;: &#123;  </span><br><span class="line">        &quot;value&quot;: 0.21110919,  </span><br><span class="line">        &quot;description&quot;: &quot;sum of:&quot;,  </span><br><span class="line">        &quot;details&quot;: [  </span><br><span class="line">            &#123;  </span><br><span class="line">                &quot;value&quot;: 0.21110919,  </span><br><span class="line">                &quot;description&quot;: &quot;weight(describe:测试 in 1) [PerFieldSimilarity], result of:&quot;  </span><br><span class="line">            &#125;,  </span><br><span class="line">            &#123;  </span><br><span class="line">                &quot;value&quot;: 0,  </span><br><span class="line">                &quot;description&quot;: &quot;match on required clause, product of:&quot;,  </span><br><span class="line">                &quot;details&quot;: [  </span><br><span class="line">                    &#123;  </span><br><span class="line">                        &quot;value&quot;: 0,  </span><br><span class="line">                        &quot;description&quot;: &quot;# clause&quot;,  </span><br><span class="line">                        &quot;details&quot;: []  </span><br><span class="line">                    &#125;,  </span><br><span class="line">                    &#123;  </span><br><span class="line">                        &quot;value&quot;: 1,  </span><br><span class="line">                        &quot;description&quot;: &quot;tab_id:[5 TO 5]&quot;,  </span><br><span class="line">                        &quot;details&quot;: []  </span><br><span class="line">                    &#125;  </span><br><span class="line">                ]  </span><br><span class="line">            &#125;  </span><br><span class="line">        ]  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="排序-sort"><a href="#排序-sort" class="headerlink" title="排序 sort"></a>排序 sort</h4><p>在执行 ES 查询时，默认的排序规则是根据相关性得分倒排，针对非全文索引字段，可以指定排序方式，使用也非常简单。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;查询时先根据tab_id降序排列，若tab_id相同，则根究status升序排列  </span><br><span class="line">GET &#x2F;[your index]&#x2F;_search  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;sort&quot;: [  </span><br><span class="line">    &#123;&quot;tab_id&quot;: &#123;&quot;order&quot;: &quot;desc&quot;&#125;&#125;,  </span><br><span class="line">    &#123;&quot;status&quot;: &#123;&quot;order&quot;: &quot;asc&quot;&#125;&#125;  </span><br><span class="line">  ]  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="好坑啊：缺失数值类字段的默认值并不是-0"><a href="#好坑啊：缺失数值类字段的默认值并不是-0" class="headerlink" title="好坑啊：缺失数值类字段的默认值并不是 0"></a>好坑啊：缺失数值类字段的默认值并不是 0</h5><p><strong>事情的背景</strong></p><p>题主使用的编程语言是 golang，通常使用 pb 定义结构体，生成对应的 go 代码，默认情况下，结构体字段的 json tag 都会包含 <code>omitempty</code> 属性，也就是忽略空值，如果数字类型的 value 为 0，进行 json marshall 时，不会生成对应字段。</p><p><strong>事情的经过</strong></p><p>刚好题主通过以上方式进行文档变更，所以实际上如果某个数值字段为 0，<strong>它并没有被存储。</strong></p><p>在题主的功能逻辑里，刚好需要对某个数值字段做<strong>升序</strong>排列，惊奇地发现我认为的字段值为 0 的文档，出现在了列表最末。</p><p><strong>事情的调查结果</strong></p><p>针对缺失数值类字段的默认值并不是 0，ES 默认会保证排序字段没有 value 的文档<strong>被放在最后</strong>，默认情况下：</p><ul><li><p><strong>降序</strong>排列，缺失字段默认值为该字段类型的<strong>最小值</strong></p></li><li><p><strong>升序</strong>排列，缺失字段默认值为该字段类型的<strong>最大值</strong></p></li></ul><p>好消息是，ES 为我们提供了 <code>missing</code> 参数，我们可以指定缺失值填充，但是它太隐蔽了 😭，其默认值为 <code>_last</code> 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">GET &#x2F;[your index]&#x2F;_search  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;sort&quot;: [  </span><br><span class="line">    &#123;&quot;num&quot;: &#123;&quot;order&quot;: &quot;asc&quot;&#125;&#125;  </span><br><span class="line">  ]  </span><br><span class="line">&#125;  </span><br><span class="line">&#x2F;&#x2F;简化结果  </span><br><span class="line">&#123;  </span><br><span class="line">    &quot;hits&quot;: [  </span><br><span class="line">      &#123;&quot;sort&quot;: [1]&#125;,  </span><br><span class="line">        &#123;&quot;sort&quot;: [9223372036854775807]&#125;,  </span><br><span class="line">        &#123;&quot;sort&quot;: [9223372036854775807]&#125;  </span><br><span class="line">    ]  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">GET &#x2F;your_index&#x2F;_search  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;sort&quot;: [  </span><br><span class="line">    &#123;&quot;num&quot;: &#123;&quot;order&quot;: &quot;desc&quot;&#125;&#125;  </span><br><span class="line">  ]  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">&#x2F;&#x2F;简化结果  </span><br><span class="line">&#123;  </span><br><span class="line">    &quot;hits&quot;: [  </span><br><span class="line">        &#123;&quot;sort&quot;: [1]&#125;,  </span><br><span class="line">        &#123;&quot;sort&quot;: [-9223372036854775808]&#125;,  </span><br><span class="line">        &#123;&quot;sort&quot;: [-9223372036854775808]&#125;  </span><br><span class="line">    ]  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">&#x2F;&#x2F; with missing  </span><br><span class="line">GET &#x2F;[your index]&#x2F;_search  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;sort&quot;: [  </span><br><span class="line">    &#123;  </span><br><span class="line">      &quot;num&quot;: &#123;  </span><br><span class="line">        &quot;order&quot;: &quot;asc&quot;,  </span><br><span class="line">        &quot;missing&quot;: &quot;0&quot;  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  ]  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">&#x2F;&#x2F;简化结果  </span><br><span class="line">&#123;  </span><br><span class="line">    &quot;hits&quot;: [  </span><br><span class="line">        &#123;&quot;sort&quot;: [0]&#125;,  </span><br><span class="line">        &#123;&quot;sort&quot;: [0]&#125;,  </span><br><span class="line">        &#123;&quot;sort&quot;: [1]&#125;  </span><br><span class="line">    ]  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="使用技巧：用-function-score-实现自定义排序"><a href="#使用技巧：用-function-score-实现自定义排序" class="headerlink" title="使用技巧：用 function score 实现自定义排序"></a>使用技巧：用 function score 实现自定义排序</h5><p>不知道大家是否遇到过类似的场景：期望查询结果按照某个类型进行排序，或者查询结果顺序由多个字段的权重组合决定。</p><p>具体解决方案需要根据业务具体情况而定，这里给出一种基于 ES 查询的解决方案。ES 为我们提供了 <code>function score</code> ，支持自定义相关性得分 score 的生成方式，部分参数介绍：</p><ul><li><p>weight：权重值</p></li><li><p>boost：加权值</p></li><li><p>boost_mode：加权值计算方式（默认为 multiple）</p></li><li><p>score_mode：得分计算方式（默认为 multiple）</p></li></ul><p>举点实际的栗子，假设咱们有一个存放水果的 Index：</p><ul><li>简单一点的 case：查询结果根据水果类型苹果，梨优先 苹果的优先级高于梨的优先级，梨的优先级高于其他水果的优先级。我们可以定义梨的权重为 1，苹果的权重为 2</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">GET &#x2F;fruit_test&#x2F;_search  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;explain&quot;: true,  </span><br><span class="line">  &quot;query&quot;: &#123;  </span><br><span class="line">    &quot;function_score&quot;: &#123;  </span><br><span class="line">      &quot;functions&quot;: [  </span><br><span class="line">        &#123;  </span><br><span class="line">          &quot;filter&quot;: &#123;&quot;term&quot;: &#123;&quot;type&quot;: &quot;pear&quot;&#125;&#125;,  </span><br><span class="line">          &quot;weight&quot;: 1  </span><br><span class="line">        &#125;,  </span><br><span class="line">        &#123;  </span><br><span class="line">          &quot;filter&quot;: &#123;&quot;term&quot;: &#123;&quot;type&quot;: &quot;apple&quot;&#125;&#125;,  </span><br><span class="line">          &quot;weight&quot;: 2  </span><br><span class="line">        &#125;  </span><br><span class="line">      ],  </span><br><span class="line">      &quot;boost&quot;: 1,  </span><br><span class="line">      &quot;score_mode&quot;: &quot;sum&quot;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>复杂一点的 case（别问我是怎么想到的）：</li></ul><ul><li><p>优先级一：根据水果是否有货排序，有货的排前面，<strong>无货的过滤掉</strong></p></li><li><p>优先级二：根据水果是否预售排序，非预售优先展示</p></li><li><p>优先级三：根据水果类型苹果，梨优先展示</p></li><li><p>优先级四：根据水果颜色红色，绿色优先展示</p></li><li><p>优先级五：根据价格升序排序 我们根据优先级顺序定义每个条件的权重，指定自定义相关性得分规则后，在 <code>sort</code> 中指定先根据 <code>_score</code> 降序排列，再根据价格升序排列。</p></li><li><p>优先级四：绿色权重 1 、红色权重 2</p></li><li><p>优先级三：梨权重 3 、苹果权重 4</p></li><li><p>优先级二：预售权重 7（优先级四 max + 优先级三 max = 6，优先级二的权重必须大于这个值）</p></li><li><p>优先级一：直接将无货水果过滤</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">GET &#x2F;fruit_test&#x2F;_search  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;query&quot;: &#123;  </span><br><span class="line">    &quot;function_score&quot;: &#123;  </span><br><span class="line">      &quot;query&quot;: &#123;&quot;range&quot;: &#123;&quot;stock&quot;: &#123;&quot;gt&quot;: 0&#125;&#125;  </span><br><span class="line">      &#125;,  </span><br><span class="line">      &quot;functions&quot;: [  </span><br><span class="line">        &#123;  </span><br><span class="line">          &quot;filter&quot;: &#123;&quot;term&quot;: &#123;&quot;color&quot;: &quot;green&quot;&#125;&#125;,  </span><br><span class="line">          &quot;weight&quot;: 1  </span><br><span class="line">        &#125;,  </span><br><span class="line">        &#123;  </span><br><span class="line">          &quot;filter&quot;: &#123;&quot;term&quot;: &#123;&quot;color&quot;: &quot;red&quot;&#125;&#125;,  </span><br><span class="line">          &quot;weight&quot;: 2  </span><br><span class="line">        &#125;,  </span><br><span class="line">        &#123;  </span><br><span class="line">          &quot;filter&quot;: &#123;&quot;term&quot;: &#123;&quot;type&quot;: &quot;pear&quot;&#125;&#125;,  </span><br><span class="line">          &quot;weight&quot;: 3  </span><br><span class="line">        &#125;,  </span><br><span class="line">        &#123;  </span><br><span class="line">          &quot;filter&quot;: &#123;&quot;term&quot;: &#123;&quot;type&quot;: &quot;apple&quot;&#125;&#125;,  </span><br><span class="line">          &quot;weight&quot;: 4  </span><br><span class="line">        &#125;,  </span><br><span class="line">        &#123;  </span><br><span class="line">          &quot;filter&quot;: &#123;&quot;term&quot;: &#123;&quot;pre_sale&quot;: false&#125;&#125;,  </span><br><span class="line">          &quot;weight&quot;: 7  </span><br><span class="line">        &#125;  </span><br><span class="line">      ],  </span><br><span class="line">      &quot;boost&quot;: 1,  </span><br><span class="line">      &quot;boost_mode&quot;: &quot;sum&quot;,  </span><br><span class="line">      &quot;score_mode&quot;: &quot;sum&quot;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;,  </span><br><span class="line">  &quot;sort&quot;: [  </span><br><span class="line">    &#123;&quot;_score&quot;: &#123;&quot;order&quot;: &quot;desc&quot;&#125;&#125;,  </span><br><span class="line">    &#123;&quot;price_per_kg&quot;: &#123;&quot;order&quot;: &quot;asc&quot;&#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  ]  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="聚合-aggs"><a href="#聚合-aggs" class="headerlink" title="聚合 aggs"></a>聚合 aggs</h4><p>聚合操作可以帮助我们将查询数据按照指定的方式进行归类。常见的聚合方式，诸如：max、min、avg、range、根据 term 聚合等等，这些都比较好理解，功能使用上也没有太多疑惑，下面主要介绍题主在使用过程中遇到的坑点以及指标聚合嵌套查询。</p><p>ES 还支持<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/search-aggregations-pipeline.html" target="_blank" rel="noopener">pipline aggs</a>，主要针对的对象不是文档集，而是其他聚合的结果，感兴趣的同学可以自行了解。</p><h5 id="好坑啊：ES-默认的时间格式为毫秒级时间"><a href="#好坑啊：ES-默认的时间格式为毫秒级时间" class="headerlink" title="好坑啊：ES 默认的时间格式为毫秒级时间"></a>好坑啊：ES 默认的时间格式为<strong>毫秒级时间</strong></h5><p>如果你有诉求，<strong>需要针对秒级时间戳进行时间聚合</strong>，例如：某销售场景下，我们期望按小时/天/月/进行销售单数统计。</p><p>那么有以下两种常见<strong>错误使用方式</strong>需要规避：</p><ul><li>如果在创建 <code>date</code> 类型字段，但是<strong>没有指定时间 format 格式</strong>，并且以<strong>秒级时间戳</strong>赋值（直接以年月日赋值没有问题） 根据时间聚合将无法解析出正确的数据，时间会被解析为 1970 年</li></ul><ul><li>如果直接使用 <code>numberic</code> 类型，例如 <code>integer</code> 存储时间戳 不管是秒级还是毫秒级，都无法被正确识别</li></ul><p>正确的做法：创建 mapping，明确指定时间的格式为秒级时间戳。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">PUT &#x2F;date_test&#x2F;_mapping  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;properties&quot;:&#123;  </span><br><span class="line">    &quot;create_time&quot;:&#123;  </span><br><span class="line">      &quot;type&quot;:&quot;date&quot;,  </span><br><span class="line">      &quot;format&quot; : &quot;epoch_second&quot;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">&#x2F;&#x2F;以年为时间间隔 进行统计  </span><br><span class="line">GET &#x2F;date_test&#x2F;_search  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;size&quot;: 0,  </span><br><span class="line">  &quot;aggs&quot;: &#123;  </span><br><span class="line">    &quot;test&quot;: &#123;  </span><br><span class="line">      &quot;date_histogram&quot;: &#123;  </span><br><span class="line">        &quot;field&quot;: &quot;create_time&quot;,  </span><br><span class="line">        &quot;format&quot;: &quot;yyyy&quot;,  </span><br><span class="line">        &quot;interval&quot;: &quot;year&quot;  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">&#x2F;&#x2F;从查询结果可以看出来，实际计算时ES会帮我们把秒级时间戳转成毫秒级时间戳  </span><br><span class="line">&#123;  </span><br><span class="line">&quot;aggregations&quot; : &#123;  </span><br><span class="line">    &quot;test&quot; : &#123;  </span><br><span class="line">      &quot;buckets&quot; : [  </span><br><span class="line">        &#123;  </span><br><span class="line">          &quot;key_as_string&quot; : &quot;2018&quot;,  </span><br><span class="line">          &quot;key&quot; : 1514764800000,  </span><br><span class="line">          &quot;doc_count&quot; : 2  </span><br><span class="line">        &#125;,  </span><br><span class="line">        &#123;  </span><br><span class="line">          &quot;key_as_string&quot; : &quot;2019&quot;,  </span><br><span class="line">          &quot;key&quot; : 1546300800000,  </span><br><span class="line">          &quot;doc_count&quot; : 0  </span><br><span class="line">        &#125;,  </span><br><span class="line">        &#123;  </span><br><span class="line">          &quot;key_as_string&quot; : &quot;2020&quot;,  </span><br><span class="line">          &quot;key&quot; : 1577836800000,  </span><br><span class="line">          &quot;doc_count&quot; : 3  </span><br><span class="line">        &#125;  </span><br><span class="line">      ]  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="聚合嵌套查询"><a href="#聚合嵌套查询" class="headerlink" title="聚合嵌套查询"></a>聚合嵌套查询</h5><p>上面介绍了根据时间聚合，还是以刚刚的例子来说，某销售场景下，我们期望在根据时间统计销售单数的同时，统计出时间区间内的销售总金额。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">GET &#x2F;date_test&#x2F;_search  </span><br><span class="line">&#123;  </span><br><span class="line">  &quot;size&quot;: 0,  </span><br><span class="line">  &quot;aggs&quot;: &#123;  </span><br><span class="line">    &quot;test&quot;: &#123;  </span><br><span class="line">      &quot;date_histogram&quot;: &#123;  </span><br><span class="line">        &quot;field&quot;: &quot;create_time&quot;,  </span><br><span class="line">        &quot;format&quot;: &quot;yyyy&quot;,  </span><br><span class="line">        &quot;interval&quot;: &quot;year&quot;  </span><br><span class="line">      &#125;,  </span><br><span class="line">      &quot;aggs&quot;: &#123;  </span><br><span class="line">        &quot;sum_profit&quot;: &#123;  </span><br><span class="line">          &quot;sum&quot;: &#123;  </span><br><span class="line">            &quot;field&quot;: &quot;profit&quot;  </span><br><span class="line">          &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">      &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line">&#123;  </span><br><span class="line">&quot;aggregations&quot; : &#123;  </span><br><span class="line">    &quot;test&quot; : &#123;  </span><br><span class="line">      &quot;buckets&quot; : [  </span><br><span class="line">        &#123;  </span><br><span class="line">          &quot;key_as_string&quot; : &quot;2018&quot;,  </span><br><span class="line">          &quot;key&quot; : 1514764800000,  </span><br><span class="line">          &quot;doc_count&quot; : 2,  </span><br><span class="line">          &quot;sum_profit&quot; : &#123;  </span><br><span class="line">            &quot;value&quot; : 200.0  </span><br><span class="line">          &#125;  </span><br><span class="line">        &#125;,  </span><br><span class="line">        &#123;  </span><br><span class="line">          &quot;key_as_string&quot; : &quot;2019&quot;,  </span><br><span class="line">          &quot;key&quot; : 1546300800000,  </span><br><span class="line">          &quot;doc_count&quot; : 0,  </span><br><span class="line">          &quot;sum_profit&quot; : &#123;  </span><br><span class="line">            &quot;value&quot; : 0.0  </span><br><span class="line">          &#125;  </span><br><span class="line">        &#125;,  </span><br><span class="line">        &#123;  </span><br><span class="line">          &quot;key_as_string&quot; : &quot;2020&quot;,  </span><br><span class="line">          &quot;key&quot; : 1577836800000,  </span><br><span class="line">          &quot;doc_count&quot; : 3,  </span><br><span class="line">          &quot;sum_profit&quot; : &#123;  </span><br><span class="line">            &quot;value&quot; : 3000.0  </span><br><span class="line">          &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">      ]  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="使用技巧：自实现-distinct"><a href="#使用技巧：自实现-distinct" class="headerlink" title="使用技巧：自实现 distinct"></a>使用技巧：自实现 distinct</h5><p>ES 默认并不支持 distinct，可以尝试使用 <code>terms</code> 聚合，解析结果中的 key</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;  </span><br><span class="line">&quot;aggregations&quot; : &#123;  </span><br><span class="line">    &quot;test&quot; : &#123;  </span><br><span class="line">      &quot;doc_count_error_upper_bound&quot; : 0,  </span><br><span class="line">      &quot;sum_other_doc_count&quot; : 0,  </span><br><span class="line">      &quot;buckets&quot; : [  </span><br><span class="line">        &#123;&quot;key&quot; : &quot;1&quot;,&quot;doc_count&quot; : 2&#125;,  </span><br><span class="line">        &#123;&quot;key&quot; : &quot;10&quot;,&quot;doc_count&quot; : 2&#125;,  </span><br><span class="line">        &#123;&quot;key&quot; : &quot;16&quot;,&quot;doc_count&quot; : 2&#125;  </span><br><span class="line">      ]  </span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="索引别名、索引生命周期策略、索引模版"><a href="#索引别名、索引生命周期策略、索引模版" class="headerlink" title="索引别名、索引生命周期策略、索引模版"></a>索引别名、索引生命周期策略、索引模版</h4><ul><li><p>Aliases 索引别名 索引别名，顾名思义，定义了别名之后，可以通过别名对 index 进行查询<code>PUT /[your index]/_alias/[your alias name]</code></p></li><li><p>Index Lifecycle Policies 索引生命周期策略 索引生命周期策略支持我们根据天、存储量级等信息去自动管理我们的索引。创建方式可以通过 RESTful API，也可以直接在 kibana 上创建，题主使用的是后者，可视化界面看起来比较清晰～ 支持配置满足一定规则后索引自动变化：</p></li></ul><ul><li><p>自动滚动索引（hot）</p></li><li><p>保留索引仅供检索（warm）</p></li><li><p>保留索引仅供检索同时减少磁盘存储（cold）</p></li><li><p>删除索引</p></li></ul><ul><li>Template 索引模板 通过 <code>index_patterns</code> 参数设置索引名正则匹配规则，向一个不存在的索引 POST 数据，命中索引名规则后即会根据索引模版创建索引，不会进行动态映射。</li></ul><p>ES 的一个比较常见的应用场景是存储日志流，自实现一套这样的系统就可以结合上述 3 个功能。</p><p><strong>参考</strong></p><ul><li><p><a href="https://www.jianshu.com/p/1a737a3dde86" target="_blank" rel="noopener">https://www.jianshu.com/p/1a737a3dde86</a></p></li><li><p><a href="https://www.modb.pro/db/130339" target="_blank" rel="noopener">https://www.modb.pro/db/130339</a></p></li><li><p><a href="https://www.cnblogs.com/qdhxhz/p/11448451.html" target="_blank" rel="noopener">https://www.cnblogs.com/qdhxhz/p/11448451.html</a></p></li><li><p><a href="https://blog.csdn.net/tengxing007/article/details/100663530" target="_blank" rel="noopener">https://blog.csdn.net/tengxing007/article/details/100663530</a></p></li><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.7/index.html</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/35469104" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/35469104</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/142641300" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/142641300</a></p></li><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.7/index.html</a></p></li><li><p><a href="https://blog.csdn.net/laoyang360/article/details/80468757" target="_blank" rel="noopener">https://blog.csdn.net/laoyang360/article/details/80468757</a></p></li><li><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.0/query-filter-context.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.0/query-filter-context.html</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/31197209" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31197209</a></p></li><li><p><a href="https://code.google.com/archive/p/ik-analyzer/" target="_blank" rel="noopener">https://code.google.com/archive/p/ik-analyzer/</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/79202151" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/79202151</a></p></li></ul><p>本文转自 <a href="https://mp.weixin.qq.com/s/GG_zrQlaiP2nfPOxzx_j9w" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/GG_zrQlaiP2nfPOxzx_j9w</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>杂谈代码整洁</title>
      <link href="/posts/6ba27ba/"/>
      <url>/posts/6ba27ba/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><blockquote><p>Programs are meant to be read by humans and only <strong>incidentally</strong> for computers to execute. ——<a href="https://en.wikipedia.org/wiki/Donald_Knuth" target="_blank" rel="noopener">Donald Knuth</a><br>“代码始终是写给人看的，只是恰好能被计算机执行。”</p></blockquote><p>什么是好的代码？局部干净，核心逻辑简洁。</p><p>本文是一篇总结笔记，是以往工作学习中关于如何实现“局部干净”的一些见闻、教训、团队实践和一些思考。写出整洁代码不仅需在函数、类级别上用功，也应该理解一些其他主题，如项目架构、设计原则等，软件工程是复杂(complex)的，只有各个方面都处理得干干净净，才能在整体上做到代码整洁。特别感谢旭哥，授我思想与技术。</p><h3 id="指导原则：消除重复，分离关注点，统一抽象层次"><a href="#指导原则：消除重复，分离关注点，统一抽象层次" class="headerlink" title="指导原则：消除重复，分离关注点，统一抽象层次"></a>指导原则：消除重复，分离关注点，统一抽象层次</h3><p>程序员终其一生所做得事大抵不超过这几个<strong>层次</strong></p><ul><li><p>函数与类</p></li><li><p>包与模块(依赖)</p></li><li><p>服务(系统)与服务域</p></li><li><p>产品</p></li></ul><p>在各个层面，这十五个字都足以作一些指导或参考。</p><h4 id="消除重复"><a href="#消除重复" class="headerlink" title="消除重复"></a>消除重复</h4><p>重复的代码会让系统臃肿，难以维护，增加程序员的心智负担。消除重复的手段不外乎封装，抽取函数、类等。</p><ol><li>代码重复</li></ol><p>完完全全重复的代码，应该抽取出公共的函数。同一段代码出现两次及以上，就应该抽取出函数。</p><ol start="2"><li>结构重复</li></ol><p>代码虽然不一样，但结构类似，也应该抽取。结构重复可以推导出一些高级技术，如</p><ul><li><p>继承体系</p></li><li><p>泛型</p></li><li><p>模板方法(template method，四人帮 23 种设计模式之一)</p></li><li><p>高阶函数，lambda</p></li></ul><p>可惜的是，这些在 golang 里支持不够，各有喜忧。</p><ol start="3"><li>过程重复</li></ol><p>如果总是重复做同一件事，应该使其自动化。</p><h4 id="分离关注点"><a href="#分离关注点" class="headerlink" title="分离关注点"></a>分离关注点</h4><p>物以类聚，人以群分，代码也是一样。关注点相同的代码应该在一起，天然具有亲和性，这句话的另一个含义，对关注点不同的代码天然具有隔离性，相互之间不应该太深入了解。</p><ol><li>分离主线和支线</li></ol><p>这是最应该注意的，特别是在业务代码开发中。主要业务逻辑是主线，应该突出主线，淡化支线，按照人的思维，这样才是好理解的。例如旋律音和伴奏音，应该突出旋律，而淡化伴奏。假使伴奏音和旋律音差不多强，喧宾夺主，这样的音乐一定是难听的，因为我们听不出旋律。代码也是这样，应该突出主线，使核心逻辑一目了然。</p><p>例如在下单的逻辑中，可能的主线是：检查库存、检查余额、生成订单。那这个下单方法里就应该只有 3 行代码，而不应该有诸如权限判断、性能记录等，如果出现就会有 2 行代码是跟主线无关的，造成不必要的干扰，不要造成无谓的心智负担，应该解放心智去完成更复杂的事情。</p><p>分离主线和支线的技术如：</p><ul><li><p>AOP</p></li><li><p>interceptor、filter 等</p></li></ul><ol start="2"><li>分离技术和业务</li></ol><p>技术型代码常常是公用的，如日期计算、日志记录、性能测量、数据库链接、基础工具类。这些应该和业务逻辑分开，相信这点大家都没有疑问。</p><ol start="3"><li>按业务性质分离</li></ol><p>对业务开发来说，业务知识永远都是第一位的。一个技术水平很高的程序员，但是对业务不理解，他也发挥不了全部水平，就像杀鸡用牛刀，施展不了全部功力。不同业务应该分开，在模块级、服务级甚至更高的产品级，这也应该是共识。但是在一个系统内部，推荐也应该按业务分成不同的包，同一业务下的对象是天然亲和的，同样也是对不同业务的对象是隔离的。</p><ol start="4"><li>分离变化快慢的代码</li></ol><p>变化快的代码和长年不变的代码分开。</p><ol start="5"><li>分离性能高低的代码</li></ol><p>重 I/O 的代码和重 CPU 的代码理应分开，方便合理分配资源，其他诸如此类的代码应该注意分开。</p><h4 id="统一抽象层次"><a href="#统一抽象层次" class="headerlink" title="统一抽象层次"></a>统一抽象层次</h4><blockquote><p>将有关认识与那些在实际中和他们同在的所有其他认识隔离开，这就是抽象，所有具有普遍性的认识都是这样得到的。——John Locke 《关于人类理解的随笔》</p></blockquote><p>怎么理解抽象？抽象的反面是具体，具体是细节，可见抽象是细节的反面，抽象刻画了统一的画像，描述能力，是对事物在某些方面的特征的提取总结。总之，抽象表达的是意图，另一个理解就是，它不表达细节。“Tom 要成为世界首富”，这句话的抽象层次就很高，意图很明显，但是关于 Tom 如何成为世界首富、用什么货币衡量等细节，一概不知。抽象层次高，偏意图，语义(代码在上下文中表达的语义)清晰，信息量小；抽象层次低，偏实现，语义模糊，信息量大。</p><p>两个原则：</p><ul><li><p>同一抽象层次上的对象才能直接对话；</p></li><li><p>同一抽象层次上的对象之间存在着紧密合作；</p></li></ul><h5 id="典型的函数结构"><a href="#典型的函数结构" class="headerlink" title="典型的函数结构"></a>典型的函数结构</h5><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/b9145b539473ab7ce25e01770cc62556.jpeg" alt=""></p><p>一个好的函数结构，应该这样像一棵树一样层次分明。一方面，每一个层次都只有 2<del>5 个步骤，一般而言我们做一件事也就 2</del>5 个步骤，分解太多太少都不好，太少没必要分解，太多记不住，增加心智负担。实际上，更多的情况，我们都喜欢 3 这个数字，例如在会议总结时，总结 3 点足够了，更多估计不会有太多人愿意继续集中注意力听超过 3 点的总结。所以<strong>一个好的函数，不应该超过 5 行</strong>，我们之所以做不到，除了抽象层次划分不准确之外，还有很大一部分原因是表达能力不足，毕竟英语不是我们的母语。(函数 10 行代码，是我在过去工作中合代码的及格线，20 行是红线。)另一方面，只有叶子节点才表达实现，非叶节点都应该表达意图。</p><p>以“把大象装进冰箱”为例，不外乎三步：</p><ol><li><p>打开冰箱门</p></li><li><p>放进大象</p></li><li><p>关闭冰箱门</p></li></ol><p>所以关于如何把大象切成碎片，不应该出现在上面，应该在步骤 2 的后续调用中。</p><p>由这个函数结构还可以得见，好的程序读起来应该像自然语言，极少部分像数学语言(偏算法)，不好的程序读起来就像是程序。当我们读一段程序，一眼看去它就像是程序，那不是它太好，它就是不够好的。一直认为，写作能力才是成为优秀程序员最重要的能力。</p><h4 id="隔离与隐藏"><a href="#隔离与隐藏" class="headerlink" title="隔离与隐藏"></a>隔离与隐藏</h4><p>信息隐藏，是抽象的一种手段。通过信息隐藏，来暴露只想让外界知道的东西，表达意图。隔离是实现信息隐藏的重要手段。隐藏与隔离有一个天然的好处，例如我们有一个包，我们只提供数个 public 的方法，包内的其他对象、方法都只是包可见的，这样，我们可以随意修改内部实现，只要保证那些 public 方法的行为不变。特别是对于复杂系统，如果做不好隔离与隐藏，到处都是 public 方法，到后面谁都不敢随意改动代码，谁也不知道哪位大哥在方法上加了一个 if-else 分支。</p><h3 id="编码-tips"><a href="#编码-tips" class="headerlink" title="编码 tips"></a>编码 tips</h3><p>以下都是一些简单实用的技术，以如何写出整洁代码，很多是出自《代码整洁之道》，一些是出自过去团队的经验。</p><h4 id="1-类"><a href="#1-类" class="headerlink" title="1. 类"></a>1. 类</h4><ol><li>类应该足够小</li></ol><p>最初级的程序员可能会在一个 Controller 里做完所有的业务逻辑，最终会使这个类成为 God Class。一个类太大，代码太多，会使类的结构不清晰，职责混乱，维护代码时花费很多时间去寻找修改位置。譬如我们所见的世界，由分子、原子甚至更小的粒子排列组合而成，所以才有缤纷多彩的各色物质(对象)，但如果构成物质的最小粒子就是人，那还能组合出什么其他物质呢？代码也是如此，类应该足够小，才能发挥排列组合的威力。</p><ol start="2"><li>单一职责</li></ol><p>类的职责应该单一，即“SOLID”五大原则的 S，职责单一意味着，“只有一个理由可以修改它”。另外，类名一般而言应该是名词，且描述其职责。</p><blockquote><p>如果无法为一个类名以精确的名称，这个类大概就太长了。类名越含混，该类越有可能拥有过多的权责。</p><p>——《Clean Code》</p></blockquote><ol start="3"><li>内聚</li></ol><p>内聚的含义是，类的每一个字段都应该被某个(些)方法所使用到。如果不能达到这个结果，应该考虑是否类的字段应该拆分出去成为新的类。</p><ol start="4"><li>严格控制访问权限，注意信息隐藏，OCP</li></ol><p>访问权限应该能小则小。能 private 就不要 package，能 package 就不要 protected。这样做能使我们更好的遵循 OCP 原则。最稳定的系统，是从不修改的系统。</p><h4 id="2-函数"><a href="#2-函数" class="headerlink" title="2. 函数"></a>2. 函数</h4><ol><li>尽可能小</li></ol><blockquote><p>经过漫长的试错，经验告诉我，函数就应该小 ——《Clean Code》</p></blockquote><p>应该控制在 10 行以内，至多 20 行，除非是细节代码。这是完全可以做到的，做不到的原因可能有：函数功能太多，职责不单一；函数抽象层次划分不清；语言支持不够等。前面已经说过，做一件事大概也就 2~5 步，每一步一个函数，加上可能的条件判断，10 行是一个比较合理的数字。而且，函数越小，功能越集中，越便于取一个好名字。</p><ol start="2"><li>单一职责</li></ol><p>一个函数只做一件事。这一点很容易理解，难的是我们如何确定函数做的那件事是什么。一千个读者就有一千个哈姆雷特，同样的，不同的人对一个函数的理解也有所不同，对于做一件事的步骤拆分也可能有所不同。对此，一个可靠的判断准则是：函数的内容(函数体内的代码)只是做了函数所在抽象层级的步骤，那这个函数就是只做了一件事。函数所在抽象层级，根据对业务的理解，应该用良好的函数名加以示意。</p><ol start="3"><li>单一抽象层次</li></ol><p>一个函数应该只在一个抽象层次上。计算机世界都是<strong>层层叠加</strong>的，例如：寄存器 -&gt; 高速缓存 -&gt; 主存 -&gt; 硬盘 -&gt; 网络(可参见《CSAPP》第六章)，再如硬件 -&gt; 机器指令 -&gt; 汇编 -&gt; C -&gt; C++ -&gt; JVM -&gt; Java -&gt; Servlet -&gt; Spring -&gt; SpringBoot。严格禁止跨层次搞事。我们应该熟悉业务，根据业务上的一次用例，划分抽象层次，使每一个函数都只在某一个抽象层次上，不要跨层次。还是以把大象装进冰箱为例：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20461b6a3bbf7bdf7c7f778341474094.jpeg" alt=""></p><p>最顶层的函数是 f，f 里就只应该有 s1, s2, s3 三个函数。s2a, s2b 里的实现代码则不应该出现在 f 里。同理在 s2 函数里，只应该有 s2a, s2b 函数，而不应该有抽象层次更低(更具体)的 s2aα, s2aβ 的实现代码等。</p><p>绿色部分是最低抽象层次的具体实现，这部分是无法拆分，且难以控制代码行数的，因为有些情况下做一件事就是有很多细节实现步骤。</p><ol start="4"><li>参数尽量少</li></ol><blockquote><p>最理想是 0 个，其次是 1 个，2 个，最多 3 个参数，不要超过 3 个参数，除非你有非常特殊的理由。——《Clean Code》</p></blockquote><p>参数带了极大的语义干扰，而且也难于测试。一个典型的不好的设计，就是用 bool 作为公开函数的参数，因为 bool 变量天然地会使人想到这个函数不会只做一件事，它分情况处理，bool 入参的命名稍有歧义就会使人困惑。例如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">func GoToWork(raining bool) &#123;  </span><br><span class="line">    if raining &#123;  </span><br><span class="line">        &#x2F;&#x2F; 开车去  </span><br><span class="line">    &#125; else &#123;  </span><br><span class="line">        &#x2F;&#x2F; 走路去  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>更推荐的做法是，将 bool 参数的函数私有，另外公开两个语义清晰的函数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">func WalkToWork() &#123;  </span><br><span class="line">    goToWork(false)  </span><br><span class="line">&#125;  </span><br><span class="line">func DriveToWork() &#123;  </span><br><span class="line">    goToWork(true)  </span><br><span class="line">&#125;  </span><br><span class="line">&#x2F;&#x2F; 私有  </span><br><span class="line">func goToWork(raining bool) &#123;  </span><br><span class="line">    if raining &#123;  </span><br><span class="line">        &#x2F;&#x2F; 开车去  </span><br><span class="line">    &#125; else &#123;  </span><br><span class="line">        &#x2F;&#x2F; 走路去  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>任何时候，我们维护代码，最关心的都是对外可访问的函数，这些函数应该尽我们所能使其整洁。另一个例子，在 JUnit 里曾有这样的方法，不知给多少初学者带来困扰</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">assertEquals(expected, actual)</span><br></pre></td></tr></table></figure><p>对使用者来说，完全没有必要去记忆两个参数的相对位置。相较而言，assertJ 里的连贯式接口就要友好得多</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">assertThat(actual).isEqualTo(expected)</span><br></pre></td></tr></table></figure><p>golang 里能够返回多个返回值，但这绝不可以滥用。试看</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">func func1(&#x2F;* params *&#x2F;) (string, string, string, string, string) &#123;  </span><br><span class="line">    &#x2F;&#x2F; 函数职责不单一，功能太多  </span><br><span class="line">&#125;  </span><br><span class="line">func func2(&#x2F;* 此处多达6个参数 *&#x2F;) &#123;  </span><br><span class="line">    &#x2F;&#x2F; 函数职责不单一，功能太多  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样多入参、多返回值，给调用方造成很大困扰，调用方需要反复分辨每个参数、返回值的对应关系。不能因为眼前就只有自己调用自己写的函数而这样放纵，我们写的代码，终究是会由别人接手的。</p><ol start="5"><li>无副作用</li></ol><p>一般而言，函数应该是无副作用的，对于调用方来说，它就是一个黑盒：给定输入，产生输出。仅此而已。不要让调用方去思考我这次调用会不会产生输出以外的其他结果。例如应该尽量避免这种情况：一个函数，以指针作为参数，返回一个结果的同时，还修改了指针所指向的内容。一个函数的作用，要么是 get，要么是 post，即要么函数无修改的 get 一个结果，要么就是单纯修改而不返回修改以外的结果。jdk 里有一个典型的反例，各种集合的 add/set 总返回了一个 bool 值，就会出现这样的代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; numbers is a list  </span><br><span class="line">if (numbers.add(1)) &#123;  </span><br><span class="line">    &#x2F;&#x2F;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于新手这可能就是一个让人迷惑的地方，可见，无副作用也不是绝对的，强如 JDK 也有不得已的折衷处理。</p><ol start="6"><li>if 嵌套不应超过 2 层</li></ol><p>if 不要嵌套超过 2 层，这初听起来有些强人所难，仿佛要求每个职业篮球运动员都应该以乔丹的能力作为基准。可人的天性就是不喜欢思考的，喜欢简单。在此再一次强调统一抽象层次，if 嵌套太多，一定要思考，是不是函数做的事情太多，跨层次在搞事情。我们应该用一些高标准去检验自己的代码，想办法去满足，这个过程才会有所成长，否则除了收获经验以外，不会有进阶的成长(其实人生又何尝不是如此)。</p><p>消除多层 if 嵌套的一些手段</p><ul><li><p>提前返回，将嵌套 if 铺陈开来，使不满足条件的分支提前返回；</p></li><li><p>碰到第三个 if，直接将其抽取为函数(简单粗暴)；</p></li><li><p>lambda，在 Java 里利用 stream 的扁平化处理，使 filter、map 等语法元素都可以接收简单的函数，从而避免在 for 里加 if 判断。对于集合的遍历处理，都应该尽量先采用 stream 的做法，这种流水线的思想，在一个步骤里就剔除了不满足条件的对象，然后流转到下一个步骤。</p></li></ul><ol start="7"><li>语义和实现距离不为 0 时应该抽取函数</li></ol><p>好的代码读起来就应该像自然语言，而不是像程序，这就要求在高抽象层次时，函数应该表达意图，而只有在叶子结点——抽象层次最低的实现部分才表达实现，这个地方的代码更像是程序。所以，在代码中的某个位置，我们本应该表达意图，却写了细节实现代码，这就应该抽取出函数。以下面这段代码为例。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tom :&#x3D; &amp;Person&#123;&#125;  </span><br><span class="line">if tom.Age &gt;&#x3D; 18 &#123;  </span><br><span class="line">    &#x2F;&#x2F; do your bussiness  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一般认为这是表达 tom 是否成年，但实际的业务含义中却是判断 tom 是否可以申领 C1 驾照。即使是想表达是否成年，这样也要使大脑经过一层转换，由<code>Age &gt;= 18</code>推理一次，才能得出结论这是表达是否成年，这是典型的“代码 prase 语义”，不要小看这层 parse 对人脑的开销，特别是所见之处都是这样的代码会让我们的大脑长期忙于“线程切换”活动，造成的思维停顿让人非常沮丧；此外，如果一个日本人看到这段代码，一定不会想是表达是否成年这个语义，因为他们的法定成年年龄是 20 岁(2022 年 4 月 1 日起改为 18 岁)，这是代码不灵活的体现。推荐的做法是</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">if tom.isAdult() &#123;  </span><br><span class="line">    &#x2F;&#x2F; do your bussiness  </span><br><span class="line">&#125;  </span><br><span class="line">func (p *Person) isAdult() bool &#123;  </span><br><span class="line">    return p.Age &gt;&#x3D; 18  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样，在<code>isAdult</code>方法里还可以更改实现，也更灵活，很多时候，如果我们程序写得好，实现比较灵活，就能够从容的应对经常变化的需求；如果需求稍微变化一下，现有代码就顶不住了，就应该思量实现是否足够好。代码应该表达意图，特别是 if 条件分支里，不要让人再去推理，直接表达语义。就像人走路，相比于一马平川，我们不会更喜欢岔路；但凡岔路，就应该明确指明路线，而不是在路口打个机锋，才让你思考十年然后顿悟才选择出了某一条路。</p><ol start="8"><li>童子军军规</li></ol><p>走的时候，比来的时候干净一点。代码中如果我们能经常注意这一点，那我们每时每刻都在改善代码。世界是朝着熵增的方向发展的，譬如一个房间，即使我们完全不去干扰它，久而久之它也会变得更加混乱，代码也是这样，它终究会变得越来越混乱、难以修改、难以维护。如果我们不注意这一点，反而每次来都扔一点垃圾，久而久之就会成为“破窗”直至“破楼”。</p><ol start="9"><li>hardcode</li></ol><p>任何时候都不应该在代码中直接出现 hardcode，hardcode 难以表达语义，且难以管理。</p><h4 id="3-命名与注释"><a href="#3-命名与注释" class="headerlink" title="3. 命名与注释"></a>3. 命名与注释</h4><p>命名是一个哲学问题，我们所知的一切，都是命名，存在、宗教、知识、伦理…没有命名，我们所知的一切所谓知识都将崩塌。</p><blockquote><p>There are only two hard things in Computer Science: cache invalidation and naming things. ——Phil Karlson</p></blockquote><p>“计算机世界只有两个难题：缓存失效和命名。”(可读一读《CSAPP》关于存储层次结构的描述，对此会深有体会。)</p><p>坊间流传着一句话，给变量命名犹如给自己亲女儿命名一般，只因如此，就不会随意命名了。命名的一般原则无外乎完整、简洁、准确等。</p><ol><li>顾名思义、望文知义、无歧义</li></ol><p>清楚明白无歧义地表达含义，不要让别人猜你的意思。在 API 设计里，有一条原则即是“Don’t Let Me Think”，命名也应该如此，乃至日常工作沟通中也应当如此。</p><ol start="2"><li>名副其实</li></ol><p><code>cat := &amp;Dog{}</code>？</p><ol start="3"><li>表达语义，避免误导</li></ol><p><code>userList</code>实际实现是一个 <code>Set</code>，<code>users</code> 这个命名会更好，语义更清晰，<code>userList</code> 有一些语义干扰。命名不应该表达实现(如 List 实现，数据结构等)，而应该表达语义。</p><ol start="4"><li>使用读得出来的名字，谨慎使用缩写</li></ol><p>人看代码，实际是在默读代码，包括你现在看到这句话的时候，心里也是在默念出来的。如<code>xxCmd</code>这样的命名，一定会在脑海中多了一次 parse，对于一些更不常见的缩写，这种情况更严重。前面提过，这种脑内 parse 会使大脑忙于“线程切换”，思维停顿更是让人沮丧。</p><ol start="5"><li>团队统一业务术语</li></ol><p>DDD 的一个重要理念就是同一术语，在一个团队内部就应该统一术语，从运营产品到开发测试等，都应该对某一个业务专有词不产生任何歧义。我见过太多因为产品和开发对某一个词的理解不同而“大打出手”的事。</p><ol start="6"><li>注释</li></ol><p>好的代码是自注释的。</p><p>命名虽然重要，但也无需发展成为圣战。</p><h4 id="4-单元测试"><a href="#4-单元测试" class="headerlink" title="4. 单元测试"></a>4. 单元测试</h4><p>应该重视单元测试。单元测试，<strong>保证软件质量和代码质量</strong>。单元测试是我们所写函数的第一个调用者，如果发现单元测试很难写，那不用说，函数实现绝对是有问题的，或者抽象层次划分不清，或者依赖复杂等。如果连我们自己调自己的方法都用得这么不爽，那可想而知其他调用者，特别是网络接口。这是为什么单元测试可以保证代码质量，它可以检验我们的代码是否写得足够好。</p><p><strong>单元测试对于修改代码或重构的重要性无可替代</strong>，对于拥有一组完善单测的函数，我们可以随意更改，只要让修改后的函数通过单测，就几乎是安全修改的，单元测试铺了一张安全网，让我们像走钢丝一样地写代码不至于失足跌入深渊万劫不复。</p><p>关于单元测试有很多实践，最著名的可能莫过于 TDD，我们虽不至于按 TDD 的实践来开发，但我们应该善用单元测试，来检验我们的函数实现是否合理，实现得好的函数，单测一定是好写的，逆否亦然。</p><p>一些 tips：</p><ul><li><p>不能依赖真实依赖，这是大忌。如依赖真实数据库且数据库出错，并不能检验单测所测函数逻辑失败，而是外部造成的，应该 mock，且对一般对象也应该尽量使用 mock 对象；否则即为集成测试；</p></li><li><p>路径应该尽可能全；</p></li><li><p>不能有条件分支，任何条件分支都应该新开单测；</p></li><li><p>单测也应该像业务代码一样，干净整洁；</p></li><li><p>realBug 测试是必要的，发生过一次的事情很有可能会反复发生，我们选择题第一次选错了，第二次还是很可能选择上次的那个错误答案；</p></li><li><p>…</p></li></ul><h3 id="其他话题"><a href="#其他话题" class="headerlink" title="其他话题"></a>其他话题</h3><p>以下这些话题，单独拎出来都是一个很大的主题，这里只是抛砖引玉，简单谈谈一些和整洁代码相关的感悟和实践，实是整洁代码需要各个方面的努力，而非仅代码一途用功。</p><h4 id="心智负担与复杂"><a href="#心智负担与复杂" class="headerlink" title="心智负担与复杂"></a>心智负担与复杂</h4><blockquote><p>Complexity is caused by two things: dependencies and obscurity.</p></blockquote><p>软件开发的复杂性由两样东西带来：依赖和晦涩。这两者都会加重心智负担。消除心智负担一定程度上意味着增加可读性和可维护性。</p><p>其实我们所做的一切，都是在驯服复杂度。人脑终究是有限的，我们眼所能见、脑所能别的资源几乎都是有限的。驯服复杂度，代码写好了，升职加薪，业余时间没有 bug 找上门，提高生活质量，我们所做的一切不就是为了这个吗？</p><p><strong>复杂是我们软件生涯的一生之敌</strong>。</p><h4 id="分层分包"><a href="#分层分包" class="headerlink" title="分层分包"></a>分层分包</h4><p>分层是除“模块化”之外最古老的架构模式，冯诺依曼计算机模型是模块化的架构，但同时计算机世界也是层层叠加的。<strong>分层分包的本质就是隔离</strong>，人处理难题的能力是有限的，无法同时处理很多复杂的事情，所以不把所有东西都放在同一层次，譬如行政体系也是分层的。隔离使得各个层次职责更清晰，更容易管理。</p><p><strong>分层的原则是只能上层调用下层，而不能反过来，反之容易导致循环依赖。分包的原则是，同一个包中的对象天然是亲和的，同时对包外的对象是不亲和(隔离)的</strong>。</p><p>从分层的理念理解，则 controller/api 层 的 request 不应该一直传递到 service 层甚至是 dao 层，然而这种现象却是非常常见。业务层不应该对界面层有所了解，而是相反，界面层调用业务层来完成一次用户用例。凡是进入业务层，就不应该有界面层的对象，而应该在界面层转换成业务对象，进而使业务层只处理它所能知的业务对象。这种跨层次的信息传递，无异于乡长直接向省长汇报工作。</p><p>传统 MVC 的分层对于简单业务而言，是简单实用的。但是其对于复杂业务系统的架构能力十分有限，一个 service 包里有上百个 xxxService 类，业务表达能力有限，如果所有对外服务都可以叫做 service，那为何要区分餐厅、医院、商场，统一叫服务不就好了？而且很多时候，往往就是一些无法准确划分职责的类干脆就合并到 Service 类里，这让 Service 类成了一个大杂烩直至成为 God Class，最终退化成过程式代码，只是机械的代码堆积，没有层次分明、职责分明的对象，没有设计感。</p><p>对于业务复杂的系统，DDD 微服务经典四层分层是一个更好的实践，重视业务、重视 OO，整个系统设计感十足，对象林立，可以做一些了解。但是对于业务简单的系统，则不应该为了炫技而使用技术。因地制宜，学会取舍。</p><p>此外，关于 dao，业务复杂情况下应该避免使用。dao 的表达能力同样很弱，dao 里的方法很难表达意图，语义表达能力很弱，findByXXX 实际是没有业务语义的，例如 findByAge 接受参数 18，还是上面的例子，并不是选择成年的业务意义。此外 dao 难以管理。例如一个 dao 里有上百个 findByXXX 方法，如果业务需要新增方法，一般最省事的做法就是直接又加一个 findByXXX 方法，这样下去 dao 会越来越膨胀并趋于崩坏。业务复杂情况应该使用 repository，repository 通过组合规格(specification)来表达查询语义，repository 是仓储的概念，类似一个 ADT，只有有限几个经过仔细设计的方法，类比一个 map 就理解了。关于更多为何不使用 dao 而应该使用 repository 的知识，可参考 <a href="https://thinkinginobjects.com/2012/08/26/dont-use-dao-use-repository/" target="_blank" rel="noopener">https://thinkinginobjects.com/2012/08/26/dont-use-dao-use-repository/</a></p><h4 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h4><p>遵循良好的设计原则，能使代码更整洁，当然意义不仅于此。有关设计原则的资料很多，我们也应该对此有所了解。常见设计原则如：</p><ul><li><p>SOLID</p></li><li><p>ADP</p></li><li><p>REP</p></li><li><p>CCP</p></li><li><p>CRP</p></li><li><p>SDP</p></li><li><p>SAP</p></li><li><p>DRY</p></li><li><p>KISS</p></li><li><p>YAGNI</p></li><li><p>SLAP</p></li><li><p>POLA</p></li><li><p>LoD</p></li></ul><h4 id="代码的非功能特性"><a href="#代码的非功能特性" class="headerlink" title="代码的非功能特性"></a>代码的非功能特性</h4><p>只完成功能的代码，是最基础的代码。好的代码还应该尽量完成代码的非功能特性，有兴趣可以了解下，不外乎：</p><ul><li><p>可操作性</p></li><li><p>健壮性</p></li><li><p>可测试性</p></li><li><p>可维护性</p></li><li><p>易用性</p></li><li><p>可重用性</p></li></ul><p>其实还有些主题是无法避而不谈的，如错误处理，但限于篇幅和能力，只能推荐读两遍《Clean Code》。</p><p>最后，人生不过是“看山是山，看山不是山，看山仍是山”，代码也是如此，不要着相。</p><p>本文转自 <a href="https://mp.weixin.qq.com/s/s_2dfOnMqND1qKjTfnmg5A" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/s_2dfOnMqND1qKjTfnmg5A</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Linux I/O 那些事儿</title>
      <link href="/posts/66a2f2c2/"/>
      <url>/posts/66a2f2c2/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><blockquote><p>介绍 Linux IO 的一些基本原理。</p></blockquote><p>作者：arraywang，腾讯 CSIG</p><p>我们先看一张图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9e429029ef7bc9947081facca8251abd.jpeg" alt=""></p><p>这张图大体上描述了 Linux 系统上，应用程序对磁盘上的文件进行读写时，从上到下经历了哪些事情。</p><p>这篇文章就以这张图为基础，介绍 Linux 在 I/O 上做了哪些事情。</p><h3 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h3><h4 id="什么是文件系统"><a href="#什么是文件系统" class="headerlink" title="什么是文件系统"></a>什么是文件系统</h4><p>文件系统，本身是对存储设备上的文件，进行组织管理的机制。组织方式不同，就会形成不同的文件系统。比如常见的 Ext4、XFS、ZFS 以及网络文件系统 NFS 等等。</p><p>但是不同类型的文件系统标准和接口可能各有差异，我们在做应用开发的时候却很少关心系统调用以下的具体实现，大部分时候都是直接系统调用 <code>open</code>, <code>read</code>, <code>write</code>, <code>close</code> 来实现应用程序的功能，不会再去关注我们具体用了什么文件系统（UFS、XFS、Ext4、ZFS），磁盘是什么接口（IDE、SCSI，SAS，SATA 等），磁盘是什么存储介质（HDD、SSD）</p><p>应用开发者之所以这么爽，各种复杂细节都不用管直接调接口，是因为内核为我们做了大量的有技术含量的脏活累活。开始的那张图看到 Linux 在各种不同的文件系统之上，虚拟了一个 VFS，目的就是统一各种不同文件系统的标准和接口，让开发者可以使用相同的系统调用来使用不同的文件系统。</p><h4 id="文件系统如何工作（VFS）"><a href="#文件系统如何工作（VFS）" class="headerlink" title="文件系统如何工作（VFS）"></a>文件系统如何工作（VFS）</h4><h5 id="Linux-系统下的文件"><a href="#Linux-系统下的文件" class="headerlink" title="Linux 系统下的文件"></a>Linux 系统下的文件</h5><p>在 Linux 中一切皆文件。不仅普通的文件和目录，就连块设备、套接字、管道等，也都要通过统一的文件系统来管理。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">用 ls -l 命令看最前面的字符可以看到这个文件是什么类型  </span><br><span class="line">  </span><br><span class="line">brw-r--r-- 1 root    root    1, 2 4月  25 11:03 bnod &#x2F;&#x2F; 块设备文件  </span><br><span class="line">crw-r--r-- 1 root    root    1, 2 4月  25 11:04 cnod &#x2F;&#x2F; 符号设备文件  </span><br><span class="line">drwxr-xr-x 2 wrn3552 wrn3552    6 4月  25 11:01 dir &#x2F;&#x2F; 目录  </span><br><span class="line">-rw-r--r-- 1 wrn3552 wrn3552    0 4月  25 11:01 file &#x2F;&#x2F; 普通文件  </span><br><span class="line">prw-r--r-- 1 root    root       0 4月  25 11:04 pipeline &#x2F;&#x2F; 有名管道  </span><br><span class="line">srwxr-xr-x 1 root    root       0 4月  25 11:06 socket.sock &#x2F;&#x2F; socket文件  </span><br><span class="line">lrwxrwxrwx 1 root    root       4 4月  25 11:04 softlink -&gt; file &#x2F;&#x2F; 软连接  </span><br><span class="line">-rw-r--r-- 2 wrn3552 wrn3552 0 4月  25 11:07 hardlink &#x2F;&#x2F; 硬链接（本质也是普通文件）</span><br></pre></td></tr></table></figure><p>Linux 文件系统设计了两个数据结构来管理这些不同种类的文件：</p><ul><li><p>inode(index node)：索引节点</p></li><li><p>dentry(directory entry)：目录项</p></li></ul><h5 id="inode-和-dentry"><a href="#inode-和-dentry" class="headerlink" title="inode 和 dentry"></a>inode 和 dentry</h5><p><strong>inode</strong></p><p>inode 是用来记录文件的 metadata，所谓 metadata 在 Wikipedia 上的描述是 data of data，其实指的就是文件的各种属性，比如 inode 编号、文件大小、访问权限、修改日期、数据的位置等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">wrn3552@novadev:~&#x2F;playground$ stat file  </span><br><span class="line">  文件：file  </span><br><span class="line">  大小：0               块：0          IO 块：4096   普通空文件  </span><br><span class="line">设备：fe21h&#x2F;65057d      Inode：32828       硬链接：2  </span><br><span class="line">权限：(0644&#x2F;-rw-r--r--)  Uid：( 3041&#x2F; wrn3552)   Gid：( 3041&#x2F; wrn3552)  </span><br><span class="line">最近访问：2021-04-25 11:07:59.603745534 +0800  </span><br><span class="line">最近更改：2021-04-25 11:07:59.603745534 +0800  </span><br><span class="line">最近改动：2021-04-25 11:08:04.739848692 +0800  </span><br><span class="line">创建时间：-</span><br></pre></td></tr></table></figure><p>inode 和文件一一对应，它跟文件内容一样，都会被持久化存储到磁盘中。所以，inode 同样占用磁盘空间，只不过相对于文件来说它大小固定且大小不算大。</p><p><strong>dentry</strong></p><p>dentry 用来记录文件的名字、inode 指针以及与其他 dentry 的关联关系。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wrn3552@novadev:~&#x2F;playground$ tree  </span><br><span class="line">.  </span><br><span class="line">├── dir  </span><br><span class="line">│   └── file_in_dir  </span><br><span class="line">├── file  </span><br><span class="line">└── hardlink</span><br></pre></td></tr></table></figure><ul><li><p>文件的名字：像 dir、file、hardlink、file_in_dir 这些名字是记录在 dentry 里的</p></li><li><p>inode 指针：就是指向这个文件的 inode</p></li><li><p>与其他 dentry 的关联关系：其实就是每个文件的层级关系，哪个文件在哪个文件下面，构成了文件系统的目录结构</p></li></ul><p>不同于 inode，dentry 是由内核维护的一个内存数据结构，所以通常也被叫做 dentry cache。</p><h5 id="文件是如何存储在磁盘上的"><a href="#文件是如何存储在磁盘上的" class="headerlink" title="文件是如何存储在磁盘上的"></a>文件是如何存储在磁盘上的</h5><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/53fc1b4d063a7a003eef13bd205d05bd.jpeg" alt=""></p><p>这里有张图解释了文件是如何存储在磁盘上的，首先，磁盘再进行文件系统格式化的时候，会分出来 3 个区：</p><ol><li><p>Superblock</p></li><li><p>inode blocks</p></li><li><p>data blocks</p></li></ol><p>（其实还有 boot block，可能会包含一些 bootstrap 代码，在机器启动的时候被读到，这里忽略）其中 inode blocks 放的都是每个文件的 inode，data blocks 里放的是每个文件的内容数据。这里关注一下 superblock，它包含了整个文件系统的 metadata，具体有：</p><ol><li><p>inode/data block 总量、使用量、剩余量</p></li><li><p>文件系统的格式，属主等等各种属性</p></li></ol><p>superblock 对于文件系统来说非常重要，如果 superblock 损坏了，文件系统就挂载不了了，相应的文件也没办法读写。既然 superblock 这么重要，那肯定不能只有一份，坏了就没了，它在系统中是有很多副本的，在 superblock 损坏的时候，可以使用 <code>fsck</code>（File System Check and repair）来恢复。回到上面的那张图，可以很清晰地看到文件的各种属性和文件的数据是如何存储在磁盘上的：</p><ol><li><p>dentry 里包含了文件的名字、目录结构、inode 指针</p></li><li><p>inode 指针指向文件特定的 inode（存在 inode blocks 里）</p></li><li><p>每个 inode 又指向 data blocks 里具体的 logical block，这里的 logical block 存的就是文件具体的数据</p></li></ol><p>这里解释一下什么是 logical block：</p><ol><li><p>对于不同存储介质的磁盘，都有最小的读写单元</p><ul><li><code>/sys/block/sda/queue/physical_block_size</code></li></ul></li></ol><ol start="2"><li><p>HDD 叫做 sector（扇区），SSD 叫做 page（页面）</p></li><li><p>对于 hdd 来说，每个 sector 大小 512Bytes</p></li><li><p>对于 SSD 来说每个 page 大小不等（和 cell 类型有关），经典的大小是 4KB</p></li><li><p>但是 Linux 觉得按照存储介质的最小读写单元来进行读写可能会有效率问题，所以支持在文件系统格式化的时候指定 block size 的大小，一般是把几个 physical_block 拼起来就成了一个 logical block</p><ul><li><code>/sys/block/sda/queue/logical_block_size</code></li></ul></li></ol><ol start="6"><li>理论上应该是 logical_block_size &gt;= physical_block_size，但是有时候我们会看到 physical_block_size = 4K，logical_block_size = 512B 情况，其实这是因为磁盘上做了一层 512B 的仿真（emulation）（详情可参考 <a href="https://g.126.fm/038DZzG" target="_blank" rel="noopener">512e 和 4Kn</a>）</li></ol><h3 id="ZFS"><a href="#ZFS" class="headerlink" title="ZFS"></a>ZFS</h3><p>这里简单介绍一个广泛应用的文件系统 ZFS，一些数据库应用也会用到 ZFS，先看一张 zfs 的层级结构图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/8b9a8e85ee62f0e919d73409853ac43a.jpeg" alt=""></p><p>这是一张从底向上的图：</p><ol><li><p>将若干物理设备 disk 组成一个虚拟设备 vdev（同时，disk 也是一种 vdev）</p></li><li><p>再将若干个虚拟设备 vdev 加到一个 zpool 里</p></li><li><p>在 zpool 的基础上创建 zfs 并挂载（zvol 可以先不看，我们没有用到）</p></li></ol><h4 id="ZFS-的一些操作"><a href="#ZFS-的一些操作" class="headerlink" title="ZFS 的一些操作"></a>ZFS 的一些操作</h4><p><strong>创建 zpool</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">root@:~ # zpool create tank raidz &#x2F;dev&#x2F;ada1 &#x2F;dev&#x2F;ada2 &#x2F;dev&#x2F;ada3 raidz &#x2F;dev&#x2F;ada4 &#x2F;dev&#x2F;ada5 &#x2F;dev&#x2F;ada6  </span><br><span class="line">root@:~ # zpool list tank  </span><br><span class="line">NAME    SIZE  ALLOC   FREE  CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP  HEALTH  ALTROOT  </span><br><span class="line">tank     11G   824K  11.0G        -         -     0%     0%  1.00x  ONLINE  -  </span><br><span class="line">root@:~ # zpool status tank  </span><br><span class="line">  pool: tank  </span><br><span class="line"> state: ONLINE  </span><br><span class="line">  scan: none requested  </span><br><span class="line">config:  </span><br><span class="line">  </span><br><span class="line">        NAME        STATE     READ WRITE CKSUM  </span><br><span class="line">        tank        ONLINE       0     0     0  </span><br><span class="line">          raidz1-0  ONLINE       0     0     0  </span><br><span class="line">            ada1    ONLINE       0     0     0  </span><br><span class="line">            ada2    ONLINE       0     0     0  </span><br><span class="line">            ada3    ONLINE       0     0     0  </span><br><span class="line">          raidz1-1  ONLINE       0     0     0  </span><br><span class="line">            ada4    ONLINE       0     0     0  </span><br><span class="line">            ada5    ONLINE       0     0     0  </span><br><span class="line">            ada6    ONLINE       0     0     0</span><br></pre></td></tr></table></figure><ul><li><p>创建了一个名为 tank 的 zpool</p></li><li><p>这里的 raidz 同 RAID5</p></li></ul><p>除了 raidz 还支持其他方案：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/eed8390e91ebb7f2a74354fcb95644df.jpeg" alt=""></p><p><strong>创建 zfs</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@:~ # zfs create -o mountpoint&#x3D;&#x2F;mnt&#x2F;srev tank&#x2F;srev  </span><br><span class="line">root@:~ # df -h tank&#x2F;srev  </span><br><span class="line">Filesystem    Size    Used   Avail Capacity  Mounted on  </span><br><span class="line">tank&#x2F;srev     7.1G    117K    7.1G     0%    &#x2F;mnt&#x2F;srev</span><br></pre></td></tr></table></figure><ul><li><p>创建了一个 zfs，挂载到了 /mnt/srev</p></li><li><p>这里没有指定 zfs 的 quota，创建的 zfs 大小即 zpool 大小</p></li></ul><p><strong>对 zfs 设置 quota</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@:~ # zfs set quota&#x3D;1G tank&#x2F;srev  </span><br><span class="line">root@:~ # df -h tank&#x2F;srev  </span><br><span class="line">Filesystem    Size    Used   Avail Capacity  Mounted on  </span><br><span class="line">tank&#x2F;srev     1.0G    118K    1.0G     0%    &#x2F;mnt&#x2F;srev</span><br></pre></td></tr></table></figure><h4 id="ZFS-特性"><a href="#ZFS-特性" class="headerlink" title="ZFS 特性"></a>ZFS 特性</h4><h5 id="Pool-存储"><a href="#Pool-存储" class="headerlink" title="Pool 存储"></a>Pool 存储</h5><p>上面的层级图和操作步骤可以看到 zfs 是基于 zpool 创建的，zpool 可以动态扩容意味着存储空间也可以动态扩容，而且可以创建多个文件系统，文件系统共享完整的 zpool 空间无需预分配。</p><h5 id="事务文件系统"><a href="#事务文件系统" class="headerlink" title="事务文件系统"></a>事务文件系统</h5><p>zfs 的写操作是事务的，意味着要么就没写，要么就写成功了，不会像其他文件系统那样，应用打开了文件，写入还没保存的时候断电，导致文件为空。zfs 保证写操作事务采用的是 copy on write 的方式：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/286982242c985eface52c994c0bc65f0.jpeg" alt=""></p><ul><li><p>当 block B 有修改变成 B1 的时候，普通的文件系统会直接在 block B 原地进行修改变成 B1</p></li><li><p>zfs 则会再另一个地方写 B1，然后再在后面安全的时候对原来的 B 进行回收</p></li><li><p>这样结果就不会出现 B 被打开而写失败的情况，大不了就是 B1 没写成功</p></li></ul><p>这个特性让 zfs 在断电后不需要执行 fsck 来检查磁盘中是否存在写操作失败需要恢复的情况，大大提升了应用的可用性。</p><h5 id="ARC-缓存"><a href="#ARC-缓存" class="headerlink" title="ARC 缓存"></a>ARC 缓存</h5><p>ZFS 中的 ARC(Adjustable Replacement Cache) 读缓存淘汰算法，是基于 IBM 的 ARP(Adaptive Replacement Cache) 演化而来。在一些文件系统中实现的标准 LRU 算法其实是有缺陷的：比如复制大文件之类的线性大量 I/O 操作，导致缓存失效率猛增（大量文件只读一次，放到内存不会被再读，坐等淘汰）。</p><p>另外，缓存可以根据时间来进行优化（LRU，最近最多使用），也可以根据频率进行优化（LFU，最近最常使用），这两种方法各有优劣，但是没办法适应所有场景。</p><p>ARC 的设计就是尝试在 LRU 和 LFU 之间找到一个平衡，根据当前的 I/O workload 来调整用 LRU 多一点还是 LFU 多一点。</p><p>ARC 定义了 4 个链表：</p><ol><li><p>LRU list：最近最多使用的页面，存具体数据</p></li><li><p>LFU list：最近最常使用的页面，存具体数据</p></li><li><p>Ghost list for LRU：最近从 LRU 表淘汰下来的页面信息，不存具体数据，只存页面信息</p></li><li><p>Ghost list for LFU：最近从 LFU 表淘汰下来的页面信息，不存具体数据，只存页面信息</p></li></ol><p>ARC 工作流程大致如下：</p><ol><li><p>LRU list 和 LFU list 填充和淘汰过程和标准算法一样</p></li><li><p>当一个页面从 LRU list 淘汰下来时，这个页面的信息会放到 LRU ghost 表中</p></li><li><p>如果这个页面一直没被再次引用到，那么这个页面的信息最终也会在 LRU ghost 表中被淘汰掉</p></li><li><p>如果这个页面在 LRU ghost 表中未被淘汰的时候，被再一次访问了，这时候会引起一次幽灵（phantom）命中</p></li><li><p>phantom 命中的时候，事实上还是要把数据从磁盘第一次放缓存</p></li><li><p>但是这时候系统知道刚刚被 LRU 表淘汰的页面又被访问到了，说明 LRU list 太小了，这时它会把 LRU list 长度加一，LFU 长度减一</p></li><li><p>对于 LFU 的过程也与上述过程类似</p></li></ol><h4 id="ZFS-参考资料"><a href="#ZFS-参考资料" class="headerlink" title="ZFS 参考资料"></a>ZFS 参考资料</h4><p>关于 ZFS 详细介绍可以参考：</p><ul><li>这篇<a href="https://farseerfc.me/zhs/zfs-layered-architecture-design.html" target="_blank" rel="noopener">文章</a></li></ul><h3 id="磁盘类型"><a href="#磁盘类型" class="headerlink" title="磁盘类型"></a>磁盘类型</h3><p>磁盘根据不同的分类方式，有各种不一样的类型。</p><h4 id="磁盘的存储介质"><a href="#磁盘的存储介质" class="headerlink" title="磁盘的存储介质"></a>磁盘的存储介质</h4><p>根据磁盘的存储介质可以分两类（大家都很熟悉）：</p><ul><li><p>HDD（机械硬盘）</p></li><li><p>SSD（固态硬盘）</p></li></ul><h4 id="磁盘的接口"><a href="#磁盘的接口" class="headerlink" title="磁盘的接口"></a>磁盘的接口</h4><p>根据磁盘接口分类：</p><ul><li><p>IDE (Integrated Drive Electronics)</p></li><li><p>SCSI (Small Computer System Interface)</p></li><li><p>SAS (Serial Attached SCSI)</p></li><li><p>SATA (Serial ATA)</p></li><li><p>…</p></li></ul><p>不同的接口，往往分配不同的设备名称。比如， IDE 设备会分配一个 hd 前缀的设备名，SCSI 和 SATA 设备会分配一个 sd 前缀的设备名。如果是多块同类型的磁盘，就会按照 a、b、c 等的字母顺序来编号。</p><h4 id="Linux-对磁盘的管理"><a href="#Linux-对磁盘的管理" class="headerlink" title="Linux 对磁盘的管理"></a>Linux 对磁盘的管理</h4><p>其实在 Linux 中，磁盘实际上是作为一个块设备来管理的，也就是以块为单位读写数据，并且支持随机读写。每个块设备都会被赋予两个设备号，分别是主、次设备号。主设备号用在驱动程序中，用来区分设备类型；而次设备号则是用来给多个同类设备编号。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">g18-&quot;299&quot; on ~# ls -l &#x2F;dev&#x2F;sda*  </span><br><span class="line">brw-rw---- 1 root disk 8,  0 Apr 25 15:53 &#x2F;dev&#x2F;sda  </span><br><span class="line">brw-rw---- 1 root disk 8,  1 Apr 25 15:53 &#x2F;dev&#x2F;sda1  </span><br><span class="line">brw-rw---- 1 root disk 8, 10 Apr 25 15:53 &#x2F;dev&#x2F;sda10  </span><br><span class="line">brw-rw---- 1 root disk 8,  2 Apr 25 15:53 &#x2F;dev&#x2F;sda2  </span><br><span class="line">brw-rw---- 1 root disk 8,  5 Apr 25 15:53 &#x2F;dev&#x2F;sda5  </span><br><span class="line">brw-rw---- 1 root disk 8,  6 Apr 25 15:53 &#x2F;dev&#x2F;sda6  </span><br><span class="line">brw-rw---- 1 root disk 8,  7 Apr 25 15:53 &#x2F;dev&#x2F;sda7  </span><br><span class="line">brw-rw---- 1 root disk 8,  8 Apr 25 15:53 &#x2F;dev&#x2F;sda8  </span><br><span class="line">brw-rw---- 1 root disk 8,  9 Apr 25 15:53 &#x2F;dev&#x2F;sda9</span><br></pre></td></tr></table></figure><ul><li><p>这些 sda 磁盘主设备号都是 8，表示它是一个 sd 类型的块设备</p></li><li><p>次设备号 0-10 表示这些不同 sd 块设备的编号</p></li></ul><h3 id="Generic-Block-Layer"><a href="#Generic-Block-Layer" class="headerlink" title="Generic Block Layer"></a>Generic Block Layer</h3><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/6c77fbca6e50059a358250fe26315ff4.jpeg" alt=""></p><p>和 VFS 类似，为了对上层屏蔽不同块设备的差异，内核在文件系统和块设备之前抽象了一个 Generic Block Layer（通用块层），有时候一些人也会把下面的 I/O 调度层并到通用块层里表述。</p><p>这两层主要做两件事：</p><ol><li><p>跟 VFS 的功能类似。向上，为文件系统和应用程序，提供访问块设备的标准接口；向下，把各种异构的磁盘设备抽象为统一的块设备，并提供统一框架来管理这些设备的驱动程序</p></li><li><p>对 I/O 请求进行调度，通过重新排序、合并等方式，提高磁盘读写效率</p></li></ol><p>下图是一个完整的 I/O 栈全景图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/eea2869ae17a8825a5684126e1976dfa.jpeg" alt=""></p><p>可以看到中间的 Block Layer 其实就是 Generic Block Layer，在图中可以看到 Block Layer 的 I/O 调度分为两类，分别表示单队列和多队列的调度：</p><ul><li><p>I/O scheduler</p></li><li><p>blkmq</p></li></ul><h4 id="I-O-调度"><a href="#I-O-调度" class="headerlink" title="I/O 调度"></a>I/O 调度</h4><p>老版本的内核里只支持单队列的 I/O scheduler，在 3.16 版本的内核开始支持多队列 blkmq，这里介绍几种经典的 I/O 调度策略。</p><p>单队列 I/O scheduler：</p><ul><li><p>NOOP：事实上是个 FIFO 的队列，只做基本的请求合并</p></li><li><p>CFQ：Completely Fair Queueing，完全公平调度器，给每个进程维护一个 I/O 调度队列，按照时间片来均匀分布每个进程 I/O 请求，</p></li><li><p>DeadLine：为读和写请求创建不同的 I/O 队列，确保达到 deadline 的请求被优先处理</p></li></ul><p>多队列 blkmq：</p><ul><li><p>bfq：Budget Fair Queueing，也是公平调度器，不过不是按时间片来分配，而是按请求的扇区数量（带宽）</p></li><li><p>kyber：维护两个队列（同步/读、异步/写），同时严格限制发到这两个队列的请求数以保证相应时间</p></li><li><p>mq-deadline：多队列版本的 deadline</p></li></ul><ul><li><p>具体各种 I/O 调度策略可以参考 <a href="https://wiki.ubuntu.com/Kernel/Reference/IOSchedulers" target="_blank" rel="noopener">IOSchedulers</a></p></li><li><p>关于 blkmq 可以参考 <a href="https://www.thomas-krenn.com/en/wiki/Linux_Multi-Queue_Block_IO_Queueing_Mechanism_(blk-mq)_Details" target="_blank" rel="noopener">Linux Multi-Queue Block IO Queueing Mechanism (blk-mq) Details</a></p></li><li><p>多队列调度可以参考 <a href="https://lwn.net/Articles/738449/" target="_blank" rel="noopener">Block layer introduction part 2: the request layer</a></p></li></ul><h3 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h3><p>一般来说 I/O 性能指标有这几个：</p><ul><li><p>使用率：ioutil，指的是磁盘处理 I/O 的时间百分比，ioutil 只看有没有 I/O 请求，不看 I/O 请求的大小。ioutil 越高表示一直都有 I/O 请求，不代表磁盘无法响应新的 I/O 请求</p></li><li><p>IOPS：每秒的 I/O 请求数</p></li><li><p>吞吐量/带宽：每秒的 I/O 请求大小，通常是 MB/s 或者 GB/s 为单位</p></li><li><p>响应时间：I/O 请求发出到收到响应的时间</p></li><li><p>饱和度：指的是磁盘处理 I/O 的繁忙程度。这个指标比较玄学，没有直接的数据可以表示，一般是根据平均队列请求长度或者响应时间跟基准测试的结果进行对比来估算</p></li></ul><p>（在做基准测试时，还会分顺序/随机、读/写进行排列组合分别去测 IOPS 和带宽）</p><p>上面的指标除了饱和度外，其他都可以在监控系统中看到。Linux 也提供了一些命令来输出不同维度的 I/O 状态：</p><ul><li><p><code>iostat -d -x</code>：看各个设备的 I/O 状态，数据来源 <code>/proc/diskstats</code></p></li><li><p><code>pidstat -d</code>：看近处的 I/O</p></li><li><p><code>iotop</code>：类似 top，按 I/O 大小对进程排序</p></li></ul><p>本文转自 <a href="https://mp.weixin.qq.com/s/diKfeu1-Lr4ZA5Ky_66TZg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/diKfeu1-Lr4ZA5Ky_66TZg</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux Shell文本处理</title>
      <link href="/posts/a84c63b7/"/>
      <url>/posts/a84c63b7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>本文将介绍Linux下使用Shell处理文本时最常用的工具：<br>find、grep、xargs、sort、uniq、tr、cut、paste、wc、sed、awk；<br>提供的例子和参数都是最常用和最为实用的；<br>我对shell脚本使用的原则是命令单行书写，尽量不要超过2行；<br>如果有更为复杂的任务需求，还是考虑python吧；</p><h2 id="find-文件查找"><a href="#find-文件查找" class="headerlink" title="find 文件查找"></a>find 文件查找</h2><ul><li><p>查找txt和pdf文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . \( -name &quot;*.txt&quot; -o -name &quot;*.pdf&quot; \) -print</span><br></pre></td></tr></table></figure></li><li><p>正则方式查找.txt和pdf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -regex  &quot;.*\(\.txt|\.pdf\)$&quot;</span><br></pre></td></tr></table></figure><p>-iregex： 忽略大小写的正则</p></li><li><p>否定参数<br>查找所有非txt文本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . ! -name &quot;*.txt&quot; -print</span><br></pre></td></tr></table></figure></li><li><p>指定搜索深度<br>打印出当前目录的文件（深度为1）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -maxdepth 1 -type f</span><br></pre></td></tr></table></figure></li></ul><h3 id="定制搜索"><a href="#定制搜索" class="headerlink" title="定制搜索"></a>定制搜索</h3><ul><li><p>按类型搜索：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -type d -print  &#x2F;&#x2F;只列出所有目录</span><br></pre></td></tr></table></figure><p>-type f 文件 / l 符号链接</p></li><li><p>按时间搜索：<br>-atime 访问时间 (单位是天，分钟单位则是-amin，以下类似）<br>-mtime 修改时间 （内容被修改）<br>-ctime 变化时间 （元数据或权限变化）<br>最近7天被访问过的所有文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -atime 7 -type f -print</span><br></pre></td></tr></table></figure></li><li><p>按大小搜索：<br>w字 k M G<br>寻找大于2k的文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -type f -size +2k</span><br></pre></td></tr></table></figure><p>按权限查找：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -type f -perm 644 -print &#x2F;&#x2F;找具有可执行权限的所有文件</span><br></pre></td></tr></table></figure><p>按用户查找：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -type f -user weber -print&#x2F;&#x2F; 找用户weber所拥有的文件</span><br></pre></td></tr></table></figure></li></ul><h3 id="找到后的后续动作"><a href="#找到后的后续动作" class="headerlink" title="找到后的后续动作"></a>找到后的后续动作</h3><ul><li><p>删除：<br>删除当前目录下所有的swp文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -type f -name &quot;*.swp&quot; -delete</span><br></pre></td></tr></table></figure></li><li><p>执行动作（强大的exec）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -type f -user root -exec chown weber &#123;&#125; \; &#x2F;&#x2F;将当前目录下的所有权变更为weber</span><br></pre></td></tr></table></figure><p>注：{}是一个特殊的字符串，对于每一个匹配的文件，{}会被替换成相应的文件名；<br>eg：将找到的文件全都copy到另一个目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -type f -mtime +10 -name &quot;*.txt&quot; -exec cp &#123;&#125; OLD \;</span><br></pre></td></tr></table></figure></li><li><p>结合多个命令<br>tips: 如果需要后续执行多个命令，可以将多个命令写成一个脚本。然后 -exec 调用时执行脚本即可；</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-exec .&#x2F;commands.sh &#123;&#125; \;</span><br></pre></td></tr></table></figure></li></ul><h3 id="print的定界符"><a href="#print的定界符" class="headerlink" title="-print的定界符"></a>-print的定界符</h3><p>默认使用’\n’作为文件的定界符；<br>-print0 使用’\0’作为文件的定界符，这样就可以搜索包含空格的文件；</p><h2 id="grep-文本搜索"><a href="#grep-文本搜索" class="headerlink" title="grep 文本搜索"></a>grep 文本搜索</h2><p>grep match_patten file // 默认访问匹配行</p><ul><li><p>常用参数<br>-o 只输出匹配的文本行 <strong>VS</strong> -v 只输出没有匹配的文本行<br>-c 统计文件中包含文本的次数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -c &quot;text&quot; filename</span><br></pre></td></tr></table></figure><p>-n 打印匹配的行号<br>-i 搜索时忽略大小写<br>-l 只打印文件名</p></li><li><p>在多级目录中对文本递归搜索(程序员搜代码的最爱）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep &quot;class&quot; . -R -n</span><br></pre></td></tr></table></figure></li><li><p>匹配多个模式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -e &quot;class&quot; -e &quot;vitural&quot; file</span><br></pre></td></tr></table></figure></li><li><p>grep输出以\0作为结尾符的文件名：（-z）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep &quot;test&quot; file* -lZ| xargs -0 rm</span><br></pre></td></tr></table></figure></li></ul><h2 id="xargs-命令行参数转换"><a href="#xargs-命令行参数转换" class="headerlink" title="xargs 命令行参数转换"></a>xargs 命令行参数转换</h2><p>xargs 能够将输入数据转化为特定命令的命令行参数；这样，可以配合很多命令来组合使用。比如grep，比如find；</p><ul><li><p>将多行输出转化为单行输出<br>cat file.txt| xargs<br>\n 是多行文本间的定界符</p></li><li><p>将单行转化为多行输出<br>cat single.txt | xargs -n 3<br>-n：指定每行显示的字段数</p></li></ul><h3 id="xargs参数说明"><a href="#xargs参数说明" class="headerlink" title="xargs参数说明"></a>xargs参数说明</h3><p>-d 定义定界符 （默认为空格 多行的定界符为 \n）<br>-n 指定输出为多行<br>-I {} 指定替换字符串，这个字符串在xargs扩展时会被替换掉,用于待执行的命令需要多个参数时<br>eg：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat file.txt | xargs -I &#123;&#125; .&#x2F;command.sh -p &#123;&#125; -1</span><br></pre></td></tr></table></figure><p>-0：指定\0为输入定界符<br>eg：统计程序行数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find source_dir&#x2F; -type f -name &quot;*.cpp&quot; -print0 |xargs -0 wc -l</span><br></pre></td></tr></table></figure><h2 id="sort-排序"><a href="#sort-排序" class="headerlink" title="sort 排序"></a>sort 排序</h2><p>字段说明：<br>-n 按数字进行排序 VS -d 按字典序进行排序<br>-r 逆序排序<br>-k N 指定按第N列排序<br>eg：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sort -nrk 1 data.txt</span><br><span class="line">sort -bd data &#x2F;&#x2F; 忽略像空格之类的前导空白字符</span><br></pre></td></tr></table></figure><h2 id="uniq-消除重复行"><a href="#uniq-消除重复行" class="headerlink" title="uniq 消除重复行"></a>uniq 消除重复行</h2><ul><li><p>消除重复行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sort unsort.txt | uniq</span><br></pre></td></tr></table></figure></li><li><p>统计各行在文件中出现的次数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sort unsort.txt | uniq -c</span><br></pre></td></tr></table></figure></li><li><p>找出重复行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sort unsort.txt | uniq -d</span><br></pre></td></tr></table></figure><p>可指定每行中需要比较的重复内容：-s 开始位置 -w 比较字符数</p></li></ul><h2 id="用tr进行转换"><a href="#用tr进行转换" class="headerlink" title="用tr进行转换"></a>用tr进行转换</h2><ul><li><p>通用用法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo 12345 | tr &#39;0-9&#39; &#39;9876543210&#39; &#x2F;&#x2F;加解密转换，替换对应字符</span><br><span class="line"> cat text| tr &#39;\t&#39; &#39; &#39;  &#x2F;&#x2F;制表符转空格</span><br></pre></td></tr></table></figure></li><li><p>tr删除字符</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat file | tr -d &#39;0-9&#39; &#x2F;&#x2F; 删除所有数字</span><br></pre></td></tr></table></figure><p>-c 求补集</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat file | tr -c &#39;0-9&#39; &#x2F;&#x2F;获取文件中所有数字</span><br><span class="line"> cat file | tr -d -c &#39;0-9 \n&#39;  &#x2F;&#x2F;删除非数字数据</span><br></pre></td></tr></table></figure></li><li><p>tr压缩字符<br>tr -s 压缩文本中出现的重复字符；最常用于压缩多余的空格</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat file | tr -s &#39; &#39;</span><br></pre></td></tr></table></figure></li><li><p>字符类<br>tr中可用各种字符类：<br>alnum：字母和数字<br>alpha：字母<br>digit：数字<br>space：空白字符<br>lower：小写<br>upper：大写<br>cntrl：控制（非可打印）字符<br>print：可打印字符<br>使用方法：tr [:class:] [:class:]</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eg: tr &#39;[:lower:]&#39; &#39;[:upper:]&#39;</span><br></pre></td></tr></table></figure></li></ul><h2 id="cut-按列切分文本"><a href="#cut-按列切分文本" class="headerlink" title="cut 按列切分文本"></a>cut 按列切分文本</h2><ul><li><p>截取文件的第2列和第4列：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cut -f2,4 filename</span><br></pre></td></tr></table></figure></li><li><p>去文件除第3列的所有列：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cut -f3 --complement filename</span><br></pre></td></tr></table></figure></li><li><p>-d 指定定界符：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat -f2 -d&quot;;&quot; filename</span><br></pre></td></tr></table></figure></li><li><p>cut 取的范围<br>N- 第N个字段到结尾<br>-M 第1个字段为M<br>N-M N到M个字段</p></li><li><p>cut 取的单位<br>-b 以字节为单位<br>-c 以字符为单位<br>-f 以字段为单位（使用定界符）</p></li><li><p>eg:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cut -c1-5 file &#x2F;&#x2F;打印第一到5个字符</span><br><span class="line"> cut -c-2 file  &#x2F;&#x2F;打印前2个字符</span><br></pre></td></tr></table></figure></li></ul><h2 id="paste-按列拼接文本"><a href="#paste-按列拼接文本" class="headerlink" title="paste 按列拼接文本"></a>paste 按列拼接文本</h2><p>将两个文本按列拼接到一起;</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cat file1</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line"></span><br><span class="line">cat file2</span><br><span class="line">colin</span><br><span class="line">book</span><br><span class="line"></span><br><span class="line">paste file1 file2</span><br><span class="line">1 colin</span><br><span class="line">2 book</span><br></pre></td></tr></table></figure><p>默认的定界符是制表符，可以用-d指明定界符<br>paste file1 file2 -d “,”<br>1,colin<br>2,book</p><h2 id="wc-统计行和字符的工具"><a href="#wc-统计行和字符的工具" class="headerlink" title="wc 统计行和字符的工具"></a>wc 统计行和字符的工具</h2><p>wc -l file // 统计行数<br>wc -w file // 统计单词数<br>wc -c file // 统计字符数</p><h2 id="sed-文本替换利器"><a href="#sed-文本替换利器" class="headerlink" title="sed 文本替换利器"></a>sed 文本替换利器</h2><ul><li><p>首处替换</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">seg &#39;s&#x2F;text&#x2F;replace_text&#x2F;&#39; file   &#x2F;&#x2F;替换每一行的第一处匹配的text</span><br></pre></td></tr></table></figure></li><li><p>全局替换</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">seg &#39;s&#x2F;text&#x2F;replace_text&#x2F;g&#39; file</span><br></pre></td></tr></table></figure><p>默认替换后，输出替换后的内容，如果需要直接替换原文件,使用-i：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">seg -i &#39;s&#x2F;text&#x2F;repalce_text&#x2F;g&#39; file</span><br></pre></td></tr></table></figure></li><li><p>移除空白行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed &#39;&#x2F;^$&#x2F;d&#39; file</span><br></pre></td></tr></table></figure></li><li><p>变量转换<br>已匹配的字符串通过标记&amp;来引用.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo this is en example | seg &#39;s&#x2F;\w+&#x2F;[&amp;]&#x2F;g&#39;</span><br><span class="line">$&gt;[this]  [is] [en] [example]</span><br></pre></td></tr></table></figure></li><li><p>子串匹配标记<br>第一个匹配的括号内容使用标记 \1 来引用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed &#39;s&#x2F;hello\([0-9]\)&#x2F;\1&#x2F;&#39;</span><br></pre></td></tr></table></figure></li><li><p>双引号求值<br>sed通常用单引号来引用；也可使用双引号，使用双引号后，双引号会对表达式求值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed &#39;s&#x2F;$var&#x2F;HLLOE&#x2F;&#39;</span><br></pre></td></tr></table></figure><p>当使用双引号时，我们可以在sed样式和替换字符串中指定变量；</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">eg:</span><br><span class="line">p&#x3D;patten</span><br><span class="line">r&#x3D;replaced</span><br><span class="line">echo &quot;line con a patten&quot; | sed &quot;s&#x2F;$p&#x2F;$r&#x2F;g&quot;</span><br><span class="line">$&gt;line con a replaced</span><br></pre></td></tr></table></figure></li><li><p>其它示例<br>字符串插入字符：将文本中每行内容（PEKSHA） 转换为 PEK/SHA</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed &#39;s&#x2F;^.\&#123;3\&#125;&#x2F;&amp;\&#x2F;&#x2F;g&#39; file</span><br></pre></td></tr></table></figure></li></ul><h2 id="awk-数据流处理工具"><a href="#awk-数据流处理工具" class="headerlink" title="awk 数据流处理工具"></a>awk 数据流处理工具</h2><ul><li><p>awk脚本结构<br>awk ‘ BEGIN{ statements } statements2 END{ statements } ‘</p></li><li><p>工作方式<br>1.执行begin中语句块；<br>2.从文件或stdin中读入一行，然后执行statements2，重复这个过程，直到文件全部被读取完毕；<br>3.执行end语句块；</p></li></ul><h3 id="print-打印当前行"><a href="#print-打印当前行" class="headerlink" title="print 打印当前行"></a>print 打印当前行</h3><ul><li><p>使用不带参数的print时，会打印当前行;</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo -e &quot;line1\nline2&quot; | awk &#39;BEGIN&#123;print &quot;start&quot;&#125; &#123;print &#125; END&#123; print &quot;End&quot; &#125;&#39;</span><br></pre></td></tr></table></figure></li><li><p>print 以逗号分割时，参数以空格定界;</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo | awk &#39; &#123;var1 &#x3D; &quot;v1&quot; ; var2 &#x3D; &quot;V2&quot;; var3&#x3D;&quot;v3&quot;; \</span><br><span class="line">print var1, var2 , var3; &#125;&#39;</span><br><span class="line">$&gt;v1 V2 v3</span><br></pre></td></tr></table></figure></li><li><p>使用-拼接符的方式（””作为拼接符）;</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo | awk &#39; &#123;var1 &#x3D; &quot;v1&quot; ; var2 &#x3D; &quot;V2&quot;; var3&#x3D;&quot;v3&quot;; \</span><br><span class="line">print var1&quot;-&quot;var2&quot;-&quot;var3; &#125;&#39;</span><br><span class="line">$&gt;v1-V2-v3</span><br></pre></td></tr></table></figure></li></ul><h3 id="特殊变量：-NR-NF-0-1-2"><a href="#特殊变量：-NR-NF-0-1-2" class="headerlink" title="特殊变量： NR NF $0 $1 $2"></a>特殊变量： NR NF $0 $1 $2</h3><p>NR:表示记录数量，在执行过程中对应当前行号；<br>NF:表示字段数量，在执行过程总对应当前行的字段数；<br>$0:这个变量包含执行过程中当前行的文本内容；<br>$1:第一个字段的文本内容；<br>$2:第二个字段的文本内容；</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo -e &quot;line1 f2 f3\n line2 \n line 3&quot; | awk &#39;&#123;print NR&quot;:&quot;$0&quot;-&quot;$1&quot;-&quot;$2&#125;&#39;</span><br></pre></td></tr></table></figure><ul><li><p>打印每一行的第二和第三个字段：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk &#39;&#123;print $2, $3&#125;&#39; file</span><br></pre></td></tr></table></figure></li><li><p>统计文件的行数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk &#39; END &#123;print NR&#125;&#39; file</span><br></pre></td></tr></table></figure></li><li><p>累加每一行的第一个字段：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo -e &quot;1\n 2\n 3\n 4\n&quot; | awk &#39;BEGIN&#123;num &#x3D; 0 ;</span><br><span class="line"> print &quot;begin&quot;;&#125; &#123;sum +&#x3D; $1;&#125; END &#123;print &quot;&#x3D;&#x3D;&quot;; print sum &#125;&#39;</span><br></pre></td></tr></table></figure></li></ul><h3 id="传递外部变量"><a href="#传递外部变量" class="headerlink" title="传递外部变量"></a>传递外部变量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var&#x3D;1000</span><br><span class="line">echo | awk &#39;&#123;print vara&#125;&#39; vara&#x3D;$var #  输入来自stdin</span><br><span class="line">awk &#39;&#123;print vara&#125;&#39; vara&#x3D;$var file # 输入来自文件</span><br></pre></td></tr></table></figure><h3 id="用样式对awk处理的行进行过滤"><a href="#用样式对awk处理的行进行过滤" class="headerlink" title="用样式对awk处理的行进行过滤"></a>用样式对awk处理的行进行过滤</h3><p>awk ‘NR &lt; 5’ #行号小于5<br>awk ‘NR==1,NR==4 {print}’ file #行号等于1和4的打印出来<br>awk ‘/linux/‘ #包含linux文本的行（可以用正则表达式来指定，超级强大）<br>awk ‘!/linux/‘ #不包含linux文本的行</p><h3 id="设置定界符"><a href="#设置定界符" class="headerlink" title="设置定界符"></a>设置定界符</h3><p>使用-F来设置定界符（默认为空格）<br>awk -F: ‘{print $NF}’ /etc/passwd</p><h3 id="读取命令输出"><a href="#读取命令输出" class="headerlink" title="读取命令输出"></a>读取命令输出</h3><p>使用getline，将外部shell命令的输出读入到变量cmdout中；</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo | awk &#39;&#123;&quot;grep root &#x2F;etc&#x2F;passwd&quot; | getline cmdout; print cmdout &#125;&#39;</span><br></pre></td></tr></table></figure><h3 id="在awk中使用循环"><a href="#在awk中使用循环" class="headerlink" title="在awk中使用循环"></a>在awk中使用循环</h3><p>for(i=0;i&lt;10;i++){print $i;}<br>for(i in array){print array[i];}</p><p>eg:<br>以逆序的形式打印行：(tac命令的实现）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">seq 9| \</span><br><span class="line">awk &#39;&#123;lifo[NR] &#x3D; $0; lno&#x3D;NR&#125; \</span><br><span class="line">END&#123; for(;lno&gt;-1;lno--)&#123;print lifo[lno];&#125;</span><br><span class="line">&#125; &#39;</span><br></pre></td></tr></table></figure><h3 id="awk实现head、tail命令"><a href="#awk实现head、tail命令" class="headerlink" title="awk实现head、tail命令"></a>awk实现head、tail命令</h3><ul><li><p>head:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk &#39;NR&lt;&#x3D;10&#123;print&#125;&#39; filename</span><br></pre></td></tr></table></figure></li><li><p>tail:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">awk &#39;&#123;buffer[NR%10] &#x3D; $0;&#125; END&#123;for(i&#x3D;0;i&lt;11;i++)&#123; \</span><br><span class="line"> print buffer[i %10]&#125; &#125; &#39; filename</span><br></pre></td></tr></table></figure></li></ul><h3 id="打印指定列"><a href="#打印指定列" class="headerlink" title="打印指定列"></a>打印指定列</h3><ul><li>awk方式实现：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -lrt | awk &#39;&#123;print $6&#125;&#39;</span><br></pre></td></tr></table></figure></li></ul><ul><li>cut方式实现<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls -lrt | cut -f6</span><br></pre></td></tr></table></figure></li></ul><h3 id="打印指定文本区域"><a href="#打印指定文本区域" class="headerlink" title="打印指定文本区域"></a>打印指定文本区域</h3><ul><li><p>确定行号</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">seq 100| awk &#39;NR&#x3D;&#x3D;4,NR&#x3D;&#x3D;6&#123;print&#125;&#39;</span><br></pre></td></tr></table></figure></li><li><p>确定文本<br>打印处于start_pattern 和end_pattern之间的文本；</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">awk &#39;&#x2F;start_pattern&#x2F;, &#x2F;end_pattern&#x2F;&#39; filename</span><br></pre></td></tr></table></figure><p>eg:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">seq 100 | awk &#39;&#x2F;13&#x2F;,&#x2F;15&#x2F;&#39;</span><br><span class="line">cat &#x2F;etc&#x2F;passwd| awk &#39;&#x2F;mai.*mail&#x2F;,&#x2F;news.*news&#x2F;&#39;</span><br></pre></td></tr></table></figure></li></ul><h3 id="awk常用内建函数"><a href="#awk常用内建函数" class="headerlink" title="awk常用内建函数"></a>awk常用内建函数</h3><p>index(string,search_string):返回search_string在string中出现的位置<br>sub(regex,replacement_str,string):将正则匹配到的第一处内容替换为replacement_str;<br>match(regex,string):检查正则表达式是否能够匹配字符串；<br>length(string)：返回字符串长度</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo | awk &#39;&#123;&quot;grep root &#x2F;etc&#x2F;passwd&quot; | getline cmdout; print length(cmdout) &#125;&#39;</span><br></pre></td></tr></table></figure><p>printf 类似c语言中的printf，对输出进行格式化<br>eg：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">seq 10 | awk &#39;&#123;printf &quot;-&gt;%4s\n&quot;, $1&#125;&#39;</span><br></pre></td></tr></table></figure><h2 id="迭代文件中的行、单词和字符"><a href="#迭代文件中的行、单词和字符" class="headerlink" title="迭代文件中的行、单词和字符"></a>迭代文件中的行、单词和字符</h2><h3 id="1-迭代文件中的每一行"><a href="#1-迭代文件中的每一行" class="headerlink" title="1.迭代文件中的每一行"></a>1.迭代文件中的每一行</h3><ul><li><p>while 循环法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">while read line;</span><br><span class="line">do</span><br><span class="line">echo $line;</span><br><span class="line">done &lt; file.txt</span><br><span class="line">改成子shell:</span><br><span class="line">cat file.txt | (while read line;do echo $line;done)</span><br></pre></td></tr></table></figure></li><li><p>awk法：<br>cat file.txt| awk ‘{print}’</p></li></ul><h3 id="2-迭代一行中的每一个单词"><a href="#2-迭代一行中的每一个单词" class="headerlink" title="2.迭代一行中的每一个单词"></a>2.迭代一行中的每一个单词</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for word in $line;</span><br><span class="line">do </span><br><span class="line">echo $word;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="3-迭代每一个字符"><a href="#3-迭代每一个字符" class="headerlink" title="3.迭代每一个字符"></a>3.迭代每一个字符</h3><p>${string:start_pos:num_of_chars}：从字符串中提取一个字符；(bash文本切片)</p><p>${&#35;word}:返回变量word的长度</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for((i&#x3D;0;i&lt;$&#123;#word&#125;;i++))</span><br><span class="line">do</span><br><span class="line">echo $&#123;word:i:1);</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>本文为《linux Shell脚本攻略》的读书笔记，文中主要内容和示例来自于 <a href="http://www.amazon.cn/Linux-Shell%E8%84%9A%E6%9C%AC%E6%94%BB%E7%95%A5-%E6%8B%89%E5%85%8B%E4%BB%80%E6%9B%BC/dp/B0060FSIE4?SubscriptionId=AKIAJOMEZLLKFEWYT4PQ&tag=z08-23&linkCode=xm2&camp=2025&creative=165953&creativeASIN=B0060FSIE4" target="_blank" rel="noopener" title="Linux Shell脚本攻略">《linux Shell脚本攻略》</a>；</p><p>本文转自 <a href="https://www.cnblogs.com/me115/p/3427319.html" target="_blank" rel="noopener">https://www.cnblogs.com/me115/p/3427319.html</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Shell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一篇详文带你入门 Redis</title>
      <link href="/posts/9b6ac726/"/>
      <url>/posts/9b6ac726/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>作者：QQ 音乐前端团队</p><blockquote><p>本文将会从：Redis 使用场景与介绍 -&gt; 数据结构与简单使用 -&gt; 小功能大用处 -&gt; 持久化、主从同步与缓存设计 -&gt; 知识拓展 来书写，初学的童鞋只要能记住 Redis 是用来干嘛，各功能的使用场景有哪些，然后对 Redis 有个大概的认识就好啦，剩下的以后有需要的时候再来查看和实践吧~</p></blockquote><h2 id="Redis-介绍"><a href="#Redis-介绍" class="headerlink" title="Redis 介绍"></a>Redis 介绍</h2><h3 id="Redis-是什么？"><a href="#Redis-是什么？" class="headerlink" title="Redis 是什么？"></a>Redis 是什么？</h3><ul><li><p>Redis 是一个开源（BSD 许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件；</p></li><li><p>Redis 支持多种类型的数据结构，如 字符串（strings），散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） ，范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询；</p></li><li><p>Redis 内置了复制（replication），LUA 脚本（Lua scripting），LRU 驱动事件（LRU eviction），事务（transactions）和不同级别的 磁盘持久化（persistence）；</p></li><li><p>Redis 通过 哨兵（Sentinel） 和自动分区（Cluster）提供高可用性（high availability）。</p></li></ul><h3 id="Redis-特性"><a href="#Redis-特性" class="headerlink" title="Redis 特性"></a>Redis 特性</h3><ul><li>速度快</li></ul><ul><li>单节点读110000次/s，写81000次/s</li></ul><ul><li><p>数据存放内存中</p></li><li><p>用 C 语言实现，离操作系统更近</p></li><li><p>单线程架构，6.0 开始支持多线程（CPU、IO 读写负荷）</p></li></ul><ul><li>持久化</li></ul><ul><li>数据的更新将异步地保存到硬盘（RDB 和 AOF）</li></ul><ul><li><p>多种数据结构 - 不仅仅支持简单的 key-value 类型数据，还支持：字符串、hash、列表、集合、有序集合，</p></li><li><p>支持多种编程语言</p></li><li><p>功能丰富</p></li></ul><ul><li>HyperLogLog、GEO、发布订阅、Lua脚本、事务、Pipeline、Bitmaps，key 过期</li></ul><ul><li>简单稳定</li></ul><ul><li>源码少、单线程模型  </li></ul><ul><li><p>主从复制</p></li><li><p>Redis 支持数据的备份（master-slave）与集群（分片存储），以及拥有哨兵监控机制。</p></li><li><p>Redis 的所有操作都是原子性的，同时 Redis 还支持对几个操作合并后的原子性执行。</p></li></ul><h3 id="Redis-典型使用场景"><a href="#Redis-典型使用场景" class="headerlink" title="Redis 典型使用场景"></a>Redis 典型使用场景</h3><p><strong>缓存:</strong></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/6436a81f44d5bd3ac9a9ad2e1d5d1caf.jpeg" alt=""></p><p><strong>计数器:</strong></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/6f45b92a8d4321ebd4c1e771c10fea16.jpeg" alt=""></p><p><strong>消息队列:</strong></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/2d9f9cf7962164b9d6ac5a8652f56509.jpeg" alt=""></p><p><strong>排行榜:</strong></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/ac60ef4b27f81863959553be40755354.jpeg" alt=""></p><p><strong>社交网络:</strong></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/721910bdc5a153091890a887551e3e95.jpeg" alt=""></p><h3 id="Redis-高并发原理"><a href="#Redis-高并发原理" class="headerlink" title="Redis 高并发原理"></a>Redis 高并发原理</h3><ol><li><p>Redis 是纯内存数据库，一般都是简单的存取操作，线程占用的时间很多，时间的花费主要集中在 IO 上，所以读取速度快</p></li><li><p>Redis 使用的是非阻塞 IO，IO 多路复用，使用了单线程来轮询描述符，将数据库的开、关、读、写都转换成了事件，减少了线程切换时上下文的切换和竞争。</p></li><li><p>Redis 采用了单线程的模型，保证了每个操作的原子性，也减少了线程的上下文切换和竞争。</p></li><li><p>Redis 存储结构多样化，不同的数据结构对数据存储进行了优化，如压缩表，对短数据进行压缩存储，再如，跳表，使用有序的数据结构加快读取的速度。</p></li><li><p>Redis 采用自己实现的事件分离器，效率比较高，内部采用非阻塞的执行方式，吞吐能力比较大。</p></li></ol><h3 id="Redis-安装"><a href="#Redis-安装" class="headerlink" title="Redis 安装"></a>Redis 安装</h3><p>这里只提供 linux 版本的安装部署</p><h4 id="下载-Redis"><a href="#下载-Redis" class="headerlink" title="下载 Redis"></a>下载 Redis</h4><p>进入官网找到下载地址：<a href="https://redis.io/download" target="_blank" rel="noopener">https://redis.io/download</a></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9ca75683dcbcc1eafbad00529d0249b2.png" alt=""></p><p>右键 Download 按钮，选择复制链接地址，然后进入 linux 的 shell 控制台：输入 wget 将上面复制的下载链接粘贴上，如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;download.redis.io&#x2F;releases&#x2F;redis-6.2.4.tar.gz</span><br></pre></td></tr></table></figure><p>回车后等待下载完毕。</p><h4 id="解压并安装-Redis"><a href="#解压并安装-Redis" class="headerlink" title="解压并安装 Redis"></a>解压并安装 Redis</h4><p>下载完成后需要将压缩文件解压，输入以下命令解压到当前目录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zvxf redis-6.2.4.tar.gz</span><br></pre></td></tr></table></figure><p>解压后在根目录上输入 <code>ls</code> 列出所有目录会发现与下载 redis 之前多了一个 redis-6.2.4.tar.gz 文件和 redis-6.2.4 的目录。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/23881bebba1fb6942380ecc81a9d653b.jpeg" alt=""></p><h4 id="移动-Redis-目录（可选）"><a href="#移动-Redis-目录（可选）" class="headerlink" title="移动 Redis 目录（可选）"></a>移动 Redis 目录（可选）</h4><p>若你不想在下载的目录安装 Redis，可以将 Redis 移动到特定目录安装，我习惯放在 ‘/usr/local/’ 目录下，所以我这里输入命令将目前在 ‘/root’ 目录下的 ‘redis-6.2.4’ 文件夹更改目录，同时修改其名字为 redis:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv &#x2F;root&#x2F;rredis-6.2.4 &#x2F;usr&#x2F;local&#x2F;redis</span><br></pre></td></tr></table></figure><p><code>cd</code> 到 ‘/usr/local’ 目录下输入 <code>ls</code> 命令可以查询到当前目录已经多了一个 redis 子目录，同时 ‘/root’ 目录下已经没有 ‘redis-6.2.4’ 文件:</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/da131e8bbdef4e8d5ff8ab93f086f964.jpeg" alt=""></p><h4 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h4><p><code>cd</code> 到 ‘/usr/local/redis’ 目录，输入命令 <code>make</code> 执行编译命令，接下来控制台会输出各种编译过程中输出的内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make</span><br></pre></td></tr></table></figure><p>最终运行结果如下:</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/4c7d3c96c8b49e6f268b8a14f8aa432b.jpeg" alt=""></p><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>输入以下命令:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;redis install</span><br></pre></td></tr></table></figure><p>这里多了一个关键字 ‘PREFIX=’ 这个关键字的作用是编译的时候用于指定程序存放的路径。比如我们现在就是指定了 redis 必须存放在 ‘/usr/local/redis’ 目录。假设不添加该关键字 linux 会将可执行文件存放在 ‘/usr/local/bin’ 目录，库文件会存放在 ‘/usr/local/lib’ 目录。配置文件会存放在 ‘/usr/local/etc 目录。其他的资源文件会存放在 ‘usr/local/share’ 目录。这里指定好目录也方便后续的卸载，后续直接 <code>rm -rf /usr/local/redis</code> 即可删除 Redis。</p><p>执行结果如下图:</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/8c64c7390bb8465236eaee61cc3e5e1c.jpeg" alt=""></p><p>到此为止，Redis 已经安装完毕，可以开始使用了～</p><h3 id="Redis-启动"><a href="#Redis-启动" class="headerlink" title="Redis 启动"></a>Redis 启动</h3><p>根据上面的操作已经将 redis 安装完成了。在目录 ‘/usr/local/redis’ 输入下面命令启动 redis：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;bin&#x2F;redis-server&amp; .&#x2F;redis.conf</span><br></pre></td></tr></table></figure><p>上面的启动方式是采取后台进程方式,下面是采取显示启动方式(如在配置文件设置了 daemonize 属性为 yes 则跟后台进程方式启动其实一样):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;bin&#x2F;redis-server .&#x2F;redis.conf</span><br></pre></td></tr></table></figure><p>两种方式区别无非是有无带符号&amp;的区别。redis-server 后面是配置文件，目的是根据该配置文件的配置启动 redis 服务。redis.conf 配置文件允许自定义多个配置文件，通过启动时指定读取哪个即可。</p><p>启动可以概括为：</p><ul><li><p>最简默认启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- 安装后在 bin 目录下直接执行 redis-server</span><br></pre></td></tr></table></figure></li></ul><ul><li>验证（ps –aux | grep redis）</li></ul><ul><li><p>动态参数启动（可配置一下参数，例如指定端口）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- .&#x2F;bin&#x2F;redis-server –port 6380</span><br></pre></td></tr></table></figure></li><li><p>配置文件启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- .&#x2F;bin&#x2F;redis-server&amp; .&#x2F;redis.conf</span><br></pre></td></tr></table></figure></li><li><p>生产环境一般选择配置启动</p></li><li><p>单机多实例配置文件可以用端口区分开</p></li></ul><p>注：若在进行 redis 命令操作，直接在 redis 中的 bin 目录下运行 redis-cli 命令即可，若开启了多个则需要加上对应的端口参数：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/44b9518f7a72bd6294be946dd4225869.jpeg" alt=""></p><p>若运行 redis-cli 提示不未安装，则安装一下即可：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/8178fb5bf32c725eab1dc8c5fe44c04b.jpeg" alt=""></p><h3 id="redis-conf-配置文件"><a href="#redis-conf-配置文件" class="headerlink" title="redis.conf 配置文件"></a>redis.conf 配置文件</h3><p>在目录 ‘/usr/local/redis’ 下有一个 redis.conf 的配置文件。我们上面启动方式就是执行了该配置文件的配置运行的。我们可以通过 <code>cat、vim、less</code> 等 linux 内置的读取命令读取该文件。</p><p>这里列举下比较重要的配置项：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/a9ecba6f04c209a39e02841e6288ff1c.jpeg" alt=""></p><p>这里我要将 daemonize 改为 yes，不然我每次启动都得在 redis-server 命令后面加符号 &amp;，不这样操作则只要回到 linux 控制台则 redis 服务会自动关闭，同时也将 bind 注释，将 p rotected-mode 设置为 no。这样启动后我就可以在外网访问了。修改方式通过 vim 或者你喜欢的方式即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;usr&#x2F;local&#x2F;redis&#x2F;redis.conf</span><br></pre></td></tr></table></figure><p>通过 /daemonize 查找到属性，默认是 no，更改为 yes 即可。(通过/关键字查找出现多个结果则使用 n 字符切换到下一个即可，按 i 可以开始编辑，ESC 退出编辑模式，输入 <code>:wq</code> 命令保存并退出)，如下图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/dbf764008432c55b5f4774327037d62a.jpeg" alt=""></p><p>其他属性也是同样方式查找和编辑即可。</p><p>安装部署部分参考：<a href="https://www.cnblogs.com/hunanzp/p/12304622.html" target="_blank" rel="noopener">https://www.cnblogs.com/hunanzp/p/12304622.html</a></p><p><strong>Redis 数据结构与命令使用</strong></p><p>Redis 的数据结构有：string(字符串)、hash(哈希)、list(列表)、set(集合)、zset(有序集 合)。但这些只是 Redis 对外的数据结构，实际上每种数据结构都有自己底层的内部编码实现，而且是多种实现， 这样 Redis 会在合适的场景选择合适的内部编码。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/ce5fe8a4bb20294309e8082701c92a17.jpeg" alt=""></p><p>可以看到每种数据结构都有两种以上的内部编码实现，例如 list 数据结 构包含了 linkedlist 和 ziplist 两种内部编码。同时，有些内部编码，例如 ziplist， 可以作为多种外部数据结构的内部实现，可以通过 <code>object encoding</code> 命令查询内部编码。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">object encoding xxx  # xxx 为键名</span><br></pre></td></tr></table></figure><p>Redis 所有的数据结构都是以唯一的 key 字符串作为名称，然后通过这个唯一 key 值来获取相应的 value 数据。不同类型的数据结 构的差异就在于 value 的结构不一样。</p><h3 id="通用全局命令"><a href="#通用全局命令" class="headerlink" title="通用全局命令"></a>通用全局命令</h3><h4 id="常用全局命令"><a href="#常用全局命令" class="headerlink" title="常用全局命令"></a>常用全局命令</h4><ul><li><p>keys：查看所有键</p></li><li><p>dbsize：键总数</p></li><li><p>exists key：检查键是否存在</p></li><li><p>del key [key …]：删除键</p></li><li><p>expire key seconds：键过期</p></li><li><p>ttl key: 通过 ttl 命令观察键键的剩余过期时间</p></li><li><p>type key：键的数据结构类型</p></li></ul><h4 id="简单使用截图"><a href="#简单使用截图" class="headerlink" title="简单使用截图"></a>简单使用截图</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/0a9e776e3033c886ab96d6e7ab051a16.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/628934a1cb9e4bc5bb273b2c1ac1b26c.jpeg" alt=""></p><p>根据上面的命令解释，大家应该比较容易看懂截图里面的所有命令含义，这里就不过多解释了。</p><h3 id="字符串使用"><a href="#字符串使用" class="headerlink" title="字符串使用"></a>字符串使用</h3><p>字符串 string 是 Redis 最简单的数据结构。Redis 的字符串是动态字符串，是可以修改的字符串，内部结构实现上类似于 Java 的 ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配。</p><p>字符串结构使用非常广泛，一个常见的用途就是缓存用户信息。我们将用户信息结构体 使用 JSON 序列化成字符串，然后将序列化后的字符串塞进 Redis 来缓存。同样，取用户 信息会经过一次反序列化的过程。</p><h4 id="常用字符串命令"><a href="#常用字符串命令" class="headerlink" title="常用字符串命令"></a>常用字符串命令</h4><ul><li><p>set key value [ex seconds][px milliseconds] [nx|xx]: 设置值，返回 ok 表示成功</p></li><li></li></ul><ul><li><p>ex seconds:为键设置秒级过期时间。</p></li><li><p>px milliseconds:为键设置毫秒级过期时间。</p></li><li><p>nx:键必须不存在，才可以设置成功，用于添加。可单独用 setnx 命令替代</p></li><li><p>xx:与 nx 相反，键必须存在，才可以设置成功，用于更新。可单独用 setxx 命令替代</p></li></ul><ul><li><p>get key：获取值</p></li><li><p>mset key value [key value …]：批量设置值，批量操作命令可以有效提高业务处理效率</p></li><li><p>mget key [key …]：批量获取值，批量操作命令可以有效提高业务处理效率</p></li><li><p>incr key：计数，返回结果分 3 种情况：</p></li><li></li></ul><ul><li><p>值不是整数，返回错误。</p></li><li><p>值是整数，返回自增后的结果。</p></li><li><p>键不存在，按照值为 0 自增，返回结果为 1。</p></li></ul><ul><li>decr(自减)、incrby(自增指定数字)、 decrby(自减指定数字)</li></ul><h4 id="字符串简单使用截图"><a href="#字符串简单使用截图" class="headerlink" title="字符串简单使用截图"></a>字符串简单使用截图</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/25dca1242d22ed75cefe1a13d4d2ae9f.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9a0e72b7f23b5e1e1d19c4915398b0db.jpeg" alt=""></p><p>根据上面的命令解释，大家应该比较容易看懂截图里面的所有命令含义，这里就不过多解释了。</p><h4 id="字符串使用场景"><a href="#字符串使用场景" class="headerlink" title="字符串使用场景"></a>字符串使用场景</h4><ol><li><p>缓存数据，提高查询性能。比如存储登录用户信息、电商中存储商品信息</p></li><li><p>可以做计数器（想知道什么时候封锁一个 IP 地址(访问超过几次)）,短信限流</p></li><li><p>共享 Session，例如：一个分布式 Web 服务将用户的 Session 信息(例如用户登录信息)保存在各自服务器中，这样会造成一个问题，出于负载均衡的考虑，分布式服务会将用户的访问均衡到不同服务器上，用户刷新一次访问可 能会发现需要重新登录，为了解决这个问题，可以使用 Redis 将用户的 Session 进行集中管理，在这种模式下只要保证 Redis 是高可用和扩展性的，每次用户 更新或者查询登录信息都直接从 Redis 中集中获取，如图：</p></li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/0754cf8912d4454dfe4487c1249b99fc.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/ca31069bc6ed3f784f06a7ff8cbe0451.jpeg" alt=""></p><h3 id="哈希-hash"><a href="#哈希-hash" class="headerlink" title="哈希 hash"></a>哈希 hash</h3><p>哈希相当于 Java 中的 HashMap，以及 Js 中的 Map，内部是无序字典。实现原理跟 HashMap 一致。一个哈希表有多个节点，每个节点保存一个键值对。</p><p>与 Java 中的 HashMap 不同的是，rehash 的方式不一样，因为 Java 的 HashMap 在字典很大时，rehash 是个耗时的操作，需要一次性全部 rehash。</p><p>Redis 为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略。</p><p>渐进式 rehash 会在 rehash 的同时，保留新旧两个 hash 结构，查询时会同时查询两个 hash 结构，然后在后续的定时任务中以及 hash 操作指令中，循序渐进地将旧 hash 的内容一点点迁移到新的 hash 结构中。当搬迁完成了，就会使用新的 hash 结构取而代之。</p><p>当 hash 移除了最后一个元素之后，该数据结构自动被删除，内存被回收。</p><h4 id="常用哈希命令"><a href="#常用哈希命令" class="headerlink" title="常用哈希命令"></a>常用哈希命令</h4><ul><li><p>hset key field value：设置值</p></li><li><p>hget key field：获取值</p></li><li><p>hdel key field [field …]：删除 field</p></li><li><p>hlen key：计算 field 个数</p></li><li><p>hmset key field value [field value …]：批量设置 field-value</p></li><li><p>hmget key field [field …]：批量获取 field-value</p></li><li><p>hexists key field：判断 field 是否存在</p></li><li><p>hkeys key：获取所有 field</p></li><li><p>hvals key：获取所有 value</p></li><li><p>hgetall key：获取所有的 field-value</p></li><li><p>incrbyfloat 和 hincrbyfloat:就像 incrby 和 incrbyfloat 命令一样，但是它们的作 用域是 filed</p></li></ul><h4 id="哈希简单使用截图"><a href="#哈希简单使用截图" class="headerlink" title="哈希简单使用截图"></a>哈希简单使用截图</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/33be72c92aa9516de058b317474ed2e6.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/564aa945adc167c53615d17798ed50ea.jpeg" alt=""></p><p>根据上面的命令解释，大家应该比较容易看懂截图里面的所有命令含义，这里同样不过多解释了</p><h4 id="哈希使用场景"><a href="#哈希使用场景" class="headerlink" title="哈希使用场景"></a>哈希使用场景</h4><ol><li>Hash 也可以同于对象存储，比如存储用户信息，与字符串不一样的是，字符串是需要将对象进行序列化（比如 json 序列化）之后才能保存，而 Hash 则可以讲用户对象的每个字段单独存储，这样就能节省序列化和反序列的时间。如下：</li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/2df9c06f2b5fb3226a47c83fed7e2d64.gif" alt=""></p><ol start="2"><li>此外还可以保存用户的购买记录，比如 key 为用户 id，field 为商品 i d，value 为商品数量。同样还可以用于购物车数据的存储，比如 key 为用户 id，field 为商品 id，value 为购买数量等等:</li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9140099d1675526111b3e7452c274f24.jpeg" alt=""></p><h3 id="列表（lists）"><a href="#列表（lists）" class="headerlink" title="列表（lists）"></a>列表（lists）</h3><p>Redis 中的 lists 相当于 Java 中的 LinkedList，实现原理是一个双向链表（其底层是一个快速列表），即可以支持反向查找和遍历，更方便操作。插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n)。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/634fdedb4bd7745479af39109f5cbf54.gif" alt=""></p><h4 id="常用列表命令"><a href="#常用列表命令" class="headerlink" title="常用列表命令"></a>常用列表命令</h4><ul><li><p>rpush key value [value …]：从右边插入元素</p></li><li><p>lpush key value [value …]：从左边插入元素</p></li><li><p>linsert key before|after pivot value：向某个元素前或者后插入元素</p></li><li><p>lrange key start end：获取指定范围内的元素列表，<code>lrange key 0 -1</code>可以从左到右获取列表的所有元素</p></li><li><p>lindex key index：获取列表指定索引下标的元素</p></li><li><p>llen key：获取列表长度</p></li><li><p>lpop key：从列表左侧弹出元素</p></li><li><p>rpop key：从列表右侧弹出</p></li><li><p>lrem key count value：删除指定元素，lrem 命令会从列表中找到等于 value 的元素进行删除，根据 count 的不同 分为三种情况:</p></li><li></li></ul><ul><li><p>·count&gt;0，从左到右，删除最多 count 个元素。</p></li><li><p>count&lt;0，从右到左，删除最多 count 绝对值个元素。</p></li><li><p>count=0，删除所有。</p></li></ul><ul><li><p>ltrim key start end：按照索引范围修剪列表</p></li><li><p>lset key index newValue：修改指定索引下标的元素</p></li><li><p>blpop key [key …] timeout 和 brpop key [key …] timeout：阻塞式弹出</p></li></ul><h4 id="列表简单使用截图"><a href="#列表简单使用截图" class="headerlink" title="列表简单使用截图"></a>列表简单使用截图</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/2c10ce57134d945b27a811e18fc54cdd.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/4c6240bab1d5791366d5219c00abad09.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/048ece9a3b3b8903816212edd72d755b.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/3a7c9a1d2804946832f1da2f514ce7de.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/16be1c4d7f2bd823e74429d3f22045e0.jpeg" alt=""></p><p>根据上面的命令解释，大家应该比较容易看懂截图里面的所有命令含义，这里同样不过多解释了</p><h4 id="列表使用场景"><a href="#列表使用场景" class="headerlink" title="列表使用场景"></a>列表使用场景</h4><ol><li><p>热销榜，文章列表</p></li><li><p>实现工作队列（利用 lists 的 push 操作，将任务存在 lists 中，然后工作线程再用 pop 操作将任务取出进行执行 ），例如消息队列</p></li><li><p>最新列表，比如最新评论</p></li></ol><p>使用参考：</p><ul><li><p>lpush+lpop=Stack(栈)</p></li><li><p>lpush+rpop=Queue(队列)</p></li><li><p>lpsh+ltrim=Capped Collection(有限集合)</p></li><li><p>lpush+brpop=Message Queue(消息队列)</p></li></ul><h3 id="set-集合和-zset-有序集合"><a href="#set-集合和-zset-有序集合" class="headerlink" title="set 集合和 zset 有序集合"></a>set 集合和 zset 有序集合</h3><p>Redis 的集合相当于 Java 语言里面的 HashSet 和 JS 里面的 Set，它内部的键值对是无序的唯一的。Set 集合中最后一个 value 被移除后，数据结构自动删除，内存被回收。</p><p>zset 可能是 Redis 提供的最为特色的数据结构，它也是在面试中面试官最爱问的数据结构。它类似于 Java 的 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权重。它的内部实现用的是一种叫着「跳跃列表」(后面会简单介绍)的数据结构。</p><h4 id="常用集合命令"><a href="#常用集合命令" class="headerlink" title="常用集合命令"></a>常用集合命令</h4><ul><li><p>sadd key element [element …]：添加元素，返回结果为添加成功的元素个数</p></li><li><p>srem key element [element …]：删除元素，返回结果为成功删除元素个数</p></li><li><p>smembers key：获取所有元素</p></li><li><p>sismember key element：判断元素是否在集合中，如果给定元素 element 在集合内返回 1，反之返回 0</p></li><li><p>scard key：计算元素个数，scard 的时间复杂度为 O(1)，它不会遍历集合所有元素</p></li><li><p>spop key：从集合随机弹出元素，从 3.2 版本开始，spop 也支持[count]参数。</p></li><li><p>srandmember key [count]：随机从集合返回指定个数元素，[count]是可选参数，如果不写默认为 1</p></li><li><p>sinter key [key …]：求多个集合的交集</p></li><li><p>suinon key [key …]：求多个集合的并集</p></li><li><p>sdiff key [key …]：求多个集合的差集</p></li></ul><h4 id="集合简单使用截图"><a href="#集合简单使用截图" class="headerlink" title="集合简单使用截图"></a>集合简单使用截图</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/db290fa8228a726b4e2acc99c661f0e9.jpeg" alt=""></p><h4 id="常用有序集合命令"><a href="#常用有序集合命令" class="headerlink" title="常用有序集合命令"></a>常用有序集合命令</h4><ul><li><p>zadd key score member [score member …]：添加成员，返回结果代表成功添加成员的个数。Redis3.2 为 zadd 命令添加了 nx、xx、ch、incr 四个选项:</p></li><li></li></ul><ul><li><p>nx:member 必须不存在，才可以设置成功，用于添加</p></li><li><p>xx:member 必须存在，才可以设置成功，用于更新</p></li><li><p>ch:返回此次操作后，有序集合元素和分数发生变化的个数</p></li><li><p>incr:对 score 做增加，相当于后面介绍的 zincrby</p></li></ul><ul><li><p>zcard key：计算成员个数</p></li><li><p>zscore key member：计算某个成员的分数</p></li><li><p>zrank key member 和 zrevrank key member：计算成员的排名，zrank 是从分数从低到高返回排名，zrevrank 反之</p></li><li><p>zrem key member [member …]：删除成员</p></li><li><p>zincrby key increment member：增加成员的分数</p></li><li><p>zrange key start end [withscores] 和 zrevrange key start end [withscores]：返回指定排名范围的成员，zrange 是从低到高返回，zrevrange 反之。</p></li><li><p>zrangebyscore key min max [withscores][limit offset count] 和 zrevrangebyscore key max min [withscores][limit offset count] 返回指定分数范围的成员，其中 zrangebyscore 按照分数从低到高返回，zrevrangebyscore 反之</p></li><li><p>zcount key min max：返回指定分数范围成员个数</p></li><li><p>zremrangebyrank key start end：删除指定排名内的升序元素</p></li><li><p>zremrangebyscore key min max：删除指定分数范围的成员</p></li><li><p>zinterstore 和 zunionstore 命令求集合的交集和并集，可用参数比较多，可用到再查文档</p></li></ul><p>有序集合相比集合提供了排序字段，但是也产生了代价，zadd 的时间 复杂度为 O(log(n))，sadd 的时间复杂度为 O(1)。</p><h4 id="有序集合简单使用截图"><a href="#有序集合简单使用截图" class="headerlink" title="有序集合简单使用截图"></a>有序集合简单使用截图</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/90d8b11960f10a5aad5ad6cb0620b011.jpeg" alt=""></p><h4 id="集合和有序集合使用场景"><a href="#集合和有序集合使用场景" class="headerlink" title="集合和有序集合使用场景"></a>集合和有序集合使用场景</h4><ol><li><p>给用户添加标签</p></li><li><p>给标签添加用户</p></li><li><p>根据某个权重进行排序的队列的场景，比如游戏积分排行榜，设置优先级的任务列表，学生成绩表等</p></li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/01eee39d6e4d845ae6b472a5f53e9ad4.gif" alt=""></p><h4 id="关于跳跃列表"><a href="#关于跳跃列表" class="headerlink" title="关于跳跃列表"></a>关于跳跃列表</h4><p>跳跃列表就是一种层级制，最下面一层所有的元素都会串起来。然后每隔几个元素挑选出一个代表来，再将这几个代表使用另外一级指针串起来。然后在这些代表里再挑出二级代表，再串起来。最终就形成了金字塔结构，如图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/6567ed263b1ec99814706c3060f105fc.jpeg" alt=""></p><p>更多可以看：<a href="https://www.jianshu.com/p/09c3b0835ba6" target="_blank" rel="noopener">https://www.jianshu.com/p/09c3b0835ba6</a></p><h4 id="列表、集合和有序集合异同"><a href="#列表、集合和有序集合异同" class="headerlink" title="列表、集合和有序集合异同"></a>列表、集合和有序集合异同</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/1f071f623d21d9bdd189e7af158ac564.jpeg" alt=""></p><h2 id="小功能大用处"><a href="#小功能大用处" class="headerlink" title="小功能大用处"></a>小功能大用处</h2><h3 id="慢查询分析"><a href="#慢查询分析" class="headerlink" title="慢查询分析"></a>慢查询分析</h3><p>许多存储系统（例如 MySQL）提供慢查询日志帮助开发和运维人员定位系统存在的慢操作。</p><p>所谓慢查询日志就是系统在命令执行前后计算每条命令的执行时间，当超过预设阈值，就将这条命令的相关信息（例如：发生时间，耗时，命令的详细信息）记录下来，Redis 也提供了类似的功能。这里可以顺带了解一下 Redis 客户端执行一条命令的过程，分为如下 4 个部分：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/57c3aa98c3df495efd0a81731f5824b8.jpeg" alt=""></p><p>对于慢查询功能，需要明确 3 件事：</p><p>1、预设阈值怎么设置？</p><p>在 redis 配置文件中修改配置 ‘slowlog-log-slower-than’ 的值，单位是微妙（1 秒 = 1000 毫秒 = 1000000 微秒），默认是 10000 微秒，如果把 slowlog-log-slower-than 设置为 0，将会记录所有命令到日志中。如果把 slowlog-log-slower-than 设置小于 0，将会不记录任何命令到日志中。</p><p>2、慢查询记录存放在哪？</p><p>在 redis 配置文件中修改配置 ‘slowlog-max-len’ 的值。slowlog-max-len 的作用是指定慢查询日志最多存储的条数。实际上，Redis 使用了一个列表存放慢查询日志，slowlog-max-len 就是这个列表的最大长度。当一个新的命令满足满足慢查询条件时，被插入这个列表中。当慢查询日志列表已经达到最大长度时，最早插入的那条命令将被从列表中移出。比如，slowlog-max-len 被设置为 10，当有第 11 条命令插入时，在列表中的第 1 条命令先被移出，然后再把第 11 条命令放入列表。</p><p>记录慢查询指 Redis 会对长命令进行截断，不会大量占用大量内存。在实际的生产环境中，为了减缓慢查询被移出的可能和更方便地定位慢查询，建议将慢查询日志的长度调整的大一些。比如可以设置为 1000 以上。</p><p>除了去配置文件中修改，也可以通过 config set 命令动态修改配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; config set slowlog-log-slower-than 1000  </span><br><span class="line">OK  </span><br><span class="line">&gt; config set slowlog-max-len 1200  </span><br><span class="line">OK  </span><br><span class="line">&gt; config rewrite  </span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>3、如何获取慢查询日志？</p><p>可以使用 <code>slowlog get</code> 命令获取慢查询日志，在 <code>slowlog get</code> 后面还可以加一个数字，用于指定获取慢查询日志的条数，比如，获取 2 条慢查询日志：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; slowlog get 3  </span><br><span class="line">1) 1) (integer) 6107  </span><br><span class="line">   2) (integer) 1616398930  </span><br><span class="line">   3) (integer) 3109  </span><br><span class="line">   4) 1) &quot;config&quot;  </span><br><span class="line">      2) &quot;rewrite&quot;  </span><br><span class="line">2) 1) (integer) 6106  </span><br><span class="line">   2) (integer) 1613701788  </span><br><span class="line">   3) (integer) 36004  </span><br><span class="line">   4) 1) &quot;flushall&quot;</span><br></pre></td></tr></table></figure><p>可以看出每一条慢查询日志都有 4 个属性组成：</p><ol><li><p>唯一标识 ID</p></li><li><p>命令执行的时间戳</p></li><li><p>命令执行时长</p></li><li><p>执行的命名和参数</p></li></ol><p>此外，可以通过 <code>slowlog len</code> 命令获取慢查询日志的长度；通过 <code>slowlog reset</code> 命令清理慢查询日志。</p><h3 id="Pipeline（流水线）机制"><a href="#Pipeline（流水线）机制" class="headerlink" title="Pipeline（流水线）机制"></a>Pipeline（流水线）机制</h3><p>Redis 提供了批量操作命令（例如 mget、mset 等），有效地节约 RTT。但大部分命令是不支持批量操作的，例如要执行 n 次 hgetall 命令，并没有 mhgetall 命令存在，需要消耗 n 次 RTT。</p><p>Redis 的客户端和服务端可能部署在不同的机器上。例如客户端在北京，Redis 服务端在上海，两地直线距离约为 1300 公里，那么 1 次 RTT 时间 = 1300×2/(300000×2/3) = 13 毫秒（光在真空中 传输速度为每秒 30 万公里，这里假设光纤为光速的 2/3），那么客户端在 1 秒 内大约只能执行 80 次左右的命令，这个和 Redis 的高并发高吞吐特性背道而驰。</p><p>Pipeline（流水线）机制能改善上面这类问题，它能将一组 Redis 命令进 行组装，通过一次 RTT 传输给 Redis，再将这组 Redis 命令的执行结果按顺序返回给客户端。</p><p>不使用 Pipeline 的命令执行流程：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/bade6c256e4173e7cedddb23a4264294.jpeg" alt=""></p><p>使用 Pipeline 的命令执行流程：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/d36a7a171cdb69008db0631bf281c865.jpeg" alt=""></p><p>Redis 的流水线是一种通信协议，没有办法通过客户端演示给大家，这里以 Jedis 为例，通过 Java API 或者使用 Spring 操作它（代码来源于互联网）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**  </span><br><span class="line"> * 测试Redis流水线  </span><br><span class="line"> * @author liu  </span><br><span class="line"> *&#x2F;  </span><br><span class="line">publicclass TestPipelined &#123;  </span><br><span class="line">  </span><br><span class="line">    &#x2F;**  </span><br><span class="line">     * 使用Java API测试流水线的性能  </span><br><span class="line">     *&#x2F;  </span><br><span class="line">    @SuppressWarnings(&#123; &quot;unused&quot;, &quot;resource&quot; &#125;)  </span><br><span class="line">    @Test  </span><br><span class="line">    public void testPipelinedByJavaAPI() &#123;  </span><br><span class="line">        JedisPoolConfig jedisPoolConfig &#x3D; new JedisPoolConfig();  </span><br><span class="line">        jedisPoolConfig.setMaxIdle(20);  </span><br><span class="line">        jedisPoolConfig.setMaxTotal(10);  </span><br><span class="line">        jedisPoolConfig.setMaxWaitMillis(20000);  </span><br><span class="line">  </span><br><span class="line">        JedisPool jedisPool &#x3D; new JedisPool(jedisPoolConfig,&quot;localhost&quot;,6379);  </span><br><span class="line">        Jedis jedis &#x3D; jedisPool.getResource();  </span><br><span class="line">        long start &#x3D; System.currentTimeMillis();  </span><br><span class="line">        &#x2F;&#x2F; 开启流水线  </span><br><span class="line">        Pipeline pipeline &#x3D; jedis.pipelined();  </span><br><span class="line">        &#x2F;&#x2F; 测试10w条数据读写  </span><br><span class="line">        for(int i &#x3D; 0; i &lt; 100000; i++) &#123;  </span><br><span class="line">            int j &#x3D; i + 1;  </span><br><span class="line">            pipeline.set(&quot;key&quot; + j, &quot;value&quot; + j);  </span><br><span class="line">            pipeline.get(&quot;key&quot; + j);  </span><br><span class="line">        &#125;  </span><br><span class="line">        &#x2F;&#x2F; 只执行同步但不返回结果  </span><br><span class="line">        &#x2F;&#x2F;pipeline.sync();  </span><br><span class="line">        &#x2F;&#x2F; 以list的形式返回执行过的命令的结果  </span><br><span class="line">        List&lt;Object&gt; result &#x3D; pipeline.syncAndReturnAll();  </span><br><span class="line">        long end &#x3D; System.currentTimeMillis();  </span><br><span class="line">        &#x2F;&#x2F; 计算耗时  </span><br><span class="line">        System.out.println(&quot;耗时&quot; + (end - start) + &quot;毫秒&quot;);  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    &#x2F;**  </span><br><span class="line">     * 使用RedisTemplate测试流水线  </span><br><span class="line">     *&#x2F;  </span><br><span class="line">    @SuppressWarnings(&#123; &quot;resource&quot;, &quot;rawtypes&quot;, &quot;unchecked&quot;, &quot;unused&quot; &#125;)  </span><br><span class="line">    @Test  </span><br><span class="line">    public void testPipelineBySpring() &#123;  </span><br><span class="line">        ApplicationContext applicationContext &#x3D; new ClassPathXmlApplicationContext(&quot;spring.xml&quot;);  </span><br><span class="line">        RedisTemplate rt &#x3D; (RedisTemplate)applicationContext.getBean(&quot;redisTemplate&quot;);  </span><br><span class="line">        SessionCallback callback &#x3D; (SessionCallback)(RedisOperations ops)-&gt;&#123;  </span><br><span class="line">            for(int i &#x3D; 0; i &lt; 100000; i++) &#123;  </span><br><span class="line">                int j &#x3D; i + 1;  </span><br><span class="line">                ops.boundValueOps(&quot;key&quot; + j).set(&quot;value&quot; + j);  </span><br><span class="line">                ops.boundValueOps(&quot;key&quot; + j).get();  </span><br><span class="line">            &#125;  </span><br><span class="line">            returnnull;  </span><br><span class="line">        &#125;;  </span><br><span class="line">        long start &#x3D; System.currentTimeMillis();  </span><br><span class="line">        &#x2F;&#x2F; 执行Redis的流水线命令  </span><br><span class="line">        List result &#x3D; rt.executePipelined(callback);  </span><br><span class="line">        long end &#x3D; System.currentTimeMillis();  </span><br><span class="line">        System.out.println(end - start);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>网上写的测试结果为：使用 Java API 耗时在 550ms 到 700ms 之间，也就是不到 1s 就完成了 10 万次读写，使用 Spring 耗时在 1100ms 到 1300ms 之间。这个与之前一条一条命令使用，1s 内就发送几十几百条（客户端和服务端距离导致）命令的差距不是一般的大了。</p><p>注意，这里只是为了测试性能而已，当你要执行很多的命令并返回结果的时候，需要考虑 List 对象的大小，因为它会“吃掉”服务器上许多的内存空间，严重时会导致内存不足，引发 JVM 溢出异常，所以在工作环境中，是需要读者自己去评估的，可以考虑使用迭代的方式去处理。</p><h3 id="事务与-Lua"><a href="#事务与-Lua" class="headerlink" title="事务与 Lua"></a>事务与 Lua</h3><h4 id="multi-和-exec-命令"><a href="#multi-和-exec-命令" class="headerlink" title="multi 和 exec 命令"></a>multi 和 exec 命令</h4><p>很多情况下我们需要一次执行不止一个命令，而且需要其同时成功或者失败。为了保证多条命令组合的原子性，Redis 提供了简单的事务功能以及集成 Lua 脚本来解决这个问题。</p><p>Redis 提供了简单的事务功能，将一组需要一起执行的命令放到 multi 和 exec 两个命令之间。Multi 命令代表事务开始，exec 命令代表事务结束，它们之间的命令是原子顺序执行的。使用案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; multi  </span><br><span class="line">OK  </span><br><span class="line">127.0.0.1:6379&gt; SET msg &quot;hello chrootliu&quot;  </span><br><span class="line">QUEUED  </span><br><span class="line">127.0.0.1:6379&gt; GET msg  </span><br><span class="line">QUEUED  </span><br><span class="line">127.0.0.1:6379&gt; EXEC  </span><br><span class="line">1) OK  </span><br><span class="line">1) hello chrootliu</span><br></pre></td></tr></table></figure><p>Redis 提供了简单的事务，之所以说它简单，主要是因为它不支持事务中的回滚特性，同时无法实现命令之间的逻辑关系计算，主要有以下几点：</p><ol><li><p><strong>不够满足原子性</strong>。一个事务执行过程中，其他事务或 client 是可以对相应的 key 进行修改的（并发情况下，例如电商常见的超卖问题），想要避免这样的并发性问题就需要使用 WATCH 命令，但是通常来说，必须经过仔细考虑才能决定究竟需要对哪些 key 进行 WATCH 加锁。然而，额外的 WATCH 会增加事务失败的可能，而缺少必要的 WATCH 又会让我们的程序产生竞争条件。</p></li><li><p><strong>后执行的命令无法依赖先执行命令的结果</strong>。由于事务中的所有命令都是互相独立的，在遇到 exec 命令之前并没有真正的执行，所以我们无法在事务中的命令中使用前面命令的查询结果。我们唯一可以做的就是通过 watch 保证在我们进行修改时，如果其它事务刚好进行了修改，则我们的修改停止，然后应用层做相应的处理。</p></li><li><p><strong>事务中的每条命令都会与 Redis 服务器进行网络交互</strong>。Redis 事务开启之后，每执行一个操作返回的都是 queued，这里就涉及到客户端与服务器端的多次交互，明明是需要一次批量执行的 n 条命令，还需要通过多次网络交互，显然非常浪费（这个就是为什么会有 pipeline 的原因，减少 RTT 的时间）。</p></li></ol><h4 id="Redis-事务缺陷的解决-–-Lua"><a href="#Redis-事务缺陷的解决-–-Lua" class="headerlink" title="Redis 事务缺陷的解决 – Lua"></a>Redis 事务缺陷的解决 – Lua</h4><p>Lua 是一个小巧的脚本语言，用标准 C 编写，几乎在所有操作系统和平台上都可以编译运行。一个完整的 Lua 解释器不过 200k，在目前所有脚本引擎中，Lua 的速度是最快的，这一切都决定了 Lua 是作为嵌入式脚本的最佳选择。</p><p>Redis 2.6 版本之后内嵌了一个 Lua 解释器，可以用于一些简单的事务与逻辑运算，也可帮助开发者定制自己的 Redis 命令（例如：一次性的执行复杂的操作，和带有逻辑判断的操作），在这之前，必须修改源码。</p><p>在 Redis 中执行 Lua 脚本有两种方法：eval 和 evalsha，这里以 eval 做为案例介绍：</p><p>eval 语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eval script numkeys key [key ...] arg [arg ...]</span><br></pre></td></tr></table></figure><p>其中：</p><ul><li><p>script 一段 Lua 脚本或 Lua 脚本文件所在路径及文件名</p></li><li><p>numkeys Lua 脚本对应参数数量</p></li><li><p>key [key …] Lua 中通过全局变量 KEYS 数组存储的传入参数</p></li><li><p>arg [arg …] Lua 中通过全局变量 ARGV 数组存储的传入附加参数</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">EVAL &quot;return &#123;KEYS[1],KEYS[2],ARGV[1],ARGV[2]&#125;&quot; 2 key1 key2 first second  </span><br><span class="line">1) &quot;key1&quot;  </span><br><span class="line">2) &quot;key2&quot;  </span><br><span class="line">3) &quot;first&quot;  </span><br><span class="line">4) &quot;second&quot;</span><br></pre></td></tr></table></figure><p>Lua 执行流程图:</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/e6ce4be3121a718ed16c4b1a0b35b3a2.jpeg" alt=""></p><p><strong>SCRIPT LOAD 与 EVALSHA 命令</strong></p><p>对于不立即执行的 Lua 脚本，或需要重用的 Lua 脚本，可以通过 SCRIPT LOAD 提前载入 Lua 脚本，这个命令会立即返回对应的 SHA1 校验码</p><p>当需要执行函数时，通过 EVALSHA 调用 SCRIPT LOAD 返回的 SHA1 即可</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">SCRIPT LOAD &quot;return &#123;KEYS[1],KEYS[2],ARGV[1],ARGV[2]&#125;&quot;  </span><br><span class="line">&quot;232fd51614574cf0867b83d384a5e898cfd24e5a&quot;  </span><br><span class="line">  </span><br><span class="line">EVALSHA &quot;232fd51614574cf0867b83d384a5e898cfd24e5a&quot; 2 key1 key2 first second  </span><br><span class="line">1) &quot;key1&quot;  </span><br><span class="line">2) &quot;key2&quot;  </span><br><span class="line">3) &quot;first&quot;  </span><br><span class="line">4) &quot;second&quot;</span><br></pre></td></tr></table></figure><p><strong>通过 Lua 脚本执行 Redis 命令</strong></p><p>在 Lua 脚本中，只要使用 <code>redis.call()</code> 或 <code>redis.pcall()</code> 传入 Redis 命令就可以直接执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eval &quot;return redis.call(&#39;set&#39;,KEYS[1],&#39;bar&#39;)&quot; 1 foo     --等同于在服务端执行 set foo bar</span><br></pre></td></tr></table></figure><p>案例，使用 Lua 脚本实现访问频率限制：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">--  </span><br><span class="line">-- KEYS[1] 要限制的ip  </span><br><span class="line">-- ARGV[1] 限制的访问次数  </span><br><span class="line">-- ARGV[2] 限制的时间  </span><br><span class="line">--  </span><br><span class="line">  </span><br><span class="line">local key &#x3D; &quot;rate.limit:&quot; .. KEYS[1]  </span><br><span class="line">local limit &#x3D; tonumber(ARGV[1])  </span><br><span class="line">local expire_time &#x3D; ARGV[2]  </span><br><span class="line">  </span><br><span class="line">local is_exists &#x3D; redis.call(&quot;EXISTS&quot;, key)  </span><br><span class="line">if is_exists &#x3D;&#x3D; 1then  </span><br><span class="line">    if redis.call(&quot;INCR&quot;, key) &gt; limit then  </span><br><span class="line">        return0  </span><br><span class="line">    else  </span><br><span class="line">        return1  </span><br><span class="line">    end  </span><br><span class="line">else  </span><br><span class="line">    redis.call(&quot;SET&quot;, key, 1)  </span><br><span class="line">    redis.call(&quot;EXPIRE&quot;, key, expire_time)  </span><br><span class="line">    return1  </span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>使用方法，通过：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">eval(file_get_contents(storage_path(&quot;limit.lua&quot;)), 3, &quot;127.0.0.1&quot;, &quot;3&quot;, &quot;100&quot;);</span><br></pre></td></tr></table></figure><p>redis 的事务与 Lua，就先介绍到这里了，更多的用法大家请查看 Lua 官方文档</p><h3 id="Bitmaps"><a href="#Bitmaps" class="headerlink" title="Bitmaps"></a>Bitmaps</h3><p>许多开发语言都提供了操作位的功能，合理地使用位能够有效地提高内存使用率和开发效率。Redis 提供了 Bitmaps 这个“数据结构”可以实现对位的操作。把数据结构加上引号主要因为：</p><ul><li><p>Bitmaps 本身不是一种数据结构，实际上它就是字符串，但是它可以对字符串的位进行操作。</p></li><li><p>Bitmaps 单独提供了一套命令，所以在 Redis 中使用 Bitmaps 和使用字符串的方法不太相同。可以把 Bitmaps 想象成一个以位为单位的数组，数组的每个单元只能存储 0 和 1，数组的下标在 Bitmaps 中叫做偏移量。</p></li></ul><p>在我们平时开发过程中，会有一些 bool 型数据需要存取，比如用户一年的签到记录， 签了是 1，没签是 0，要记录 365 天。如果使用普通的 key/value，每个用户要记录 365 个，当用户上亿的时候，需要的存储空间是惊人的。为了解决这个问题，Redis 提供了位图数据结构，这样每天的签到记录只占据一个位， 365 天就是 365 个位，46 个字节 (一个稍长一点的字符串) 就可以完全容纳下，这就大大节约了存储空间。</p><p>语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">setbit key offset value  # 设置或者清空 key 的 value(字符串)在 offset 处的 bit 值  </span><br><span class="line">getbit key offset  # 返回 key 对应的 string 在 offset 处的 bit 值  </span><br><span class="line">bitcount key [start end] # start end 范围内被设置为1的数量，不传递 start end 默认全范围</span><br></pre></td></tr></table></figure><p>使用案例，统计用户登录（活跃）情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; setbit userLogin:2021-04-10 66666 1 #userId&#x3D;66666的用户登录，这是今天登录的第一个用户。  </span><br><span class="line">(integer) 0  </span><br><span class="line">127.0.0.1:6379&gt; setbit userLogin:2021-04-10 999999 1 #userId&#x3D;999999的用户登录，这是今天第二个登录、的用户。  </span><br><span class="line">(integer) 0  </span><br><span class="line">127.0.0.1:6379&gt; setbit userLogin:2021-04-10 3333 1  </span><br><span class="line">(integer) 0  </span><br><span class="line">127.0.0.1:6379&gt; setbit userLogin:2021-04-10 8888 1  </span><br><span class="line">(integer) 0  </span><br><span class="line">127.0.0.1:6379&gt; setbit userLogin:2021-04-10 100000 1  </span><br><span class="line">(integer) 0  </span><br><span class="line">  </span><br><span class="line">127.0.0.1:6379&gt; getbit active:2021-04-10 66666  </span><br><span class="line">(integer) 1  </span><br><span class="line">127.0.0.1:6379&gt; getbit active:2021-04-10 55555  </span><br><span class="line">(integer)  </span><br><span class="line">  </span><br><span class="line">127.0.0.1:6379&gt; bitcount active:2021-04-10  </span><br><span class="line">(integer) 5</span><br></pre></td></tr></table></figure><p>由于 bit 数组的每个位置只能存储 0 或者 1 这两个状态；所以对于实际生活中，处理两个状态的业务场景就可以考虑使用 bitmaps。如用户登录/未登录，签到/未签到，关注/未关注，打卡/未打卡等。同时 bitmap 还通过了相关的统计方法进行快速统计。</p><h3 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h3><p>HyperLogLog 并不是一种新的数据结构（实际类型为字符串类型），而 是一种基数算法，通过 HyperLogLog 可以利用极小的内存空间完成独立总数的统计，数据集可以是 IP、Email、ID 等。</p><p>HyperLogLog 提供了 3 个命令：pfadd、pfcount、pfmerge。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"># 用于向 HyperLogLog 添加元素  </span><br><span class="line"># 如果 HyperLogLog 估计的近似基数在 PFADD 命令执行之后出现了变化， 那么命令返回 1 ， 否则返回 0  </span><br><span class="line"># 如果命令执行时给定的键不存在， 那么程序将先创建一个空的 HyperLogLog 结构， 然后再执行命令  </span><br><span class="line">pfadd key value1 [value2 value3]  </span><br><span class="line">  </span><br><span class="line"># PFCOUNT 命令会给出 HyperLogLog 包含的近似基数  </span><br><span class="line"># 在计算出基数后， PFCOUNT 会将值存储在 HyperLogLog 中进行缓存，知道下次 PFADD 执行成功前，就都不需要再次进行基数的计算。  </span><br><span class="line">pfcount key  </span><br><span class="line">  </span><br><span class="line"># PFMERGE 将多个 HyperLogLog 合并为一个 HyperLogLog ， 合并后的 HyperLogLog 的基数接近于所有输入 HyperLogLog 的并集基数。  </span><br><span class="line">pfmerge destkey key1 key2 [...keyn]  </span><br><span class="line">127.0.0.1:6379&gt; pfadd totaluv user1  </span><br><span class="line">(integer) 1  </span><br><span class="line">127.0.0.1:6379&gt; pfcount totaluv  </span><br><span class="line">(integer) 1  </span><br><span class="line">127.0.0.1:6379&gt; pfadd totaluv user2  </span><br><span class="line">(integer) 1  </span><br><span class="line">127.0.0.1:6379&gt; pfcount totaluv  </span><br><span class="line">(integer) 2  </span><br><span class="line">127.0.0.1:6379&gt; pfadd totaluv user3  </span><br><span class="line">(integer) 1  </span><br><span class="line">127.0.0.1:6379&gt; pfcount totaluv  </span><br><span class="line">(integer) 3  </span><br><span class="line">127.0.0.1:6379&gt; pfadd totaluv user4  </span><br><span class="line">(integer) 1  </span><br><span class="line">127.0.0.1:6379&gt; pfcount totaluv  </span><br><span class="line">(integer) 4  </span><br><span class="line">127.0.0.1:6379&gt; pfadd totaluv user5  </span><br><span class="line">(integer) 1  </span><br><span class="line">127.0.0.1:6379&gt; pfcount totaluv  </span><br><span class="line">(integer) 5  </span><br><span class="line">127.0.0.1:6379&gt; pfadd totaluv user6 user7 user8 user9 user10  </span><br><span class="line">(integer) 1  </span><br><span class="line">127.0.0.1:6379&gt; pfcount totaluv  </span><br><span class="line">(integer) 10</span><br></pre></td></tr></table></figure><p>HyperLogLog 内存占用量非常小，但是存在错误率，开发者在进行数据 229 结构选型时只需要确认如下两条即可：</p><ol><li><p>只为了计算独立总数，不需要获取单条数据。</p></li><li><p>可以容忍一定误差率，毕竟 HyperLogLog 在内存的占用量上有很大的优势。</p></li></ol><p>例如：如果你负责开发维护一个大型的网站，有一天老板找产品经理要网站每个网页每天的 UV 数据，然后让你来开发这个统计模块，你会如何实现?</p><p>如果统计 PV 那非常好办，给每个网页一个独立的 Redis 计数器就可以了，这个计数器 的 key 后缀加上当天的日期。这样来一个请求，incrby 一次，最终就可以统计出所有的 PV 数据。</p><p>但是 UV 不一样，它要去重，同一个用户一天之内的多次访问请求只能计数一次。这就 要求每一个网页请求都需要带上用户的 ID，无论是登录用户还是未登录用户都需要一个唯一 ID 来标识。</p><p>你也许已经想到了一个简单的方案，那就是为每一个页面一个独立的 set 集合来存储所 有当天访问过此页面的用户 ID。当一个请求过来时，我们使用 sadd 将用户 ID 塞进去就可 以了。通过 scard 可以取出这个集合的大小，这个数字就是这个页面的 UV 数据。没错，这是一个非常简单的方案。</p><p>但是，如果你的页面访问量非常大，比如一个爆款页面几千万的 UV，你需要一个很大 的 set 集合来统计，这就非常浪费空间。如果这样的页面很多，那所需要的存储空间是惊人 的。为这样一个去重功能就耗费这样多的存储空间，值得么?其实老板需要的数据又不需要 太精确，105w 和 106w 这两个数字对于老板们来说并没有多大区别，So，有没有更好的解 决方案呢?</p><p>Redis 提供了 HyperLogLog 数据结构就是用来解决 这种统计问题的。HyperLogLog 提供不精确的去重计数方案，虽然不精确但是也不是非常不精确，标准误差是 0.81%，这样的精确度已经可以满足上面的 UV 统计需求了。</p><p>对于上面的场景，同学们可能有疑问，我或许同样可以使用 HashMap、BitMap 和 HyperLogLog 来解决。对于这三种解决方案，这边做下对比：</p><ul><li><p>HashMap：算法简单，统计精度高，对于少量数据建议使用，但是对于大量的数据会占用很大内存空间；</p></li><li><p>BitMap：位图算法，具体内容可以参考我的这篇文章，统计精度高，虽然内存占用要比 HashMap 少，但是对于大量数据还是会占用较大内存；</p></li><li><p>HyperLogLog：存在一定误差，占用内存少，稳定占用 12k 左右内存，可以统计 2^64 个元素，对于上面举例的应用场景，建议使用。</p></li></ul><h3 id="发布订阅"><a href="#发布订阅" class="headerlink" title="发布订阅"></a>发布订阅</h3><p>Redis 提供了基于“发布/订阅”模式的消息机制，此种模式下，消息发布者和订阅者不进行直接通信，发布者客户端向指定的频道（channel）发布消 息，订阅该频道的每个客户端都可以收到该消息：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/585b0ae93c8a31045d0ac1c7266944ec.jpeg" alt=""></p><p>主要对应的 Redis 命令为:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">subscribe channel [channel ...] # 订阅一个或多个频道  </span><br><span class="line">unsubscribe channel # 退订指定频道  </span><br><span class="line">publish channel message # 发送消息  </span><br><span class="line">psubscribe pattern # 订阅指定模式  </span><br><span class="line">punsubscribe pattern # 退订指定模式</span><br></pre></td></tr></table></figure><p>使用案例：</p><p>打开一个 Redis 客户端，如向 TestChanne 说一声 hello:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; publish TestChanne hello  </span><br><span class="line">(integer) 1 # 返回的是接收这条消息的订阅者数量</span><br></pre></td></tr></table></figure><p>这样消息就发出去了。发出去的消息不会被持久化，也就是有客户端订阅 TestChanne 后只能接收到后续发布到该频道的消息，之前的就接收不到了。</p><p>打开另一 Redis 个客户端，这里假设发送消息之前就打开并且订阅了 TestChanne 频道：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; subscribe TestChanne # 执行上面命令客户端会进入订阅状态  </span><br><span class="line">Reading messages... (press Ctrl-C to quit)  </span><br><span class="line">1) &quot;subscribe&quot; &#x2F;&#x2F; 消息类型  </span><br><span class="line">2) &quot;TestChanne&quot; &#x2F;&#x2F; 频道  </span><br><span class="line">3) &quot;hello&quot; &#x2F;&#x2F; 消息内容</span><br></pre></td></tr></table></figure><p>我们可以利用 Redis 发布订阅功能，实现的简单 MQ 功能，实现上下游的解耦。不过需要注意了，由于 Redis 发布的消息不会被持久化，这就会导致新订阅的客户端将不会收到历史消息。所以，如果当前的业务场景不能容忍这些缺点，那还是用专业 MQ 吧。</p><h3 id="GEO"><a href="#GEO" class="headerlink" title="GEO"></a>GEO</h3><p>Redis3.2 版本提供了 GEO（地理信息定位）功能，支持存储地理位置信 息用来实现诸如附近位置、摇一摇这类依赖于地理位置信息的功能，对于需 要实现这些功能的开发者来说是一大福音。GEO 功能是 Redis 的另一位作者 Matt Stancliff 借鉴 NoSQL 数据库 Ardb 实现的，Ardb 的作者来自中国，它提供了优秀的 GEO 功能。</p><p>Redis GEO 相关的命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"># 添加一个空间元素,longitude、latitude、member分别是该地理位置的经度、纬度、成员  </span><br><span class="line"># 这里的成员就是指代具体的业务数据，比如说用户的ID等  </span><br><span class="line"># 需要注意的是Redis的纬度有效范围不是[-90,90]而是[-85,85]  </span><br><span class="line"># 如果在添加一个空间元素时，这个元素中的menber已经存在key中，那么GEOADD命令会返回0,相当于更新了这个menber的位置信息  </span><br><span class="line">GEOADD key longitude latitude member [longitude latitude member]  </span><br><span class="line"># 用于添加城市的坐标信息  </span><br><span class="line">geoadd cities:locations 117.12 39.08 tianjin 114.29 38.02 shijiazhuang 118.01 39.38 tangshan 115.29 38.51 baoding  </span><br><span class="line">  </span><br><span class="line"># 获取地理位置信息  </span><br><span class="line">geopos key member [member ...]  </span><br><span class="line"># 获取天津的坐标  </span><br><span class="line">geopos cities:locations tianjin  </span><br><span class="line">  </span><br><span class="line"># 获取两个坐标之间的距离  </span><br><span class="line"># unit代表单位，有4个单位值  </span><br><span class="line">  - m (meter) 代表米  </span><br><span class="line">  - km （kilometer）代表千米  </span><br><span class="line">  - mi （miles）代表英里  </span><br><span class="line">  - ft （ft）代表尺  </span><br><span class="line">geodist key member1 member2 [unit]  </span><br><span class="line"># 获取天津和保定之间的距离  </span><br><span class="line">GEODIST cities:locations tianjin baoding km  </span><br><span class="line">  </span><br><span class="line"># 获取指定位置范围内的地理信息位置集合，此命令可以用于实现附近的人的功能  </span><br><span class="line"># georadius和georadiusbymember两个命令的作用是一样的，都是以一个地理位置为中心算出指定半径内的其他地理信息位置，不同的是georadius命令的中心位置给出了具体的经纬度，georadiusbymember只需给出成员即可。其中radiusm|km|ft|mi是必需参数，指定了半径（带单位），这两个命令有很多可选参数，参数含义如下：  </span><br><span class="line"># - withcoord：返回结果中包含经纬度。  </span><br><span class="line"># - withdist：返回结果中包含离中心节点位置的距离。  </span><br><span class="line"># - withhash：返回结果中包含geohash，有关geohash后面介绍。  </span><br><span class="line"># - COUNT count：指定返回结果的数量。  </span><br><span class="line"># - asc|desc：返回结果按照离中心节点的距离做升序或者降序。  </span><br><span class="line"># - store key：将返回结果的地理位置信息保存到指定键。  </span><br><span class="line"># - storedist key：将返回结果离中心节点的距离保存到指定键。  </span><br><span class="line">georadius key longitude latitude radiusm|km|ft|mi [withcoord] [withdist] [withhash] [COUNT count] [asc|desc] [store key] [storedist key]  </span><br><span class="line">  </span><br><span class="line">georadiusbymember key member radiusm|km|ft|mi [withcoord] [withdist] [withhash] [COUNT count] [asc|desc] [store key] [storedist key]  </span><br><span class="line">  </span><br><span class="line"># 获取geo hash  </span><br><span class="line"># Redis使用geohash将二维经纬度转换为一维字符串，geohash有如下特点：  </span><br><span class="line"># - GEO的数据类型为zset，Redis将所有地理位置信息的geohash存放在zset中。  </span><br><span class="line"># - 字符串越长，表示的位置更精确，表3-8给出了字符串长度对应的精度，例如geohash长度为9时，精度在2米左右。长度和精度的对应关系，请参考：https:&#x2F;&#x2F;easyreadfs.nosdn.127.net&#x2F;9F42_CKRFsfc8SUALbHKog&#x3D;&#x3D;&#x2F;8796093023252281390  </span><br><span class="line"># - 两个字符串越相似，它们之间的距离越近，Redis利用字符串前缀匹配算法实现相关的命令。  </span><br><span class="line"># - geohash编码和经纬度是可以相互转换的。  </span><br><span class="line"># - Redis正是使用有序集合并结合geohash的特性实现了GEO的若干命令。  </span><br><span class="line">geohash key member [member ...]  </span><br><span class="line">  </span><br><span class="line"># 删除操作，GEO没有提供删除成员的命令，但是因为GEO的底层实现是zset，所以可以借用zrem命令实现对地理位置信息的删除。  </span><br><span class="line">zrem key member</span><br></pre></td></tr></table></figure><p>使用案例，例如咋部门是做直播的，那直播业务一般会有一个“附近的直播”功能，这里就可以考虑用 Redis 的 GEO 技术来完成这个功能。</p><p>数据操作主要有两个：一是主播开播的时候写入主播 Id 的经纬度，二是主播关播的时候删除主播 Id 元素。这样就维护了一个具有位置信息的在线主播集合提供给线上检索。</p><p>大家具体使用的时候，可以去了解一下 Redis GEO 原理，主要用到了空间索引的算法 GEOHASH 的相关知识，针对索引我们日常所见都是一维的字符，那么如何对三维空间里面的坐标点建立索引呢，直接点就是三维变二维，二维变一维。这里就不再详细阐述了。</p><p><strong>Redis 客户端</strong></p><p>主流编程语言都有对应的常用 Redis 客户端，例如：</p><ul><li><p>java -&gt; Jedis</p></li><li><p>python -&gt; redis-py</p></li><li><p>node -&gt; ioredis</p></li></ul><p>具体使用语法，大家可以根据自己的需要查找对应的官方文档：</p><p>Jedis 文档：<a href="https://github.com/redis/jedis" target="_blank" rel="noopener">https://github.com/redis/jedis</a></p><p>redis-py 文档：<a href="https://github.com/redis/redis-py" target="_blank" rel="noopener">https://github.com/redis/redis-py</a></p><p>ioredis 文档：<a href="https://github.com/luin/ioredis" target="_blank" rel="noopener">https://github.com/luin/ioredis</a></p><h2 id="持久化、主从同步与缓存设计"><a href="#持久化、主从同步与缓存设计" class="headerlink" title="持久化、主从同步与缓存设计"></a>持久化、主从同步与缓存设计</h2><h3 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h3><p>Redis 支持 RDB 和 AOF 两种持久化机制，持久化功能有效地避免因进程 退出造成的数据丢失问题，当下次重启时利用之前持久化的文件即可实现数据恢复。</p><ul><li><p>RDB 是一次全量备份，AOF 日志是连续的增量备份， RDB 是内存数据的二进制序列化形式，在存储上非常紧凑，而 AOF 日志记录的是内存数据修改的指令记录文本。</p></li><li><p>AOF 以独立日志的方式记录每次写命令， 重启时再重新执行 AOF 文件中的命令达到恢复数据的目的。AOF 的主要作用 是解决了数据持久化的实时性，目前已经是 Redis 持久化的主流方式。</p></li></ul><p>AOF 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长。所以需要定期进行 AOF 重写，给 AOF 日志进行瘦身。</p><h4 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h4><p>我们知道 Redis 是单线程程序，这个线程要同时负责多个客户端套接字的并发读写操作和内存数据结构的逻辑读写。</p><p>在服务线上请求的同时，Redis 还需要进行内存 RDB，内存 RDB 要求 Redis 必须进行文件 IO 操作，可文件 IO 操作是不能使用多路复用 API。这意味着单线程同时在服务线上的请求还要进行文件 IO 操作，文件 IO 操作会严重拖垮服务器请求的性能。还有个重要的问题是为了不阻塞线上的业务，就需要边持久化边响应客户端请求。持久化的同时，内存数据结构还在改变，比如一个大型的 hash 字典正在持久化，结果一个请求过来把它给删掉了，还没持久化完呢，这可怎么办?</p><p>那该怎么办呢? Redis 使用操作系统的多进程 COW(Copy On Write) 机制来实现 RDB 持久化，以下为 RDB 备份流程：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/5d3cbe99807b87e5a3f0a95339cc905c.jpeg" alt=""></p><ol><li><p>执行 bgsave 命令，Redis 父进程判断当前是否存在正在执行的子进 程，如 RDB/AOF 子进程，如果存在 bgsave 命令直接返回。</p></li><li><p>父进程执行 fork 操作创建子进程，fork 操作过程中父进程会阻塞，通 过 info stats 命令查看 latest_fork_usec 选项，可以获取最近一个 fork 操作的耗 时，单位为微秒。</p></li><li><p>父进程 fork 完成后，bgsave 命令返回 “Background saving started” 信息 并不再阻塞父进程，可以继续响应其他命令。</p></li><li><p>子进程创建 RDB 文件，根据父进程内存生成临时快照文件，完成后 对原有文件进行原子替换。执行 lastsave 命令可以获取最后一次生成 RDB 的 时间，对应 info 统计的 rdb_last_save_time 选项。</p></li><li><p>进程发送信号给父进程表示完成，父进程更新统计信息，具体见 info Persistence 下的 rdb_* 相关选项。</p></li></ol><h4 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h4><p>AOF 日志存储的是 Redis 服务器的顺序指令序列，AOF 日志只记录对内存进行修改的 指令记录。</p><p>假设 AOF 日志记录了自 Redis 实例创建以来所有的修改性指令序列，那么就可以通过 对一个空的 Redis 实例顺序执行所有的指令，也就是「重放」，来恢复 Redis 当前实例的内 存数据结构的状态。</p><p>Redis 会在收到客户端修改指令后，先进行参数校验，如果没问题，就立即将该指令文本存储到 AOF 日志中，也就是先存到磁盘，然后再执行指令。这样即使遇到突发宕机，已经存储到 AOF 日志的指令进行重放一下就可以恢复到宕机前的状态。通过 appendfsync 参数可以控制实时/秒级持久化 。</p><p>AOF 流程:</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/7701524c20a74cdd7244a809c1fccbdc.jpeg" alt=""></p><ol><li><p>所有的写入命令会追加到 aof_buf(缓冲区)中。</p></li><li><p>AOF 缓冲区根据对应的策略向硬盘做同步操作。</p></li><li><p>随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。</p></li><li><p>当 Redis 服务器重启时，可以加载 AOF 文件进行数据恢复。</p></li></ol><p>Redis 在长期运行的过程中，AOF 的日志会越变越长。如果实例宕机重启，重放整个 AOF 日志会非常耗时，导致长时间 Redis 无法对外提供服务。所以需要对 AOF 日志瘦身。</p><p>Redis 提供了 bgrewriteaof 指令用于对 AOF 日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。</p><p>AOF 瘦身重写流程：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/d6b39b1ad148829663e7334838d79ae8.jpeg" alt=""></p><p>AOF 重写可以通过 auto-aof-rewrite-min-siz e 和 auto-aof-rewrite- percentage 参数控制自动触发，也可以使用 bgrewriteaof 命令手动触发。</p><p>子进程执行期间使用 copy-on-write 机制与父进程共享内存，避免内 存消耗翻倍。AOF 重写期间还需要维护重写缓冲区，保存新的写入命令避免 数据丢失。</p><p>单机下部署多个实例时，为了防止出现多个子进程执行重写操作， 建议做隔离控制，避免 CPU 和 IO 资源竞争。</p><h4 id="Redis-4-0-混合持久化"><a href="#Redis-4-0-混合持久化" class="headerlink" title="Redis 4.0 混合持久化"></a>Redis 4.0 混合持久化</h4><p>重启 Redis 时，我们很少使用 RDB 来恢复内存状态，因为会丢失大量数据。我们通常 使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实 例很大的情况下，启动需要花费很长的时间。</p><p>Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。将 RDB 文 件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自 持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。</p><p>于是在 Redis 重启的时候，可以先加载 RDB 的内容，然后再重放增量 AOF 日志就可 以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/8f2010881ec2f79295f9ec1850a8467b.jpeg" alt=""></p><h3 id="主从同步—简单了解"><a href="#主从同步—简单了解" class="headerlink" title="主从同步—简单了解"></a>主从同步—简单了解</h3><p>很多企业都没有使用到 Redis 的集群，但是至少都做了主从。有了主从，当 master 挂 掉的时候，运维让从库过来接管，服务就可以继续，否则 master 需要经过数据恢复和重启的过程，这就可能会拖很长的时间，影响线上业务的持续服务。</p><p>Redis 通过主从同步功能实现主节点的多个副本。从节点可灵活地通过 slaveof 命令建立或断开同步流程。同步复制分为：全量复制和部分增量复制主从节点之间维护心跳和偏移量检查机制，保证主从节点通信正常和数据一致。</p><p>Redis 为了保证高性能复制过程是异步的，写命令处理完后直接返回给客户端，不等待从节点复制完成。因此从节点数据集会有延迟情况。即当使用从节点用于读写分离时会存在数据延迟、过期数据、从节点可用性等问题，需要根据自身业务提前作出规避。</p><p>注意：在运维过程中，主节点存在多个从节点或者一台机器上部署大量主节点的情况下，会有复制风暴的风险。</p><p><strong>Redis Sentinel(哨兵)</strong></p><p>主从复制是 Redis 分布式的基础，Redis 的高可用离开了主从复制将无从进行。后面的我们会讲到 Redis 的集群模式，集群模式都依赖于本节所讲的主从复制。</p><p>不过复制功能也不是必须的，如果你将 Redis 只用来做缓存，也就无需要从库做备份，挂掉了重新启动一下就行。但是只要你使用了 Redis 的持久化 功能，就必须认真对待主从复制，它是系统数据安全的基础保障。</p><p>举例：如果主节点凌晨 3 点突发宕机怎么办?就坐等运维从床上爬起来，然后手工进行从主切换，再通知所有的程 序把地址统统改一遍重新上线么?毫无疑问，这样的人工运维效率太低，事故发生时估计得 至少 1 个小时才能缓过来。</p><p>Sentinel 负责持续监控主从节点的健康，当主节点挂掉时，自动选择一个最优的从节点切换为主节点。客户端来连接集群时，会首先连接 sentinel，通过 sentinel 来查询主节点的地址， 然后再去连接主节点进行数据交互。当主节点发生故障时，客户端会重新向 sentinel 要地址，sentinel 会将最新的主节点地址告诉客户端。如此应用程序将无需重启即可自动完成节点切换。如图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/0cad18a475b56dc543ca5f8a555571d1.jpeg" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/3d8db93c8231c9b2c90c975dd2185e27.jpeg" alt=""></p><h4 id="消息丢失"><a href="#消息丢失" class="headerlink" title="消息丢失"></a>消息丢失</h4><p>Redis 主从采用异步复制，意味着当主节点挂掉时，从节点可能没有收到全部的同步消息，这部分未同步的消息就丢失了。如果主从延迟特别大，那么丢失的数据就可能会特别 多。Sentinel 无法保证消息完全不丢失，但是也尽可能保证消息少丢失。它有两个选项可以 限制主从延迟过大：</p><ul><li><p>min-slaves-to-write 1</p></li><li><p>min-slaves-max-lag 10</p></li></ul><p>第一个参数表示主节点必须至少有一个从节点在进行正常复制，否则就停止对外写服务，丧失可用性。</p><p>何为正常复制，何为异常复制?这个就是由第二个参数控制的，它的单位是秒，表示如果 10s 没有收到从节点的反馈，就意味着从节点同步不正常，要么网络断开了，要么一直没有给反馈。</p><h4 id="Redis-最终一致"><a href="#Redis-最终一致" class="headerlink" title="Redis 最终一致"></a>Redis 最终一致</h4><p>Redis 的主从数据是异步同步的，所以分布式的 Redis 系统并不满足「一致性」要求。当客户端在 Redis 的主节点修改了数据后，立即返回，即使在主从网络断开的情况下，主节 点依旧可以正常对外提供修改服务，所以 Redis 满足「可用性」。</p><p>Redis 保证「最终一致性」，从节点会努力追赶主节点，最终从节点的状态会和主节点 的状态将保持一致。如果网络断开了，主从节点的数据将会出现大量不一致，一旦网络恢 复，从节点会采用多种策略努力追赶上落后的数据，继续尽力保持和主节点一致。</p><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><h4 id="缓存的收益与成本"><a href="#缓存的收益与成本" class="headerlink" title="缓存的收益与成本"></a>缓存的收益与成本</h4><p>收益：</p><ul><li><p>加速读写：CPU L1/L2/L3 Cache、浏览器缓存等。因为缓存通常都是全内存的（例如 Redis、Memcache），而 存储层通常读写性能不够强悍（例如 MySQL），通过缓存的使用可以有效 地加速读写，优化用户体验。</p></li><li><p>降低后端负载：帮助后端减少访问量和复杂计算，在很大程度降低了后端的负载。成本：</p></li><li><p>数据不一致：缓存层和数据层有时间窗口不一致，和更新策略有关。</p></li><li><p>代码维护成本：加入缓存后，需要同时处理缓存层和存储层的逻辑， 增大了开发者维护代码的成本。</p></li><li><p>运维成本：以 Redis Cluster 为例，加入后无形中增加了运维成本。使用场景：</p></li><li><p>降低后端负载：对高消耗的 SQL：join 结果集/分组统计结果缓存。</p></li><li><p>加速请求响应：利用 Redis/Memcache 优化 IO 响应时间。</p></li><li><p>大量写合并为批量写：比如计数器先 Redis 累加再批量写入 DB。</p></li></ul><h4 id="缓存更新策略—算法剔除"><a href="#缓存更新策略—算法剔除" class="headerlink" title="缓存更新策略—算法剔除"></a>缓存更新策略—算法剔除</h4><ul><li><p>LRU：Least Recently Used，最近最少使用。</p></li><li><p>LFU：Least Frequently Used，最不经常使用。</p></li><li><p>FIFO：First In First Out，先进先出。</p></li></ul><p>使用场景：剔除算法通常用于缓存使用量超过了预设的最大值时候，如何对现有的数据进行剔除。例如 Redis 使用 maxmemory-policy 这个配置作为内存最大值后对于数据的剔除策略。</p><p>一致性：要清理哪些数据是由具体算法决定，开发人员只能决定使用哪种算法，所以数据的一致性是最差的。</p><p>维护成本：算法不需要开发人员自己来实现，通常只需要配置最大 maxmemory 和对应的策略即可。</p><h4 id="缓存更新策略—超时剔除"><a href="#缓存更新策略—超时剔除" class="headerlink" title="缓存更新策略—超时剔除"></a>缓存更新策略—超时剔除</h4><p>使用场景：超时剔除通过给缓存数据设置过期时间，让其在过期时间后自动删除，例如 Redis 提供的 expire 命令。如果业务可以容忍一段时间内，缓存层数据和存储层数据不一致，那么可以为其设置过期时间。在数据过期后，再从真实数据源获取数据，重新放到缓存并设置过期时间。</p><p>一致性：一段时间窗口内（取决于过期时间长短）存在一致性问题，即缓存数据和真实数据源的数据不一致。</p><p>维护成本：维护成本不是很高，只需设置 expire 过期时间即可，当然前提是应用方允许这段时间可能发生的数据不一致。</p><h4 id="缓存更新策略—主动更新"><a href="#缓存更新策略—主动更新" class="headerlink" title="缓存更新策略—主动更新"></a>缓存更新策略—主动更新</h4><p>使用场景：应用方对于数据的一致性要求高，需要在真实数据更新后， 立即更新缓存数据。例如可以利用消息系统或者其他方式通知缓存更新。</p><p>一致性：一致性最高，但如果主动更新发生了问题，那么这条数据很可能很长时间不会更新，所以建议结合超时剔除一起使用效果会更好。</p><p>维护成本：维护成本会比较高，开发者需要自己来完成更新，并保证更新操作的正确性。</p><h4 id="缓存更新策略—总结"><a href="#缓存更新策略—总结" class="headerlink" title="缓存更新策略—总结"></a>缓存更新策略—总结</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/71ead4d6f009d6c3543d6a1190ab4682.jpeg" alt=""></p><p>低一致性业务：建议配置最大内存和淘汰策略的方式使用。</p><p>高一致性业务：可以结合使用超时剔除和主动更新，这样即使主动更新出了问题，也能保证数据过期时间后删除脏数据。</p><h4 id="缓存可能会遇到的问题"><a href="#缓存可能会遇到的问题" class="headerlink" title="缓存可能会遇到的问题"></a>缓存可能会遇到的问题</h4><p>缓存穿透：指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能 DB 就挂掉了，要是有人利用不存在的 key 频繁攻击我们的应用，这就是漏洞。解决方法：</p><ul><li><p>布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被 这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力。</p></li><li><p>另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。</p></li></ul><p>缓存雪崩：指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到 DB，DB 瞬时压力过重雪崩。解决方法：我们可以在原有的失效时间基础上增加一个随机值，比如 1-5 分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。</p><p>缓存击穿：对于一些设置了过期时间的 key，如果这些 key 可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一 key 缓存，前者则是很多 key。缓存在某个时间点过期的时候，恰好在这个时间点对这个 Key 有大量的并发请求过来，这些请求发现缓存过期一般都会从后端 DB 加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端 DB 压垮。解决方法：互斥锁、永远不过期设置、资源保护等等。</p><p>缓存无底洞问题：Facebook 的工作人员反应 2010 年已达到 3000 个 memcached 节点，储存数千 G 的缓存。他们发现一个问题– memcached 的连接效率下降了，于是添加 memcached 节点，添加完之后，并没有好转。称为“无底洞”现象。原因：客户端一次批量操作会涉及多次网络操作，也就意味着批量操作会随着实例的增多，耗时会不断增大。服务端网络连接次数变多，对实例的性能也有一定影响。即：更多的机器不代表更多的性能，所谓“无底洞”就是说投入越多不一定产出越多。解决方案有：串行 mget、串行 IO、并行 IO、Hash tag 实现等，更多请看：缓存无底洞问题（<a href="http://ifeve.com/redis-multiget-hole/）" target="_blank" rel="noopener">http://ifeve.com/redis-multiget-hole/）</a></p><h2 id="知识拓展"><a href="#知识拓展" class="headerlink" title="知识拓展"></a>知识拓展</h2><h3 id="缓存与数据库同步策略（如何保证缓存-Redis-与数据库-MySQL-的一致性？）"><a href="#缓存与数据库同步策略（如何保证缓存-Redis-与数据库-MySQL-的一致性？）" class="headerlink" title="缓存与数据库同步策略（如何保证缓存(Redis)与数据库(MySQL)的一致性？）"></a>缓存与数据库同步策略（如何保证缓存(Redis)与数据库(MySQL)的一致性？）</h3><p>对于热点数据（经常被查询，但不经常被修改的数据），我们一般会将其放入 Redis 缓存中，以增加查询效率，但需要保证从 Redis 中读取的数据与数据库中存储的数据最终是一致的，这就是经典的<strong>缓存与数据库同步问题</strong>。</p><p>那么，如何保证缓存(Redis)与数据库(MySQL)的一致性呢？根据缓存是删除还是更新，以及操作顺序大概是可以分为下面四种情况：</p><ol><li><p>先更新数据库，再更新缓存</p></li><li><p>先更新缓存，再更新数据库</p></li><li><p>先删除缓存，再更新数据库</p></li><li><p>先更新数据库，再删除缓存</p></li></ol><h4 id="删除缓存对比更新缓存"><a href="#删除缓存对比更新缓存" class="headerlink" title="删除缓存对比更新缓存"></a>删除缓存对比更新缓存</h4><ul><li><p>删除缓存: 数据只会写入数据库，不会写入缓存，只会删除缓存</p></li><li><p>更新缓存: 数据不但写入数据库，还会写入缓存</p></li></ul><p><strong>删除缓存</strong></p><ul><li><p>优点：操作简单，无论更新操作是否复杂，直接删除，并且能防止更新出现的线程安全问题</p></li><li><p>缺点：删除后，下一次查询无法在 cache 中查到，会有一次 Cache Miss，这时需要重新读取数据库，高并发下可能会出现上面说的缓存问题</p></li></ul><p><strong>更新缓存</strong></p><ul><li><p>优点：命中率高，直接更新缓存，不会有 Cache Miss 的情况</p></li><li><p>缺点：更新缓存消耗较大，尤其在复杂的操作流程中</p></li></ul><p>那到底是选择更新缓存还是删除缓存呢，主要取决于更新缓存的复杂度</p><ul><li><p>更新缓存的代价很小，此时我们应该更倾向于更新缓存，以保证更高的缓存命中率</p></li><li><p>更新缓存的代价很大，此时我们应该更倾向于删除缓存</p></li></ul><p>例如：只是简单的更新一下用户积分，只操作一个字段，那就可以采用更新缓存，还有类似秒杀下商品库存数量这种并发下查询频繁的数据，也可以使用更新缓存，不过也要注意线程安全的问题，防止产生脏数据。但是当更新操作的逻辑较复杂时，需要涉及到其它数据，如用户购买商品付款时，需要考虑打折、优惠券、红包等多种因素，这样需要缓存与数据库进行多次交互，将打折等信息传入缓存，再与缓存中的其它值进行计算才能得到最终结果，此时更新缓存的消耗要大于直接淘汰缓存。</p><p>所以还是要根据业务场景来进行选择，<strong>不过大部分场景下删除缓存操作简单，并且带来的副作用只是增加了一次 Cache Miss，建议作为通用的处理方式。</strong></p><h4 id="先更新数据库，再更新缓存"><a href="#先更新数据库，再更新缓存" class="headerlink" title="先更新数据库，再更新缓存"></a>先更新数据库，再更新缓存</h4><p>这种方式就适合更新缓存的代价很小的数据，例如上面说的用户积分，库存数量这类数据，同样还是要注意线程安全的问题。</p><p><strong>线程安全角度</strong></p><p>同时有请求 A 和请求 B 进行更新操作，那么会出现</p><ol><li><p>线程 A 更新了数据库</p></li><li><p>线程 B 更新了数据库</p></li><li><p>线程 B 更新了缓存</p></li><li><p>线程 A 更新了缓存</p></li></ol><p>这就出现请求 A 更新缓存应该比请求 B 更新缓存早才对，但是因为网络等原因，B 却比 A 更早更新了缓存，这就导致了脏数据。</p><p><strong>业务场景角度</strong></p><p>有如下两种不适合场景：</p><ol><li><p>如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能</p></li><li><p>如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是也浪费性能的</p></li></ol><h4 id="先更新缓存，再更新数据库"><a href="#先更新缓存，再更新数据库" class="headerlink" title="先更新缓存，再更新数据库"></a>先更新缓存，再更新数据库</h4><p>这种情况应该是和第一种情况一样会存在线程安全问题的，但是这种情况是有人使用过的，根据书籍《淘宝技术这十年》里，多隆把商品详情页放入缓存，采取的正是先更新缓存，再将缓存中的数据异步更新到数据库这种方式，有兴趣了解的可以查看这篇博客: <a href="https://www.cnblogs.com/rjzheng/p/9240611.html" target="_blank" rel="noopener">https://www.cnblogs.com/rjzheng/p/9240611.html</a></p><p>还有现在互联网常见的点赞功能，也可以采用这种方式，有兴趣了解的可以查看这篇文章: <a href="https://juejin.im/post/5bdc257e6fb9a049ba410098" target="_blank" rel="noopener">https://juejin.im/post/5bdc257e6fb9a049ba410098</a></p><h4 id="先删除缓存，再更新数据库"><a href="#先删除缓存，再更新数据库" class="headerlink" title="先删除缓存，再更新数据库"></a>先删除缓存，再更新数据库</h4><p>简单的想一下，好像这种方式不错，就算是第一步删除缓存成功，第二步写数据库失败，则只会引发一次 Cache Miss，对数据没有影响，其实仔细一想并发下也很容易导致了脏数据，例如</p><ol><li><p>请求 A 进行写操作，删除缓存</p></li><li><p>请求 B 查询发现缓存不存在</p></li><li><p>请求 B 去数据库查询得到旧值</p></li><li><p>请求 B 将旧值写入缓存</p></li><li><p>请求 A 将新值写入数据库</p></li></ol><p>那怎么解决呢，先看第四种情况（先更新数据库，再删除缓存），后面再统一说第三种和第四种的解决方案。</p><h4 id="先更新数据库，再删除缓存"><a href="#先更新数据库，再删除缓存" class="headerlink" title="先更新数据库，再删除缓存"></a>先更新数据库，再删除缓存</h4><p>先说一下，国外有人提出了一个缓存更新套路，名为 Cache-Aside Pattern：<a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/cache-aside" target="_blank" rel="noopener">https://docs.microsoft.com/en-us/azure/architecture/patterns/cache-aside</a></p><ul><li><p><strong>失效</strong>：应用程序先从 cache 取数据，没有得到，则从数据库中取数据，成功后，放到缓存中</p></li><li><p><strong>命中</strong>：应用程序从 cache 中取数据，渠道后返回</p></li><li><p><strong>更新</strong>：先把数据存到数据库中，成功后再让缓存失效</p></li></ul><p>更新操作就是先更新数据库，再删除缓存；读取操作先从缓存取数据，没有，则从数据库中取数据，成功后，放到缓存中；这是标准的设计方案，包括 Facebook 的论文 Scaling Memcache at Facebook：chrome-extension://ikhdkkncnoglghljlkmcimlnlhkeamad/pdf-viewer/web/viewer.html? file=https%3A%2F%2F<a href="http://www.usenix.org%2Fsystem%2Ffiles%2Fconference%2Fnsdi13%2Fnsdi13-final170\_update.pdf">www.usenix.org%2Fsystem%2Ffiles%2Fconference%2Fnsdi13%2Fnsdi13-final170\_update.pdf</a> 也使用了这个策略。</p><p>为什么他们都用这种方式呢，这种情况不存在并发问题么?</p><p>答案是也存在，但是出现概率比第三种低，例如：</p><ol><li><p>请求缓存刚好失效</p></li><li><p>请求 A 查询数据库，得一个旧值</p></li><li><p>请求 B 将新值写入数据库</p></li><li><p>请求 B 删除缓存</p></li><li><p>请求 A 将查到的旧值写入缓存</p></li></ol><p>这样就出现脏数据了，然而，实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作删除缓存，所有的这些条件都具备的概率基本并不大，但是还是会有出现的概率。</p><p>并且假如第一步写数据库成功，第二步删除缓存失败，这样也导致脏数据，请看解决方案。</p><h4 id="方案三四脏数据解决方案"><a href="#方案三四脏数据解决方案" class="headerlink" title="方案三四脏数据解决方案"></a>方案三四脏数据解决方案</h4><p>那怎么解决呢，可以采用<strong>延时双删策略(缓存双淘汰法)</strong>，可以将前面所造成的缓存脏数据，再次删除：</p><ol><li><p>先删除(淘汰)缓存</p></li><li><p>再写数据库（这两步和原来一样）</p></li><li><p>休眠 1 秒，再次删除(淘汰)缓存</p></li></ol><p>或者是：</p><ol><li><p>先写数据库</p></li><li><p>再删除(淘汰)缓存（这两步和原来一样）</p></li><li><p>休眠 1 秒，再次删除(淘汰)缓存</p></li></ol><p>这个 1 秒应该看你的业务场景，应该自行评估自己的项目的读数据业务逻辑的耗时，然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百毫秒即可，这么做确保读请求结束，写请求可以删除读请求造成的缓存脏数据。</p><p>如果你用了 MySql 的读写分离架构怎么办？，例如：</p><ol><li><p>请求 A 进行写操作，删除缓存</p></li><li><p>请求 A 将数据写入数据库了，(或者是先更新数据库，后删除缓存)</p></li><li><p>请求 B 查询缓存发现，缓存没有值</p></li><li><p>请求 B 去从库查询，这时，还没有完成主从同步，因此查询到的是旧值</p></li><li><p>请求 B 将旧值写入缓存</p></li><li><p>数据库完成主从同步，从库变为新值</p></li></ol><p>这种情景，就是数据不一致的原因，还是采用延时双删策略(缓存双淘汰法)，只是，休眠时间修改为在主从同步的延时时间基础上，加几百毫秒</p><p><strong>并且为了性能更快，可以把第二次删除缓存可以做成异步的，这样不会阻塞请求了，如果再严谨点，防止第二次删除缓存失败，这个异步删除缓存可以加上重试机制，失败一直重试，直到成功。</strong></p><p>这里给出两种重试机制参考</p><p>方案一</p><ol><li><p>更新数据库数据</p></li><li><p>缓存因为种种问题删除失败</p></li><li><p>将需要删除的 key 发送至消息队列</p></li><li><p>自己消费消息，获得需要删除的 key</p></li><li><p>继续重试删除操作，直到成功</p></li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9a5cd7d1f07a4d084b2f3e2275726a50.jpeg" alt=""></p><p>然而，该方案有一个缺点，对业务线代码造成大量的侵入，于是有了方案二，启动一个订阅程序去订阅数据库的 Binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作</p><p>方案二：</p><ol><li><p>更新数据库数据</p></li><li><p>数据库会将操作信息写入 binlog 日志当中</p></li><li><p>订阅程序提取出所需要的数据以及 key</p></li><li><p>另起一段非业务代码，获得该信息</p></li><li><p>尝试删除缓存操作，发现删除失败</p></li><li><p>将这些信息发送至消息队列</p></li><li><p>重新从消息队列中获得该数据，重试操作</p></li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/1384f11a03ecc27bd9f8f02eccac60fa.jpeg" alt=""></p><p>上述的订阅 Binlog 程序在 MySql 中有现成的中间件叫 Canal，可以完成订阅 Binlog 日志的功能，另外，重试机制，这里采用的是消息队列的方式。如果对一致性要求不是很高，直接在程序中另起一个线程，每隔一段时间去重试即可，这些大家可以灵活自由发挥，只是提供一个思路。</p><p><strong>总结：</strong> 大部分应该使用的都是第三种或第四种方式，如果都是采用延时双删策略(缓存双淘汰法)，可能区别不会很大，不过第四种方式出现脏数据概率是更小点，更多的话还是要结合自身业务场景使用，灵活变通。</p><h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><p>例如一个操作要修改用户的状态，修改状态需要先读出用户的状态，在内存里进行修 改，改完了再存回去。如果这样的操作同时进行了，就会出现并发问题，因为读取和保存状 态这两个操作不是原子的。（Wiki 解释：所谓原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch 线程切换。）如图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/88bee6ee45d933ce44b44bd47e795349.jpeg" alt=""></p><p>这个时候就要使用到分布式锁来限制程序的并发执行。</p><p>分布式锁本质上要实现的目标就是在 Redis 里面占一个“茅坑”，当别的进程也要来占 时，发现已经有人蹲在那里了，就只好放弃或者稍后再试。占坑一般是使用 setnx(set if not exists) 指令，只允许被一个客户端占坑。先来先占， 用 完了，再调用 del 指令释放茅坑。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">setnx lock:codehole true  </span><br><span class="line">OK  </span><br><span class="line"> ... do something critical ...  </span><br><span class="line">del lock:codehole  </span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><p>但是有个问题，如果逻辑执行到中间出现异常了，可能会导致 del 指令没有被调用，这样 就会陷入死锁，锁永远得不到释放。于是我们在拿到锁之后，再给锁加上一个过期时间，比如 5s，这样即使中间出现异常也 可以保证 5 秒之后锁会自动释放。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">setnx lock:codehole true  </span><br><span class="line">OK  </span><br><span class="line">&gt; expire lock:codehole 5 ...  </span><br><span class="line">do something critical ...  </span><br><span class="line">&gt; del lock:codehole  </span><br><span class="line"> (integer) 1</span><br></pre></td></tr></table></figure><p>如果在 setnx 和 expire 之间服务器进程突然挂掉了，可能是因为机器掉电或者是被人为杀掉的，就会导致 expire 得不到执行，也会造成死锁。</p><p>这种问题的根源就在于 setnx 和 expire 是两条指令而不是原子指令。如果这两条指令可 以一起执行就不会出现问题。也许你会想到用 Redis 事务来解决。但是这里不行，因为 expire 是依赖于 setnx 的执行结果的，如果 setnx 没抢到锁，expire 是不应该执行的。事务里没有 if else 分支逻辑，事务的特点是一口气执行，要么全部执行要么一个都不执行。</p><p>Redis 2.8 版本中作者加入了 set 指令的扩展参数，使得 setnx 和 expire 指令可以一起执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">set lock:codehole trueex 5 nx  </span><br><span class="line">OK  </span><br><span class="line">... do something critical ...  </span><br><span class="line">del lock:codehole</span><br></pre></td></tr></table></figure><p>上面这个指令就是 setnx 和 expire 组合在一起的原子指令，它就是分布式锁的奥义所在。</p><h4 id="分布式锁存在的问题"><a href="#分布式锁存在的问题" class="headerlink" title="分布式锁存在的问题"></a>分布式锁存在的问题</h4><p>超时问题：如果在加锁和释放锁之间的逻辑执行的太长，以至于超出了锁的超时限制，就会出现问题。因为这时候锁过期了，第二个线程重新持有了这把锁，但是紧接着第一个线程执行完了业务逻辑，就把锁给释放了，第三个线程就会在第二个线程逻辑执行完之间拿到了锁。</p><p>单节点的分布式锁问题：在单 Matste 的主从 Matster-Slave Redis 系统中，正常情况下 Client 向 Master 获取锁之后同步给 Slave，如果 Client 获取锁成功之后 Master 节点挂掉，并且未将该锁同步到 Slave，之后在 Sentinel 的帮助下 Slave 升级为 Master 但是并没有之前未同步的锁的信息，此时如果有新的 Client 要在新 Master 获取锁，那么将可能出现两个 Client 持有同一把锁的问题，来看个图来想下这个过程：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/1c97108fa388012e83ea4259ed872eb1.jpeg" alt=""></p><p>所以，为了保证自己的锁只能自己释放需要增加唯一性的校验，综上基于单 Redis 节点的获取锁和释放锁的简单过程如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 获取锁 unique_value作为唯一性的校验  </span><br><span class="line">SET resource_name unique_value NX PX 30000  </span><br><span class="line">  </span><br><span class="line">&#x2F;&#x2F; 释放锁 比较unique_value是否相等 避免误释放  </span><br><span class="line">if redis.call(&quot;get&quot;,KEYS[1]) &#x3D;&#x3D; ARGV[1] then  </span><br><span class="line">    return redis.call(&quot;del&quot;,KEYS[1])  </span><br><span class="line">else  </span><br><span class="line">    return 0  </span><br><span class="line">end</span><br></pre></td></tr></table></figure><h4 id="关于分布式锁的-Redlock-算法"><a href="#关于分布式锁的-Redlock-算法" class="headerlink" title="关于分布式锁的 Redlock 算法"></a>关于分布式锁的 Redlock 算法</h4><p>Redis 性能好并且实现方便，但是单节点的分布式锁在故障迁移时产生安全问题，Redlock 算法是 Redis 的作者 Antirez 提出的集群模式分布式锁，基于 N 个完全独立的 Redis 节点实现分布式锁的高可用。</p><p>在 Redis 的分布式环境中，我们假设有 N 个完全互相独立的 Redis 节点，在 N 个 Redis 实例上使用与在 Redis 单实例下相同方法获取锁和释放锁。</p><p>现在假设有 5 个 Redis 主节点(大于 3 的奇数个)，这样基本保证他们不会同时都宕掉，获取锁和释放锁的过程中，客户端会执行以下操作:</p><ol><li><p>获取当前 Unix 时间，以毫秒为单位</p></li><li><p>依次尝试从 5 个实例，使用相同的 key 和具有唯一性的 value 获取锁 当向 Redis 请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间，这样可以避免客户端死等</p></li><li><p>客户端使用当前时间减去开始获取锁时间就得到获取锁使用的时间。当且仅当从半数以上的 Redis 节点取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功</p></li><li><p>如果取到了锁，key 的真正有效时间等于有效时间减去获取锁所使用的时间，这个很重要</p></li><li><p>如果因为某些原因，获取锁失败（没有在半数以上实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的 Redis 实例上进行解锁，无论 Redis 实例是否加锁成功，因为可能服务端响应消息丢失了但是实际成功了，毕竟多释放一次也不会有问题</p></li></ol><h3 id="关于集群"><a href="#关于集群" class="headerlink" title="关于集群"></a>关于集群</h3><p>在大数据高并发场景下，单个 Redis 实例往往会显得捉襟见肘。首先体现在内存上，单个 Redis 的内存不宜过大，内存太大会导致 rdb 文件过大，进一步导致主从同步时全量同步时间过长，在实例重启恢复时也会消耗很长的数据加载时间，特别是在云环境下，单个实例内存往往都是受限的。其次体现在 CPU 的利用率上，单个 Redis 实例只能利用单个核心，这单个核心要完成海量数据的存取和管理工作压力会非常大。所以孕育而生了 Redis 集群，集群方案主要有以下几种：</p><ul><li><p>Sentinel：Sentinel（哨兵）模式，基于主从复制模式，只是引入了哨兵来监控与自动处理故障</p></li><li><p>Codis：Codis 是 Redis 集群方案之一，令我们感到骄傲的是，它是中国人开发并开源的，来自前豌豆荚中间件团队。</p></li><li><p>Cluster：Redis Cluster 是 Redis 的亲儿子，它是 Redis 作者自己提供的 Redis 集群化方案。</p></li></ul><p>感谢阅读，部分图片来源于互联网，暂未备注来源～</p><p><strong>本文参考：</strong></p><p>Redis 开发与运维：<a href="https://book.douban.com/subject/26971561" target="_blank" rel="noopener">https://book.douban.com/subject/26971561</a></p><p>事务和 Lua 脚本：<a href="https://whiteccinn.github.io/2020/06/02/Redis/redis%E4%BA%8B%E5%8A%A1%E5%92%8Clua" target="_blank" rel="noopener">https://whiteccinn.github.io/2020/06/02/Redis/redis%E4%BA%8B%E5%8A%A1%E5%92%8Clua</a></p><p>Redis GEO 功能使用场景：<a href="https://www.cnblogs.com/54chensongxia/p/13813533.html" target="_blank" rel="noopener">https://www.cnblogs.com/54chensongxia/p/13813533.html</a></p><p>Redis 与数据库一致性：<a href="https://note.dolyw.com/cache/00-DataBaseConsistency.html" target="_blank" rel="noopener">https://note.dolyw.com/cache/00-DataBaseConsistency.html</a></p><p>本文转自 <a href="https://mp.weixin.qq.com/s/-3fcK4WspGk6SEsaVrdx8A" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/-3fcK4WspGk6SEsaVrdx8A</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MongoDB全方位知识图谱</title>
      <link href="/posts/ff140f31/"/>
      <url>/posts/ff140f31/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>作者：sakychen，腾讯 CSIG 后台开发工程师</p><p>MongoDB 是一个强大的分布式存储引擎，天然支持高可用、分布式和灵活设计。MongoDB 的一个很重要的设计理念是：服务端只关注底层核心能力的输出，至于怎么用，就尽可能的将工作交个客户端去决策。这也就是 MongoDB 灵活性的保证，但是灵活性带来的代价就是使用成本的提升。与 MySql 相比，想要用好 MongoDB，减少在项目中出问题，用户需要掌握的东西更多。本文致力于全方位的介绍 MongoDB 的理论和应用知识，目标是让大家可以通过阅读这篇文章之后能够掌握 MongoDB 的常用知识，具备在实际项目中高效应用 MongoDB 的能力。</p><p>本文既有 MongoDB 基础知识也有相对深入的进阶知识，同时适用于对 MonogDB 感兴趣的初学者或者希望对 MongoDB 有更深入了解的业务开发者。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/ff559ffbc94a2dfe172f03807cc75b7f.jpeg" alt=""></p><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>以下是笔者在学习和使用 MongoDB 过程中总结的 MongoDB 知识图谱。本文将按照一下图谱中依次介绍 MongoDB 的一些核心内容。由于能力和篇幅有限，本文并不会对图谱中全部内容都做深入分析，后续将会针对特定条目做专门的分析。同时，如果图谱和内容中有错误或疏漏的地方，也请大家随意指正，笔者这边会积极修正和完善。</p><p>本文按照图谱从以下 3 个方面来介绍 MongoDB 相关知识：</p><ol><li><p><strong>基础知识</strong>：主要介绍 MongoDB 的重要特性，No Schema、高可用、分布式扩展等特性，以及支撑这些特性的相关设计</p></li><li><p><strong>应用接入：</strong>主要介绍 MongoDB 的一些测试数据、接入方式、spring-data-mongo 应用以及使用 Mongo 的一些注意事项。</p></li><li><p><strong>进阶知识：</strong>主要介绍 MongoDB 的一些核心功能的设计实现，包括 WiredTiger 存储引擎介绍、Page/Chunk 等数据结构、一致性/高可用保证、索引等相关知识。</p></li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/bfb0d07740d6eb09fff1636a6b8978a9.png" alt=""></p><h3 id="第一部分：基础知识"><a href="#第一部分：基础知识" class="headerlink" title="第一部分：基础知识"></a>第一部分：基础知识</h3><p>MongoDB 是基于文档的 NoSql 存储引擎。MongoDB 的数据库管理由数据库、Collection（集合，类似 MySql 的表）、Document（文档，类似 MySQL 的行）组成，每个 Document 都是一个类 JSON 结构 BSON 结构数据。</p><p>MongoDB 的核心特性是：No Schema、高可用、分布式（可平行扩展），另外 MongoDB 自带数据压缩功能，使得同样的数据存储所需的资源更少。本节将会依次介绍这些特性的基本知识，以及 MongoDB 是如何实现这些能力的。</p><h4 id="1-1-No-Schema"><a href="#1-1-No-Schema" class="headerlink" title="1.1 No Schema"></a>1.1 No Schema</h4><p>MongoDB 是文档型数据库，其文档组织结构是 BSON(Binary Serialized Document Format) 是类 JSON 的二进制存储格式，数据组织和访问方式完全和 JSON 一样。支持动态的添加字段、支持内嵌对象和数组对象，同时它也对 JSON 做了一些扩充，如支持 Date 和 BinData 数据类型。正是 BSON 这种字段灵活管理能力赋予了 Mongo 的 No Schema 或者 Schema Free 的特性。</p><p>No Schema 特性带来的好处包括：</p><ul><li><p>强大的表现能力：对象嵌套和数组结构可以让数据库中的对象具备更高的表现能力，能够用更少的数据对象表现复杂的领域模型对象。</p></li><li><p>便于开发和快速迭代：灵活的字段管理，使得项目迭代新增字段非常容易</p></li><li><p>降低运维成本：数据对象结构变更不需要执行 DDL 语句，降低 Online 环境的数据库操作风险，特别是在海量数据分库分表场景。</p><p>MongoDB 在提供 No Schema 特性基础上，提供了部分可选的 Schema 特性：Validation。其主要功能有包括：</p></li><li><p>规定某个 Document 对象必须包含某些字段</p></li><li><p>规定 Document 某个字段的数据类型 $（中 $开头的都是关键字）</p></li><li><p>规定 Document 某个字段的取值范围：可以是枚举 $，或者正则$$regex</p><p>上面的字段包含内嵌文档的，也就是说，你可以指定 Document 内任意一层 JSON 文件的字段属性。validator 的值有两种，一种是简单的 JSON Object，另一种是通过关键字 $jsonSchema 指定。以下是简单示例，想了解更多请参考官方文档：<a href="https://www.docs4dev.com/docs/zh/mongodb/v3.6/reference/reference-operator-query-jsonSchema.html" target="_blank" rel="noopener">MongoDB JSON Schema 详解</a>。</p></li></ul><p>方式一：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">db.createCollection(&quot;saky_test_validation&quot;,&#123;validator:  </span><br><span class="line">  &#123;  </span><br><span class="line">    $and:[  </span><br><span class="line">      &#123;name:&#123;$type: &quot;string&quot;&#125;&#125;,  </span><br><span class="line">      &#123;status:&#123;$in:[&quot;INIT&quot;,&quot;DEL&quot;]&#125;&#125;]  </span><br><span class="line">  &#125;  </span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>方式二：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">db.createCollection(&quot;saky_test_validation&quot;, &#123;  </span><br><span class="line">   validator: &#123;  </span><br><span class="line">      $jsonSchema: &#123;  </span><br><span class="line">         bsonType: &quot;object&quot;,  </span><br><span class="line">         required: [ &quot;name&quot;, &quot;status&quot;, ],  </span><br><span class="line">         properties: &#123;  </span><br><span class="line">            name: &#123;  </span><br><span class="line">               bsonType: &quot;string&quot;,  </span><br><span class="line">               description: &quot;must be a string and is required&quot;  </span><br><span class="line">            &#125;,  </span><br><span class="line">            status: &#123;  </span><br><span class="line">  </span><br><span class="line">               enum: [ &quot;INIT&quot;, &quot;DEL&quot;],  </span><br><span class="line">  </span><br><span class="line">               description: &quot;can only be one of the enum values and is required&quot;  </span><br><span class="line">           &#125;  </span><br><span class="line">&#125; &#125;&#125;)</span><br></pre></td></tr></table></figure><h4 id="1-2-MongoDB-的高可用"><a href="#1-2-MongoDB-的高可用" class="headerlink" title="1.2 MongoDB 的高可用"></a>1.2 MongoDB 的高可用</h4><p>高可用是 MongoDB 最核心的功能之一，相信很多同学也是因为这一特性才想深入了解它的。那么本节就来说下 MongoDB 通过哪些方式来实现它的高可用，然后给予这些特性我们可以实现什么程度的高可用。</p><p>相信一旦提到高可用，浮现在大家脑海里会有如下几个问题：</p><ul><li><p>是什么：MongoDB 高可用包括些什么功能？它能保证多大程度的高可用？</p></li><li><p>为什么：MongoDB 是怎样做到这些高可用的？</p></li><li><p>怎么用：我们需要做些怎样的配置或者使用才能享受到 MongoDB 的高可用特性？</p><p>那么，带着这些问题，我们继续看下去，看完大家应该会对这些问题有所了解了。</p></li></ul><h5 id="1-2-1-MongDB-复制集群"><a href="#1-2-1-MongDB-复制集群" class="headerlink" title="1.2.1 MongDB 复制集群"></a>1.2.1 MongDB 复制集群</h5><p>MongoDB 高可用的基础是复制集群，复制集群本质来说就是一份数据存多份，保证一台机器挂掉了数据不会丢失。一个副本集至少有 3 个节点组成：</p><ul><li><p><strong>至少一个主节点（Primary）：</strong>负责整个集群的写操作入口，主节点挂掉之后会自动选出新的主节点。</p></li><li><p><strong>一个或多个从节点（Secondary）：</strong>一般是 2 个或以上，从主节点同步数据，在主节点挂掉之后选举新节点。</p></li><li><p><strong>零个或 1 个仲裁节点（Arbiter）：</strong>这个是为了节约资源或者多机房容灾用，只负责主节点选举时投票不存数据，保证能有节点获得多数赞成票。</p><p>从上面的节点类型可以看出，一个三节点的复制集群可能是 PSS 或者 PSA 结构。PSA 结构优点是节约成本，但是缺点是 Primary 挂掉之后，一些依赖 majority（多数）特性的写功能出问题，因此一般不建议使用。</p><p>复制集群确保数据一致性的核心设计是：</p></li><li><p><strong>Journal</strong>：Journal日志是 MongoDB 的预写日志 WAL，类似 MySQL 的 redo log，然后100ms一次将Journal 日子刷盘。  </p></li><li><p><strong>Oplog</strong>：Oplog 是用来做主从复制的，类似 MySql 里的 binlog。MongoDB 的写操作都由 Primary 节点负责，Primary 节点会在写数据时会将操作记录在 Oplog 中，Secondary 节点通过拉取 oplog 信息，回放操作实现数据同步的。</p></li><li><p><strong>Checkpoint</strong>：上面提到了 MongoDB 的写只写了内存和 Journal 日志 ，并没有做数据持久化，Checkpoint 就是将内存变更刷新到磁盘持久化的过程。MongoDB 会每60s一次将内存中的变更刷盘，并记录当前持久化点（checkpoint），以便数据库在重启后能快速恢复数据。</p></li><li><p><strong>节点选举：</strong>MongoDB 的节点选举规则能够保证在Primary挂掉之后选取的新节点一定是集群中数据最全的一个，在3.3.1节点选举有说明具体实现。</p></li></ul><p>从上面 4 点我们可以得出 MongoDB 高可用的如下结论：</p><ol><li><p><strong>MongoDB</strong> <strong>宕机重启之后可以通过 checkpoint 快速恢复上一个 60s 之前的数据。</strong></p></li><li><p><strong>MongoDB</strong> <strong>最后一个 checkpoint 到宕机期间的数据可以通过 Journal日志回放恢复。</strong></p></li><li><p><strong>Journal日志</strong>因为是 100ms 刷盘一次，因此至多会丢失 100ms 的数据（这个可以通过 WriteConcern 的参数控制不丢失，只是性能会受影响，适合可靠性要求非常严格的场景）</p></li><li><p><strong>如果在写数据开启了多数写，那么就算 Primary 宕机了也是至多丢失 100ms 数据（可避免，同上）</strong></p></li></ol><h5 id="1-2-2-读写策略"><a href="#1-2-2-读写策略" class="headerlink" title="1.2.2 读写策略"></a>1.2.2 读写策略</h5><p>从上一小节发现，MongoDB 的高可用机制在不同的场景表现是不一样的。实际上，MongoDB 提供了一整套的机制让用户根据自己业务场景选择不同的策略。这里要说的就是 MongoDB 的读写策略，根据用户选取不同的读写策略，你会得到不同程度的数据可靠性和一致性保障。这些对业务开放者非常重要，因为你只有彻底掌握了这些知识，才能根据自己的业务场景选取合适的策略，同时兼顾读写性能和可靠性。</p><p><strong>Write Concern ——</strong> <strong>写策略</strong></p><p>控制服务端一次写操作在什么情况下才返回客户端成功，由两个参数控制：</p><ul><li><p>w 参数：控制数据同步到多少个节点才算成功，取值范围<strong>0</strong>～节点个数/majority<strong>。0 表示服务端收到请求就返回成功，</strong>major<strong>表示同步到大多数（大于等于 N/2）</strong>节点才返回成功。其它值表示具体的同步节点个数。<strong>默认为 1，表示 Primary 写成功</strong>就返回成功。</p></li><li><p>j 参数：控制单个节点是否完成 oplog 持久化到磁盘才返回成功，取值范围 true/false。默认 false，因此可能最多丢 100ms 数据。</p></li></ul><p><strong>Read Concern ——</strong> <strong>读策略</strong></p><p>控制客户端从什么节点读取数据，默认为 primary，具体参数及含义：</p><ul><li><p>primary：读主节点</p></li><li><p>primaryPreferred：优先读主节点，不存在时读从节点</p></li><li><p>secondary：读从节点</p></li><li><p>secondaryPreferred：优先读从节点，不存在时读主节点</p></li><li><p>nearest：就近读，不区分主节点还是从节点，只考虑节点延时。</p></li></ul><p>更多信息可参考<a href="https://www.mongodb.com/docs/v4.0/reference/read-preference/index.html?_ga=2.71414227.1531435120.1648536327-1778944104.1630835426" target="_blank" rel="noopener">MongoDB 官方文档</a></p><p><strong>Read Concern Level ——</strong> <strong>读级别</strong></p><p>这是一个非常有意思的参数，也是最不容易理解的异常参数。它主要控制的是读到的数据是不是最新的、是不是持久的，最新的和持久的是一对矛盾，最新的数据可能会被回滚，持久的数据可能不是最新的，这需要业务根据自己场景的容忍度做决策，前提是你的先知道有哪些，他们代表什么意义：</p><ul><li><p>local：直接从查询节点返回，不关心这些数据被同步到了多少个节点。存在被回滚的风险。</p></li><li><p>available：适用于分片集群，和 local 差不多，也存在被回滚的风险。</p></li><li><p>majority：返回被大多数节点确认过的数据，不会被回滚，前提是 WriteConcern=majority</p></li><li><p>linearizable：适用于事务，读操作会等待在它开始前已经在执行的事务提交了才返回</p></li><li><p>snapshot：适用于事务，快照隔离，直接从快照去。</p></li></ul><p>为了便于理解 local 和 majority，这里引用一下 MongoDB 官网上的一张 WriteConcern=majority 时写操作的过程图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/ce0a9d62add67850855f590e282db6cb.jpeg" alt=""></p><p>通过这张图可以看出，不同节点在不同阶段看待同一条数据满足的 level 是不同的：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9387247f7de36c67cb174c92b6fea138.jpeg" alt=""></p><h4 id="1-3-MongoDB-的可扩展性-——-分片集群"><a href="#1-3-MongoDB-的可扩展性-——-分片集群" class="headerlink" title="1.3 MongoDB 的可扩展性 —— 分片集群"></a>1.3 MongoDB 的可扩展性 —— 分片集群</h4><p>水平扩展是 MongoDB 的另一个核心特性，它是 MongoDB 支持海量数据存储的基础。MongoDB 天然的分布式特性使得它几乎可无限的横向扩展，你再也不用为 MySQL 分库分表的各种繁琐问题操碎心了。当然，我们这里不讨论 MongoDB 和其它存储引擎的对比，这个以后专门写下，这里只关注分片集群相关信息。</p><h5 id="1-3-1-分片集群架构"><a href="#1-3-1-分片集群架构" class="headerlink" title="1.3.1 分片集群架构"></a>1.3.1 分片集群架构</h5><p>MongoDB 的分片集群由如下三个部分组成：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/12b6a35550c7efed59f241189363c0fd.jpeg" alt=""></p><ul><li><p><strong>Config</strong>：配置，本质上是一个 MongoDB 的副本集，负责存储集群的各种元数据和配置，如分片地址、chunks 等</p></li><li><p><strong>Mongos</strong>：路由服务，不存具体数据，从 Config 获取集群配置讲请求转发到特定的分片，并且整合分片结果返回给客户端。</p></li><li><p><strong>Mongod</strong>：一般将具体的单个分片叫 mongod，实质上每个分片都是一个单独的复制集群，具备负责集群的高可用特性。</p></li></ul><p>其实分片集群的架构看起来和很多支持海量存储的设计很像，本质上都是将存储分片，然后在前面挂一个 proxy 做请求路由。但是，<strong>MongoDB</strong> <strong>的分片集群有个非常重要的特性是其它数据库没有的，这个特性就是数据均衡</strong>。数据分片一个绕不开的话题就是数据分布不均匀导致不同分片负载差异巨大，不能最大化利用集群资源。</p><p>MongoDB 的数据均衡的实现方式是：</p><ol><li><p>分片集群上数据管理单元叫 chunk，一个 chunk 默认 64M，可选范围 1 ～ 1024M。</p></li><li><p>集群有多少个 chunk，每个 chunk 的范围，每个 chunk 是存在哪个分片上的，这些数据都是存储在 Config 的。</p></li><li><p>chunk 会在其内部包含的数据超过阈值时分裂成两个。</p></li><li><p>MongoDB 在运行时会自定检测不同分片上的 chunk 数，当发现最多和最少的差异超过阈值就会启动 chunk 迁移，使得每个分片上的 chunk 数差不多。</p></li><li><p>chunk 迁移过程叫 rebalance，会比较耗资源，因此一般要把它的执行时间设置到业务低峰期。</p></li></ol><p>关于 chunk 更加深入的知识会在后面进阶知识里面讲解，这里就不展开了。</p><h5 id="1-3-2-分片算法"><a href="#1-3-2-分片算法" class="headerlink" title="1.3.2 分片算法"></a>1.3.2 分片算法</h5><p>MongoDB 支持两种分片算法来满足不同的查询需求：</p><ul><li><p><strong>区间分片：</strong>可以按 shardkey 做区间查询的分片算法，直接按照 shardkey 的值来分片。</p></li><li><p><strong>hash</strong>分片：用的最多的分片算法，按 shardkey 的 hash 值来分片。hash 分片可以看作一种特殊的区间分片。</p></li></ul><p>区间分片示例：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/48d1dce842136cf28ee9e14ed7863484.jpeg" alt=""></p><p>hash 分片示例：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/1b1b63ee7104e277fd03fd17217c880d.jpeg" alt=""></p><p>从上面两张图可以看出：</p><ul><li><p>分片的本质是<strong>将 shardkey 按一定的函数变换 f(x) 之后的空间划分为一个个连续的段</strong>，每一段就是一个 chunk。</p></li><li><p>区间分片 f(x) = x；hash 分片 f(x) = hash(x)</p></li><li><p>每个 chunk 在空间中起始值是存在 Config 里面的。</p></li><li><p>当请求到 Mongos 的时候，根据 shardkey 的值算出 f(x) 的具体值为 f(shardkey)，找到包含该值的 chunk，然后就能定位到数据的实际位置了。</p></li></ul><h4 id="1-4-数据压缩"><a href="#1-4-数据压缩" class="headerlink" title="1.4 数据压缩"></a>1.4 数据压缩</h4><p>MongoDB 的另外一个比较重要的特性是数据压缩，MongoDB 会自动把客户数据压缩之后再落盘，这样就可以节省存储空间。MongoDB 的数据压缩算法有多种：</p><ul><li><p>Snappy：默认的压缩算法，压缩比 3 ～ 5 倍</p></li><li><p>Zlib：高度压缩算法，压缩比 5 ～ 7 倍</p></li><li><p>前缀压缩：索引用的压缩算法，简单理解就是丢掉重复的前缀</p></li><li><p>zstd：MongoDB 4.2 之后新增的压缩算法，拥有更好的压缩率</p></li></ul><p>现在推荐的 MongoDB 版本是 4.0，在这个版本下推荐使用 snappy 算法，虽然 zlib 有更高的压缩比，但是读写会有一定的性能波动，不适合核心业务，但是比较适合流水、日志等场景。</p><h3 id="第二部分：应用接入"><a href="#第二部分：应用接入" class="headerlink" title="第二部分：应用接入"></a>第二部分：应用接入</h3><p>在掌握第一部分的基础上，基本上对 MongoDB 有一个比较直观的认识了，知道它是什么，有什么优势，适合什么场景。在此基础上，我们基本上已经可以判定 MongoDB 是否适合自己的业务了。如果适合，那么接下来就需要考虑怎么将其应用到业务中。在此之前，我们还得先对 MonoDB 的性能有个大致的了解，这样才能根据业务情况选取合适的配置。</p><h4 id="2-1-基本性能测试"><a href="#2-1-基本性能测试" class="headerlink" title="2.1 基本性能测试"></a>2.1 基本性能测试</h4><p>在使用 MongoDB 之前，需要对其功能和性能有一定的了解，才能判定是否符合自己的业务场景，以及需要注意些什么才能更好的使用。笔者这边对其做了一些测试，本测试是基于自己业务的一些数据特性，而且这边使用的是分片集群。因此有些测试项不同数据会有差异，如压缩比、读写性能具体值等。但是也有一些是共性的结论，如写性能随数据量递减并最终区域平稳。</p><p><strong>压缩比</strong></p><p>对比了同样数据在 Mongo 和 MySQL 下压缩比对比，可以看出 snapy 算法大概是 MySQL 的 3 倍，zlib 大概是 6 倍。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/eb0ed71f4995b4b876341f667405b4ad.jpeg" alt=""></p><p><strong>写性能</strong></p><p>分片集群写性能在测试之后得到如下结论，这里分片是 4 核 8G 的配置：</p><ul><li><p>写性能的瓶颈在单个分片上</p></li><li><p>当数据量小时是存内存读写，写性能很好，之后随着数量增加急剧下降，并最终趋于平稳，在 3000QPS。</p></li><li><p>少量简单的索引对写性能影响不大</p></li><li><p>分片集群批量写和逐条写性能无差异，而如果是复制集群批量写性能是逐条写性能的数倍。这点有点违背常识，具体原因这边还未找到。</p></li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/c65cdeca180207d37afbde58ae5ce803.jpeg" alt=""></p><p><strong>读性能</strong></p><p>分片集群的读分为三年种情况：按 shardkey 查询、按索引查询、其他查询。下面这些测试数据都是在单分片 2 亿以上的数据，这个时候 cache 已经不能完全换成业务数据了，如果数据量很小，数据全在 cache 这个性能应该会很好。</p><ul><li><p>按 shardkey 查下，在 Mongos 处能算出具体的分片和 chunk，所以查询速度非常稳定，不会随着数据量变化。平均耗时 2ms 以内，4 核 8G 单分片 3 万 QPS。这种查询方式的瓶颈一般在 分片 Mongod 上，但也要注意 Mongos 配置不能太低。</p></li><li><p>按索引查询的时候，由于 Mongos 需要将数据全部转发到所有的分片，然后聚合全部结果返回客户端，因此性能瓶颈在 Mongos 上。测试 Mongos 8 核 16G + 10 分片情况下，单个 Mongos 的性能在 1400QPS，平均时延 10ms。业务场景索引是唯一的，因此如果索引数据不唯一，后端分片数更多，这个性能还会更低。</p></li><li><p>如果不按 shardkey 和索引查询因为涉及全表扫描，因此在数据量上千万之后基本不可用</p><p>Mongos 有点特殊情况要注意的，就是客户端请求会到哪个 Mongos 是通过客户端 ip 的 hash 值决定的，因此同一个客户端所有请求一定会到同一个 Mongos，如果客户端过少的时候还会出现 Mongos 负载不均问题。</p></li></ul><h4 id="2-2-分片选择"><a href="#2-2-分片选择" class="headerlink" title="2.2 分片选择"></a>2.2 分片选择</h4><p>在了解了 MongoDB 的基本性能数据之后，就可以根据自己的业务需求选取合适的配置了。如果是分片集群，其中最重要的就是分片选取，包括：</p><ul><li><p>需要多少个 Mongos</p></li><li><p>需要分为多少个分片</p></li><li><p>分片键和分片算法用什么</p></li></ul><p>关于前面两点，其实在知道各种性能参数之后就很简单了，前人已经总结出了相关的公式，我这里就简单把图再贴一下。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/e70d98827b18ce7d317b35de67b06295.jpeg" alt=""></p><h4 id="2-3-spring-data-mongo"><a href="#2-3-spring-data-mongo" class="headerlink" title="2.3 spring-data-mongo"></a>2.3 spring-data-mongo</h4><p>MonogDB 官方提供了各种语言的 Client，这些 Client 是对 mongo 原始命令的封装。笔者这边是使用的 java，因此并未直接使用 MongoDB 官方的客户端，而是经过二次封装之后的 spring-data-mongo。好处是可以不用他关心底层的设计如连接管理、POJO 转换等。</p><h5 id="2-3-1-接入步骤"><a href="#2-3-1-接入步骤" class="headerlink" title="2.3.1 接入步骤"></a>2.3.1 接入步骤</h5><p>spring-data-mongo 的使用方式非常简单。</p><p><strong>第一步：引入 jar 包</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#96;&lt;dependency&gt;  </span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;  </span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;&#x2F;artifactId&gt;  </span><br><span class="line">        &lt;&#x2F;dependency&gt;&#96;</span><br></pre></td></tr></table></figure><p><strong>第二步：ymal 配置</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">spring:  </span><br><span class="line">  data:  </span><br><span class="line">    mongodb:  </span><br><span class="line">      host: &#123;&#123;.MONGO_HOST&#125;&#125;  </span><br><span class="line">      port: &#123;&#123;.MONGO_PORT&#125;&#125;  </span><br><span class="line">      database: &#123;&#123;.MONGO_DB&#125;&#125;  </span><br><span class="line">      username: &#123;&#123;.MONGO_USER&#125;&#125;  </span><br><span class="line">      password: &#123;&#123;.MONGO_PASS&#125;&#125;</span><br></pre></td></tr></table></figure><p>这里有个两个要注意：</p><ul><li><p>权限，MongoDB 的权限是到数据级别的，所有配置的 username 必须有 database 那个库的权限，要不然会连不上。</p></li><li><p>这种方式配置没有指定读写 concern，如果需要在连接上指定的话，需要用 uri 的方式来配置，两种配置方式是不兼容的，或者自己初始化 MongoTemplate。</p></li></ul><p>关于配置，跟多的可以在 IDEA 里面搜索 _Mongo_AutoConfiguration 查看源码，具体就是这个类：org.springframework.boot.autoconfigure.mongo.MongoProperties</p><p>关于自己初始化 MongoTemplate 的方式是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@Configuration  </span><br><span class="line">public class MyMongoConfig &#123;  </span><br><span class="line">    @Primary  </span><br><span class="line">    @Bean  </span><br><span class="line">    public MongoTemplate mongoTemplate(MongoDbFactory mongoDbFactory,  MongoConverter mongoConverter)&#123;  </span><br><span class="line">        MongoTemplate mongoTemplate &#x3D; new MongoTemplate(mongoDbFactory,mongoConverter);  </span><br><span class="line">        mongoTemplate.setWriteConcern(WriteConcern.MAJORITY);  </span><br><span class="line">        return mongoTemplate;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第三步：使用 MongoTemplate</p><p>在完成上面这些之后，就可以在代码里面注入 MongoTemplate，然后使用各种增删改查接口了。</p><h5 id="2-3-2-批量操作注意事项"><a href="#2-3-2-批量操作注意事项" class="headerlink" title="2.3.2 批量操作注意事项"></a>2.3.2 批量操作注意事项</h5><p>MongoDB Client 的批量操作有两种方式：</p><ul><li><p><strong>一条命令操作批量数据：</strong>insertAll，updateMany 等</p></li><li><p><strong>批量提交一批命令：</strong>bulkOps，这种方式节省的就是客户端与服务端的交互次数</p><p>bulkOps 的方式会比另外一种方式在性能上低一些。</p><p>这两种方式到引擎层面具体执行时都是一条条语句单独执行，它们有一个很重要的参数：<strong>ordered</strong>，这个参数的作用是控制批量操作在引擎内最终执行时是并行的还是穿行的。其默认值是 true。</p></li><li><p><strong>true</strong>：批量命令窜行执行，遇到某个命令错误时就退出并报错，这个和事物不一样，它不会回滚已经执行成功的命令，如批量插入如果某条数据主键冲突了，那么它前面的数据都会插入成功，后面的会不执行。</p></li><li><p><strong>false</strong>：批量命令并行执行，单个命令错误不影响其它，在执行结构里会返回错误的部分。还是以批量插入为例，这种模式下只会是主键冲突那条插入失败，其他都会成功。</p><p>显然，false 模式下插入耗时会低一些，但是 MongoTemplate 的 insertAll 函数是在内部写死的 true。因此，如果想用 false 模式，需要自己继承 MongoTemplate 然后重写里面的 insertDocumentList 方法。</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#96;public class MyMongoTemplate extends MongoTemplate &#123;  </span><br><span class="line">    @Override  </span><br><span class="line">    protected List&lt;Object&gt; insertDocumentList(String collectionName, List&lt;Document&gt; documents) &#123;  </span><br><span class="line">                .........  </span><br><span class="line">                InsertManyOptions options &#x3D; new InsertManyOptions();  </span><br><span class="line">                options &#x3D; options.ordered(false);  &#x2F;&#x2F; 要自己初始化一个这对象，然后设置为false  </span><br><span class="line">                long begin &#x3D; System.currentTimeMillis();  </span><br><span class="line">                if (writeConcernToUse &#x3D;&#x3D; null) &#123;  </span><br><span class="line">                    collection.insertMany(documents, options); &#x2F;&#x2F; options这里默认是null  </span><br><span class="line">                &#125; else &#123;  </span><br><span class="line">              collection.withWriteConcern(writeConcernToUse).insertMany(documents,options);  </span><br><span class="line">                &#125;  </span><br><span class="line">                return null;  </span><br><span class="line">            &#125;);  </span><br><span class="line">            return MappedDocument.toIds(documents);  </span><br><span class="line">    &#125;&#96;</span><br></pre></td></tr></table></figure><h5 id="2-3-3-一些常见的坑"><a href="#2-3-3-一些常见的坑" class="headerlink" title="2.3.3 一些常见的坑"></a>2.3.3 一些常见的坑</h5><p>因为 MongoDB 真的将太多自主性交给的客户端来决策，因此如果对其了解不够，真的会很容易踩坑。这里例举一些常见的坑，避免大家遇到。</p><p><strong>预分片</strong></p><p>这个问题的常见表现就是：为啥我的数据分布很随机了，但是分片集群的 MongoDB 插入性能还是这么低？</p><p>首先我们说下预分片是什么，预分片就是提前把 shard key 的空间划分成若干段，然后把这些段对应的 chunk 创建出来。那么，这个和插入性能的关系是什么呢？</p><p>我们回顾下前面说到的 chunk 知识，其中有两点需要注意：</p><ol><li><p>当 chunk 内的数据超过阈值就会将 chunk 拆分成两个。</p></li><li><p>当各个分片上 chunk 数差异过大时就会启动 rebalance，迁移 chunk。</p></li></ol><p>那么，很明显，问题就是出在这了，chunk 分裂和 chunk 迁移都是比较耗资源的，必然就会影响插入性能。</p><p>因此，如果提前将个分片上的 chunk 创建好，就能避免频繁的分裂和迁移 chunk，进而提升插入性能。预分片的设置方式为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#96;sh.shardCollection(&quot;saky_db.saky_table&quot;, &#123;&quot;_id&quot;: &quot;hashed&quot;&#125;, false,&#123;numInitialChunks:8192*分片数&#125;)&#96;</span><br></pre></td></tr></table></figure><p>numInitialChunks 的最大值为 8192 * 分片数</p><p><strong>内存排序</strong></p><p>这个是一个不容易被注意到的问题，但是使用 MongoDB 时一定要注意的就是避免任何查询的内存操作，因为用 MongoDB 的很多场景都是海量数据，这个情况下任何内存操作的成本都可能是非常高昂甚至会搞垮数据库的，当然 MongoDB 为了避免内存操作搞垮它，是有个阈值，如果需要内存处理的数据超过阈值它就不会处理并报错。</p><p>继续说内存排序问题，它的本质是索引问题。MongoDB 的索引都是有序的，正序或者逆序。如果我们有一个 Collection 里面记录了学生信息，包括年龄和性别两个字段。然后我们创建了这样一个复合索引：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;gender: 1, age: 1&#125; &#x2F;&#x2F; 这个索引先按性别升序排序，相同的再按年龄升序排序</span><br></pre></td></tr></table></figure><p>当这个时候，如果你排序顺序是下面这样的话，就会导致内存排序，如果数据两小到没事，如果非常大的话就会影响性能。避免内存排序就是要查询的排序方式要和索引的相同。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;gender: 1, age: -1&#125; &#x2F;&#x2F; 这个索引先按性别升序排序，相同的再按年龄降序排序</span><br></pre></td></tr></table></figure><p><strong>链式复制</strong></p><p>链式复制是指副本集的各个副本在复制数据时，并不是都是从 Primary 节点拉 oplog，而是各个节点排成一条链，依次复制过去。</p><p>优点：避免大量 Secondary 从 Primary 拉 oplog ，影响 Primary 的性能。</p><p>缺点：如果 WriteConcern=majority，那么链式复制会导致写操作耗时更长。</p><p>因此，是否开启链式复制就是一个成本与性能的平衡，默认是开启链式复制的：</p><ul><li><p>是关闭链式复制，用更好的机器配置来支持所有节点从 Primary 拉 oplog。</p></li><li><p>还是开启链式复制，用更长的写耗时来降低对节点配置的需求。</p><p>链式复制关闭时，节点数据复制对 Primary 节点性能影响程度目前没有专业测试过，因此不能评判到底开启还是关闭好，这边数据库同学从他们的经验来建议是关闭，因此我这边是关闭的，如果有用到 MongoDB 的可以考虑关掉。</p></li></ul><h3 id="第三部分：进阶知识"><a href="#第三部分：进阶知识" class="headerlink" title="第三部分：进阶知识"></a>第三部分：进阶知识</h3><p>接下来终于到了最重要的部分了，这部分将讲解一些 MongoDB 的一些高级功能和底层设计。虽然不了解这些也能使用，但是如果想用好 MongoDB，这部分知识是必须掌握的。</p><h4 id="3-1-存储引擎-Wired-Tiger"><a href="#3-1-存储引擎-Wired-Tiger" class="headerlink" title="3.1 存储引擎 Wired Tiger"></a>3.1 存储引擎 Wired Tiger</h4><p>说到 MongoDB 最重要的知识，其存储引擎 Wired Tiger 肯定是要第一个说的。因为 MongoDB 的所有功能都是依赖底层存储引擎实现的，掌握了存储引擎的核心知识，有利于我们理解 MongoDB 的各种功能。存储引擎的核心工作是管理数据如何在磁盘和内存上读写，从 MongoDB 3.2 开始支持多种存储引擎：Wired Tiger，MMAPv1 和 In-Memory，其中默认为 Wired Tiger。</p><h5 id="3-1-1-重要数据结构和-Page"><a href="#3-1-1-重要数据结构和-Page" class="headerlink" title="3.1.1 重要数据结构和 Page"></a>3.1.1 重要数据结构和 Page</h5><p><strong>B+ Tree</strong></p><p>存储引擎最核心的功能就是完成数据在客户端 - 内存 - 磁盘之间的交互。客户端是不可控的，因此如何设计一个高效的数据结构和算法，实现数据快速在内存和磁盘间交互就是存储引擎需要考虑的核心问题。目前大多少流行的存储引擎都是基于 B/B+ Tree 和 LSM(Log Structured Merge) Tree 来实现，至于他们的优势和劣势，以及各种适用的场景，暂时超出了笔者的能力，后面到是有兴趣去研究一下。</p><p>Oracle、SQL Server、DB2、MySQL (InnoDB) 这些传统的关系数据库依赖的底层存储引擎是基于 B+ Tree 开发的；而像 Cassandra、Elasticsearch (Lucene)、Google Bigtable、Apache HBase、LevelDB 和 RocksDB 这些当前比较流行的 NoSQL 数据库存储引擎是基于 LSM 开发的。MongoDB 虽然是 NoSQL 的，但是其存储引擎 Wired Tiger 却是用的 B+ Tree，因此有种说法是 MongoDB 是最接近 SQL 的 NoSQL 存储引擎。好了，我们这里知道 Wired Tiger 的存储结构是 B+ Tree 就行了，至于什么是 B+ Tree，它有些啥优势网都有很多文章，这里就不在赘述了。</p><p><strong>Page</strong></p><p>Wired Tiger 在内存和磁盘上的数据结构都 B+ Tree，B+ 的特点是中间节点只有索引，数据都是存在叶节点。Wired Tiger 管理数据结构的基本单元 Page。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/36f029a407fcdf2bb90fb6140137cf16.jpeg" alt=""></p><p>上图是 Page 在内存中的数据结构，是一个典型的 B+ Tree，Page 上有 3 个重要的 list WT_ROW、WT_UPDATE、WT_INSERT。这个 Page 的组织结构和 Page 的 3 个 list 对后面理解 cache、checkpoint 等操作很重要：</p><ul><li><p>内存中的 Page 树是一个 checkpoint</p></li><li><p>叶节点 Page 的 WT_ROW：是从磁盘加载进来的数据数组</p></li><li><p>叶节点 Page 的 WT_UPDATE：是记录数据加载之后到下个 checkpoint 之间被修改的数据</p></li><li><p>叶节点 Page 的 WT_INSERT：是记录数据加载之后到下个 checkpoint 之间新增的数据</p></li></ul><p>上面说了 Page 的基本结构，接下来再看下 Page 的生命周期和状态扭转，这个生命周期和 Wired Tiger 的缓存息息相关。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/fda042d575c4654d0ae90b5288aefac3.jpeg" alt=""></p><p>Page 在磁盘和内存中的整个生命周期状态机如上图：</p><ul><li><p>DIST：Page 在磁盘中</p></li><li><p>DELETE：Page 已经在磁盘中从树中删除</p></li><li><p>READING：Page 正在被从磁盘加载到内存中</p></li><li><p>MEM：Page 在内存中，且能正常读写。</p></li><li><p>LOCKED：内存淘汰过程（evict）正在锁住 Page</p></li><li><p>LOOKASIDE：在执行 reconcile 的时候，如果 page 正在被其他线程读取被修改的部分，这个时候会把数据存储在 lookasidetable 里面。当页面再次被读时可以通过 lookasidetable 重构出内存 Page。</p></li><li><p>LIMBO：在执行完 reconcile 之后，Page 会被刷到磁盘。这个时候如果 page 有 lookasidetable 数据，并且还没合并过来之前就又被加载到内存了，就会是这个状态，需要先从 lookasidetable 重构内存 Page 才能正常访问。</p></li></ul><p>其中两个比较重要的过程是 reconcile 和 evict。</p><p>其中 reconcile 发生在 checkpoint 的时候，将内存中 Page 的修改转换成磁盘需要的 B+ Tree 结构。前面说了 Page 的 WT_UPDATE 和 WT_UPDATE 列表存储了数据被加载到内存之后的修改，类似一个内存级的 oplog，而数据在磁盘中时显然不可能是这样的结构。因此 reconcile 会新建一个 Page 来将修改了的数据做整合，然后原 Page 就会被 discarded，新 page 会被刷新到磁盘，同时加入 LRU 队列。</p><p>evict 是内存不够用了或者脏数据过多的时候触发的，根据 LRU 规则淘汰内存 Page 到磁盘。</p><h5 id="3-1-2-cache"><a href="#3-1-2-cache" class="headerlink" title="3.1.2 cache"></a>3.1.2 cache</h5><p>MongoDB 不是内存数据库，但是为了提供高效的读写操作存储引擎会最大化的利用内存缓存。MongoDB 的读写性能都会随着数据量增加到了某个点出现近乎断崖式跌落最终趋于稳定。这其中的根本原因就是内存是否能 cover 住全部的数据，数据量小的时候是纯内存读写，性能肯定非常好，当数据量过大时就会触发内存和磁盘间数据的来回交换，导致性能降低。所以，如果在使用 MongoDB 时，如果发现自己某些操作明显高于常规，那么很大可能是它触发了磁盘操作。</p><p>接下来说下 MongoDB 的存储引擎 Wired Tiger 是怎样利用内存 cache 的。首先，Wired Tiger 会将整个内存划分为 3 块：</p><ul><li><p><strong>存储引擎内部 cache：</strong>缓存前面提到的内存数据，默认大小 Max((RAM - 1G)/2,256M )，服务器 16G 的话，就是(16-1)/2 = 7.5G 。这个内存配置一定要注意，因为 Wired Tiger 如果内存不够可能会导致数据库宕掉的。</p></li><li><p><strong>索引 cache：</strong>换成索引信息，默认 500M</p></li><li><p><strong>文件系统 cache：</strong>这个实际上不是存储引擎管理，是利用的操作系统的文件系统缓存，目的是减少内存和磁盘交互。剩下的内存都会用来做这个。</p></li></ul><p>内存分配大小一般是不建议改的，除非你确实想把自己全部数据放到内存，并且主够的引擎知识。</p><p>引擎 cache 和文件系统 cache 在数据结构上是不一样的，文件系统 cache 是直接加载的内存文件，是经过压缩的数据，可以占用更少的内存空间，相对的就是数据不能直接用，需要解压；而引擎中的数据就是前面提到的 B+ Tree，是解压后的，可以直接使用的数据，占有的内存会大一些。</p><p><strong>Evict</strong></p><p>就算内存再大它与磁盘间的差距也是数据量级的差异，随着数据增长也会出现内存不够用的时候。因此内存管理一个很重要的操作就是内存淘汰 evict。内存淘汰时机由 eviction_target（内存使用量）和 eviction_dirty_target（内存脏数据量）来控制，而内存淘汰默认是有后台的 evict 线程控制的。但是如果超过一定阈值就会把用户线程也用来淘汰，会严重影响性能，应该避免这种情况。用户线程参与 evict 的原因，一般是大量的写入导致磁盘 IO 抗不住了，需要控制写入或者更换磁盘。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/6f3ab4c296d5cc789d8a4ee94464ff06.jpeg" alt=""></p><h5 id="3-1-3-checkpoint"><a href="#3-1-3-checkpoint" class="headerlink" title="3.1.3 checkpoint"></a>3.1.3 checkpoint</h5><p>前面说过，MongoDB 的读写都是操作的内存，因此必须要有一定的机制将内存数据持久化到磁盘，这个功能就是 Wired Tiger 的 checkpoint 来实现的。checkpoint 实现将内存中修改的数据持久化到磁盘，保证系统在因意外重启之后能快速恢复数据。checkpoint 本身数据也是会在每次 checkpoint 执行时落盘持久化的。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/49894c36253ea072fce4d97a1c077fb6.png" alt=""></p><p>一个 checkpoint 就是一个内存 B+ Tree，其结构就是前面提到的 Page 组成的树，它有几个重要的字段：</p><ul><li><p>root page：就是指向 B+ Tree 的根节点</p></li><li><p>allocated list pages：上个 checkpoint 结束之后到本 checkpoint 结束前新分配的 page 列表</p></li><li><p>available list pages：Wired Tiger 分配了但是没有使用的 page，新建 page 时直接从这里取。</p></li><li><p>discarded list pages：上个 checkpoint 结束之后到本 checkpoint 结束前被删掉的 page 列表</p></li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/fae83e7ddcc366a272713a866ea9a146.jpeg" alt=""></p><p>checkpoint 的大致流程入上图所述：</p><ol><li><p>在系统启动或者集合文件打开时，从磁盘加载最新的 checkpoint。</p></li><li><p>根据 checkpoint 的 file size truncate 文件。因为只有 checkpoint 确认的数据才是真正持久化的数据，它后面的数据可能是最新 checkpoint 之后到宕机之间的数据，不能直接用，需要通过 Journal 日志来回放。</p></li><li><p>根据 checkpoint 构建内存的 B+ Tree。</p></li><li><p>数据库 run 起来之后，各种修改操作都是操作 checkpoint 的 B+ Tree，并且会 checkpoint 会有专门的 list 来记录这些修改和新增的 page</p></li><li><p>在 60s 一次的 checkpoint 执行时，会创建新的 checkpoint，并且将旧的 checkpoint 数据合并过来。然后执行 reconcile 将修改的数据刷新到磁盘，并删除旧的 checkpoint。这时候会清空 allocated，discarded 里面的 page，并且将空闲的 page 加到 available 里面。</p></li></ol><h4 id="3-2-Chunk"><a href="#3-2-Chunk" class="headerlink" title="3.2 Chunk"></a>3.2 Chunk</h4><p>Chunk 为啥要单独出来说一下呢，因为它是 MongoDB 分片集群的一个核心概念，是使用和理解分片集群读写实现的最基础的概念。</p><h5 id="3-2-1-基本信息"><a href="#3-2-1-基本信息" class="headerlink" title="3.2.1 基本信息"></a><strong>3.2.1</strong> <strong>基本信息</strong></h5><p>首先，说下 chunk 是什么，chunk 本质上就是由一组 Document 组成的逻辑数据单元。它是分片集群用来管理数据存储和路由的基本单元。具体来说就是，分片集群不会记录每条数据在哪个分片上，这不现实，它只会记录哪一批（一个 chunk）数据存储在哪个分片上，以及这个 chunk 包含哪些范围的数据。而数据与 chunk 之间的关联是有数据的 shard key 的分片算法 f(x) 的值是否在 chunk 的起始范围来确定的。</p><p>前面说过，分片集群的 chunk 信息是存在 Config 里面的，而 Config 本质上是一个复制集群。如果你创建一个分片集群，那么你默认会得到两个库，admin 和 config，其中 config 库对应的就是分片集群架构里面的 Config。其中的包含一个 Collection chunks 里面记录的就是分片集群的全部 chunk 信息，具体结构如下图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/2d07f7945e66c84d8693dc8ffaedbac2.jpeg" alt=""></p><p>chunk 的几个关键属性：</p><ul><li><p>_id：chunk 的唯一标识</p></li><li><p>ns：命名空间，就是 DB.COLLECTION 的结构</p></li><li><p>min：chunk 包含数据的 shard key 的 f(x) 最小值</p></li><li><p>max：chunk 包含数据的 shard key 的 f(x) 最大值</p></li><li><p>shard：chunk 当前所在分片 ID</p></li><li><p>history：记录 chunk 的迁移历史</p></li></ul><h5 id="3-2-2-chunk-分裂"><a href="#3-2-2-chunk-分裂" class="headerlink" title="3.2.2 chunk 分裂"></a>3.2.2 chunk 分裂</h5><p>chunk 是分片集群管理数据的基本单元，本身有一个大小，那么随着 chunk 内的数据不断新增，最终大小会超过限制，这个时候就需要把 chunk 拆分成 2 个，这个就 chunk 的分裂。</p><p>chunk 的大小不能太大也不能太小。太大了会导致迁移成本高，太小了有会触发频繁分裂。因此它需要一个合理的范围，默认大小是 64M，可配置的取值范围是 1M ～ 1024M。这个大小一般来说是不用专门配置的，但是也有特例：</p><ul><li><p>如果你的单条数据太小了，25W 条也远小于 64M，那么可以适当调小，但也不是必要的。</p></li><li><p>如果你的数据单条过大，大于了 64M，那么就必须得调大 chunk 了，否则会产生 jumbo chunk，导致 chunk 不能迁移。</p><p>导致 chunk 分裂有两个条件，达到任何一个都会触发：</p></li><li><p><strong>容量达到阈值：</strong>就是 chunk 中的数据大小加起来超过阈值，默认是上面说的 64M</p></li><li><p><strong>数据量到达阈值：</strong>前面提到了，如果单条数据太小，不加限制的话，一个 chunk 内数据量可能几十上百万条，这也会影响读写性能，因此 MongoDB 内置了一个阈值，chunk 内数据量超过 25W 条也会分裂。</p></li></ul><h5 id="3-2-3-rebalance"><a href="#3-2-3-rebalance" class="headerlink" title="3.2.3 rebalance"></a>3.2.3 rebalance</h5><p>MongoDB 一个区别于其他分布式数据库的特性就是自动数据均衡。</p><p><strong>chunk</strong> <strong>分裂是 MongoDB 保证数据均衡的基础</strong>：数据的不断增加，chunk 不断分裂，如果数据不均匀就会导致不同分片上的 chunk 数目出现差异，这就解决了分片集群的<strong>数据不均匀问题发现</strong>。然后就可以通过将 chunk 从数据多的分片迁移到数据少的分片来实现数据均衡，这个过程就是 rebalance。</p><p>如下图所示，随着数据插入，导致 chunk 分裂，让 AB 两个分片有 3 个 chunk，C 分片只有一个，这个时候就会把 B 分配的迁移一个到 C 分分片实现集群数据均衡。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/de13bc633079e6555a6cd2fa6f26b2cf.jpeg" alt=""></p><p>执行 rebalance 是有几个前置条件的：</p><ul><li><p>数据库和集合开启了 rebalance 开关，默认是开启的。</p></li><li><p>当前时间在设置的 rebalance 时间窗，默认没有配置，就是只要检测到了就会执行 rebalance。</p></li><li><p>集群中分片 chunk 数最大和最小之差超过阈值，这个阈值和 chunk 总数有关，具体如下：</p></li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/95ea180359ec04e52845b61f5185e23d.jpeg" alt=""></p><p>rebalance 为了尽快完成数据迁移，其设计是尽最大努力迁移，因此是非常消耗系统资源的，在系统配置不高的时候会影响系统正常业务。因此，为了减少其影响需要：</p><ul><li><p>预分片：减少大量数据插入时频繁的分裂和迁移 chunk</p></li><li><p>设置 rebalance 时间窗</p></li><li><p>对于可能会影响业务的大规模数据迁移，如扩容分片，可以采取手段迁移的方式来控制迁移速度。</p></li></ul><h4 id="3-3-一致性-高可用"><a href="#3-3-一致性-高可用" class="headerlink" title="3.3 一致性/高可用"></a>3.3 一致性/高可用</h4><p>分布式系统必须要面对的一个问题就是数据的一致性和高可用，针对这个问题有一个非常著名的理论就是 CAP 理论。CAP 理论的核心结论是：一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。关于 CAP 理论在网上有非常多的论述，这里也不赘述。</p><p>CAP 理论提出了分布式系统必须面临的问题，但是我们也不可能因为这个问题就不用分布式系统。因此，BASE（Basically Available 基本可用、Soft state 软状态、Eventually consistent 最终一致性）理论被提出来了。BASE 理论是在一致性和可用性上的平衡，现在大部分分布式系统都是基于 BASE 理论设计的，当然 MongoDB 也是遵循此理论的。</p><h5 id="3-3-1-选举和-Raft-协议"><a href="#3-3-1-选举和-Raft-协议" class="headerlink" title="3.3.1 选举和 Raft 协议"></a>3.3.1 选举和 Raft 协议</h5><p>MongoDB 为了保证可用性和分区容错性，采用的是副本集的方式，这种模式就必须要解决的一个问题就是怎样快速在系统启动和 Primary 发生异常时选取一个合适的主节点。这里潜在着多个问题：</p><ul><li><p>系统怎样发现 Primary 异常？</p></li><li><p>哪些 Secondary 节点有资格参加 Primary 选举？</p></li><li><p>发现 Primary 异常之后用什么样的算法选出新的 Primary 节点？</p></li><li><p>怎么样确保选出的 Primary 是最合适的？</p></li></ul><p><strong>Raft</strong> <strong>协议</strong></p><p>MongoDB 的选举算法是基于 Raft 协议的改进，Raft 协议将分布式集群里面的节点有 3 种状态：</p><ul><li><p>leader：就是 Primary 节点，负责整个集群的写操作。</p></li><li><p>candidate：候选者，在 Primary 节点挂掉之后，参与竞选的节点。只有选举期间才会存在，是个临时状态。</p></li><li><p>flower：就是 Secondary 节点，被动的从 Primary 节点拉取更新数据。</p></li></ul><p>节点的状态变化是：正常情况下只有一个 leader 和多个 flower，当 leader 挂掉了，那么 flower 里面就会有部分节点成为 candidate 参与竞选。当某个 candidate 竞选成功之后就成为新的 leader，而其他 candidate 回到 flower 状态。具体状态机如下：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/e1d9def15ad7b9ad47a3691f7f98685e.jpeg" alt=""></p><p>Raft 协议中有两个核心 RPC 协议分别应用在选举阶段和正常阶段：</p><ul><li><p><strong>请求投票：</strong>选举阶段，candidate 向其他节点发起请求，请求对方给自己投票。</p></li><li><p><strong>追加条目：</strong>正常阶段，leader 节点向 flower 节点发起请求，告诉对方有数据更新，同时作为心跳机制来向所有 flower 宣示自己的地位。如果 flower 在一定时间内没有收到该请求就会启动新一轮的选举投票。</p></li></ul><p><strong>投票规则</strong></p><p>Raft 协议规定了在选举阶段的投票规则：</p><ul><li><p>一个节点，在一个选举周期（Term）内<strong>只能给一个</strong> candidate 节点投赞成票，且<strong>先到先得</strong></p></li><li><p>只有在 candidate 节点的 oplog 领先或和自己相同时才投赞成票</p></li></ul><p><strong>选举过程</strong></p><p>一轮完整的选举过程包含如下内容：</p><ol><li><p>某个/多个 flower 节点超时未收到 leader 的心跳，将自己改变成 candidate 状态，增加选举周期（Term），然后先给自己投一票，并向其他节点发起投票请求。</p></li><li><p>等待其它节点的投票返回，在此期间如果收到其它 candidate 发来的请求，根据投票规则给其它节点投票。</p></li><li><p>如果某个 candidate 在收到过半的赞成票之后，就把自己转换成 leader 状态，并向其它节点发送心跳宣誓即位。</p></li><li><p>如果节点在没有收到过半赞成票之前，收到了来自 leader 的心跳，就将自己退回到 flower 状态。</p></li><li><p>只要本轮有选出 leader 就完成了选举，否则超时启动新一轮选举。</p></li></ol><p><strong>catchup</strong>（追赶）</p><p>以上就是目前掌握的 MongoDB 的选举机制，其中有个问题暂时还未得到解答，就是最后一个，怎样确保选出的 Primary 是最合适的那一个。因为，从前面的协议来看，存在一个逻辑 bug：<strong>由于 flower 转换成 candidate 是随机并行的，再加上先到先得的投票机制会导致选出一个次优的节点成为 Primary</strong>。但是这一点应该是笔者自己掌握知识不够，应该是有相关机制保证的，怀疑是通过节点优先级实现的。这点也和相关同学确认过，因此这里暂定此问题不存在，等深入学习这里的细节之后补充其设计和实现。</p><p>针对 Raft 协议的这个问题，下来查询了一些资料，结论是：</p><ul><li><p>Raft 协议确实不保证选举出来的 Primary 节点是最优的</p></li><li><p>MongoDB 通过在选举成功，到新 Primary 即位之前，新增了一个 catchup（追赶）操作来解决。即在节点获取投票胜利之后，会先检查其它节点是否有比自己更新的 oplog，如果没有就直接即位，如果有就先把数据同步过来再即位。</p></li></ul><h5 id="3-3-2-主从同步"><a href="#3-3-2-主从同步" class="headerlink" title="3.3.2 主从同步"></a>3.3.2 主从同步</h5><p>MongoDB 的主从同步机制是确保数据一致性和可靠性的重要机制。其同步的基础是 oplog，类似 MySQL 的 binlog，但是也有一些差异，oplog 虽然叫 log 但并不是一个文件，而是一个集合（Collection）。同时由于 oplog 的并行写入，存在尾部乱序和空洞现象，具体来说就是 oplog 里面的数据顺序可能是和实际数据顺序不一致，并且存在时间的不连续问题。为了解决这个问题，MongoDB 采用的是混合逻辑时钟（HLC）来解决的，HLC 不止解决乱序和空洞问题，同时也是用来解决分布式系统上事务一致性的方案。</p><p>主从同步的本质实际上就是，Primary 节点接收客户端请求，将更新操作写到 oplog，然后 Secondary 从同步源拉取 oplog 并本地回放，实现数据的同步。</p><p><strong>同步源选取</strong></p><p>同步源是指节点拉取 oplog 的源节点，这个节点不一定是 Primary ，链式复制模式下就可能是任何节点。节点的同步源选取是一个非常复杂的过程，大致上来说是：</p><ul><li><p>节点维护整个集群的全部节点信息，并每 2s 发送一次心跳检测，存活的节点都是同步源备选节点。</p></li><li><p>落后自己的节点不能做同步源：就是源节点最新的 opTime 不能小于自己最新的 opTime</p></li><li><p>落后 Primary 30s 以上的不能作为同步源</p></li><li><p>太超前的节点不能作为同步源：就是源节点最老的 opTime 不能大于自己最新的 opTime，否则有 oplog 空洞。</p></li></ul><p>在同步源选取时有些特殊情况：</p><ul><li><p>用户可以为节点指定同步源</p></li><li><p>如果关闭链式复制，所有 Secondary 节点的同步源都是 Primary 节点</p></li><li><p>如果从同步源拉取出错了，会被短期加入黑名单</p></li></ul><p><strong>oplog</strong>拉取和回放</p><p>整个拉取和回放的逻辑非常复杂，这里根据自己的理解简化说明，如果想了解更多知识可以参考<a href="https://mongoing.com/archives/72571" target="_blank" rel="noopener">《MongoDB 复制技术内幕》</a></p><p>节点有一个专门拉取 oplog 的线程，通过 Exhausted cursor 从同步源拉取 oplog。拉取下来之后，并不会执行回放执行，而是会将其丢到一个本地的阻塞队列中。</p><p>然后有多个具体的执行线程，从阻塞队列中取出 oplog 并执行。在取出过程中，同一个 Collection 的 oplog 一定会被同一个线程取出执行，线程会尽可能的合并连续的插入命令。</p><p>整个回放的执行过程，大致为先加锁，然后写本店 oplog，然后将 oplog 刷盘（WAL 机制），最后更新自己的最新 opTime。</p><h4 id="3-4-索引"><a href="#3-4-索引" class="headerlink" title="3.4 索引"></a>3.4 索引</h4><p>索引对任何数据库而言都是非常重要的一个功能。数据库支持的索引类型，决定的数据库的查询方式和应用场景。而正确的使用索引能够让我们最大化的利用数据库性能，同时避免不合理的操作导致的数据库问题，最常见的问题就是 CPU 或内存耗尽。</p><h5 id="3-4-1-基本概念"><a href="#3-4-1-基本概念" class="headerlink" title="3.4.1 基本概念"></a>3.4.1 基本概念</h5><p>MongoDB 的索引和 MySql 的索引有点不一样，它的索引在创建时必须指定顺序（1：升序，-1：降序），同时所有的集合都有一个默认索引 _id，这是一个唯一索引，类似 MySql 的主键。</p><p>MongoDB 支持的索引类型有：</p><ul><li><p>单字段索引：建立在单个字段上的索引，索引创建的排序顺序无所谓，MongoDB 可以头/尾开始遍历。</p></li><li><p>复合索引：建立在多个字段上的索引。</p></li><li><p>多 key 索引：我们知道 MongoDB 的一个字段可能是数组，在对这种字段创建索引时，就是多 key 索引。MongoDB 会为数组的每个值创建索引。就是说你可以按照数组里面的值做条件来查询，这个时候依然会走索引。</p></li><li><p>Hash 索引：按数据的哈希值索引，用在 hash 分片集群上。</p></li><li><p>地理位置索引：基于经纬度的索引，适合 2D 和 3D 的位置查询。</p></li><li><p>文本索引：MongoDB 虽然支持全文索引，但是性能低下，暂时不建议使用。</p></li></ul><h5 id="3-4-2-注意事项"><a href="#3-4-2-注意事项" class="headerlink" title="3.4.2 注意事项"></a>3.4.2 注意事项</h5><p>索引功能强大，但是也有很多限制，使用索引时一定要注意一些问题。</p><p><strong>复合索引</strong></p><p>复合索引有几个问题需要注意：</p><ul><li><p>复合索引遵循前缀匹配原则：{userid:1,score:-1} 的索引隐含了 {userid:1} 的索引</p></li><li><p>避免内存排序：复合索引除第一个字段之外，其他字段的查询排序方式，必须和索引排序方式一致，否则会导致内存排序。如前面的索引，可以支持 {userid:-1,score:-1} 的查询，同时也能支持 {userid:1,score:1} 的查询，只是后一种需要内存排序 score 字段。</p></li><li><p>索引交集：索引交集时查询优化器的优化方案，很少用到，尽量不要依赖这个功能。索引交集本质上就有创建两个独立的单字段索引，在查询保护两个字段时，优化器自动做索引交集。如 {user:1} + {score:-1} 两个索引的交集可以支持前面的 {userid:1,score:1} 的查询</p></li></ul><p><strong>后台创建索引</strong></p><p>在对一个已经拥有较大数据集的 Collection 创建索引时，建议通过创建命令参数指定后台创建，不会阻塞命令和意外中断。但是，在后台创建多个索引时，不能命令执行完就接着下一个。因为是后台创建，命令行虽然推出了，但是索引还没创建完。这个时候如果同事输入多个创建索引命令，会因为<strong>大量的写操作和数据复制导致系统 cpu 耗尽</strong>。这个时候需要观察系统监控，确定第一个索引创建完了再执行下一个。</p><h5 id="3-4-3-explain"><a href="#3-4-3-explain" class="headerlink" title="3.4.3 explain"></a>3.4.3 explain</h5><p>explain 是 MongoDB 的查询计划工具，和 MySql 的 explain 功能相同，都是用来分析一条语句的索引使用情况、影响行数、执行时间等。</p><p>explain 有三种参数分别对应结果输出的三部分数据：</p><ul><li><p><strong>queryPlanner</strong>：MongoDB 运行查询优化器对当前的查询进行评估并选择一个最佳的查询计划。</p></li><li><p><strong>exectionStats</strong>：mongoDB 运行查询优化器对当前的查询进行评估并选择一个最佳的查询计划进行执行。在执行完毕后返回这个最佳执行计划执行完成时的相关统计信息。</p></li><li><p><strong>allPlansExecution</strong>：即按照最佳的执行计划执行以及列出统计信息，如果有多个查询计划，还会列出这些非最佳执行计划部分的统计信息。</p></li></ul><p>explain 是一个非常有用的工具，建议在一个数据量较大的数据库上开发新功能时，一定要用 explain 分析一下自己的语句是否合理、索引是否合理，避免在项目上线之后出现问题。</p><p>本文转自 <a href="https://mp.weixin.qq.com/s/qStIOFcynQCiYw-WppAebg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/qStIOFcynQCiYw-WppAebg</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> MongoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis多线程网络模型全面揭秘</title>
      <link href="/posts/d1946b30/"/>
      <url>/posts/d1946b30/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="导言"><a href="#导言" class="headerlink" title="导言"></a>导言</h2><p>在目前的技术选型中，Redis 俨然已经成为了系统高性能缓存方案的事实标准，因此现在 Redis 也成为了后端开发的基本技能树之一，Redis 的底层原理也顺理成章地成为了必须学习的知识。</p><p>Redis 从本质上来讲是一个网络服务器，而对于一个网络服务器来说，网络模型是它的精华，搞懂了一个网络服务器的网络模型，你也就搞懂了它的本质。</p><p>本文通过层层递进的方式，介绍了 Redis 网络模型的版本变更历程，剖析了其从单线程进化到多线程的工作原理，此外，还一并分析并解答了 Redis 的网络模型的很多抉择背后的思考，帮助读者能更深刻地理解 Redis 网络模型的设计。</p><h2 id="Redis-有多快？"><a href="#Redis-有多快？" class="headerlink" title="Redis 有多快？"></a>Redis 有多快？</h2><p>根据官方的 benchmark，通常来说，在一台普通硬件配置的 Linux 机器上跑单个 Redis 实例，处理简单命令（时间复杂度 O(N) 或者 O(log(N))），QPS 可以达到 8w+，而如果使用 pipeline 批处理功能，则 QPS 至高能达到 100w。</p><p>仅从性能层面进行评判，Redis 完全可以被称之为高性能缓存方案。</p><h2 id="Redis-为什么快？"><a href="#Redis-为什么快？" class="headerlink" title="Redis 为什么快？"></a>Redis 为什么快？</h2><p>Redis 的高性能得益于以下几个基础：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9b1212b00b793c659edec0d92a51c2c0.png" alt=""></p><ul><li><strong>C 语言实现</strong>，虽然 C 对 Redis 的性能有助力，但语言并不是最核心因素。</li><li><strong>纯内存 I/O</strong>，相较于其他基于磁盘的 DB，Redis 的纯内存操作有着天然的性能优势。</li><li><strong>I/O 多路复用</strong>，基于 epoll/select/kqueue 等 I/O 多路复用技术，实现高吞吐的网络 I/O。</li><li><strong>单线程模型</strong>，单线程无法利用多核，但是从另一个层面来说则避免了多线程频繁上下文切换，以及同步机制如锁带来的开销。</li></ul><h2 id="Redis-为何选择单线程？"><a href="#Redis-为何选择单线程？" class="headerlink" title="Redis 为何选择单线程？"></a>Redis 为何选择单线程？</h2><p>Redis 的核心网络模型选择用单线程来实现，这在一开始就引起了很多人的不解，Redis 官方的对于此的回答是：</p><blockquote><p>It’s not very frequent that CPU becomes your bottleneck with Redis, as usually Redis is either memory or network bound. For instance, using pipelining Redis running on an average Linux system can deliver even 1 million requests per second, so if your application mainly uses O(N) or O(log(N)) commands, it is hardly going to use too much CPU.</p></blockquote><p>核心意思就是，对于一个 DB 来说，CPU 通常不会是瓶颈，因为大多数请求不会是 CPU 密集型的，而是 I/O 密集型。具体到 Redis 的话，如果不考虑 RDB/AOF 等持久化方案，Redis 是完全的纯内存操作，执行速度是非常快的，因此这部分操作通常不会是性能瓶颈，Redis 真正的性能瓶颈在于网络 I/O，也就是客户端和服务端之间的网络传输延迟，因此 Redis 选择了单线程的 I/O 多路复用来实现它的核心网络模型。</p><p>上面是比较笼统的官方答案，实际上更加具体的选择单线程的原因可以归纳如下：</p><h3 id="避免过多的上下文切换开销"><a href="#避免过多的上下文切换开销" class="headerlink" title="避免过多的上下文切换开销"></a>避免过多的上下文切换开销</h3><p>多线程调度过程中必然需要在 CPU 之间切换线程上下文 context，而上下文的切换又涉及程序计数器、堆栈指针和程序状态字等一系列的寄存器置换、程序堆栈重置甚至是 CPU 高速缓存、TLB 快表的汰换，如果是进程内的多线程切换还好一些，因为单一进程内多线程共享进程地址空间，因此线程上下文比之进程上下文要小得多，如果是跨进程调度，则需要切换掉整个进程地址空间。</p><p>如果是单线程则可以规避进程内频繁的线程切换开销，因为程序始终运行在进程中单个线程内，没有多线程切换的场景。</p><h3 id="避免同步机制的开销"><a href="#避免同步机制的开销" class="headerlink" title="避免同步机制的开销"></a>避免同步机制的开销</h3><p>如果 Redis 选择多线程模型，又因为 Redis 是一个数据库，那么势必涉及到底层数据同步的问题，则必然会引入某些同步机制，比如锁，而我们知道 Redis 不仅仅提供了简单的 key-value 数据结构，还有 list、set 和 hash 等等其他丰富的数据结构，而不同的数据结构对同步访问的加锁粒度又不尽相同，可能会导致在操作数据过程中带来很多加锁解锁的开销，增加程序复杂度的同时还会降低性能。</p><h3 id="简单可维护"><a href="#简单可维护" class="headerlink" title="简单可维护"></a>简单可维护</h3><p>Redis 的作者 Salvatore Sanfilippo (别称 antirez) 对 Redis 的设计和代码有着近乎偏执的简洁性理念，你可以在阅读 Redis 的源码或者给 Redis 提交 PR 的之时感受到这份偏执。因此代码的简单可维护性必然是 Redis 早期的核心准则之一，而引入多线程必然会导致代码的复杂度上升和可维护性下降。</p><p>事实上，多线程编程也不是那么尽善尽美，首先多线程的引入会使得程序不再保持代码逻辑上的串行性，代码执行的顺序将变成不可预测的，稍不注意就会导致程序出现各种并发编程的问题；其次，多线程模式也使得程序调试更加复杂和麻烦。网络上有一幅很有意思的图片，生动形象地描述了并发编程面临的窘境。</p><p>你期望的多线程编程 <strong>VS</strong> 实际上的多线程编程：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/f4bdcad372aac865e948c6f0085e3159.jpeg" alt="你期望的多线程VS实际上的多线程"></p><p>前面我们提到引入多线程必须的同步机制，如果 Redis 使用多线程模式，那么所有的底层数据结构都必须实现成线程安全的，这无疑又使得 Redis 的实现变得更加复杂。</p><p>总而言之，Redis 选择单线程可以说是多方博弈之后的一种权衡：在保证足够的性能表现之下，使用单线程保持代码的简单和可维护性。</p><h2 id="Redis-真的是单线程？"><a href="#Redis-真的是单线程？" class="headerlink" title="Redis 真的是单线程？"></a>Redis 真的是单线程？</h2><p>在讨论这个问题之前，我们要先明确『单线程』这个概念的边界：它的覆盖范围是核心网络模型，抑或是整个 Redis？如果是前者，那么答案是肯定的，在 Redis 的 v6.0 版本正式引入多线程之前，其网络模型一直是单线程模式的；如果是后者，那么答案则是否定的，Redis 早在 v4.0 就已经引入了多线程。</p><p>因此，当我们讨论 Redis 的多线程之时，有必要对 Redis 的版本划出两个重要的节点：</p><ol><li>Redis v4.0（引入多线程处理异步任务）</li><li>Redis v6.0（正式在网络模型中实现 I/O 多线程）</li></ol><h3 id="单线程事件循环"><a href="#单线程事件循环" class="headerlink" title="单线程事件循环"></a>单线程事件循环</h3><p>我们首先来剖析一下 Redis 的核心网络模型，从 Redis 的 v1.0 到 v6.0 版本之前，Redis 的核心网络模型一直是一个典型的单 Reactor 模型：利用 epoll/select/kqueue 等多路复用技术，在单线程的事件循环中不断去处理事件（客户端请求），最后回写响应数据到客户端：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/966d88bb982d4677e8ab98e9e6820796.png" alt=""></p><p>这里有几个核心的概念需要学习：</p><ul><li><strong>client</strong>：客户端对象，Redis 是典型的 CS 架构（Client &lt;—&gt; Server），客户端通过 <strong>socket</strong> 与服务端建立网络通道然后发送请求命令，服务端执行请求的命令并回复。<strong>Redis</strong> 使用结构体 <strong>client</strong> 存储客户端的所有相关信息，包括但不限于<code>封装的套接字连接 -- *conn</code>，<code>当前选择的数据库指针 -- *db</code>，<code>读入缓冲区 -- querybuf</code>，<code>写出缓冲区 -- buf</code>，<code>写出数据链表 -- reply</code>等。</li><li><strong>aeApiPoll</strong>：I/O 多路复用 API，是基于 epoll_wait/select/kevent 等系统调用的封装，监听等待读写事件触发，然后处理，它是事件循环（Event Loop）中的核心函数，是事件驱动得以运行的基础。</li><li><strong>acceptTcpHandler</strong>：连接应答处理器，底层使用系统调用 <code>accept</code> 接受来自客户端的新连接，并为新连接注册绑定命令读取处理器，以备后续处理新的客户端 TCP 连接；除了这个处理器，还有对应的 <code>acceptUnixHandler</code> 负责处理 Unix Domain Socket 以及 <code>acceptTLSHandler</code> 负责处理 TLS 加密连接。</li><li><strong>readQueryFromClient</strong>：命令读取处理器，解析并执行客户端的请求命令。</li><li><strong>beforeSleep</strong>：事件循环中进入 aeApiPoll 等待事件到来之前会执行的函数，其中包含一些日常的任务，比如把 <code>client-&gt;buf</code> 或者 <code>client-&gt;reply</code> （后面会解释为什么这里需要两个缓冲区）中的响应写回到客户端，持久化 AOF 缓冲区的数据到磁盘等，相对应的还有一个 afterSleep 函数，在 aeApiPoll 之后执行。</li><li><strong>sendReplyToClient</strong>：命令回复处理器，当一次事件循环之后写出缓冲区中还有数据残留，则这个处理器会被注册绑定到相应的连接上，等连接触发写就绪事件时，它会将写出缓冲区剩余的数据回写到客户端。</li></ul><p>Redis 内部实现了一个高性能的事件库 — AE，基于 epoll/select/kqueue/evport 四种事件驱动技术，实现 Linux/MacOS/FreeBSD/Solaris 多平台的高性能事件循环模型。Redis 的核心网络模型正式构筑在 AE 之上，包括 I/O 多路复用、各类处理器的注册绑定，都是基于此才得以运行。</p><p>至此，我们可以描绘出客户端向 Redis 发起请求命令的工作原理：</p><ol><li>Redis 服务器启动，开启主线程事件循环（Event Loop），注册 <code>acceptTcpHandler</code> 连接应答处理器到用户配置的监听端口对应的文件描述符，等待新连接到来；</li><li>客户端和服务端建立网络连接；</li><li><code>acceptTcpHandler</code> 被调用，主线程使用 AE 的 API 将 <code>readQueryFromClient</code> 命令读取处理器绑定到新连接对应的文件描述符上，并初始化一个 <code>client</code> 绑定这个客户端连接；</li><li>客户端发送请求命令，触发读就绪事件，主线程调用 <code>readQueryFromClient</code> 通过 socket 读取客户端发送过来的命令存入 <code>client-&gt;querybuf</code> 读入缓冲区；</li><li>接着调用 <code>processInputBuffer</code>，在其中使用 <code>processInlineBuffer</code> 或者 <code>processMultibulkBuffer</code> 根据 Redis 协议解析命令，最后调用 <code>processCommand</code> 执行命令；</li><li>根据请求命令的类型（SET, GET, DEL, EXEC 等），分配相应的命令执行器去执行，最后调用 <code>addReply</code> 函数族的一系列函数将响应数据写入到对应 <code>client</code> 的写出缓冲区：<code>client-&gt;buf</code> 或者 <code>client-&gt;reply</code> ，<code>client-&gt;buf</code> 是首选的写出缓冲区，固定大小 16KB，一般来说可以缓冲足够多的响应数据，但是如果客户端在时间窗口内需要响应的数据非常大，那么则会自动切换到 <code>client-&gt;reply</code> 链表上去，使用链表理论上能够保存无限大的数据（受限于机器的物理内存），最后把 <code>client</code> 添加进一个 LIFO 队列 <code>clients_pending_write</code>；</li><li>在事件循环（Event Loop）中，主线程执行 <code>beforeSleep</code> –&gt; <code>handleClientsWithPendingWrites</code>，遍历 <code>clients_pending_write</code> 队列，调用 <code>writeToClient</code> 把 <code>client</code> 的写出缓冲区里的数据回写到客户端，如果写出缓冲区还有数据遗留，则注册 <code>sendReplyToClient</code> 命令回复处理器到该连接的写就绪事件，等待客户端可写时在事件循环中再继续回写残余的响应数据。</li></ol><p>对于那些想利用多核优势提升性能的用户来说，Redis 官方给出的解决方案也非常简单粗暴：在同一个机器上多跑几个 Redis 实例。事实上，为了保证高可用，线上业务一般不太可能会是单机模式，更加常见的是利用 Redis 分布式集群多节点和数据分片负载均衡来提升性能和保证高可用。</p><h3 id="多线程异步任务"><a href="#多线程异步任务" class="headerlink" title="多线程异步任务"></a>多线程异步任务</h3><p>以上便是 Redis 的核心网络模型，这个单线程网络模型一直到 Redis v6.0 才改造成多线程模式，但这并不意味着整个 Redis 一直都只是单线程。</p><p>Redis 在 v4.0 版本的时候就已经引入了的多线程来做一些异步操作，此举主要针对的是那些非常耗时的命令，通过将这些命令的执行进行异步化，避免阻塞单线程的事件循环。</p><p>我们知道 Redis 的 <code>DEL</code> 命令是用来删除掉一个或多个 key 储存的值，它是一个阻塞的命令，大多数情况下你要删除的 key 里存的值不会特别多，最多也就几十上百个对象，所以可以很快执行完，但是如果你要删的是一个超大的键值对，里面有几百万个对象，那么这条命令可能会阻塞至少好几秒，又因为事件循环是单线程的，所以会阻塞后面的其他事件，导致吞吐量下降。</p><p>Redis 的作者 antirez 为了解决这个问题进行了很多思考，一开始他想的办法是一种渐进式的方案：利用定时器和数据游标，每次只删除一小部分的数据，比如 1000 个对象，最终清除掉所有的数据，但是这种方案有个致命的缺陷，如果同时还有其他客户端往某个正在被渐进式删除的 key 里继续写入数据，而且删除的速度跟不上写入的数据，那么将会无止境地消耗内存，虽然后来通过一个巧妙的办法解决了，但是这种实现使 Redis 变得更加复杂，而多线程看起来似乎是一个水到渠成的解决方案：简单、易理解。于是，最终 antirez 选择引入多线程来实现这一类非阻塞的命令。更多 antirez 在这方面的思考可以阅读一下他发表的博客：<a href="http://antirez.com/news/93" target="_blank" rel="noopener">Lazy Redis is better Redis</a>。</p><p>于是，在 Redis v4.0 之后增加了一些的非阻塞命令如 <code>UNLINK</code>、<code>FLUSHALL ASYNC</code>、<code>FLUSHDB ASYNC</code>。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/237520a121762db3e732d44e143dfa18.png" alt=""></p><p><code>UNLINK</code> 命令其实就是 <code>DEL</code> 的异步版本，它不会同步删除数据，而只是把 key 从 keyspace 中暂时移除掉，然后将任务添加到一个异步队列，最后由后台线程去删除，不过这里需要考虑一种情况是如果用 <code>UNLINK</code> 去删除一个很小的 key，用异步的方式去做反而开销更大，所以它会先计算一个开销的阀值，只有当这个值大于 64 才会使用异步的方式去删除 key，对于基本的数据类型如 List、Set、Hash 这些，阀值就是其中存储的对象数量。</p><h2 id="Redis-多线程网络模型"><a href="#Redis-多线程网络模型" class="headerlink" title="Redis 多线程网络模型"></a>Redis 多线程网络模型</h2><p>前面提到 Redis 最初选择单线程网络模型的理由是：CPU 通常不会成为性能瓶颈，瓶颈往往是<strong>内存</strong>和<strong>网络</strong>，因此单线程足够了。那么为什么现在 Redis 又要引入多线程呢？很简单，就是 Redis 的网络 I/O 瓶颈已经越来越明显了。</p><p>随着互联网的飞速发展，互联网业务系统所要处理的线上流量越来越大，Redis 的单线程模式会导致系统消耗很多 CPU 时间在网络 I/O 上从而降低吞吐量，要提升 Redis 的性能有两个方向：</p><ul><li>优化网络 I/O 模块</li><li>提高机器内存读写的速度</li></ul><p>后者依赖于硬件的发展，暂时无解。所以只能从前者下手，网络 I/O 的优化又可以分为两个方向：</p><ul><li>零拷贝技术或者 DPDK 技术</li><li>利用多核优势</li></ul><p>零拷贝技术有其局限性，无法完全适配 Redis 这一类复杂的网络 I/O 场景，更多网络 I/O 对 CPU 时间的消耗和 Linux 零拷贝技术，可以阅读我的另一篇文章：<a href="https://strikefreedom.top/linux-io-and-zero-copy" target="_blank" rel="noopener">Linux I/O 原理和 Zero-copy 技术全面揭秘</a>。而 DPDK 技术通过旁路网卡 I/O 绕过内核协议栈的方式又太过于复杂以及需要内核甚至是硬件的支持。</p><p>因此，利用多核优势成为了优化网络 I/O 性价比最高的方案。</p><p>6.0 版本之后，Redis 正式在核心网络模型中引入了多线程，也就是所谓的 _I/O threading_，至此 Redis 真正拥有了多线程模型。前一小节，我们了解了 Redis 在 6.0 版本之前的单线程事件循环模型，实际上就是一个非常经典的 Reactor 模型：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/ade21e10e9ac49bf15ff1e3a3719f5b7.png" alt=""></p><p>目前 Linux 平台上主流的高性能网络库/框架中，大都采用 Reactor 模式，比如 netty、libevent、libuv、POE(Perl)、Twisted(Python)等。</p><p>Reactor 模式本质上指的是使用 <code>I/O 多路复用(I/O multiplexing) + 非阻塞 I/O(non-blocking I/O)</code> 的模式。</p><p>更多关于 Reactor 模式的细节可以参考我之前的文章：<a href="https://strikefreedom.top/go-netpoll-io-multiplexing-reactor" target="_blank" rel="noopener">Go netpoller 原生网络模型之源码全面揭秘</a>，Reactor 网络模型那一小节，这里不再赘述。</p><p>Redis 的核心网络模型在 6.0 版本之前，一直是单 Reactor 模式：所有事件的处理都在单个线程内完成，虽然在 4.0 版本中引入了多线程，但是那个更像是针对特定场景（删除超大 key 值等）而打的补丁，并不能被视作核心网络模型的多线程。</p><p>通常来说，单 Reactor 模式，引入多线程之后会进化为 Multi-Reactors 模式，基本工作模式如下：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/760a1703326d170cd6ca243ce0987b7c.png" alt=""></p><p>区别于单 Reactor 模式，这种模式不再是单线程的事件循环，而是有多个线程（Sub Reactors）各自维护一个独立的事件循环，由 Main Reactor 负责接收新连接并分发给 Sub Reactors 去独立处理，最后 Sub Reactors 回写响应给客户端。</p><p>Multiple Reactors 模式通常也可以等同于 Master-Workers 模式，比如 Nginx 和 Memcached 等就是采用这种多线程模型，虽然不同的项目实现细节略有区别，但总体来说模式是一致的。</p><h3 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h3><p>Redis 虽然也实现了多线程，但是却不是标准的 Multi-Reactors/Master-Workers 模式，这其中的缘由我们后面会分析，现在我们先看一下 Redis 多线程网络模型的总体设计：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/5a7ffda1371b515b5ba959cf926def52.png" alt=""></p><ol><li>Redis 服务器启动，开启主线程事件循环（Event Loop），注册 <code>acceptTcpHandler</code> 连接应答处理器到用户配置的监听端口对应的文件描述符，等待新连接到来；</li><li>客户端和服务端建立网络连接；</li><li><code>acceptTcpHandler</code> 被调用，主线程使用 AE 的 API 将 <code>readQueryFromClient</code> 命令读取处理器绑定到新连接对应的文件描述符上，并初始化一个 <code>client</code> 绑定这个客户端连接；</li><li>客户端发送请求命令，触发读就绪事件，服务端主线程不会通过 socket 去读取客户端的请求命令，而是先将 <code>client</code> 放入一个 LIFO 队列 <code>clients_pending_read</code>；</li><li>在事件循环（Event Loop）中，主线程执行 <code>beforeSleep</code> –&gt;<code>handleClientsWithPendingReadsUsingThreads</code>，利用 Round-Robin 轮询负载均衡策略，把 <code>clients_pending_read</code>队列中的连接均匀地分配给 I/O 线程各自的本地 FIFO 任务队列 <code>io_threads_list[id]</code> 和主线程自己，I/O 线程通过 socket 读取客户端的请求命令，存入 <code>client-&gt;querybuf</code> 并解析第一个命令，<strong>但不执行命令</strong>，主线程忙轮询，等待所有 I/O 线程完成读取任务；</li><li>主线程和所有 I/O 线程都完成了读取任务，主线程结束忙轮询，遍历 <code>clients_pending_read</code> 队列，<strong>执行所有客户端连接的请求命令</strong>，先调用 <code>processCommandAndResetClient</code> 执行第一条已经解析好的命令，然后调用 <code>processInputBuffer</code> 解析并执行客户端连接的所有命令，在其中使用 <code>processInlineBuffer</code> 或者 <code>processMultibulkBuffer</code> 根据 Redis 协议解析命令，最后调用 <code>processCommand</code> 执行命令；</li><li>根据请求命令的类型（SET, GET, DEL, EXEC 等），分配相应的命令执行器去执行，最后调用 <code>addReply</code> 函数族的一系列函数将响应数据写入到对应 <code>client</code> 的写出缓冲区：<code>client-&gt;buf</code> 或者 <code>client-&gt;reply</code> ，<code>client-&gt;buf</code> 是首选的写出缓冲区，固定大小 16KB，一般来说可以缓冲足够多的响应数据，但是如果客户端在时间窗口内需要响应的数据非常大，那么则会自动切换到 <code>client-&gt;reply</code> 链表上去，使用链表理论上能够保存无限大的数据（受限于机器的物理内存），最后把 <code>client</code> 添加进一个 LIFO 队列 <code>clients_pending_write</code>；</li><li>在事件循环（Event Loop）中，主线程执行 <code>beforeSleep</code> –&gt; <code>handleClientsWithPendingWritesUsingThreads</code>，利用 Round-Robin 轮询负载均衡策略，把 <code>clients_pending_write</code> 队列中的连接均匀地分配给 I/O 线程各自的本地 FIFO 任务队列 <code>io_threads_list[id]</code> 和主线程自己，I/O 线程通过调用 <code>writeToClient</code> 把 <code>client</code> 的写出缓冲区里的数据回写到客户端，主线程忙轮询，等待所有 I/O 线程完成写出任务；</li><li>主线程和所有 I/O 线程都完成了写出任务， 主线程结束忙轮询，遍历 <code>clients_pending_write</code> 队列，如果 <code>client</code> 的写出缓冲区还有数据遗留，则注册 <code>sendReplyToClient</code> 到该连接的写就绪事件，等待客户端可写时在事件循环中再继续回写残余的响应数据。</li></ol><p>这里大部分逻辑和之前的单线程模型是一致的，变动的地方仅仅是把读取客户端请求命令和回写响应数据的逻辑异步化了，交给 I/O 线程去完成，这里需要特别注意的一点是：<strong>I/O 线程仅仅是读取和解析客户端命令而不会真正去执行命令，客户端命令的执行最终还是要在主线程上完成</strong>。</p><h3 id="源码剖析"><a href="#源码剖析" class="headerlink" title="源码剖析"></a>源码剖析</h3><blockquote><p>以下所有代码基于目前最新的 <a href="https://github.com/redis/redis/tree/6.0.10" target="_blank" rel="noopener">Redis v6.0.10</a> 版本。</p></blockquote><h4 id="多线程初始化"><a href="#多线程初始化" class="headerlink" title="多线程初始化"></a>多线程初始化</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"> 1void initThreadedIO(void) &#123;</span><br><span class="line"> 2    server.io_threads_active &#x3D; 0; &#x2F;* We start with threads not active. *&#x2F;</span><br><span class="line"> 3</span><br><span class="line"> 4    &#x2F;&#x2F; 如果用户只配置了一个 I&#x2F;O 线程，则不会创建新线程（效率低），直接在主线程里处理 I&#x2F;O。</span><br><span class="line"> 5    if (server.io_threads_num &#x3D;&#x3D; 1) return;</span><br><span class="line"> 6</span><br><span class="line"> 7    if (server.io_threads_num &gt; IO_THREADS_MAX_NUM) &#123;</span><br><span class="line"> 8        serverLog(LL_WARNING,&quot;Fatal: too many I&#x2F;O threads configured. &quot;</span><br><span class="line"> 9                             &quot;The maximum number is %d.&quot;, IO_THREADS_MAX_NUM);</span><br><span class="line">10        exit(1);</span><br><span class="line">11    &#125;</span><br><span class="line">12</span><br><span class="line">13    &#x2F;&#x2F; 根据用户配置的 I&#x2F;O 线程数，启动线程。 14    for (int i &#x3D; 0; i &lt; server.io_threads_num; i++) &#123;</span><br><span class="line">15        &#x2F;&#x2F; 初始化 I&#x2F;O 线程的本地任务队列。 16        io_threads_list[i] &#x3D; listCreate();</span><br><span class="line">17        if (i &#x3D;&#x3D; 0) continue; &#x2F;&#x2F; 线程 0 是主线程。 18</span><br><span class="line">19        &#x2F;&#x2F; 初始化 I&#x2F;O 线程并启动。 20        pthread_t tid;</span><br><span class="line">21        &#x2F;&#x2F; 每个 I&#x2F;O 线程会分配一个本地锁，用来休眠和唤醒线程。 22        pthread_mutex_init(&amp;io_threads_mutex[i],NULL);</span><br><span class="line">23        &#x2F;&#x2F; 每个 I&#x2F;O 线程分配一个原子计数器，用来记录当前遗留的任务数量。 24        io_threads_pending[i] &#x3D; 0;</span><br><span class="line">25        &#x2F;&#x2F; 主线程在启动 I&#x2F;O 线程的时候会默认先锁住它，直到有 I&#x2F;O 任务才唤醒它。 26        pthread_mutex_lock(&amp;io_threads_mutex[i]);</span><br><span class="line">27        &#x2F;&#x2F; 启动线程，进入 I&#x2F;O 线程的主逻辑函数 IOThreadMain。 28        if (pthread_create(&amp;tid,NULL,IOThreadMain,(void*)(long)i) !&#x3D; 0) &#123;</span><br><span class="line">29            serverLog(LL_WARNING,&quot;Fatal: Can&#39;t initialize IO thread.&quot;);</span><br><span class="line">30            exit(1);</span><br><span class="line">31        &#125;</span><br><span class="line">32        io_threads[i] &#x3D; tid;</span><br><span class="line">33    &#125;</span><br><span class="line">34&#125;</span><br></pre></td></tr></table></figure><p><code>initThreadedIO</code> 会在 Redis 服务器启动时的初始化工作的末尾被调用，初始化 I/O 多线程并启动。</p><p>Redis 的多线程模式默认是关闭的，需要用户在 <code>redis.conf</code> 配置文件中开启：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1io-threads 4</span><br><span class="line">2io-threads-do-reads yes</span><br></pre></td></tr></table></figure><h4 id="读取请求"><a href="#读取请求" class="headerlink" title="读取请求"></a>读取请求</h4><p>当客户端发送请求命令之后，会触发 Redis 主线程的事件循环，命令处理器 <code>readQueryFromClient</code> 被回调，在以前的单线程模型下，这个方法会直接读取解析客户端命令并执行，但是多线程模式下，则会把 <code>client</code> 加入到 <code>clients_pending_read</code> 任务队列中去，后面主线程再分配到 I/O 线程去读取客户端请求命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"> 1void readQueryFromClient(connection *conn) &#123;</span><br><span class="line"> 2    client *c &#x3D; connGetPrivateData(conn);</span><br><span class="line"> 3    int nread, readlen;</span><br><span class="line"> 4    size_t qblen;</span><br><span class="line"> 5</span><br><span class="line"> 6    &#x2F;&#x2F; 检查是否开启了多线程，如果是则把 client 加入异步队列之后返回。</span><br><span class="line"> 7    if (postponeClientRead(c)) return;</span><br><span class="line"> 8    </span><br><span class="line"> 9    &#x2F;&#x2F; 省略代码，下面的代码逻辑和单线程版本几乎是一样的。 10    ... </span><br><span class="line">11&#125;</span><br><span class="line">12</span><br><span class="line">13int postponeClientRead(client *c) &#123;</span><br><span class="line">14    &#x2F;&#x2F; 当多线程 I&#x2F;O 模式开启、主线程没有在处理阻塞任务时，将 client 加入异步队列。 15    if (server.io_threads_active &amp;&amp;</span><br><span class="line">16        server.io_threads_do_reads &amp;&amp;</span><br><span class="line">17        !ProcessingEventsWhileBlocked &amp;&amp;</span><br><span class="line">18        !(c-&gt;flags &amp; (CLIENT_MASTER|CLIENT_SLAVE|CLIENT_PENDING_READ)))</span><br><span class="line">19    &#123;</span><br><span class="line">20        &#x2F;&#x2F; 给 client 打上 CLIENT_PENDING_READ 标识，表示该 client 需要被多线程处理， 21        &#x2F;&#x2F; 后续在 I&#x2F;O 线程中会在读取和解析完客户端命令之后判断该标识并放弃执行命令，让主线程去执行。 22        c-&gt;flags |&#x3D; CLIENT_PENDING_READ;</span><br><span class="line">23        listAddNodeHead(server.clients_pending_read,c);</span><br><span class="line">24        return 1;</span><br><span class="line">25    &#125; else &#123;</span><br><span class="line">26        return 0;</span><br><span class="line">27    &#125;</span><br><span class="line">28&#125;</span><br></pre></td></tr></table></figure><p>接着主线程会在事件循环的 <code>beforeSleep()</code> 方法中，调用 <code>handleClientsWithPendingReadsUsingThreads</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"> 1int handleClientsWithPendingReadsUsingThreads(void) &#123;</span><br><span class="line"> 2    if (!server.io_threads_active || !server.io_threads_do_reads) return 0;</span><br><span class="line"> 3    int processed &#x3D; listLength(server.clients_pending_read);</span><br><span class="line"> 4    if (processed &#x3D;&#x3D; 0) return 0;</span><br><span class="line"> 5</span><br><span class="line"> 6    if (tio_debug) printf(&quot;%d TOTAL READ pending clients\n&quot;, processed);</span><br><span class="line"> 7</span><br><span class="line"> 8    &#x2F;&#x2F; 遍历待读取的 client 队列 clients_pending_read，</span><br><span class="line"> 9    &#x2F;&#x2F; 通过 RR 轮询均匀地分配给 I&#x2F;O 线程和主线程自己（编号 0）。 10    listIter li;</span><br><span class="line">11    listNode *ln;</span><br><span class="line">12    listRewind(server.clients_pending_read,&amp;li);</span><br><span class="line">13    int item_id &#x3D; 0;</span><br><span class="line">14    while((ln &#x3D; listNext(&amp;li))) &#123;</span><br><span class="line">15        client *c &#x3D; listNodeValue(ln);</span><br><span class="line">16        int target_id &#x3D; item_id % server.io_threads_num;</span><br><span class="line">17        listAddNodeTail(io_threads_list[target_id],c);</span><br><span class="line">18        item_id++;</span><br><span class="line">19    &#125;</span><br><span class="line">20</span><br><span class="line">21    &#x2F;&#x2F; 设置当前 I&#x2F;O 操作为读取操作，给每个 I&#x2F;O 线程的计数器设置分配的任务数量， 22    &#x2F;&#x2F; 让 I&#x2F;O 线程可以开始工作：只读取和解析命令，不执行。 23    io_threads_op &#x3D; IO_THREADS_OP_READ;</span><br><span class="line">24    for (int j &#x3D; 1; j &lt; server.io_threads_num; j++) &#123;</span><br><span class="line">25        int count &#x3D; listLength(io_threads_list[j]);</span><br><span class="line">26        io_threads_pending[j] &#x3D; count;</span><br><span class="line">27    &#125;</span><br><span class="line">28</span><br><span class="line">29    &#x2F;&#x2F; 主线程自己也会去执行读取客户端请求命令的任务，以达到最大限度利用 CPU。 30    listRewind(io_threads_list[0],&amp;li);</span><br><span class="line">31    while((ln &#x3D; listNext(&amp;li))) &#123;</span><br><span class="line">32        client *c &#x3D; listNodeValue(ln);</span><br><span class="line">33        readQueryFromClient(c-&gt;conn);</span><br><span class="line">34    &#125;</span><br><span class="line">35    listEmpty(io_threads_list[0]);</span><br><span class="line">36</span><br><span class="line">37    &#x2F;&#x2F; 忙轮询，累加所有 I&#x2F;O 线程的原子任务计数器，直到所有计数器的遗留任务数量都是 0， 38    &#x2F;&#x2F; 表示所有任务都已经执行完成，结束轮询。 39    while(1) &#123;</span><br><span class="line">40        unsigned long pending &#x3D; 0;</span><br><span class="line">41        for (int j &#x3D; 1; j &lt; server.io_threads_num; j++)</span><br><span class="line">42            pending +&#x3D; io_threads_pending[j];</span><br><span class="line">43        if (pending &#x3D;&#x3D; 0) break;</span><br><span class="line">44    &#125;</span><br><span class="line">45    if (tio_debug) printf(&quot;I&#x2F;O READ All threads finshed\n&quot;);</span><br><span class="line">46</span><br><span class="line">47    &#x2F;&#x2F; 遍历待读取的 client 队列，清除 CLIENT_PENDING_READ 和 CLIENT_PENDING_COMMAND 标记， 48    &#x2F;&#x2F; 然后解析并执行所有 client 的命令。 49    while(listLength(server.clients_pending_read)) &#123;</span><br><span class="line">50        ln &#x3D; listFirst(server.clients_pending_read);</span><br><span class="line">51        client *c &#x3D; listNodeValue(ln);</span><br><span class="line">52        c-&gt;flags &amp;&#x3D; ~CLIENT_PENDING_READ;</span><br><span class="line">53        listDelNode(server.clients_pending_read,ln);</span><br><span class="line">54</span><br><span class="line">55        if (c-&gt;flags &amp; CLIENT_PENDING_COMMAND) &#123;</span><br><span class="line">56            c-&gt;flags &amp;&#x3D; ~CLIENT_PENDING_COMMAND;</span><br><span class="line">57            &#x2F;&#x2F; client 的第一条命令已经被解析好了，直接尝试执行。 58            if (processCommandAndResetClient(c) &#x3D;&#x3D; C_ERR) &#123;</span><br><span class="line">59                &#x2F;* If the client is no longer valid, we avoid 60 * processing the client later. So we just go 61 * to the next. *&#x2F;</span><br><span class="line">62                continue;</span><br><span class="line">63            &#125;</span><br><span class="line">64        &#125;</span><br><span class="line">65        processInputBuffer(c); &#x2F;&#x2F; 继续解析并执行 client 命令。 66</span><br><span class="line">67        &#x2F;&#x2F; 命令执行完成之后，如果 client 中有响应数据需要回写到客户端，则将 client 加入到待写出队列 clients_pending_write 68        if (!(c-&gt;flags &amp; CLIENT_PENDING_WRITE) &amp;&amp; clientHasPendingReplies(c))</span><br><span class="line">69            clientInstallWriteHandler(c);</span><br><span class="line">70    &#125;</span><br><span class="line">71</span><br><span class="line">72    &#x2F;* Update processed count on server *&#x2F;</span><br><span class="line">73    server.stat_io_reads_processed +&#x3D; processed;</span><br><span class="line">74</span><br><span class="line">75    return processed;</span><br><span class="line">76&#125;</span><br></pre></td></tr></table></figure><p>这里的核心工作是：</p><ul><li>遍历待读取的 <code>client</code> 队列 <code>clients_pending_read</code>，通过 RR 策略把所有任务分配给 I/O 线程和主线程去读取和解析客户端命令。</li><li>忙轮询等待所有 I/O 线程完成任务。</li><li>最后再遍历 <code>clients_pending_read</code>，执行所有 <code>client</code> 的命令。</li></ul><h4 id="写回响应"><a href="#写回响应" class="headerlink" title="写回响应"></a>写回响应</h4><p>完成命令的读取、解析以及执行之后，客户端命令的响应数据已经存入 <code>client-&gt;buf</code> 或者 <code>client-&gt;reply</code> 中了，接下来就需要把响应数据回写到客户端了，还是在 <code>beforeSleep</code> 中， 主线程调用 <code>handleClientsWithPendingWritesUsingThreads</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"> 1int handleClientsWithPendingWritesUsingThreads(void) &#123;</span><br><span class="line"> 2    int processed &#x3D; listLength(server.clients_pending_write);</span><br><span class="line"> 3    if (processed &#x3D;&#x3D; 0) return 0; &#x2F;* Return ASAP if there are no clients. *&#x2F;</span><br><span class="line"> 4</span><br><span class="line"> 5    &#x2F;&#x2F; 如果用户设置的 I&#x2F;O 线程数等于 1 或者当前 clients_pending_write 队列中待写出的 client</span><br><span class="line"> 6    &#x2F;&#x2F; 数量不足 I&#x2F;O 线程数的两倍，则不用多线程的逻辑，让所有 I&#x2F;O 线程进入休眠，</span><br><span class="line"> 7    &#x2F;&#x2F; 直接在主线程把所有 client 的相应数据回写到客户端。</span><br><span class="line"> 8    if (server.io_threads_num &#x3D;&#x3D; 1 || stopThreadedIOIfNeeded()) &#123;</span><br><span class="line"> 9        return handleClientsWithPendingWrites();</span><br><span class="line">10    &#125;</span><br><span class="line">11</span><br><span class="line">12    &#x2F;&#x2F; 唤醒正在休眠的 I&#x2F;O 线程（如果有的话）。 13    if (!server.io_threads_active) startThreadedIO();</span><br><span class="line">14</span><br><span class="line">15    if (tio_debug) printf(&quot;%d TOTAL WRITE pending clients\n&quot;, processed);</span><br><span class="line">16</span><br><span class="line">17    &#x2F;&#x2F; 遍历待写出的 client 队列 clients_pending_write， 18    &#x2F;&#x2F; 通过 RR 轮询均匀地分配给 I&#x2F;O 线程和主线程自己（编号 0）。 19    listIter li;</span><br><span class="line">20    listNode *ln;</span><br><span class="line">21    listRewind(server.clients_pending_write,&amp;li);</span><br><span class="line">22    int item_id &#x3D; 0;</span><br><span class="line">23    while((ln &#x3D; listNext(&amp;li))) &#123;</span><br><span class="line">24        client *c &#x3D; listNodeValue(ln);</span><br><span class="line">25        c-&gt;flags &amp;&#x3D; ~CLIENT_PENDING_WRITE;</span><br><span class="line">26</span><br><span class="line">27        &#x2F;* Remove clients from the list of pending writes since 28 * they are going to be closed ASAP. *&#x2F;</span><br><span class="line">29        if (c-&gt;flags &amp; CLIENT_CLOSE_ASAP) &#123;</span><br><span class="line">30            listDelNode(server.clients_pending_write, ln);</span><br><span class="line">31            continue;</span><br><span class="line">32        &#125;</span><br><span class="line">33</span><br><span class="line">34        int target_id &#x3D; item_id % server.io_threads_num;</span><br><span class="line">35        listAddNodeTail(io_threads_list[target_id],c);</span><br><span class="line">36        item_id++;</span><br><span class="line">37    &#125;</span><br><span class="line">38</span><br><span class="line">39    &#x2F;&#x2F; 设置当前 I&#x2F;O 操作为写出操作，给每个 I&#x2F;O 线程的计数器设置分配的任务数量， 40    &#x2F;&#x2F; 让 I&#x2F;O 线程可以开始工作，把写出缓冲区（client-&gt;buf 或 c-&gt;reply）中的响应数据回写到客户端。 41    io_threads_op &#x3D; IO_THREADS_OP_WRITE;</span><br><span class="line">42    for (int j &#x3D; 1; j &lt; server.io_threads_num; j++) &#123;</span><br><span class="line">43        int count &#x3D; listLength(io_threads_list[j]);</span><br><span class="line">44        io_threads_pending[j] &#x3D; count;</span><br><span class="line">45    &#125;</span><br><span class="line">46</span><br><span class="line">47    &#x2F;&#x2F; 主线程自己也会去执行读取客户端请求命令的任务，以达到最大限度利用 CPU。 48    listRewind(io_threads_list[0],&amp;li);</span><br><span class="line">49    while((ln &#x3D; listNext(&amp;li))) &#123;</span><br><span class="line">50        client *c &#x3D; listNodeValue(ln);</span><br><span class="line">51        writeToClient(c,0);</span><br><span class="line">52    &#125;</span><br><span class="line">53    listEmpty(io_threads_list[0]);</span><br><span class="line">54</span><br><span class="line">55    &#x2F;&#x2F; 忙轮询，累加所有 I&#x2F;O 线程的原子任务计数器，直到所有计数器的遗留任务数量都是 0。 56    &#x2F;&#x2F; 表示所有任务都已经执行完成，结束轮询。 57    while(1) &#123;</span><br><span class="line">58        unsigned long pending &#x3D; 0;</span><br><span class="line">59        for (int j &#x3D; 1; j &lt; server.io_threads_num; j++)</span><br><span class="line">60            pending +&#x3D; io_threads_pending[j];</span><br><span class="line">61        if (pending &#x3D;&#x3D; 0) break;</span><br><span class="line">62    &#125;</span><br><span class="line">63    if (tio_debug) printf(&quot;I&#x2F;O WRITE All threads finshed\n&quot;);</span><br><span class="line">64</span><br><span class="line">65    &#x2F;&#x2F; 最后再遍历一次 clients_pending_write 队列，检查是否还有 client 的写出缓冲区中有残留数据， 66    &#x2F;&#x2F; 如果有，那就为 client 注册一个命令回复器 sendReplyToClient，等待客户端写就绪再继续把数据回写。 67    listRewind(server.clients_pending_write,&amp;li);</span><br><span class="line">68    while((ln &#x3D; listNext(&amp;li))) &#123;</span><br><span class="line">69        client *c &#x3D; listNodeValue(ln);</span><br><span class="line">70</span><br><span class="line">71        &#x2F;&#x2F; 检查 client 的写出缓冲区是否还有遗留数据。 72        if (clientHasPendingReplies(c) &amp;&amp;</span><br><span class="line">73                connSetWriteHandler(c-&gt;conn, sendReplyToClient) &#x3D;&#x3D; AE_ERR)</span><br><span class="line">74        &#123;</span><br><span class="line">75            freeClientAsync(c);</span><br><span class="line">76        &#125;</span><br><span class="line">77    &#125;</span><br><span class="line">78    listEmpty(server.clients_pending_write);</span><br><span class="line">79</span><br><span class="line">80    &#x2F;* Update processed count on server *&#x2F;</span><br><span class="line">81    server.stat_io_writes_processed +&#x3D; processed;</span><br><span class="line">82</span><br><span class="line">83    return processed;</span><br><span class="line">84&#125;</span><br></pre></td></tr></table></figure><p>这里的核心工作是：</p><ul><li>检查当前任务负载，如果当前的任务数量不足以用多线程模式处理的话，则休眠 I/O 线程并且直接同步将响应数据回写到客户端。</li><li>唤醒正在休眠的 I/O 线程（如果有的话）。</li><li>遍历待写出的 <code>client</code> 队列 <code>clients_pending_write</code>，通过 RR 策略把所有任务分配给 I/O 线程和主线程去将响应数据写回到客户端。</li><li>忙轮询等待所有 I/O 线程完成任务。</li><li>最后再遍历 <code>clients_pending_write</code>，为那些还残留有响应数据的 <code>client</code> 注册命令回复处理器 <code>sendReplyToClient</code>，等待客户端可写之后在事件循环中继续回写残余的响应数据。</li></ul><h4 id="I-O-线程主逻辑"><a href="#I-O-线程主逻辑" class="headerlink" title="I/O 线程主逻辑"></a>I/O 线程主逻辑</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"> 1void *IOThreadMain(void *myid) &#123;</span><br><span class="line"> 2    &#x2F;* The ID is the thread number (from 0 to server.iothreads_num-1), and is</span><br><span class="line"> 3 * used by the thread to just manipulate a single sub-array of clients. *&#x2F;</span><br><span class="line"> 4    long id &#x3D; (unsigned long)myid;</span><br><span class="line"> 5    char thdname[16];</span><br><span class="line"> 6</span><br><span class="line"> 7    snprintf(thdname, sizeof(thdname), &quot;io_thd_%ld&quot;, id);</span><br><span class="line"> 8    redis_set_thread_title(thdname);</span><br><span class="line"> 9    &#x2F;&#x2F; 设置 I&#x2F;O 线程的 CPU 亲和性，尽可能将 I&#x2F;O 线程（以及主线程，不在这里设置）绑定到用户配置的 10    &#x2F;&#x2F; CPU 列表上。 11    redisSetCpuAffinity(server.server_cpulist);</span><br><span class="line">12    makeThreadKillable();</span><br><span class="line">13</span><br><span class="line">14    while(1) &#123;</span><br><span class="line">15        &#x2F;&#x2F; 忙轮询，100w 次循环，等待主线程分配 I&#x2F;O 任务。 16        for (int j &#x3D; 0; j &lt; 1000000; j++) &#123;</span><br><span class="line">17            if (io_threads_pending[id] !&#x3D; 0) break;</span><br><span class="line">18        &#125;</span><br><span class="line">19</span><br><span class="line">20        &#x2F;&#x2F; 如果 100w 次忙轮询之后如果还是没有任务分配给它，则通过尝试加锁进入休眠， 21        &#x2F;&#x2F; 等待主线程分配任务之后调用 startThreadedIO 解锁，唤醒 I&#x2F;O 线程去执行。 22        if (io_threads_pending[id] &#x3D;&#x3D; 0) &#123;</span><br><span class="line">23            pthread_mutex_lock(&amp;io_threads_mutex[id]);</span><br><span class="line">24            pthread_mutex_unlock(&amp;io_threads_mutex[id]);</span><br><span class="line">25            continue;</span><br><span class="line">26        &#125;</span><br><span class="line">27</span><br><span class="line">28        serverAssert(io_threads_pending[id] !&#x3D; 0);</span><br><span class="line">29</span><br><span class="line">30        if (tio_debug) printf(&quot;[%ld] %d to handle\n&quot;, id, (int)listLength(io_threads_list[id]));</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33        &#x2F;&#x2F; 注意：主线程分配任务给 I&#x2F;O 线程之时， 34        &#x2F;&#x2F; 会把任务加入每个线程的本地任务队列 io_threads_list[id]， 35        &#x2F;&#x2F; 但是当 I&#x2F;O 线程开始执行任务之后，主线程就不会再去访问这些任务队列，避免数据竞争。 36        listIter li;</span><br><span class="line">37        listNode *ln;</span><br><span class="line">38        listRewind(io_threads_list[id],&amp;li);</span><br><span class="line">39        while((ln &#x3D; listNext(&amp;li))) &#123;</span><br><span class="line">40            client *c &#x3D; listNodeValue(ln);</span><br><span class="line">41            &#x2F;&#x2F; 如果当前是写出操作，则把 client 的写出缓冲区中的数据回写到客户端。 42            if (io_threads_op &#x3D;&#x3D; IO_THREADS_OP_WRITE) &#123;</span><br><span class="line">43                writeToClient(c,0);</span><br><span class="line">44              &#x2F;&#x2F; 如果当前是读取操作，则socket 读取客户端的请求命令并解析第一条命令。 45            &#125; else if (io_threads_op &#x3D;&#x3D; IO_THREADS_OP_READ) &#123;</span><br><span class="line">46                readQueryFromClient(c-&gt;conn);</span><br><span class="line">47            &#125; else &#123;</span><br><span class="line">48                serverPanic(&quot;io_threads_op value is unknown&quot;);</span><br><span class="line">49            &#125;</span><br><span class="line">50        &#125;</span><br><span class="line">51        listEmpty(io_threads_list[id]);</span><br><span class="line">52        &#x2F;&#x2F; 所有任务执行完之后把自己的计数器置 0，主线程通过累加所有 I&#x2F;O 线程的计数器 53        &#x2F;&#x2F; 判断是否所有 I&#x2F;O 线程都已经完成工作。 54        io_threads_pending[id] &#x3D; 0;</span><br><span class="line">55</span><br><span class="line">56        if (tio_debug) printf(&quot;[%ld] Done\n&quot;, id);</span><br><span class="line">57    &#125;</span><br><span class="line">58&#125;</span><br></pre></td></tr></table></figure><p>I/O 线程启动之后，会先进入忙轮询，判断原子计数器中的任务数量，如果是非 0 则表示主线程已经给它分配了任务，开始执行任务，否则就一直忙轮询一百万次等待，忙轮询结束之后再查看计数器，如果还是 0，则尝试加本地锁，因为主线程在启动 I/O 线程之时就已经提前锁住了所有 I/O 线程的本地锁，因此 I/O 线程会进行休眠，等待主线程唤醒。</p><p>主线程会在每次事件循环中尝试调用 <code>startThreadedIO</code> 唤醒 I/O 线程去执行任务，如果接收到客户端请求命令，则 I/O 线程会被唤醒开始工作，根据主线程设置的 <code>io_threads_op</code> 标识去执行命令读取和解析或者回写响应数据的任务，I/O 线程在收到主线程通知之后，会遍历自己的本地任务队列 <code>io_threads_list[id]</code>，取出一个个 <code>client</code> 执行任务：</p><ul><li>如果当前是写出操作，则调用 <code>writeToClient</code>，通过 socket 把 <code>client-&gt;buf</code> 或者 <code>client-&gt;reply</code> 里的响应数据回写到客户端。</li><li>如果当前是读取操作，则调用 <code>readQueryFromClient</code>，通过 socket 读取客户端命令，存入 <code>client-&gt;querybuf</code>，然后调用 <code>processInputBuffer</code> 去解析命令，这里最终只会解析到第一条命令，然后就结束，不会去执行命令。</li><li>在全部任务执行完之后把自己的原子计数器置 0，以告知主线程自己已经完成了工作。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"> 1void processInputBuffer(client *c) &#123;</span><br><span class="line"> 2&#x2F;&#x2F; 省略代码</span><br><span class="line"> 3...</span><br><span class="line"> 4</span><br><span class="line"> 5    while(c-&gt;qb_pos &lt; sdslen(c-&gt;querybuf)) &#123;</span><br><span class="line"> 6        &#x2F;* Return if clients are paused. *&#x2F;</span><br><span class="line"> 7        if (!(c-&gt;flags &amp; CLIENT_SLAVE) &amp;&amp; clientsArePaused()) break;</span><br><span class="line"> 8</span><br><span class="line"> 9        &#x2F;* Immediately abort if the client is in the middle of something. *&#x2F;</span><br><span class="line">10        if (c-&gt;flags &amp; CLIENT_BLOCKED) break;</span><br><span class="line">11</span><br><span class="line">12        &#x2F;* Don&#39;t process more buffers from clients that have already pending 13 * commands to execute in c-&gt;argv. *&#x2F;</span><br><span class="line">14        if (c-&gt;flags &amp; CLIENT_PENDING_COMMAND) break;</span><br><span class="line">15        &#x2F;* Multibulk processing could see a &lt;&#x3D; 0 length. *&#x2F;</span><br><span class="line">16        if (c-&gt;argc &#x3D;&#x3D; 0) &#123;</span><br><span class="line">17            resetClient(c);</span><br><span class="line">18        &#125; else &#123;</span><br><span class="line">19            &#x2F;&#x2F; 判断 client 是否具有 CLIENT_PENDING_READ 标识，如果是处于多线程 I&#x2F;O 的模式下， 20            &#x2F;&#x2F; 那么此前已经在 readQueryFromClient -&gt; postponeClientRead 中为 client 打上该标识， 21            &#x2F;&#x2F; 则立刻跳出循环结束，此时第一条命令已经解析完成，但是不执行命令。 22            if (c-&gt;flags &amp; CLIENT_PENDING_READ) &#123;</span><br><span class="line">23                c-&gt;flags |&#x3D; CLIENT_PENDING_COMMAND;</span><br><span class="line">24                break;</span><br><span class="line">25            &#125;</span><br><span class="line">26</span><br><span class="line">27            &#x2F;&#x2F; 执行客户端命令 28            if (processCommandAndResetClient(c) &#x3D;&#x3D; C_ERR) &#123;</span><br><span class="line">29                &#x2F;* If the client is no longer valid, we avoid exiting this 30 * loop and trimming the client buffer later. So we return 31 * ASAP in that case. *&#x2F;</span><br><span class="line">32                return;</span><br><span class="line">33            &#125;</span><br><span class="line">34        &#125;</span><br><span class="line">35    &#125;</span><br><span class="line">36</span><br><span class="line">37...</span><br><span class="line">38&#125;</span><br></pre></td></tr></table></figure><p>这里需要额外关注 I/O 线程初次启动时会设置当前线程的 CPU 亲和性，也就是绑定当前线程到用户配置的 CPU 上，在启动 Redis 服务器主线程的时候同样会设置 CPU 亲和性，Redis 的核心网络模型引入多线程之后，加上之前的多线程异步任务、多进程（BGSAVE、AOF、BIO、Sentinel 脚本任务等），Redis 现如今的系统并发度已经很大了，而 Redis 本身又是一个对吞吐量和延迟极度敏感的系统，所以用户需要 Redis 对 CPU 资源有更细粒度的控制，这里主要考虑的是两方面：CPU 高速缓存和 NUMA 架构。</p><p>首先是 CPU 高速缓存（这里讨论的是 L1 Cache 和 L2 Cache 都集成在 CPU 中的硬件架构），这里想象一种场景：Redis 主进程正在 CPU-1 上运行，给客户端提供数据服务，此时 Redis 启动了子进程进行数据持久化（BGSAVE 或者 AOF），系统调度之后子进程抢占了主进程的 CPU-1，主进程被调度到 CPU-2 上去运行，导致之前 CPU-1 的高速缓存里的相关指令和数据被汰换掉，CPU-2 需要重新加载指令和数据到自己的本地高速缓存里，浪费 CPU 资源，降低性能。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/ce81e210d8a490462c28664fda507171.png" alt=""></p><p>因此，Redis 通过设置 CPU 亲和性，可以将主进程/线程和子进程/线程绑定到不同的核隔离开来，使之互不干扰，能有效地提升系统性能。</p><p>其次是基于 NUMA 架构的考虑，在 NUMA 体系下，内存控制器芯片被集成到处理器内部，形成 CPU 本地内存，访问本地内存只需通过内存通道而无需经过系统总线，访问时延大大降低，而多个处理器之间通过 QPI 数据链路互联，跨 NUMA 节点的内存访问开销远大于本地内存的访问：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/8e0d1bd1801cb3016ffe3cbc0b1b851e.png" alt=""></p><p>因此，Redis 通过设置 CPU 亲和性，让主进程/线程尽可能在固定的 NUMA 节点上的 CPU 上运行，更多地使用本地内存而不需要跨节点访问数据，同样也能大大地提升性能。</p><p>关于 NUMA 相关知识请读者自行查阅，篇幅所限这里就不再展开，以后有时间我再单独写一篇文章介绍。</p><p>最后还有一点，阅读过源码的读者可能会有疑问，Redis 的多线程模式下，似乎并没有对数据进行锁保护，事实上 Redis 的多线程模型是全程无锁（Lock-free）的，这是通过原子操作+交错访问来实现的，主线程和 I/O 线程之间共享的变量有三个：<code>io_threads_pending</code> 计数器、<code>io_threads_op</code> I/O 标识符和 <code>io_threads_list</code> 线程本地任务队列。</p><p><code>io_threads_pending</code> 是原子变量，不需要加锁保护，<code>io_threads_op</code> 和 <code>io_threads_list</code> 这两个变量则是通过控制主线程和 I/O 线程交错访问来规避共享数据竞争问题：I/O 线程启动之后会通过忙轮询和锁休眠等待主线程的信号，在这之前它不会去访问自己的本地任务队列 <code>io_threads_list[id]</code>，而主线程会在分配完所有任务到各个 I/O 线程的本地队列之后才去唤醒 I/O 线程开始工作，并且主线程之后在 I/O 线程运行期间只会访问自己的本地任务队列 <code>io_threads_list[0]</code> 而不会再去访问 I/O 线程的本地队列，这也就保证了主线程永远会在 I/O 线程之前访问 <code>io_threads_list</code> 并且之后不再访问，保证了交错访问。<code>io_threads_op</code> 同理，主线程会在唤醒 I/O 线程之前先设置好 <code>io_threads_op</code> 的值，并且在 I/O 线程运行期间不会再去访问这个变量。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/c39803cf3a011071130780a4975793fb.png" alt=""></p><h3 id="性能提升"><a href="#性能提升" class="headerlink" title="性能提升"></a>性能提升</h3><p>Redis 将核心网络模型改造成多线程模式追求的当然是最终性能上的提升，所以最终还是要以 benchmark 数据见真章：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/57f8ca43cabf9f730919626d7e6fe1a0.png" alt=""></p><p>测试数据表明，Redis 在使用多线程模式之后性能大幅提升，达到了一倍。更详细的性能压测数据可以参阅这篇文章：<a href="https://itnext.io/benchmarking-the-experimental-redis-multi-threaded-i-o-1bb28b69a314" target="_blank" rel="noopener">Benchmarking the experimental Redis Multi-Threaded I/O</a>。</p><p>以下是美图技术团队实测的新旧 Redis 版本性能对比图，仅供参考：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/5fc23efb73e636b4cbb8fcc31c1996cb.png" alt=""></p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/fdf397bbe83896bcc1ac482731012aa1.png" alt=""></p><h3 id="模型缺陷"><a href="#模型缺陷" class="headerlink" title="模型缺陷"></a>模型缺陷</h3><p>首先第一个就是我前面提到过的，Redis 的多线程网络模型实际上并不是一个标准的 Multi-Reactors/Master-Workers 模型，和其他主流的开源网络服务器的模式有所区别，最大的不同就是在标准的 Multi-Reactors/Master-Workers 模式下，Sub Reactors/Workers 会完成 <code>网络读 -&gt; 数据解析 -&gt; 命令执行 -&gt; 网络写</code> 整套流程，Main Reactor/Master 只负责分派任务，而在 Redis 的多线程方案中，I/O 线程任务仅仅是通过 socket 读取客户端请求命令并解析，却没有真正去执行命令，所有客户端命令最后还需要回到主线程去执行，因此对多核的利用率并不算高，而且每次主线程都必须在分配完任务之后忙轮询等待所有 I/O 线程完成任务之后才能继续执行其他逻辑。</p><p>Redis 之所以如此设计它的多线程网络模型，我认为主要的原因是为了保持兼容性，因为以前 Redis 是单线程的，所有的客户端命令都是在单线程的事件循环里执行的，也因此 Redis 里所有的数据结构都是非线程安全的，现在引入多线程，如果按照标准的 Multi-Reactors/Master-Workers 模式来实现，则所有内置的数据结构都必须重构成线程安全的，这个工作量无疑是巨大且麻烦的。</p><p>所以，在我看来，Redis 目前的多线程方案更像是一个折中的选择：既保持了原系统的兼容性，又能利用多核提升 I/O 性能。</p><p>其次，目前 Redis 的多线程模型中，主线程和 I/O 线程的通信过于简单粗暴：忙轮询和锁，因为通过自旋忙轮询进行等待，导致 Redis 在启动的时候以及运行期间偶尔会有短暂的 CPU 空转引起的高占用率，而且这个通信机制的最终实现看起来非常不直观和不简洁，希望后面 Redis 能对目前的方案加以改进。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Redis 作为缓存系统的事实标准，它的底层原理值得开发者去深入学习，Redis 自 2009 年发布第一版之后，其单线程网络模型的选择在社区中从未停止过讨论，多年来一直有呼声希望 Redis 能引入多线程从而利用多核优势，但是作者 antirez 是一个追求大道至简的开发者，对 Redis 加入任何新功能都异常谨慎，所以在 Redis 初版发布的十年后才最终将 Redis 的核心网络模型改造成多线程模式，这期间甚至诞生了一些 Redis 多线程的替代项目。虽然 antirez 一直在推迟多线程的方案，但却从未停止思考多线程的可行性，Redis 多线程网络模型的改造不是一朝一夕的事情，这其中牵扯到项目的方方面面，所以我们可以看到 Redis 的最终方案也并不完美，没有采用主流的多线程模式设计。</p><p>让我们来回顾一下 Redis 多线程网络模型的设计方案：</p><ul><li>使用 I/O 线程实现网络 I/O 多线程化，I/O 线程只负责网络 I/O 和命令解析，不执行客户端命令。</li><li>利用原子操作+交错访问实现无锁的多线程模型。</li><li>通过设置 CPU 亲和性，隔离主进程和其他子进程，让多线程网络模型能发挥最大的性能。</li></ul><p>通读本文之后，相信读者们应该能够了解到一个优秀的网络系统的实现所涉及到的计算机领域的各种技术：设计模式、网络 I/O、并发编程、操作系统底层，甚至是计算机硬件。另外还需要对项目迭代和重构的谨慎，对技术方案的深入思考，绝不仅仅是写好代码这一个难点。</p><h2 id="参考-amp-延伸阅读"><a href="#参考-amp-延伸阅读" class="headerlink" title="参考&amp;延伸阅读"></a>参考&amp;延伸阅读</h2><ul><li><a href="https://github.com/redis/redis/tree/5.0.10" target="_blank" rel="noopener">Redis v5.0.10</a></li><li><a href="https://github.com/redis/redis/tree/6.0.10" target="_blank" rel="noopener">Redis v6.0.10</a></li><li><a href="http://antirez.com/news/93" target="_blank" rel="noopener">Lazy Redis is better Redis</a></li><li><a href="http://antirez.com/news/126" target="_blank" rel="noopener">An update about Redis developments in 2019</a></li><li><a href="https://redis.io/topics/benchmarks" target="_blank" rel="noopener">How fast is Redis?</a></li><li><a href="https://strikefreedom.top/go-netpoll-io-multiplexing-reactor" target="_blank" rel="noopener">Go netpoller 原生网络模型之源码全面揭秘</a></li><li><a href="https://strikefreedom.top/linux-io-and-zero-copy" target="_blank" rel="noopener">Linux I/O 原理和 Zero-copy 技术全面揭秘</a></li><li><a href="https://itnext.io/benchmarking-the-experimental-redis-multi-threaded-i-o-1bb28b69a314" target="_blank" rel="noopener">Benchmarking the experimental Redis Multi-Threaded I/O</a></li><li><a href="https://frankdenneman.nl/2016/07/07/numa-deep-dive-part-1-uma-numa/" target="_blank" rel="noopener">NUMA DEEP DIVE PART 1: FROM UMA TO NUMA</a></li></ul><p>本文转自 <a href="https://strikefreedom.top/multiple-threaded-network-model-in-redis" target="_blank" rel="noopener">https://strikefreedom.top/multiple-threaded-network-model-in-redis</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>24张图，九大数据结构安排得明明白白！</title>
      <link href="/posts/1fa9bd20/"/>
      <url>/posts/1fa9bd20/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>数据结构想必大家都不会陌生，对于一个成熟的程序员而言，熟悉和掌握数据结构和算法也是基本功之一。数据结构本身其实不过是数据按照特点关系进行存储或者组织的集合，特殊的结构在不同的应用场景中往往会带来不一样的处理效率。</p><p>常用的数据结构可根据数据访问的特点分为<strong>线性结构</strong>和<strong>非线性结构</strong>。线性结构包括常见的链表、栈、队列等，非线性结构包括树、图等。数据结构种类繁多，本文将通过<strong>图解的方式</strong>对常用的数据结构进行理论上的介绍和讲解，以方便大家掌握常用数据结构的基本知识。</p><h2 id="1-数组"><a href="#1-数组" class="headerlink" title=" 1  数组"></a> 1  数组</h2><p>数组可以说是最基本最常见的数据结构。数组一般用来存储相同类型的数据，可通过数组名和下标进行数据的访问和更新。数组中元素的存储是按照先后顺序进行的，同时在内存中也是按照这个顺序进行连续存放。数组相邻元素之间的内存地址的间隔一般就是数组数据类型的大小。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/748b5f62c21fd156d2ac0aa8e45ee3cd.jpeg" alt=""></p><h2 id="2-链表"><a href="#2-链表" class="headerlink" title=" 2  链表"></a> 2  链表</h2><p>链表相较于数组，除了数据域，还增加了指针域用于构建链式的存储数据。链表中每一个节点都包含此节点的数据和指向下一节点地址的指针。由于是通过指针进行下一个数据元素的查找和访问，使得链表的自由度更高。</p><p>这表现在对节点进行增加和删除时，只需要对上一节点的指针地址进行修改，而无需变动其它的节点。不过事物皆有两极，指针带来高自由度的同时，自然会牺牲数据查找的效率和多余空间的使用。</p><p>一般常见的是有头有尾的单链表，对指针域进行反向链接，还可以形成双向链表或者循环链表。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/f8849098ed9806efb722d05937f48d93.jpeg" alt=""></p><h4 id="链表和数组对比"><a href="#链表和数组对比" class="headerlink" title="链表和数组对比"></a>链表和数组对比</h4><p>链表和数组在实际的使用过程中需要根据自身的优劣势进行选择。链表和数组的异同点也是面试中高频的考察点之一。这里对单链表和数组的区别进行了对比和总结。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/e2ef0825aacb46149329a6a0ed26fe82.png" alt=""></p><h2 id="3-跳表"><a href="#3-跳表" class="headerlink" title=" 3  跳表"></a> 3  跳表</h2><p>从上面的对比中可以看出，链表虽然通过增加指针域提升了自由度，但是却导致数据的查询效率恶化。特别是当链表长度很长的时候，对数据的查询还得从头依次查询，这样的效率会更低。跳表的产生就是为了解决链表过长的问题，通过增加链表的多级索引来加快原始链表的查询效率。这样的方式可以让查询的时间复杂度从O(n)提升至O(logn)。  </p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/99835eb24cb99c86e2b06a23a7697b0e.jpeg" alt=""></p><p>跳表通过增加的多级索引能够实现高效的动态插入和删除，其效率和红黑树和平衡二叉树不相上下。目前redis和levelDB都有用到跳表。</p><p>从上图可以看出，索引级的指针域除了指向下一个索引位置的指针，还有一个down指针指向低一级的链表位置，这样才能实现跳跃查询的目的。</p><h2 id="4-栈"><a href="#4-栈" class="headerlink" title=" 4 栈"></a> 4 栈</h2><p>栈是一种比较简单的数据结构，常用一句话描述其特性，后进先出。栈本身是一个线性表，但是在这个表中只有一个口子允许数据的进出。这种模式可以参考腔肠动物…即进食和排泄都用一个口…</p><p>栈的常用操作包括入栈push和出栈pop，对应于数据的压入和压出。还有访问栈顶数据、判断栈是否为空和判断栈的大小等。由于栈后进先出的特性，常可以作为数据操作的临时容器，对数据的顺序进行调控，与其它数据结构相结合可获得许多灵活的处理。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/99664227c2793530c6dad54358c19231.gif" alt=""></p><h2 id="5-队列"><a href="#5-队列" class="headerlink" title=" 5  队列"></a> 5  队列</h2><p>队列是栈的兄弟结构，与栈的后进先出相对应，队列是一种先进先出的数据结构。顾名思义，队列的数据存储是如同排队一般，先存入的数据先被压出。常与栈一同配合，可发挥最大的实力。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/b01d61540e5c073f053f94037d517360.gif" alt=""></p><h2 id="6-树"><a href="#6-树" class="headerlink" title=" 6  树"></a> 6  树</h2><p>树作为一种树状的数据结构，其数据节点之间的关系也如大树一样，将有限个节点根据不同层次关系进行排列，从而形成数据与数据之间的父子关系。常见的数的表示形式更接近“倒挂的树”，因为它将根朝上，叶朝下。</p><p>树的数据存储在结点中，每个结点有零个或者多个子结点。没有父结点的结点在最顶端，成为根节点；没有非根结点有且只有一个父节点；每个非根节点又可以分为多个不相交的子树。</p><p>这意味着树是具备层次关系的，父子关系清晰，家庭血缘关系明朗；这也是树与图之间最主要的区别。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/6376759251e504ff02b8ce35387eb676.jpeg" alt=""></p><p>别看树好像很高级，其实可看作是链表的高配版。树的实现就是对链表的指针域进行了扩充，增加了多个地址指向子结点。同时将“链表”竖起来，从而凸显了结点之间的层次关系，更便于分析和理解。</p><p>树可以衍生出许多的结构，若将指针域设置为双指针，那么即可形成最常见的二叉树，即每个结点最多有两个子树的树结构。二叉树根据结点的排列和数量还可进一度划分为完全二叉树、满二叉树、平衡二叉树、红黑树等。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/045501fd30e7f82ff164c9c8f8f74ba3.jpeg" alt=""></p><blockquote><p><strong>完全二叉树</strong>：除了最后一层结点，其它层的结点数都达到了最大值；同时最后一层的结点都是按照从左到右依次排布。</p></blockquote><blockquote><p><strong>满二叉树</strong>：除了最后一层，其它层的结点都有两个子结点。</p></blockquote><h4 id="平衡二叉树"><a href="#平衡二叉树" class="headerlink" title="平衡二叉树"></a>平衡二叉树</h4><p>平衡二叉树又被称为AVL树，它是一棵二叉排序树，且具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。</p><blockquote><p><strong>二叉排序树</strong>：是一棵空树，或者：若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；它的左、右子树也分别为二叉排序树。</p></blockquote><blockquote><p><strong>树的高度</strong>：结点层次的最大值</p></blockquote><blockquote><p><strong>平衡因子</strong>：左子树高度 - 右子树高度</p></blockquote><p>二叉排序树意味着二叉树中的数据是排好序的，顺序为左结点&lt;根节点&lt;右结点，这表明二叉排序树的中序遍历结果是有序的。（还不懂二叉树四种遍历方式[前序遍历、中序遍历、后序遍历、层序遍历]的同学赶紧补习！）</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/bd3a92045f324401714d9b002b84c91c.jpeg" alt=""></p><p>平衡二叉树的产生是为了解决二叉排序树在插入时发生线性排列的现象。由于二叉排序树本身为有序，当插入一个有序程度十分高的序列时，生成的二叉排序树会持续在某个方向的字数上插入数据，导致最终的二叉排序树会退化为链表，从而使得二叉树的查询和插入效率恶化。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/eac91a71da9b77e90d9f992cb986b49c.jpeg" alt=""></p><p>平衡二叉树的出现能够解决上述问题，但是在构造平衡二叉树时，却需要采用不同的调整方式，使得二叉树在插入数据后保持平衡。主要的四种调整方式有LL（左旋）、RR（右旋）、LR（先左旋再右旋）、RL（先右旋再左旋）。这里先给大家介绍下简单的单旋转操作，左旋和右旋。LR和RL本质上只是LL和RR的组合。</p><blockquote><p>在插入一个结点后应该沿搜索路径将路径上的结点平衡因子进行修改，当平衡因子大于1时，就需要进行平衡化处理。从发生不平衡的结点起，沿刚才回溯的路径取直接下两层的结点，如果这三个结点在一条直线上，则采用<strong>单旋转</strong>进行平衡化，如果这三个结点位于一条折线上，则采用<strong>双旋转</strong>进行平衡化。</p></blockquote><p>左旋：S为当前需要左旋的结点，E为当前结点的父节点。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/ae87f7acf4f59a2feff794bb588f5781.jpeg" alt=""></p><p>左旋的操作可以用一句话简单表示：将当前结点S的左孩子旋转为当前结点父结点E的右孩子，同时将父结点E旋转为当前结点S的左孩子。可用动画表示：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/591b2b8b5dece5da4936d823a07a3f39.gif" alt=""></p><p>右旋：S为当前需要左旋的结点，E为当前结点的父节点。右单旋是左单旋的镜像旋转。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9b9e7cf462a0f097d79cbd2286aba499.jpeg" alt=""></p><p>左旋的操作同样可以用一句话简单表示：将当前结点S的左孩子E的右孩子旋转为当前结点S的左孩子，同时将当前结点S旋转为左孩子E的右孩子。可用动画表示：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/772eb4f59b7f5ba6da045f220a506d04.gif" alt=""></p><h4 id="红黑树"><a href="#红黑树" class="headerlink" title="红黑树"></a>红黑树</h4><p>平衡二叉树（AVL）为了追求高度平衡，需要通过平衡处理使得左右子树的高度差必须小于等于1。高度平衡带来的好处是能够提供更高的搜索效率，其最坏的查找时间复杂度都是O(logN)。但是由于需要维持这份高度平衡，所付出的代价就是当对树种结点进行插入和删除时，需要经过多次旋转实现复衡。这导致AVL的插入和删除效率并不高。</p><p>为了解决这样的问题，能不能找一种结构能够兼顾搜索和插入删除的效率呢？这时候红黑树便申请出战了。</p><p>红黑树具有五个特性：</p><blockquote><ol><li><p>每个结点要么是红的要么是黑的。</p></li><li><p>根结点是黑的。</p></li><li><p>每个叶结点（叶结点即指树尾端NIL指针或NULL结点）都是黑的。</p></li><li><p>如果一个结点是红的，那么它的两个儿子都是黑的。</p></li><li><p>对于任意结点而言，其到叶结点树尾端NIL指针的每条路径都包含相同数目的黑结点。</p></li></ol></blockquote><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/eabfffc43643266c9337557e6eef5103.jpeg" alt="">红黑树通过将结点进行红黑着色，使得原本高度平衡的树结构被稍微打乱，平衡程度降低。红黑树不追求完全平衡，只要求达到部分平衡。这是一种折中的方案，大大提高了结点删除和插入的效率。C++中的STL就常用到红黑树作为底层的数据结构。</p><h4 id="红黑树VS平衡二叉树"><a href="#红黑树VS平衡二叉树" class="headerlink" title="红黑树VS平衡二叉树"></a>红黑树VS平衡二叉树</h4><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/0ff26c83bd79e937ef6622a4f8665a91.png" alt=""></p><p>除了上面所提及的树结构，还有许多广泛应用在数据库、磁盘存储等场景下的树结构。比如B树、B+树等。这里就先不介绍了诶，下次在讲述相关存储原理的时候将会着重介绍。（其实是因为懒）</p><h2 id="7-堆"><a href="#7-堆" class="headerlink" title=" 7  堆"></a> 7  堆</h2><p>了解完二叉树，再来理解堆就不是什么难事了。堆通常是一个可以被看做一棵树的数组对象。堆的具体实现一般不通过指针域，而是通过构建一个一维数组与二叉树的父子结点进行对应，因此堆总是一颗完全二叉树。</p><p>对于任意一个父节点的序号n来说（这里n从0算），它的子节点的序号一定是2n+1，2n+2，因此可以直接用数组来表示一个堆。</p><p>不仅如此，堆还有一个性质：堆中某个节点的值总是不大于或不小于其父节点的值。将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/8e6450fe20fb277333c140f12c7ad805.jpeg" alt=""></p><p>堆常用来实现优先队列，在面试中经常考的问题都是与排序有关，比如堆排序、topK问题等。由于堆的根节点是序列中最大或者最小值，因而可以在建堆以及重建堆的过程中，筛选出数据序列中的极值，从而达到排序或者挑选topK值的目的。</p><h2 id="8-散列表"><a href="#8-散列表" class="headerlink" title=" 8  散列表"></a> 8  散列表</h2><p>散列表也叫哈希表，是一种通过键值对直接访问数据的机构。在初中，我们就学过一种能够将一个x值通过一个函数获得对应的一个y值的操作，叫做映射。散列表的实现原理正是映射的原理，通过设定的一个关键字和一个映射函数，就可以直接获得访问数据的地址，实现O(1)的数据访问效率。在映射的过程中，事先设定的函数就是一个映射表，也可以称作散列函数或者哈希函数。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/3683115b176ba375b6f7c334026993bf.jpeg" alt=""></p><p>散列表的实现最关键的就是散列函数的定义和选择。一般常用的有以下几种散列函数：</p><blockquote><p><strong>直接寻址法</strong>：取关键字或关键字的某个线性函数值为散列地址。</p><p><strong>数字分析法</strong>：通过对数据的分析，发现数据中冲突较少的部分，并构造散列地址。例如同学们的学号，通常同一届学生的学号，其中前面的部分差别不太大，所以用后面的部分来构造散列地址。</p><p><strong>平方取中**</strong>法**：当无法确定关键字里哪几位的分布相对比较均匀时，可以先求出关键字的平方值，然后按需要取平方值的中间几位作为散列地址。这是因为：计算平方之后的中间几位和关键字中的每一位都相关，所以不同的关键字会以较高的概率产生不同的散列地址。</p><p><strong>取随机数法</strong>：使用一个随机函数，取关键字的随机值作为散列地址，这种方式通常用于关键字长度不同的场合。</p><p><strong>除留取余法</strong>：取关键字被某个不大于散列表的表长 n 的数 m 除后所得的余数 p 为散列地址。这种方式也可以在用过其他方法后再使用。该函数对 m 的选择很重要，一般取素数或者直接用 n。</p></blockquote><p>确定好散列函数之后，通过某个<code>key</code>值的确会得到一个唯一的<code>value</code>地址。但是却会出现一些特殊情况。即通过不同的<code>key</code>值可能会访问到同一个地址，这个现象称之为冲突。</p><p>冲突在发生之后，当在对不同的<code>key</code>值进行操作时会使得造成相同地址的数据发生覆盖或者丢失，是非常危险的。所以在设计散列表往往还需要采用冲突解决的办法。</p><p>常用的冲突处理方式有很多，常用的包括以下几种：</p><blockquote><p><strong>开放地址法</strong>（也叫开放寻址法）：实际上就是当需要存储值时，对Key哈希之后，发现这个地址已经有值了，这时该怎么办？不能放在这个地址，不然之前的映射会被覆盖。这时对计算出来的地址进行一个探测再哈希，比如往后移动一个地址，如果没人占用，就用这个地址。如果超过最大长度，则可以对总长度取余。这里移动的地址是产生冲突时的增列序量。</p><p><strong>再哈希法</strong>：在产生冲突之后，使用关键字的其他部分继续计算地址，如果还是有冲突，则继续使用其他部分再计算地址。这种方式的缺点是时间增加了。</p><p><strong>链地址法</strong>：链地址法其实就是对Key通过哈希之后落在同一个地址上的值，做一个链表。其实在很多高级语言的实现当中，也是使用这种方式处理冲突的。</p><p><strong>公共溢出区</strong>：这种方式是建立一个公共溢出区，当地址存在冲突时，把新的地址放在公共溢出区里。</p></blockquote><p>目前比较常用的冲突解决方法是链地址法，一般可以通过数组和链表的结合达到冲突数据缓存的目的。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/7dfd5ef7aaa0afacba75db12845446c6.jpeg" alt=""></p><p>左侧数组的每个成员包括一个指针，指向一个链表的头。每发生一个冲突的数据，就将该数据作为链表的节点链接到链表尾部。这样一来，就可以保证冲突的数据能够区分并顺利访问。  </p><p>考虑到链表过长造成的问题，还可以使用红黑树替换链表进行冲突数据的处理操作，来提高散列表的查询稳定性。</p><h2 id="9-图"><a href="#9-图" class="headerlink" title=" 9  图"></a> 9  图</h2><p>图相较于上文的几个结构可能接触的不多，但是在实际的应用场景中却经常出现。比方说交通中的线路图，常见的思维导图都可以看作是图的具体表现形式。</p><p>图结构一般包括顶点和边，顶点通常用圆圈来表示，边就是这些圆圈之间的连线。边还可以根据顶点之间的关系设置不同的权重，默认权重相同皆为1。此外根据边的方向性，还可将图分为有向图和无向图。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/8ea569b2edc21ac2f485ca31dbe2cfaf.jpeg" alt=""></p><p>图结构用抽象的图线来表示十分简单，顶点和边之间的关系非常清晰明了。但是在具体的代码实现中，为了将各个顶点和边的关系存储下来，却不是一件易事。</p><h4 id="邻接矩阵"><a href="#邻接矩阵" class="headerlink" title="邻接矩阵"></a>邻接矩阵</h4><p>目前常用的图存储方式为邻接矩阵，通过所有顶点的二维矩阵来存储两个顶点之间是否相连，或者存储两顶点间的边权重。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/79b9a8f76acf566ac94a2e490ef492d7.jpeg" alt=""></p><p>无向图的邻接矩阵是一个对称矩阵，是因为边不具有方向性，若能从此顶点能够到达彼顶点，那么彼顶点自然也能够达到此顶点。此外，由于顶点本身与本身相连没有意义，所以在邻接矩阵中对角线上皆为0。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/7e1d752dcf523bf7c20a3ffef25076ce.jpeg" alt=""></p><p>有向图由于边具有方向性，因此彼此顶点之间并不能相互达到，所以其邻接矩阵的对称性不再。  </p><p>用邻接矩阵可以直接从二维关系中获得任意两个顶点的关系，可直接判断是否相连。但是在对矩阵进行存储时，却需要完整的一个二维数组。若图中顶点数过多，会导致二维数组的大小剧增，从而占用大量的内存空间。</p><p>而根据实际情况可以分析得，图中的顶点并不是任意两个顶点间都会相连，不是都需要对其边上权重进行存储。那么存储的邻接矩阵实际上会存在大量的0。虽然可以通过稀疏表示等方式对稀疏性高的矩阵进行关键信息的存储，但是却增加了图存储的复杂性。</p><p>因此，为了解决上述问题，一种可以只存储相连顶点关系的邻接表应运而生。</p><h4 id="邻接表"><a href="#邻接表" class="headerlink" title="邻接表"></a>邻接表</h4><p>在邻接表中，图的每一个顶点都是一个链表的头节点，其后连接着该顶点能够直接达到的相邻顶点。相较于无向图，有向图的情况更为复杂，因此这里采用有向图进行实例分析。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/602a625f0c214363d4818ae6f1e63be8.jpeg" alt="">在邻接表中，每一个顶点都对应着一条链表，链表中存储的是顶点能够达到的相邻顶点。存储的顺序可以按照顶点的编号顺序进行。比如上图中对于顶点B来说，其通过有向边可以到达顶点A和顶点E，那么其对应的邻接表中的顺序即B-&gt;A-&gt;E，其它顶点亦如此。</p><p>通过邻接表可以获得从某个顶点出发能够到达的顶点，从而省去了对不相连顶点的存储空间。然而，这还不够。对于有向图而言，图中有效信息除了从顶点“指出去”的信息，还包括从别的顶点“指进来”的信息。这里的“指出去”和“指进来”可以用出度和入度来表示。</p><blockquote><p>入度：有向图的某个顶点作为终点的次数和。</p><p>出度：有向图的某个顶点作为起点的次数和。</p></blockquote><p>由此看出，在对有向图进行表示时，邻接表只能求出图的出度，而无法求出入度。这个问题很好解决，那就是增加一个表用来存储能够到达某个顶点的相邻顶点。这个表称作逆邻接表。</p><h4 id="逆邻接表"><a href="#逆邻接表" class="headerlink" title="逆邻接表"></a>逆邻接表</h4><p>逆邻接表与邻接表结构类似，只不过图的顶点链接着能够到达该顶点的相邻顶点。也就是说，邻接表时顺着图中的箭头寻找相邻顶点，而逆邻接表时逆着图中的箭头寻找相邻顶点。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/92610435650703b6561e6cb2a58b5482.jpeg" alt=""></p><p>邻接表和逆邻接表的共同使用下，就能够把一个完整的有向图结构进行表示。可以发现，邻接表和逆邻接表实际上有一部分数据时重合的，因此可以将两个表合二为一，从而得到了所谓的十字链表。</p><h4 id="十字链表"><a href="#十字链表" class="headerlink" title="十字链表"></a>十字链表</h4><p>十字链表似乎很简单，只需要通过相同的顶点分别链向以该顶点为终点和起点的相邻顶点即可。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/90943e524bdd908dd99925e2954ad6ab.jpeg" alt=""></p><p>但这并不是最优的表示方式。虽然这样的方式共用了中间的顶点存储空间，但是邻接表和逆邻接表的链表节点中重复出现的顶点并没有得到重复利用，反而是进行了再次存储。因此，上图的表示方式还可以进行进一步优化。</p><p>十字链表优化后，可通过扩展的顶点结构和边结构来进行正逆邻接表的存储：（下面的弧头可看作是边的箭头那端，弧尾可看作是边的圆点那端）</p><blockquote><p><strong>data</strong>：用于存储该顶点中的数据；</p><p><strong>firstin指针</strong>：用于连接以当前顶点为弧头的其他顶点构成的链表，即从别的顶点指进来的顶点；</p><p><strong>firstout指针</strong>：用于连接以当前顶点为弧尾的其他顶点构成的链表，即从该顶点指出去的顶点；</p></blockquote><p>边结构通过存储两个顶点来确定一条边，同时通过分别代表这两个顶点的指针来与相邻顶点进行链接：</p><blockquote><p><strong>tailvex</strong>：用于存储作为弧尾的顶点的编号；</p><p><strong>headvex</strong>：用于存储作为弧头的顶点的编号；</p><p><strong>headlink</strong> <strong>指针</strong>：用于链接下一个存储作为弧头的顶点的节点；</p><p><strong>taillink</strong> <strong>指针</strong>：用于链接下一个存储作为弧尾的顶点的节点；</p></blockquote><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/af1c97826af345570556b21ab5b1e2c3.jpeg" alt=""></p><p>以上图为例子，对于顶点A而言，其作为起点能够到达顶点E。因此在邻接表中顶点A要通过边<code>AE</code>（即边04）指向顶点E，顶点A的<code>firstout</code>指针需要指向边04的<code>tailvex</code>。同时，从B出发能够到达A，所以在逆邻接表中顶点A要通过边<code>AB</code>（即边10）指向B，顶点A的<code>firstin</code>指针需要指向边10的弧头，即<code>headlink</code>指针。依次类推。</p><p>十字链表采用了一种看起来比较繁乱的方式对边的方向性进行了表示，能够在尽可能降低存储空间的情况下增加指针保留顶点之间的方向性。具体的操作可能一时间不好弄懂，建议多看几次上图，弄清指针指向的意义，明白正向和逆向邻接表的表示。</p><h2 id="10-总结"><a href="#10-总结" class="headerlink" title=" 10  总结"></a> 10  总结</h2><p>数据结构博大精深，没有高等数学的讳莫如深，也没有量子力学的玄乎其神，但是其在计算机科学的各个领域都具有强大的力量。本文试图采用图解的方式对九种数据结构进行理论上的介绍，但是其实这都是不够的。</p><p>即便是简单的数组、栈、队列等结构，在实际使用以及底层实现上都会有许多优化设计以及使用技巧，这意味着还需要真正把它们灵活的用起来，才能够算是真正意义上的熟悉和精通。但是本文可以作为常见数据结构的一个总结，当你对某些结构有些淡忘的时候，不妨重新回来看看。</p><p>本文转自 <a href="https://mp.weixin.qq.com/s/ZVwIUN-xf9FuxOFXW8H3Nw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/ZVwIUN-xf9FuxOFXW8H3Nw</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper面试题</title>
      <link href="/posts/c8bc9c82/"/>
      <url>/posts/c8bc9c82/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="ZooKeeper-是什么？"><a href="#ZooKeeper-是什么？" class="headerlink" title="ZooKeeper 是什么？"></a>ZooKeeper 是什么？</h2><ul><li><p>ZooKeeper 是一个开源的分布式协调服务。它是一个为分布式应用提供一致性服务的软件，分布式应用程序可以基于 Zookeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。</p></li><li><p>ZooKeeper 的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。</p></li><li><p>Zookeeper 保证了如下分布式一致性特性：</p><p>（1）顺序一致性</p><p>（2）原子性</p><p>（3）单一视图</p><p>（4）可靠性</p><p>（5）实时性（最终一致性）</p></li><li><p>客户端的读请求可以被集群中的任意一台机器处理，如果读请求在节点上注册了监听器，这个监听器也是由所连接的 zookeeper 机器来处理。对于写请求，这些请求会同时发给其他 zookeeper 机器并且达成一致后，请求才会返回成功。因此，随着 zookeeper 的集群机器增多，读请求的吞吐会提高但是写请求的吞吐会下降。</p></li><li><p>有序性是 zookeeper 中非常重要的一个特性，所有的更新都是全局有序的，每个更新都有一个唯一的时间戳，这个时间戳称为 zxid（Zookeeper Transaction Id）。而读请求只会相对于更新有序，也就是读请求的返回结果中会带有这个zookeeper 最新的 zxid。</p></li></ul><h2 id="ZooKeeper-提供了什么？"><a href="#ZooKeeper-提供了什么？" class="headerlink" title="ZooKeeper 提供了什么？"></a>ZooKeeper 提供了什么？</h2><ul><li>文件系统</li><li>通知机制</li></ul><h2 id="Zookeeper-文件系统"><a href="#Zookeeper-文件系统" class="headerlink" title="Zookeeper 文件系统"></a>Zookeeper 文件系统</h2><ul><li>Zookeeper 提供一个多层级的节点命名空间（节点称为 znode）。与文件系统不同的是，这些节点都可以设置关联的数据，而文件系统中只有文件节点可以存放数据而目录节点不行。</li><li>Zookeeper 为了保证高吞吐和低延迟，在内存中维护了这个树状的目录结构，这种特性使得 Zookeeper 不能用于存放大量的数据，每个节点的存放数据上限为1M。</li></ul><h2 id="Zookeeper-怎么保证主从节点的状态同步？"><a href="#Zookeeper-怎么保证主从节点的状态同步？" class="headerlink" title="Zookeeper 怎么保证主从节点的状态同步？"></a>Zookeeper 怎么保证主从节点的状态同步？</h2><ul><li>Zookeeper 的核心是原子广播机制，这个机制保证了各个 server 之间的同步。实现这个机制的协议叫做 Zab 协议。Zab 协议有两种模式，它们分别是恢复模式和广播模式。</li></ul><h3 id="恢复模式"><a href="#恢复模式" class="headerlink" title="恢复模式"></a>恢复模式</h3><ul><li>当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数 server 完成了和 leader 的状态同步以后，恢复模式就结束了。状态同步保证了 leader 和 server 具有相同的系统状态。</li></ul><h3 id="广播模式"><a href="#广播模式" class="headerlink" title="广播模式"></a>广播模式</h3><ul><li>一旦 leader 已经和多数的 follower 进行了状态同步后，它就可以开始广播消息了，即进入广播状态。这时候当一个 server 加入 ZooKeeper 服务中，它会在恢复模式下启动，发现 leader，并和 leader 进行状态同步。待到同步结束，它也参与消息广播。ZooKeeper 服务一直维持在 Broadcast 状态，直到 leader 崩溃了或者 leader 失去了大部分的 followers 支持。</li></ul><h2 id="四种类型的数据节点-Znode"><a href="#四种类型的数据节点-Znode" class="headerlink" title="四种类型的数据节点 Znode"></a>四种类型的数据节点 Znode</h2><ul><li>（1）PERSISTENT-持久节点 除非手动删除，否则节点一直存在于 Zookeeper 上</li><li>（2）EPHEMERAL-临时节点 临时节点的生命周期与客户端会话绑定，一旦客户端会话失效（客户端与zookeeper 连接断开不一定会话失效），那么这个客户端创建的所有临时节点都会被移除。</li><li>（3）PERSISTENT_SEQUENTIAL-持久顺序节点 基本特性同持久节点，只是增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字。</li><li>（4）EPHEMERAL_SEQUENTIAL-临时顺序节点 基本特性同临时节点，增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字。</li></ul><h2 id="Zookeeper-Watcher-机制-–-数据变更通知"><a href="#Zookeeper-Watcher-机制-–-数据变更通知" class="headerlink" title="Zookeeper Watcher 机制 – 数据变更通知"></a>Zookeeper Watcher 机制 – 数据变更通知</h2><ul><li><p>Zookeeper 允许客户端向服务端的某个 Znode 注册一个 Watcher 监听，当服务端的一些指定事件触发了这个 Watcher，服务端会向指定客户端发送一个事件通知来实现分布式的通知功能，然后客户端根据 Watcher 通知状态和事件类型做出业务上的改变。</p></li><li><p>工作机制：</p><p>（1）客户端注册 watcher</p><p>（2）服务端处理 watcher</p><p>（3）客户端回调 watcher</p></li></ul><h4 id="Watcher-特性总结"><a href="#Watcher-特性总结" class="headerlink" title="Watcher 特性总结"></a>Watcher 特性总结</h4><ol><li>一次性 无论是服务端还是客户端，一旦一个 Watcher 被 触 发 ，Zookeeper 都会将其从相应的存储中移除。这样的设计有效的减轻了服务端的压力，不然对于更新非常频繁的节点，服务端会不断的向客户端发送事件通知，无论对于网络还是服务端的压力都非常大。</li><li>客户端串行执行 客户端 Watcher 回调的过程是一个串行同步的过程。</li><li>轻量 3.1、Watcher 通知非常简单，只会告诉客户端发生了事件，而不会说明事件的具体内容。 3.2、客户端向服务端注册 Watcher 的时候，并不会把客户端真实的 Watcher 对象实体传递到服务端，仅仅是在客户端请求中使用 boolean 类型属性进行了标记。</li><li>watcher event 异步发送 watcher 的通知事件从 server 发送到 client 是异步的，这就存在一个问题，不同的客户端和服务器之间通过 socket 进行通信，由于网络延迟或其他因素导致客户端在不通的时刻监听到事件，由于 Zookeeper 本身提供了 ordering guarantee，即客户端监听事件后，才会感知它所监视 znode发生了变化。所以我们使用 Zookeeper 不能期望能够监控到节点每次的变化。Zookeeper 只能保证最终的一致性，而无法保证强一致性。</li><li>注册 watcher getData、exists、getChildren</li><li>触发 watcher create、delete、setData</li><li>当一个客户端连接到一个新的服务器上时，watch 将会被以任意会话事件触发。当与一个服务器失去连接的时候，是无法接收到 watch 的。而当 client 重新连接时，如果需要的话，所有先前注册过的 watch，都会被重新注册。通常这是完全透明的。只有在一个特殊情况下，watch 可能会丢失：对于一个未创建的 znode的 exist watch，如果在客户端断开连接期间被创建了，并且随后在客户端连接上之前又删除了，这种情况下，这个 watch 事件可能会被丢失。</li></ol><h2 id="客户端注册-Watcher-实现"><a href="#客户端注册-Watcher-实现" class="headerlink" title="客户端注册 Watcher 实现"></a>客户端注册 Watcher 实现</h2><ul><li>（1）调用 getData()/getChildren()/exist()三个 API，传入 Watcher 对象</li><li>（2）标记请求 request，封装 Watcher 到 WatchRegistration</li><li>（3）封装成 Packet 对象，发服务端发送 request</li><li>（4）收到服务端响应后，将 Watcher 注册到 ZKWatcherManager 中进行管理</li><li>（5）请求返回，完成注册。</li></ul><h2 id="服务端处理-Watcher-实现"><a href="#服务端处理-Watcher-实现" class="headerlink" title="服务端处理 Watcher 实现"></a>服务端处理 Watcher 实现</h2><ol><li><p>服务端接收 Watcher 并存储 接收到客户端请求，处理请求判断是否需要注册 Watcher，需要的话将数据节点的节点路径和 ServerCnxn（ServerCnxn 代表一个客户端和服务端的连接，实现了 Watcher 的 process 接口，此时可以看成一个 Watcher 对象）存储在WatcherManager 的 WatchTable 和 watch2Paths 中去。</p></li><li><p>Watcher 触发 以服务端接收到 setData() 事务请求触发 NodeDataChanged 事件为例：</p><p>2.1 封装 WatchedEvent 将通知状态（SyncConnected）、事件类型（NodeDataChanged）以及节点路径封装成一个 WatchedEvent 对象</p><p>2.2 查询 Watcher 从 WatchTable 中根据节点路径查找 Watcher</p><p>2.3 没找到；说明没有客户端在该数据节点上注册过 Watcher</p><p>2.4 找到；提取并从 WatchTable 和 Watch2Paths 中删除对应 Watcher（从这里可以看出 Watcher 在服务端是一次性的，触发一次就失效了）</p></li><li><p>调用 process 方法来触发 Watcher 这里 process 主要就是通过 ServerCnxn 对应的 TCP 连接发送 Watcher 事件通知。</p></li></ol><h2 id="客户端回调-Watcher"><a href="#客户端回调-Watcher" class="headerlink" title="客户端回调 Watcher"></a>客户端回调 Watcher</h2><ul><li>客户端 SendThread 线程接收事件通知，交由 EventThread 线程回调 Watcher。</li><li>客户端的 Watcher 机制同样是一次性的，一旦被触发后，该 Watcher 就失效了。</li></ul><h2 id="ACL-权限控制机制"><a href="#ACL-权限控制机制" class="headerlink" title="ACL 权限控制机制"></a>ACL 权限控制机制</h2><ul><li>UGO（User/Group/Others）</li><li>目前在 Linux/Unix 文件系统中使用，也是使用最广泛的权限控制方式。是一种粗粒度的文件系统权限控制模式。</li><li>ACL（Access Control List）访问控制列表</li><li><strong>包括三个方面：</strong></li><li>权限模式（Scheme） （1）IP：从 IP 地址粒度进行权限控制 （2）Digest：最常用，用类似于 username:password 的权限标识来进行权限配置，便于区分不同应用来进行权限控制 （3）World：最开放的权限控制方式，是一种特殊的 digest 模式，只有一个权限标识“world:anyone” （4）Super：超级用户</li><li><strong>授权对象</strong> 授权对象指的是权限赋予的用户或一个指定实体，例如 IP 地址或是机器灯。</li><li><strong>权限 Permission</strong> （1）CREATE：数据节点创建权限，允许授权对象在该 Znode 下创建子节点 （2）DELETE：子节点删除权限，允许授权对象删除该数据节点的子节点 （3）READ：数据节点的读取权限，允许授权对象访问该数据节点并读取其数据内容或子节点列表等 （4）WRITE：数据节点更新权限，允许授权对象对该数据节点进行更新操作 （5）ADMIN：数据节点管理权限，允许授权对象对该数据节点进行 ACL 相关设置操作</li></ul><h2 id="Chroot-特性"><a href="#Chroot-特性" class="headerlink" title="Chroot 特性"></a>Chroot 特性</h2><ul><li>3.2.0 版本后，添加了 Chroot 特性，该特性允许每个客户端为自己设置一个命名空间。如果一个客户端设置了 Chroot，那么该客户端对服务器的任何操作，都将会被限制在其自己的命名空间下。</li><li>通过设置 Chroot，能够将一个客户端应用于 Zookeeper 服务端的一颗子树相对应，在那些多个应用公用一个 Zookeeper 进群的场景下，对实现不同应用间的相互隔离非常有帮助。</li></ul><h2 id="会话管理"><a href="#会话管理" class="headerlink" title="会话管理"></a>会话管理</h2><ul><li><p>分桶策略：将类似的会话放在同一区块中进行管理，以便于 Zookeeper 对会话进行不同区块的隔离处理以及同一区块的统一处理。</p></li><li><p>分配原则：每个会话的“下次超时时间点”（ExpirationTime）</p></li><li><p>计算公式：</p><p>ExpirationTime_ = currentTime + sessionTimeout</p><p>ExpirationTime = (ExpirationTime_ / ExpirationInrerval + 1) *</p><p>ExpirationInterval , ExpirationInterval 是指 Zookeeper 会话超时检查时间间隔，默认 tickTime</p></li></ul><h2 id="服务器角色"><a href="#服务器角色" class="headerlink" title="服务器角色"></a>服务器角色</h2><ul><li><p>Leader</p><p>（1）事务请求的唯一调度和处理者，保证集群事务处理的顺序性</p><p>（2）集群内部各服务的调度者</p></li><li><p>Follower</p><p>（1）处理客户端的非事务请求，转发事务请求给 Leader 服务器</p><p>（2）参与事务请求 Proposal 的投票</p><p>（3）参与 Leader 选举投票</p></li><li><p>Observer</p><p>（1）3.0 版本以后引入的一个服务器角色，在不影响集群事务处理能力的基础上提升集群的非事务处理能力</p><p>（2）处理客户端的非事务请求，转发事务请求给 Leader 服务器</p><p>（3）不参与任何形式的投票</p></li></ul><h2 id="Zookeeper-下-Server-工作状态"><a href="#Zookeeper-下-Server-工作状态" class="headerlink" title="Zookeeper 下 Server 工作状态"></a>Zookeeper 下 Server 工作状态</h2><ul><li><p>服务器具有四种状态，分别是 LOOKING、FOLLOWING、LEADING、OBSERVING。</p><p>（1）LOOKING：寻 找 Leader 状态。当服务器处于该状态时，它会认为当前集群中没有 Leader，因此需要进入 Leader 选举状态。</p><p>（2）FOLLOWING：跟随者状态。表明当前服务器角色是 Follower。</p><p>（3）LEADING：领导者状态。表明当前服务器角色是 Leader。</p><p>（4）OBSERVING：观察者状态。表明当前服务器角色是 Observer。</p></li></ul><h2 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h2><ul><li><p>整个集群完成 Leader 选举之后，Learner（Follower 和 Observer 的统称）回向Leader 服务器进行注册。当 Learner 服务器想 Leader 服务器完成注册后，进入数据同步环节。</p></li><li><p>数据同步流程：（均以消息传递的方式进行）</p><ul><li>Learner 向 Learder 注册</li><li>数据同步</li><li>同步确认</li></ul></li><li><p>Zookeeper 的数据同步通常分为四类：</p><p>（1）直接差异化同步（DIFF 同步）</p><p>（2）先回滚再差异化同步（TRUNC+DIFF 同步）</p><p>（3）仅回滚同步（TRUNC 同步）</p><p>（4）全量同步（SNAP 同步）</p></li><li><p>在进行数据同步前，Leader服务器会完成数据同步初始化：</p><ul><li>peerLastZxid：从learner服务器注册时发送的ACKEPOCH消息中提取lastZxid（该Learner服务器最后处理的ZXID）</li><li>minCommittedLog：Leader服务器Proposal缓存队列committedLog中最小ZXID</li><li>maxCommittedLog：Leader服务器Proposal缓存队列committedLog中最大ZXID</li></ul></li><li><p>直接差异化同步（DIFF同步） 场景：peerLastZxid介于minCommittedLog和maxCommittedLog之间</p></li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/94c37738a3c180493bb436a118a4096e.png" alt="jiezuiquanmiandemianshiti_1.png"></p><ul><li>先回滚再差异化同步（TRUNC+DIFF同步） 场景：当新的Leader服务器发现某个Learner服务器包含了一条自己没有的事务记录，那么就需要让该Learner服务器进行事务回滚–回滚到Leader服务器上存在的，同时也是最接近于peerLastZxid的ZXID</li><li>仅回滚同步（TRUNC同步） 场景：peerLastZxid 大于 maxCommittedLog</li><li>全量同步（SNAP同步） 场景一：peerLastZxid 小于 minCommittedLog 场景二：Leader服务器上没有Proposal缓存队列且peerLastZxid不等于lastProcessZxid</li></ul><h2 id="zookeeper-是如何保证事务的顺序一致性的？"><a href="#zookeeper-是如何保证事务的顺序一致性的？" class="headerlink" title="zookeeper 是如何保证事务的顺序一致性的？"></a>zookeeper 是如何保证事务的顺序一致性的？</h2><ul><li>zookeeper 采用了全局递增的事务 Id 来标识，所有的 proposal（提议）都在被提出的时候加上了 zxid，zxid 实际上是一个 64 位的数字，高 32 位是 epoch（ 时期; 纪元; 世; 新时代）用来标识 leader 周期，如果有新的 leader 产生出来，epoch会自增，低 32 位用来递增计数。当新产生 proposal 的时候，会依据数据库的两阶段过程，首先会向其他的 server 发出事务执行请求，如果超过半数的机器都能执行并且能够成功，那么就会开始执行。</li></ul><h2 id="分布式集群中为什么会有-Master主节点？"><a href="#分布式集群中为什么会有-Master主节点？" class="headerlink" title="分布式集群中为什么会有 Master主节点？"></a>分布式集群中为什么会有 Master主节点？</h2><ul><li>在分布式环境中，有些业务逻辑只需要集群中的某一台机器进行执行，其他的机器可以共享这个结果，这样可以大大减少重复计算，提高性能，于是就需要进行 leader 选举。</li></ul><h2 id="zk-节点宕机如何处理？"><a href="#zk-节点宕机如何处理？" class="headerlink" title="zk 节点宕机如何处理？"></a>zk 节点宕机如何处理？</h2><ul><li>Zookeeper 本身也是集群，推荐配置不少于 3 个服务器。Zookeeper 自身也要保证当一个节点宕机时，其他节点会继续提供服务。</li><li>如果是一个 Follower 宕机，还有 2 台服务器提供访问，因为 Zookeeper 上的数据是有多个副本的，数据并不会丢失；</li><li>如果是一个 Leader 宕机，Zookeeper 会选举出新的 Leader。</li><li>ZK 集群的机制是只要超过半数的节点正常，集群就能正常提供服务。只有在 ZK节点挂得太多，只剩一半或不到一半节点能工作，集群才失效。</li></ul><p><strong>所以</strong></p><ul><li>3 个节点的 cluster 可以挂掉 1 个节点(leader 可以得到 2 票&gt;1.5)</li><li>2 个节点的 cluster 就不能挂掉任何 1 个节点了(leader 可以得到 1 票&lt;=1)</li></ul><h2 id="zookeeper-负载均衡和-nginx-负载均衡区别"><a href="#zookeeper-负载均衡和-nginx-负载均衡区别" class="headerlink" title="zookeeper 负载均衡和 nginx 负载均衡区别"></a>zookeeper 负载均衡和 nginx 负载均衡区别</h2><ul><li>zk 的负载均衡是可以调控，nginx 只是能调权重，其他需要可控的都需要自己写插件；但是 nginx 的吞吐量比 zk 大很多，应该说按业务选择用哪种方式。</li></ul><h2 id="Zookeeper-有哪几种几种部署模式？"><a href="#Zookeeper-有哪几种几种部署模式？" class="headerlink" title="Zookeeper 有哪几种几种部署模式？"></a>Zookeeper 有哪几种几种部署模式？</h2><ul><li><p>Zookeeper 有三种部署模式：</p><ol><li>单机部署：一台集群上运行；</li><li>集群部署：多台集群运行；</li><li>伪集群部署：一台集群启动多个 Zookeeper 实例运行。</li></ol></li></ul><h2 id="集群最少要几台机器，集群规则是怎样的？集群中有-3-台服务器，其中一个节点宕机，这个时候-Zookeeper-还可以使用吗？"><a href="#集群最少要几台机器，集群规则是怎样的？集群中有-3-台服务器，其中一个节点宕机，这个时候-Zookeeper-还可以使用吗？" class="headerlink" title="集群最少要几台机器，集群规则是怎样的？集群中有 3 台服务器，其中一个节点宕机，这个时候 Zookeeper 还可以使用吗？"></a>集群最少要几台机器，集群规则是怎样的？集群中有 3 台服务器，其中一个节点宕机，这个时候 Zookeeper 还可以使用吗？</h2><ul><li>集群规则为 2N+1 台，N&gt;0，即 3 台。可以继续使用，单数服务器只要没超过一半的服务器宕机就可以继续使用。</li></ul><h2 id="集群支持动态添加机器吗？"><a href="#集群支持动态添加机器吗？" class="headerlink" title="集群支持动态添加机器吗？"></a>集群支持动态添加机器吗？</h2><ul><li>其实就是水平扩容了，Zookeeper 在这方面不太好。两种方式：</li><li>全部重启：关闭所有 Zookeeper 服务，修改配置之后启动。不影响之前客户端的会话。</li><li>逐个重启：在过半存活即可用的原则下，一台机器重启不影响整个集群对外提供服务。这是比较常用的方式。</li><li>3.5 版本开始支持动态扩容。</li></ul><h2 id="Zookeeper-对节点的-watch-监听通知是永久的吗？为什么不是永久的"><a href="#Zookeeper-对节点的-watch-监听通知是永久的吗？为什么不是永久的" class="headerlink" title="Zookeeper 对节点的 watch 监听通知是永久的吗？为什么不是永久的?"></a>Zookeeper 对节点的 watch 监听通知是永久的吗？为什么不是永久的?</h2><ul><li>不是。官方声明：一个 Watch 事件是一个一次性的触发器，当被设置了 Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了 Watch 的客户端，以便通知它们。</li><li>为什么不是永久的，举个例子，如果服务端变动频繁，而监听的客户端很多情况下，每次变动都要通知到所有的客户端，给网络和服务器造成很大压力。</li><li>一般是客户端执行 getData(“/节点 A”,true)，如果节点 A 发生了变更或删除，客户端会得到它的 watch 事件，但是在之后节点 A 又发生了变更，而客户端又没有设置 watch 事件，就不再给客户端发送。</li><li>在实际应用中，很多情况下，我们的客户端不需要知道服务端的每一次变动，我只要最新的数据即可。</li></ul><h2 id="Zookeeper-的-java-客户端都有哪些？"><a href="#Zookeeper-的-java-客户端都有哪些？" class="headerlink" title="Zookeeper 的 java 客户端都有哪些？"></a>Zookeeper 的 java 客户端都有哪些？</h2><ul><li>java 客户端：zk 自带的 zkclient 及 Apache 开源的 Curator。</li></ul><h2 id="chubby-是什么，和-zookeeper-比你怎么看？"><a href="#chubby-是什么，和-zookeeper-比你怎么看？" class="headerlink" title="chubby 是什么，和 zookeeper 比你怎么看？"></a>chubby 是什么，和 zookeeper 比你怎么看？</h2><ul><li>chubby 是 google 的，完全实现 paxos 算法，不开源。zookeeper 是 chubby的开源实现，使用 zab 协议，paxos 算法的变种。</li></ul><h2 id="说几个-zookeeper-常用的命令。"><a href="#说几个-zookeeper-常用的命令。" class="headerlink" title="说几个 zookeeper 常用的命令。"></a>说几个 zookeeper 常用的命令。</h2><ul><li>常用命令：ls get set create delete 等。</li></ul><h2 id="ZAB-和-Paxos-算法的联系与区别？"><a href="#ZAB-和-Paxos-算法的联系与区别？" class="headerlink" title="ZAB 和 Paxos 算法的联系与区别？"></a>ZAB 和 Paxos 算法的联系与区别？</h2><ul><li><p>相同点：</p><p>（1）两者都存在一个类似于 Leader 进程的角色，由其负责协调多个 Follower 进程的运行</p><p>（2）Leader 进程都会等待超过半数的 Follower 做出正确的反馈后，才会将一个提案进行提交</p><p>（3）ZAB 协议中，每个 Proposal 中都包含一个 epoch 值来代表当前的 Leader周期，Paxos 中名字为 Ballot</p></li><li><p>不同点：</p><p>ZAB 用来构建高可用的分布式数据主备系统（Zookeeper），Paxos 是用来构建分布式一致性状态机系统。</p></li></ul><h2 id="Zookeeper-的典型应用场景"><a href="#Zookeeper-的典型应用场景" class="headerlink" title="Zookeeper 的典型应用场景"></a>Zookeeper 的典型应用场景</h2><ul><li><p>Zookeeper 是一个典型的发布/订阅模式的分布式数据管理与协调框架，开发人员可以使用它来进行分布式数据的发布和订阅。</p></li><li><p>通过对 Zookeeper 中丰富的数据节点进行交叉使用，配合 Watcher 事件通知机制，可以非常方便的构建一系列分布式应用中年都会涉及的核心功能，如：</p><p>（1）数据发布/订阅</p><p>（2）负载均衡</p><p>（3）命名服务</p><p>（4）分布式协调/通知</p><p>（5）集群管理</p><p>（6）Master 选举</p><p>（7）分布式锁</p><p>（8）分布式队列</p></li></ul><h4 id="1-数据发布-订阅"><a href="#1-数据发布-订阅" class="headerlink" title="1 数据发布/订阅"></a>1 数据发布/订阅</h4><p><strong>介绍</strong></p><ul><li>数据发布/订阅系统，即所谓的配置中心，顾名思义就是发布者发布数据供订阅者进行数据订阅。</li></ul><p><strong>目的</strong></p><ul><li>动态获取数据（配置信息）</li><li>实现数据（配置信息）的集中式管理和数据的动态更新</li></ul><p><strong>设计模式</strong></p><ul><li>Push 模式</li><li>Pull 模式</li></ul><p><strong>数据（配置信息）特性</strong></p><p>（1）数据量通常比较小 （2）数据内容在运行时会发生动态更新 （3）集群中各机器共享，配置一致</p><ul><li>如：机器列表信息、运行时开关配置、数据库配置信息等</li></ul><p><strong>基于 Zookeeper 的实现方式</strong></p><ul><li>· 数据存储：将数据（配置信息）存储到 Zookeeper 上的一个数据节点</li><li>· 数据获取：应用在启动初始化节点从 Zookeeper 数据节点读取数据，并在该节点上注册一个数据变更 Watcher</li><li>· 数据变更：当变更数据时，更新 Zookeeper 对应节点数据，Zookeeper会将数据变更通知发到各客户端，客户端接到通知后重新读取变更后的数据即可。</li></ul><h4 id="2-负载均衡"><a href="#2-负载均衡" class="headerlink" title="2 负载均衡"></a>2 负载均衡</h4><ul><li>zk 的命名服务</li><li>命名服务是指通过指定的名字来获取资源或者服务的地址，利用 zk 创建一个全局的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。</li></ul><p><strong>分布式通知和协调</strong></p><ul><li>对于系统调度来说：操作人员发送通知实际是通过控制台改变某个节点的状态，然后 zk 将这些变化发送给注册了这个节点的 watcher 的所有客户端。</li><li>对于执行情况汇报：每个工作进程都在某个目录下创建一个临时节点。并携带工作的进度数据，这样汇总的进程可以监控目录子节点的变化获得工作进度的实时的全局情况。</li></ul><p><strong>zk 的命名服务（文件系统）</strong></p><ul><li>命名服务是指通过指定的名字来获取资源或者服务的地址，利用 zk 创建一个全局的路径，即是唯一的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。</li></ul><p><strong>zk 的配置管理（文件系统、通知机制）</strong></p><ul><li>程序分布式的部署在不同的机器上，将程序的配置信息放在 zk 的 znode 下，当有配置发生改变时，也就是 znode 发生变化时，可以通过改变 zk 中某个目录节点的内容，利用 watcher 通知给各个客户端，从而更改配置。</li></ul><p><strong>Zookeeper 集群管理（文件系统、通知机制）</strong></p><ul><li>所谓集群管理无在乎两点：是否有机器退出和加入、选举 master。</li><li>对于第一点，所有机器约定在父目录下创建临时目录节点，然后监听父目录节点</li><li>的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper 的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了。</li><li>新机器加入也是类似，所有机器收到通知：新兄弟目录加入，highcount 又有了，对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为 master 就好。</li></ul><p><strong>Zookeeper 分布式锁（文件系统、通知机制）</strong></p><ul><li>有了 zookeeper 的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。</li><li>对于第一类，我们将 zookeeper 上的一个 znode 看作是一把锁，通过 createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的 distribute_lock 节点就释放出锁。</li><li>对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选 master 一样，编号最小的获得锁，用完删除，依次方便。</li></ul><p><strong>Zookeeper 队列管理（文件系统、通知机制）</strong></p><ul><li><p>两种类型的队列：</p><p>（1）同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。 （2）队列按照 FIFO 方式进行入队和出队操作。</p></li><li><p>第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。</p></li><li><p>第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。在特定的目录下创建 PERSISTENT_SEQUENTIAL 节点，创建成功时Watcher 通知等待的队列，队列删除序列号最小的节点用以消费。此场景下Zookeeper 的 znode 用于消息存储，znode 存储的数据就是消息队列中的消息内容，SEQUENTIAL 序列号就是消息的编号，按序取出即可。由于创建的节点是持久化的，所以不必担心队列消息的丢失问题。</p></li></ul><h2 id="Zookeeper-都有哪些功能？"><a href="#Zookeeper-都有哪些功能？" class="headerlink" title="Zookeeper 都有哪些功能？"></a>Zookeeper 都有哪些功能？</h2><ol><li>集群管理：监控节点存活状态、运行请求等；</li><li>主节点选举：主节点挂掉了之后可以从备用的节点开始新一轮选主，主节点选举说的就是这个选举的过程，使用 Zookeeper 可以协助完成这个过程；</li><li>分布式锁：Zookeeper 提供两种锁：独占锁、共享锁。独占锁即一次只能有一个线程使用资源，共享锁是读锁共享，读写互斥，即可以有多线线程同时读同一个资源，如果要使用写锁也只能有一个线程使用。Zookeeper 可以对分布式锁进行控制。</li><li>命名服务：在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息。</li></ol><h2 id="说一下-Zookeeper-的通知机制？"><a href="#说一下-Zookeeper-的通知机制？" class="headerlink" title="说一下 Zookeeper 的通知机制？"></a>说一下 Zookeeper 的通知机制？</h2><ul><li>client 端会对某个 znode 建立一个 watcher 事件，当该 znode 发生变化时，这些 client 会收到 zk 的通知，然后 client 可以根据 znode 变化来做出业务上的改变等。</li></ul><h2 id="Zookeeper-和-Dubbo-的关系？"><a href="#Zookeeper-和-Dubbo-的关系？" class="headerlink" title="Zookeeper 和 Dubbo 的关系？"></a>Zookeeper 和 Dubbo 的关系？</h2><ul><li><p>Zookeeper的作用： zookeeper用来注册服务和进行负载均衡，哪一个服务由哪一个机器来提供必需让调用者知道，简单来说就是ip地址和服务名称的对应关系。当然也可以通过硬编码的方式把这种对应关系在调用方业务代码中实现，但是如果提供服务的机器挂掉调用者无法知晓，如果不更改代码会继续请求挂掉的机器提供服务。zookeeper通过心跳机制可以检测挂掉的机器并将挂掉机器的ip和服务对应关系从列表中删除。至于支持高并发，简单来说就是横向扩展，在不更改代码的情况通过添加机器来提高运算能力。通过添加新的机器向zookeeper注册服务，服务的提供者多了能服务的客户就多了。</p></li><li><p>dubbo： 是管理中间层的工具，在业务层到数据仓库间有非常多服务的接入和服务提供者需要调度，dubbo提供一个框架解决这个问题。<br>注意这里的dubbo只是一个框架，至于你架子上放什么是完全取决于你的，就像一个汽车骨架，你需要配你的轮子引擎。这个框架中要完成调度必须要有一个分布式的注册中心，储存所有服务的元数据，你可以用zk，也可以用别的，只是大家都用zk。</p></li><li><p>zookeeper和dubbo的关系： Dubbo 的将注册中心进行抽象，它可以外接不同的存储媒介给注册中心提供服务，有 ZooKeeper，Memcached，Redis 等。</p><p>引入了 ZooKeeper 作为存储媒介，也就把 ZooKeeper 的特性引进来。首先是负载均衡，单注册中心的承载能力是有限的，在流量达到一定程度的时 候就需要分流，负载均衡就是为了分流而存在的，一个 ZooKeeper 群配合相应的 Web 应用就可以很容易达到负载均衡；资源同步，单单有负载均衡还不 够，节点之间的数据和资源需要同步，ZooKeeper 集群就天然具备有这样的功能；命名服务，将树状结构用于维护全局的服务地址列表，服务提供者在启动 的时候，向 ZooKeeper 上的指定节点 /dubbo/${serviceName}/providers 目录下写入自己的 URL 地址，这个操作就完成了服务的发布。 其他特性还有 Mast 选举，分布式锁等。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/1a81fd95fe3bdc7cda12826408a2b61a.jpeg" alt="jiezuiquanmiandemianshiti_2.png"></p></li></ul><p>本文转自 <a href="https://juejin.cn/post/6844904127076499464" target="_blank" rel="noopener">https://juejin.cn/post/6844904127076499464</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Nginx面试题</title>
      <link href="/posts/296bbdc7/"/>
      <url>/posts/296bbdc7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h3 id="什么是Nginx？"><a href="#什么是Nginx？" class="headerlink" title="什么是Nginx？"></a>什么是Nginx？</h3><ul><li>Nginx是一个 轻量级/高性能的反向代理Web服务器，他实现非常高效的反向代理、负载平衡，他可以处理2-3万并发连接数，官方监测能支持5万并发，现在中国使用nginx网站用户有很多，例如：新浪、网易、 腾讯等。</li></ul><h3 id="为什么要用Nginx？"><a href="#为什么要用Nginx？" class="headerlink" title="为什么要用Nginx？"></a>为什么要用Nginx？</h3><ul><li><p>跨平台、配置简单、方向代理、高并发连接：处理2-3万并发连接数，官方监测能支持5万并发，内存消耗小：开启10个nginx才占150M内存 ，nginx处理静态文件好，耗费内存少，</p></li><li><p>而且Nginx内置的健康检查功能：如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上。</p></li><li><p>使用Nginx的话还能：</p><ol><li>节省宽带：支持GZIP压缩，可以添加浏览器本地缓存</li><li>稳定性高：宕机的概率非常小</li><li>接收用户请求是异步的</li></ol></li></ul><h3 id="为什么Nginx性能这么高？"><a href="#为什么Nginx性能这么高？" class="headerlink" title="为什么Nginx性能这么高？"></a>为什么Nginx性能这么高？</h3><ul><li>因为他的事件处理机制：异步非阻塞事件处理机制：运用了epoll模型，提供了一个队列，排队解决</li></ul><h3 id="Nginx怎么处理请求的？"><a href="#Nginx怎么处理请求的？" class="headerlink" title="Nginx怎么处理请求的？"></a>Nginx怎么处理请求的？</h3><ul><li>nginx接收一个请求后，首先由listen和server_name指令匹配server模块，再匹配server模块里的location，location就是实际地址</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">server &#123;                # 第一个Server区块开始，表示一个独立的虚拟主机站点</span><br><span class="line">           listen       80；              # 提供服务的端口，默认80</span><br><span class="line">           server_name  localhost；    # 提供服务的域名主机名</span><br><span class="line">           location &#x2F; &#123;                    # 第一个location区块开始</span><br><span class="line">               root   html；       # 站点的根目录，相当于Nginx的安装目录</span><br><span class="line">               index  index.html index.htm；    # 默认的首页文件，多个用空格分开</span><br><span class="line">           &#125;          # 第一个location区块结果</span><br><span class="line">       &#125;           </span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><h3 id="什么是正向代理和反向代理？"><a href="#什么是正向代理和反向代理？" class="headerlink" title="什么是正向代理和反向代理？"></a>什么是正向代理和反向代理？</h3><ol><li>正向代理就是一个人发送一个请求直接就到达了目标的服务器</li><li>反方代理就是请求统一被Nginx接收，nginx反向代理服务器接收到之后，按照一定的规 则分发给了后端的业务处理服务器进行处理了</li></ol><h3 id="使用“反向代理服务器的优点是什么"><a href="#使用“反向代理服务器的优点是什么" class="headerlink" title="使用“反向代理服务器的优点是什么?"></a>使用“反向代理服务器的优点是什么?</h3><ul><li>反向代理服务器可以隐藏源服务器的存在和特征。它充当互联网云和web服务器之间的中间层。这对于安全方面来说是很好的，特别是当您使用web托管服务时。</li></ul><h3 id="Nginx的优缺点？"><a href="#Nginx的优缺点？" class="headerlink" title="Nginx的优缺点？"></a>Nginx的优缺点？</h3><ul><li><p>优点：</p><ol><li>占内存小，可实现高并发连接，处理响应快</li><li>可实现http服务器、虚拟主机、方向代理、负载均衡</li><li>Nginx配置简单</li><li>可以不暴露正式的服务器IP地址</li></ol></li><li><p>缺点： 动态处理差：nginx处理静态文件好,耗费内存少，但是处理动态页面则很鸡肋，现在一般前端用nginx作为反向代理抗住压力，</p></li></ul><h3 id="Nginx应用场景？"><a href="#Nginx应用场景？" class="headerlink" title="Nginx应用场景？"></a>Nginx应用场景？</h3><ol><li>http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。</li><li>虚拟主机。可以实现在一台服务器虚拟出多个网站，例如个人网站使用的虚拟机。</li><li>反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做反向代理。并且多台服务器可以平均分担负载，不会应为某台服务器负载高宕机而某台服务器闲置的情况。</li><li>nginz 中也可以配置安全管理、比如可以使用Nginx搭建API接口网关,对每个接口服务进行拦截。</li></ol><h3 id="Nginx目录结构有哪些？"><a href="#Nginx目录结构有哪些？" class="headerlink" title="Nginx目录结构有哪些？"></a>Nginx目录结构有哪些？</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# tree &#x2F;usr&#x2F;local&#x2F;nginx</span><br><span class="line">   &#x2F;usr&#x2F;local&#x2F;nginx</span><br><span class="line">   ├── client_body_temp</span><br><span class="line">   ├── conf                             # Nginx所有配置文件的目录</span><br><span class="line">   │   ├── fastcgi.conf                 # fastcgi相关参数的配置文件</span><br><span class="line">   │   ├── fastcgi.conf.default         # fastcgi.conf的原始备份文件</span><br><span class="line">   │   ├── fastcgi_params               # fastcgi的参数文件</span><br><span class="line">   │   ├── fastcgi_params.default       </span><br><span class="line">   │   ├── koi-utf</span><br><span class="line">   │   ├── koi-win</span><br><span class="line">   │   ├── mime.types                   # 媒体类型</span><br><span class="line">   │   ├── mime.types.default</span><br><span class="line">   │   ├── nginx.conf                   # Nginx主配置文件</span><br><span class="line">   │   ├── nginx.conf.default</span><br><span class="line">   │   ├── scgi_params                  # scgi相关参数文件</span><br><span class="line">   │   ├── scgi_params.default  </span><br><span class="line">   │   ├── uwsgi_params                 # uwsgi相关参数文件</span><br><span class="line">   │   ├── uwsgi_params.default</span><br><span class="line">   │   └── win-utf</span><br><span class="line">   ├── fastcgi_temp                     # fastcgi临时数据目录</span><br><span class="line">   ├── html                             # Nginx默认站点目录</span><br><span class="line">   │   ├── 50x.html                     # 错误页面优雅替代显示文件，例如当出现502错误时会调用此页面</span><br><span class="line">   │   └── index.html                   # 默认的首页文件</span><br><span class="line">   ├── logs                             # Nginx日志目录</span><br><span class="line">   │   ├── access.log                   # 访问日志文件</span><br><span class="line">   │   ├── error.log                    # 错误日志文件</span><br><span class="line">   │   └── nginx.pid                    # pid文件，Nginx进程启动后，会把所有进程的ID号写到此文件</span><br><span class="line">   ├── proxy_temp                       # 临时目录</span><br><span class="line">   ├── sbin                             # Nginx命令目录</span><br><span class="line">   │   └── nginx                        # Nginx的启动命令</span><br><span class="line">   ├── scgi_temp                        # 临时目录</span><br><span class="line">   └── uwsgi_temp                       # 临时目录</span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><h3 id="Nginx配置文件nginx-conf有哪些属性模块"><a href="#Nginx配置文件nginx-conf有哪些属性模块" class="headerlink" title="Nginx配置文件nginx.conf有哪些属性模块?"></a>Nginx配置文件nginx.conf有哪些属性模块?</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">worker_processes  1；                # worker进程的数量</span><br><span class="line">   events &#123;                              # 事件区块开始</span><br><span class="line">       worker_connections  1024；          # 每个worker进程支持的最大连接数</span><br><span class="line">   &#125;                               # 事件区块结束</span><br><span class="line">   http &#123;                           # HTTP区块开始</span><br><span class="line">       include       mime.types；         # Nginx支持的媒体类型库文件</span><br><span class="line">       default_type  application&#x2F;octet-stream；            # 默认的媒体类型</span><br><span class="line">       sendfile        on；       # 开启高效传输模式</span><br><span class="line">       keepalive_timeout  65；       # 连接超时</span><br><span class="line">       server &#123;                            # 第一个Server区块开始，表示一个独立的虚拟主机站点</span><br><span class="line">           listen       80；              # 提供服务的端口，默认80</span><br><span class="line">           server_name  localhost；    # 提供服务的域名主机名</span><br><span class="line">           location &#x2F; &#123;                    # 第一个location区块开始</span><br><span class="line">               root   html；       # 站点的根目录，相当于Nginx的安装目录</span><br><span class="line">               index  index.html index.htm；       # 默认的首页文件，多个用空格分开</span><br><span class="line">           &#125;                  # 第一个location区块结果</span><br><span class="line">           error_page   500502503504  &#x2F;50x.html；          # 出现对应的http状态码时，使用50x.html回应客户</span><br><span class="line">           location &#x3D; &#x2F;50x.html &#123;                  # location区块开始，访问50x.html</span><br><span class="line">               root   html；                    # 指定对应的站点目录为html</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;  </span><br><span class="line">       ......</span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><h3 id="Nginx静态资源"><a href="#Nginx静态资源" class="headerlink" title="Nginx静态资源?"></a>Nginx静态资源?</h3><ul><li>静态资源访问，就是存放在nginx的html页面，我们可以自己编写</li></ul><h3 id="如何用Nginx解决前端跨域问题？"><a href="#如何用Nginx解决前端跨域问题？" class="headerlink" title="如何用Nginx解决前端跨域问题？"></a>如何用Nginx解决前端跨域问题？</h3><ul><li>使用Nginx转发请求。把跨域的接口写成调本域的接口，然后将这些接口转发到真正的请求地址。</li></ul><h3 id="Nginx虚拟主机怎么配置"><a href="#Nginx虚拟主机怎么配置" class="headerlink" title="Nginx虚拟主机怎么配置?"></a>Nginx虚拟主机怎么配置?</h3><ul><li>1、基于域名的虚拟主机，通过域名来区分虚拟主机——应用：外部网站</li><li>2、基于端口的虚拟主机，通过端口来区分虚拟主机——应用：公司内部网站，外部网站的管理后台</li><li>3、基于ip的虚拟主机。</li></ul><h4 id="基于虚拟主机配置域名"><a href="#基于虚拟主机配置域名" class="headerlink" title="基于虚拟主机配置域名"></a>基于虚拟主机配置域名</h4><ul><li>需要建立/data/www /data/bbs目录，windows本地hosts添加虚拟机ip地址对应的域名解析；对应域名网站目录下新增index.html文件；</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#当客户端访问www.lijie.com,监听端口号为80,直接跳转到data&#x2F;www目录下文件</span><br><span class="line">       server &#123;</span><br><span class="line">           listen       80;</span><br><span class="line">           server_name  www.lijie.com;</span><br><span class="line">           location &#x2F; &#123;</span><br><span class="line">               root   data&#x2F;www;</span><br><span class="line">               index  index.html index.htm;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   </span><br><span class="line">       #当客户端访问www.lijie.com,监听端口号为80,直接跳转到data&#x2F;bbs目录下文件</span><br><span class="line">       server &#123;</span><br><span class="line">           listen       80;</span><br><span class="line">           server_name  bbs.lijie.com;</span><br><span class="line">           location &#x2F; &#123;</span><br><span class="line">               root   data&#x2F;bbs;</span><br><span class="line">               index  index.html index.htm;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><h4 id="基于端口的虚拟主机"><a href="#基于端口的虚拟主机" class="headerlink" title="基于端口的虚拟主机"></a>基于端口的虚拟主机</h4><ul><li>使用端口来区分，浏览器使用域名或ip地址:端口号 访问</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#当客户端访问www.lijie.com,监听端口号为8080,直接跳转到data&#x2F;www目录下文件</span><br><span class="line">       server &#123;</span><br><span class="line">           listen       8080;</span><br><span class="line">           server_name  8080.lijie.com;</span><br><span class="line">           location &#x2F; &#123;</span><br><span class="line">               root   data&#x2F;www;</span><br><span class="line">               index  index.html index.htm;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   </span><br><span class="line">       #当客户端访问www.lijie.com,监听端口号为80直接跳转到真实ip服务器地址 127.0.0.1:8080</span><br><span class="line">       server &#123;</span><br><span class="line">           listen       80;</span><br><span class="line">           server_name  www.lijie.com;</span><br><span class="line">           location &#x2F; &#123;</span><br><span class="line">   proxy_pass http:&#x2F;&#x2F;127.0.0.1:8080;</span><br><span class="line">                   index  index.html index.htm;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><h3 id="location的作用是什么？"><a href="#location的作用是什么？" class="headerlink" title="location的作用是什么？"></a>location的作用是什么？</h3><ul><li>location指令的作用是根据用户请求的URI来执行不同的应用，也就是根据用户请求的网站URL进行匹配，匹配成功即进行相关的操作。</li></ul><h4 id="location的语法能说出来吗？"><a href="#location的语法能说出来吗？" class="headerlink" title="location的语法能说出来吗？"></a>location的语法能说出来吗？</h4><blockquote><p>注意：~ 代表自己输入的英文字母</p><table><thead><tr><th>匹配符</th><th>匹配规则</th><th>优先级</th></tr></thead><tbody><tr><td>=</td><td>精确匹配</td><td>1</td></tr><tr><td>^~</td><td>以某个字符串开头</td><td>2</td></tr><tr><td>~</td><td>区分大小写的正则匹配</td><td>3</td></tr><tr><td>~*</td><td>不区分大小写的正则匹配</td><td>4</td></tr><tr><td>!~</td><td>区分大小写不匹配的正则</td><td>5</td></tr><tr><td>!~*</td><td>不区分大小写不匹配的正则</td><td>6</td></tr><tr><td>/</td><td>通用匹配，任何请求都会匹配到</td><td>7</td></tr></tbody></table></blockquote><h4 id="Location正则案例"><a href="#Location正则案例" class="headerlink" title="Location正则案例"></a>Location正则案例</h4><ul><li>示例：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">#优先级1,精确匹配，根路径</span><br><span class="line">       location &#x3D;&#x2F; &#123;</span><br><span class="line">           return 400;</span><br><span class="line">       &#125;</span><br><span class="line">   </span><br><span class="line">       #优先级2,以某个字符串开头,以av开头的，优先匹配这里，区分大小写</span><br><span class="line">       location ^~ &#x2F;av &#123;</span><br><span class="line">          root &#x2F;data&#x2F;av&#x2F;;</span><br><span class="line">       &#125;</span><br><span class="line">   </span><br><span class="line">       #优先级3，区分大小写的正则匹配，匹配&#x2F;media*****路径</span><br><span class="line">       location ~ &#x2F;media &#123;</span><br><span class="line">             alias &#x2F;data&#x2F;static&#x2F;;</span><br><span class="line">       &#125;</span><br><span class="line">   </span><br><span class="line">       #优先级4 ，不区分大小写的正则匹配，所有的****.jpg|gif|png 都走这里</span><br><span class="line">       location ~* .*\.(jpg|gif|png|js|css)$ &#123;</span><br><span class="line">          root  &#x2F;data&#x2F;av&#x2F;;</span><br><span class="line">       &#125;</span><br><span class="line">   </span><br><span class="line">       #优先7，通用匹配</span><br><span class="line">       location &#x2F; &#123;</span><br><span class="line">           return 403;</span><br><span class="line">       &#125;</span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><h3 id="限流怎么做的？"><a href="#限流怎么做的？" class="headerlink" title="限流怎么做的？"></a>限流怎么做的？</h3><ul><li><p>Nginx限流就是限制用户请求速度，防止服务器受不了</p></li><li><p>限流有3种</p><ol><li>正常限制访问频率（正常流量）</li><li>突发限制访问频率（突发流量）</li><li>限制并发连接数</li></ol></li><li><p>Nginx的限流都是基于漏桶流算法，底下会说道什么是桶铜流</p></li></ul><p><strong>实现三种限流算法</strong></p><h5 id="1、正常限制访问频率（正常流量）："><a href="#1、正常限制访问频率（正常流量）：" class="headerlink" title="1、正常限制访问频率（正常流量）："></a>1、正常限制访问频率（正常流量）：</h5><ul><li>限制一个用户发送的请求，我Nginx多久接收一个请求。</li><li>Nginx中使用ngx_http_limit_req_module模块来限制的访问频率，限制的原理实质是基于漏桶算法原理来实现的。在nginx.conf配置文件中可以使用limit_req_zone命令及limit_req命令限制单个IP的请求处理频率。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#定义限流维度，一个用户一分钟一个请求进来，多余的全部漏掉</span><br><span class="line">   limit_req_zone $binary_remote_addr zone&#x3D;one:10m rate&#x3D;1r&#x2F;m;</span><br><span class="line">   </span><br><span class="line">   #绑定限流维度</span><br><span class="line">   server&#123;</span><br><span class="line">   </span><br><span class="line">   location&#x2F;seckill.html&#123;</span><br><span class="line">   limit_req zone&#x3D;zone;</span><br><span class="line">   proxy_pass http:&#x2F;&#x2F;lj_seckill;</span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">   &#125;</span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><ul><li>1r/s代表1秒一个请求，1r/m一分钟接收一个请求， 如果Nginx这时还有别人的请求没有处理完，Nginx就会拒绝处理该用户请求。</li></ul><h5 id="2、突发限制访问频率（突发流量）："><a href="#2、突发限制访问频率（突发流量）：" class="headerlink" title="2、突发限制访问频率（突发流量）："></a>2、突发限制访问频率（突发流量）：</h5><ul><li>限制一个用户发送的请求，我Nginx多久接收一个。</li><li>上面的配置一定程度可以限制访问频率，但是也存在着一个问题：如果突发流量超出请求被拒绝处理，无法处理活动时候的突发流量，这时候应该如何进一步处理呢？Nginx提供burst参数结合nodelay参数可以解决流量突发的问题，可以设置能处理的超过设置的请求数外能额外处理的请求数。我们可以将之前的例子添加burst参数以及nodelay参数：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#定义限流维度，一个用户一分钟一个请求进来，多余的全部漏掉</span><br><span class="line">   limit_req_zone $binary_remote_addr zone&#x3D;one:10m rate&#x3D;1r&#x2F;m;</span><br><span class="line">   </span><br><span class="line">   #绑定限流维度</span><br><span class="line">   server&#123;</span><br><span class="line">   </span><br><span class="line">   location&#x2F;seckill.html&#123;</span><br><span class="line">   limit_req zone&#x3D;zone burst&#x3D;5 nodelay;</span><br><span class="line">   proxy_pass http:&#x2F;&#x2F;lj_seckill;</span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">   &#125;</span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><ul><li>为什么就多了一个 burst=5 nodelay; 呢，多了这个可以代表Nginx对于一个用户的请求会立即处理前五个，多余的就慢慢来落，没有其他用户的请求我就处理你的，有其他的请求的话我Nginx就漏掉不接受你的请求</li></ul><h5 id="3、-限制并发连接数"><a href="#3、-限制并发连接数" class="headerlink" title="3、 限制并发连接数"></a>3、 限制并发连接数</h5><ul><li>Nginx中的ngx_http_limit_conn_module模块提供了限制并发连接数的功能，可以使用limit_conn_zone指令以及limit_conn执行进行配置。接下来我们可以通过一个简单的例子来看下：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">   limit_conn_zone $binary_remote_addr zone&#x3D;myip:10m;</span><br><span class="line">   limit_conn_zone $server_name zone&#x3D;myServerName:10m;</span><br><span class="line">       &#125;</span><br><span class="line">   </span><br><span class="line">       server &#123;</span><br><span class="line">           location &#x2F; &#123;</span><br><span class="line">               limit_conn myip 10;</span><br><span class="line">               limit_conn myServerName 100;</span><br><span class="line">               rewrite &#x2F; http:&#x2F;&#x2F;www.lijie.net permanent;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><ul><li>上面配置了单个IP同时并发连接数最多只能10个连接，并且设置了整个虚拟服务器同时最大并发数最多只能100个链接。当然，只有当请求的header被服务器处理后，虚拟服务器的连接数才会计数。刚才有提到过Nginx是基于漏桶算法原理实现的，实际上限流一般都是基于漏桶算法和令牌桶算法实现的。接下来我们来看看两个算法的介绍：</li></ul><h3 id="漏桶流算法和令牌桶算法知道？"><a href="#漏桶流算法和令牌桶算法知道？" class="headerlink" title="漏桶流算法和令牌桶算法知道？"></a>漏桶流算法和令牌桶算法知道？</h3><h4 id="漏桶算法"><a href="#漏桶算法" class="headerlink" title="漏桶算法"></a>漏桶算法</h4><ul><li>漏桶算法是网络世界中流量整形或速率限制时经常使用的一种算法，它的主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。漏桶算法提供了一种机制，通过它，突发流量可以被整形以便为网络提供一个稳定的流量。也就是我们刚才所讲的情况。漏桶算法提供的机制实际上就是刚才的案例：<strong>突发流量会进入到一个漏桶，漏桶会按照我们定义的速率依次处理请求，如果水流过大也就是突发流量过大就会直接溢出，则多余的请求会被拒绝。所以漏桶算法能控制数据的传输速率。</strong><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/3c39041354da8461c28576c8dea55920.png" alt="jiezuiquanmiandemianshiti_2_1.png"></li></ul><h4 id="令牌桶算法"><a href="#令牌桶算法" class="headerlink" title="令牌桶算法"></a>令牌桶算法</h4><ul><li>令牌桶算法是网络流量整形和速率限制中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。Google开源项目Guava中的RateLimiter使用的就是令牌桶控制算法。<strong>令牌桶算法的机制如下：存在一个大小固定的令牌桶，会以恒定的速率源源不断产生令牌。如果令牌消耗速率小于生产令牌的速度，令牌就会一直产生直至装满整个令牌桶。</strong></li></ul><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/5fab055f4ae068ba9edd7d7425fedd7a.png" alt="jiezuiquanmiandemianshiti_3.png"></p><h3 id="为什么要做动静分离？"><a href="#为什么要做动静分离？" class="headerlink" title="为什么要做动静分离？"></a>为什么要做动静分离？</h3><ul><li>Nginx是当下最热的Web容器，网站优化的重要点在于静态化网站，网站静态化的关键点则是是动静分离，动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们则根据静态资源的特点将其做缓存操作。</li><li>让静态的资源只走静态资源服务器，动态的走动态的服务器</li><li>Nginx的静态处理能力很强，但是动态处理能力不足，因此，在企业中常用动静分离技术。</li><li>对于静态资源比如图片，js，css等文件，我们则在反向代理服务器nginx中进行缓存。这样浏览器在请求一个静态资源时，代理服务器nginx就可以直接处理，无需将请求转发给后端服务器tomcat。 若用户请求的动态文件，比如servlet,jsp则转发给Tomcat服务器处理，从而实现动静分离。这也是反向代理服务器的一个重要的作用。</li></ul><h3 id="Nginx怎么做的动静分离？"><a href="#Nginx怎么做的动静分离？" class="headerlink" title="Nginx怎么做的动静分离？"></a>Nginx怎么做的动静分离？</h3><ul><li>只需要指定路径对应的目录。location/可以使用正则表达式匹配。并指定对应的硬盘中的目录。如下：（操作都是在Linux上）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">location &#x2F;image&#x2F; &#123;</span><br><span class="line">               root   &#x2F;usr&#x2F;local&#x2F;static&#x2F;;</span><br><span class="line">               autoindex on;</span><br><span class="line">           &#125;</span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><ol><li>创建目录</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir &#x2F;usr&#x2F;local&#x2F;static&#x2F;image</span><br><span class="line">       Java极客，javajike.com</span><br></pre></td></tr></table></figure><ol start="2"><li><p>进入目录</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd  /usr/local/<span class="keyword">static</span>/image</span><br><span class="line">  Java极客，javajike.com</span><br></pre></td></tr></table></figure></li><li><p>放一张照片上去#</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>.jpg</span><br><span class="line">  Java极客，javajike.com</span><br></pre></td></tr></table></figure></li><li><p>重启 nginx</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo nginx -s reload</span><br><span class="line">  Java极客，javajike.com</span><br></pre></td></tr></table></figure></li><li><p>打开浏览器 输入 server_name/image/1.jpg 就可以访问该静态图片了</p></li></ol><h3 id="Nginx负载均衡的算法怎么实现的-策略有哪些"><a href="#Nginx负载均衡的算法怎么实现的-策略有哪些" class="headerlink" title="Nginx负载均衡的算法怎么实现的?策略有哪些?"></a>Nginx负载均衡的算法怎么实现的?策略有哪些?</h3><ul><li>为了避免服务器崩溃，大家会通过负载均衡的方式来分担服务器压力。将对台服务器组成一个集群，当用户访问时，先访问到一个转发服务器，再由转发服务器将访问分发到压力更小的服务器。</li><li>Nginx负载均衡实现的策略有以下五种：</li></ul><h4 id="1-轮询-默认"><a href="#1-轮询-默认" class="headerlink" title="1 轮询(默认)"></a>1 轮询(默认)</h4><ul><li>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某个服务器宕机，能自动剔除故障系统。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">upstream backserver &#123; </span><br><span class="line">   server <span class="number">192.168</span><span class="number">.0</span><span class="number">.12</span>; </span><br><span class="line">   server <span class="number">192.168</span><span class="number">.0</span><span class="number">.13</span>; </span><br><span class="line">  &#125; </span><br><span class="line">  Java极客，javajike.com</span><br></pre></td></tr></table></figure><h4 id="2-权重-weight"><a href="#2-权重-weight" class="headerlink" title="2 权重 weight"></a>2 权重 weight</h4><ul><li>weight的值越大分配</li><li>到的访问概率越高，主要用于后端每台服务器性能不均衡的情况下。其次是为在主从的情况下设置不同的权值，达到合理有效的地利用主机资源。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">upstream backserver &#123; </span><br><span class="line">    server 192.168.0.12 weight&#x3D;2; </span><br><span class="line">    server 192.168.0.13 weight&#x3D;8; </span><br><span class="line">   &#125; </span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><ul><li>权重越高，在被访问的概率越大，如上例，分别是20%，80%。</li></ul><h4 id="3-ip-hash-IP绑定"><a href="#3-ip-hash-IP绑定" class="headerlink" title="3 ip_hash( IP绑定)"></a>3 ip_hash( IP绑定)</h4><ul><li>每个请求按访问IP的哈希结果分配，使来自同一个IP的访客固定访问一台后端服务器，<code>并且可以有效解决动态网页存在的session共享问题</code></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">upstream backserver &#123; </span><br><span class="line">    ip_hash; </span><br><span class="line">    server 192.168.0.12:88; </span><br><span class="line">    server 192.168.0.13:80; </span><br><span class="line">   &#125; </span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><h4 id="4-fair-第三方插件"><a href="#4-fair-第三方插件" class="headerlink" title="4 fair(第三方插件)"></a>4 fair(第三方插件)</h4><ul><li>必须安装upstream_fair模块。</li><li>对比 weight、ip_hash更加智能的负载均衡算法，fair算法可以根据页面大小和加载时间长短智能地进行负载均衡，响应时间短的优先分配。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">upstream backserver &#123; </span><br><span class="line">    server server1; </span><br><span class="line">    server server2; </span><br><span class="line">    fair; </span><br><span class="line">   &#125; </span><br><span class="line">   </span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><ul><li>哪个服务器的响应速度快，就将请求分配到那个服务器上。</li></ul><h4 id="5、url-hash-第三方插件"><a href="#5、url-hash-第三方插件" class="headerlink" title="5、url_hash(第三方插件)"></a>5、url_hash(第三方插件)</h4><ul><li>必须安装Nginx的hash软件包</li><li>按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">upstream backserver &#123; </span><br><span class="line">    server squid1:3128; </span><br><span class="line">    server squid2:3128; </span><br><span class="line">    hash $request_uri; </span><br><span class="line">    hash_method crc32; </span><br><span class="line">   &#125; </span><br><span class="line">   </span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><h3 id="Nginx配置高可用性怎么配置？"><a href="#Nginx配置高可用性怎么配置？" class="headerlink" title="Nginx配置高可用性怎么配置？"></a>Nginx配置高可用性怎么配置？</h3><ul><li>当上游服务器(真实访问服务器)，一旦出现故障或者是没有及时相应的话，应该直接轮训到下一台服务器，保证服务器的高可用</li><li>Nginx配置代码：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">           listen       80;</span><br><span class="line">           server_name  www.lijie.com;</span><br><span class="line">           location &#x2F; &#123;</span><br><span class="line">       ### 指定上游服务器负载均衡服务器</span><br><span class="line">       proxy_pass http:&#x2F;&#x2F;backServer;</span><br><span class="line">   ###nginx与上游服务器(真实访问的服务器)超时时间 后端服务器连接的超时时间_发起握手等候响应超时时间</span><br><span class="line">   proxy_connect_timeout 1s;</span><br><span class="line">   ###nginx发送给上游服务器(真实访问的服务器)超时时间</span><br><span class="line">               proxy_send_timeout 1s;</span><br><span class="line">   ### nginx接受上游服务器(真实访问的服务器)超时时间</span><br><span class="line">               proxy_read_timeout 1s;</span><br><span class="line">               index  index.html index.htm;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">   </span><br><span class="line">   </span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><h3 id="Nginx怎么判断别IP不可访问？"><a href="#Nginx怎么判断别IP不可访问？" class="headerlink" title="Nginx怎么判断别IP不可访问？"></a>Nginx怎么判断别IP不可访问？</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 如果访问的ip地址为192.168.9.115,则返回403</span><br><span class="line">   if  ($remote_addr &#x3D; 192.168.9.115) &#123;  </span><br><span class="line">        return 403;  </span><br><span class="line">   &#125;  </span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><h3 id="怎么限制浏览器访问？"><a href="#怎么限制浏览器访问？" class="headerlink" title="怎么限制浏览器访问？"></a>怎么限制浏览器访问？</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## 不允许谷歌浏览器访问 如果是谷歌浏览器返回500</span><br><span class="line">   if ($http_user_agent ~ Chrome) &#123;   </span><br><span class="line">       return 500;  </span><br><span class="line">   &#125;</span><br><span class="line">   Java极客，javajike.com</span><br></pre></td></tr></table></figure><h3 id="Rewrite全局变量是什么？"><a href="#Rewrite全局变量是什么？" class="headerlink" title="Rewrite全局变量是什么？"></a>Rewrite全局变量是什么？</h3><blockquote><table><thead><tr><th>变量</th><th>含义</th></tr></thead><tbody><tr><td>$args</td><td>这个变量等于请求行中的参数，同$query_string</td></tr><tr><td>$contentlength</td><td>请求头中的Content-length字段。</td></tr><tr><td>$content_type</td><td>请求头中的Content-Type字段。</td></tr><tr><td>$document_root</td><td>当前请求在root指令中指定的值。</td></tr><tr><td>$host</td><td>请求主机头字段，否则为服务器名称。</td></tr><tr><td>$http_user_agent</td><td>客户端agent信息</td></tr><tr><td>$http_cookie</td><td>客户端cookie信息</td></tr><tr><td>$limit_rate</td><td>这个变量可以限制连接速率。</td></tr><tr><td>$request_method</td><td>客户端请求的动作，通常为GET或POST。</td></tr><tr><td>$remote_addr</td><td>客户端的IP地址。</td></tr><tr><td>$remote_port</td><td>客户端的端口。</td></tr><tr><td>$remote_user</td><td>已经经过AuthBasicModule验证的用户名。</td></tr><tr><td>$request_filename</td><td>当前请求的文件路径，由root或alias指令与URI请求生成。</td></tr><tr><td>$scheme</td><td>HTTP方法（如http，https）。</td></tr><tr><td>$server_protocol</td><td>请求使用的协议，通常是HTTP/1.0或HTTP/1.1。</td></tr><tr><td>$server_addr</td><td>服务器地址，在完成一次系统调用后可以确定这个值。</td></tr><tr><td>$server_name</td><td>服务器名称。</td></tr><tr><td>$server_port</td><td>请求到达服务器的端口号。</td></tr><tr><td>$request_uri</td><td>包含请求参数的原始URI，不包含主机名，如”/foo/bar.php?arg=baz”。</td></tr><tr><td>$uri</td><td>不带请求参数的当前URI，$uri不包含主机名，如”/foo/bar.html”。</td></tr><tr><td>$document_uri</td><td>与$uri相同。</td></tr></tbody></table></blockquote><p>本文转自 <a href="https://juejin.cn/post/6844904125784653837" target="_blank" rel="noopener">https://juejin.cn/post/6844904125784653837</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git分支管理策略</title>
      <link href="/posts/f61bc5a7/"/>
      <url>/posts/f61bc5a7/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>如果你严肃对待编程，就必定会使用”<a href="https://www.ruanyifeng.com/blog/2008/12/a_visual_guide_to_version_control.html" target="_blank" rel="noopener">版本管理系统</a>“（Version Control System）。</p><p>眼下最流行的”版本管理系统”，非<a href="https://git-scm.com/" target="_blank" rel="noopener">Git</a>莫属。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9be4602299a15aa95b32e793ff7bad40.png" alt=""></p><p>相比同类软件，Git有很多优点。其中很显著的一点，就是版本的分支（branch）和合并（merge）十分方便。有些传统的版本管理软件，分支操作实际上会生成一份现有代码的物理拷贝，而Git只生成一个指向当前版本（又称”快照”）的指针，因此非常快捷易用。</p><p>但是，太方便了也会产生副作用。如果你不加注意，很可能会留下一个枝节蔓生、四处开放的版本库，到处都是分支，完全看不出主干发展的脉络。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/c35cb5ea9ae0889383e3ea341e65041e.png" alt=""></p><p><a href="http://nvie.com/" target="_blank" rel="noopener">Vincent Driessen</a>提出了一个分支管理的<a href="http://nvie.com/posts/a-successful-git-branching-model/" target="_blank" rel="noopener">策略</a>，我觉得非常值得借鉴。它可以使得版本库的演进保持简洁，主干清晰，各个分支各司其职、井井有条。理论上，这些策略对所有的版本管理系统都适用，Git只是用来举例而已。如果你不熟悉Git，跳过举例部分就可以了。</p><p><strong>一、主分支Master</strong></p><p>首先，代码库应该有一个、且仅有一个主分支。所有提供给用户使用的正式版本，都在这个主分支上发布。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/0f57b7200b5215f120f02adfa0e22b2b.png" alt=""></p><p>Git主分支的名字，默认叫做Master。它是自动建立的，版本库初始化以后，默认就是在主分支在进行开发。</p><p><strong>二、开发分支Develop</strong></p><p>主分支只用来分布重大版本，日常开发应该在另一条分支上完成。我们把开发用的分支，叫做Develop。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/53ea0bc518ecb2d89fdee4b1d18023a5.png" alt=""></p><p>这个分支可以用来生成代码的最新隔夜版本（nightly）。如果想正式对外发布，就在Master分支上，对Develop分支进行”合并”（merge）。</p><p>Git创建Develop分支的命令：</p><blockquote><p>　　git checkout -b develop master</p></blockquote><p>将Develop分支发布到Master分支的命令：</p><blockquote><p>　　# 切换到Master分支<br>　　git checkout master</p><p>　　# 对Develop分支进行合并<br>　　git merge –no-ff develop</p></blockquote><p>这里稍微解释一下，上一条命令的–no-ff参数是什么意思。默认情况下，Git执行”快进式合并”（fast-farward merge），会直接将Master分支指向Develop分支。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/cab161df2f633d196304e10cc91dde46.png" alt=""></p><p>使用–no-ff参数后，会执行正常合并，在Master分支上生成一个新节点。为了保证版本演进的清晰，我们希望采用这种做法。关于合并的更多解释，请参考Benjamin Sandofsky的<a href="https://sandofsky.com/blog/git-workflow.html" target="_blank" rel="noopener">《Understanding the Git Workflow》</a>。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/e5de87638e4aacce963b5762a5bfe455.png" alt=""></p><p><strong>三、临时性分支</strong></p><p>前面讲到版本库的两条主要分支：Master和Develop。前者用于正式发布，后者用于日常开发。其实，常设分支只需要这两条就够了，不需要其他了。</p><p>但是，除了常设分支以外，还有一些临时性分支，用于应对一些特定目的的版本开发。临时性分支主要有三种：</p><blockquote><p>　　* 功能（feature）分支</p><p>　　* 预发布（release）分支</p><p>　　* 修补bug（fixbug）分支</p></blockquote><p>这三种分支都属于临时性需要，使用完以后，应该删除，使得代码库的常设分支始终只有Master和Develop。</p><p><strong>四、 功能分支</strong></p><p>接下来，一个个来看这三种”临时性分支”。</p><p>第一种是功能分支，它是为了开发某种特定功能，从Develop分支上面分出来的。开发完成后，要再并入Develop。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/628a56932d94f20e99c4667a29994dd8.png" alt=""></p><p>功能分支的名字，可以采用feature-*的形式命名。</p><p>创建一个功能分支：</p><blockquote><p>　　git checkout -b feature-x develop</p></blockquote><p>开发完成后，将功能分支合并到develop分支：</p><blockquote><p>　　git checkout develop</p><p>　　git merge –no-ff feature-x</p></blockquote><p>删除feature分支：</p><blockquote><p>　　git branch -d feature-x</p></blockquote><p><strong>五、预发布分支</strong></p><p>第二种是预发布分支，它是指发布正式版本之前（即合并到Master分支之前），我们可能需要有一个预发布的版本进行测试。</p><p>预发布分支是从Develop分支上面分出来的，预发布结束以后，必须合并进Develop和Master分支。它的命名，可以采用release-*的形式。</p><p>创建一个预发布分支：</p><blockquote><p>　　git checkout -b release-1.2 develop</p></blockquote><p>确认没有问题后，合并到master分支：</p><blockquote><p>　　git checkout master</p><p>　　git merge –no-ff release-1.2</p><p>　　# 对合并生成的新节点，做一个标签<br>　　git tag -a 1.2</p></blockquote><p>再合并到develop分支：</p><blockquote><p>　　git checkout develop</p><p>　　git merge –no-ff release-1.2</p></blockquote><p>最后，删除预发布分支：</p><blockquote><p>　　git branch -d release-1.2</p></blockquote><p><strong>六、修补bug分支</strong></p><p>最后一种是修补bug分支。软件正式发布以后，难免会出现bug。这时就需要创建一个分支，进行bug修补。</p><p>修补bug分支是从Master分支上面分出来的。修补结束以后，再合并进Master和Develop分支。它的命名，可以采用fixbug-*的形式。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/00b1f317a57828edb7590ffe6665f008.png" alt=""></p><p>创建一个修补bug分支：</p><blockquote><p>　　git checkout -b fixbug-0.1 master</p></blockquote><p>修补结束后，合并到master分支：</p><blockquote><p>　　git checkout master</p><p>　　git merge –no-ff fixbug-0.1</p><p>　　git tag -a 0.1.1</p></blockquote><p>再合并到develop分支：</p><blockquote><p>　　git checkout develop</p><p>　　git merge –no-ff fixbug-0.1</p></blockquote><p>最后，删除”修补bug分支”：</p><blockquote><p>　　git branch -d fixbug-0.1</p></blockquote><p>（完）</p><p>本文转自 <a href="http://www.ruanyifeng.com/blog/2012/07/git.html" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2012/07/git.html</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>详解一条 SQL 的执行过程</title>
      <link href="/posts/b276c97d/"/>
      <url>/posts/b276c97d/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>天天和数据库打交道，一天能写上几十条 SQL 语句，但你知道我们的系统是如何和数据库交互的吗？MySQL 如何帮我们存储数据、又是如何帮我们管理事务？….是不是感觉真的除了写几个 「select * from dual」外基本脑子一片空白？这篇文章就将带你走进 MySQL 的世界，让你彻底了解系统到底是如何和 MySQL 交互的，MySQL 在接受到我们发送的 SQL 语句时又分别做了哪些事情。</p><h2 id="MySQL-驱动"><a href="#MySQL-驱动" class="headerlink" title="MySQL 驱动"></a>MySQL 驱动</h2><p>我们的系统在和 MySQL 数据库进行通信的时候，总不可能是平白无故的就能接收和发送请求，就算是你没有做什么操作，那总该是有其他的“人”帮我们做了一些事情，基本上使用过 MySQL 数据库的程序员多多少少都会知道 MySQL 驱动这个概念的。就是这个 MySQL  驱动在底层帮我们做了对数据库的连接，只有建立了连接了，才能够有后面的交互。看下图表示</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/7eeeb54467dbf69c11677fd3a8f086bc.png" alt=""></p><p>这样的话，在系统和 MySQL 进行交互之前，MySQL 驱动会帮我们建立好连接，然后我们只需要发送 SQL 语句就可以执行 CRUD 了。一次 SQL 请求就会建立一个连接，多个请求就会建立多个连接，那么问题来了，我们系统肯定不是一个人在使用的，换句话说肯定是存在多个请求同时去争抢连接的情况。我们的 web 系统一般都是部署在 tomcat 容器中的，而  tomcat  是可以并发处理多个请求的，这就会导致多个请求会去建立多个连接，然后使用完再都去关闭，这样会有什么问题呢？如下图</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/1eb94fb5f21b172961bbbb279e4463db.png" alt=""></p><p>java 系统在通过 MySQL 驱动和 MySQL 数据库连接的时候是基于 TCP/IP 协议的，所以如果每个请求都是新建连接和销毁连接，那这样势必会造成不必要的浪费和性能的下降，也就说上面的多线程请求的时候频繁的创建和销毁连接显然是不合理的。必然会大大降低我们系统的性能，但是如果给你提供一些固定的用来连接的线程，这样是不是不需要反复的创建和销毁连接了呢？相信懂行的朋友会会心一笑，没错，说的就是数据库连接池。</p><blockquote><p>数据库连接池：维护一定的连接数，方便系统获取连接，使用就去池子中获取，用完放回去就可以了，我们不需要关心连接的创建与销毁，也不需要关心线程池是怎么去维护这些连接的。</p></blockquote><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/6741d87b1ea9255fca882c29733aadf1.png" alt="">常见的数据库连接池有 <code>Druid、C3P0、DBCP</code>，连接池实现原理在这里就不深入讨论了，采用连接池大大节省了不断创建与销毁线程的开销，这就是有名的「池化」思想，不管是线程池还是 HTTP 连接池，都能看到它的身影。</p><h2 id="数据库连接池"><a href="#数据库连接池" class="headerlink" title="数据库连接池"></a>数据库连接池</h2><p>到这里，我们已经知道的是我们的系统在访问  MySQL  数据库的时候，建立的连接并不是每次请求都会去创建的，而是从数据库连接池中去获取，这样就解决了因为反复的创建和销毁连接而带来的性能损耗问题了。不过这里有个小问题，业务系统是并发的，而 MySQL 接受请求的线程呢，只有一个？</p><p>其实 MySQL 的架构体系中也已经提供了这样的一个池子，也是数据库连池。双方都是通过数据库连接池来管理各个连接的，这样一方面线程之前不需要是争抢连接，更重要的是不需要反复的创建的销毁连接。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/548a30c27dedf31d5d7e8f024dffaba3.png" alt=""></p><p>至此系统和 MySQL 数据库之间的连接问题已经说明清楚了。那么 MySQL 数据库中的这些连接是怎么来处理的，又是谁来处理呢？</p><h2 id="网络连接必须由线程来处理"><a href="#网络连接必须由线程来处理" class="headerlink" title="网络连接必须由线程来处理"></a>网络连接必须由线程来处理</h2><p>对计算基础稍微有一点了解的的同学都是知道的，网络中的连接都是由线程来处理的，所谓网络连接说白了就是一次请求，每次请求都会有相应的线程去处理的。也就是说对于 SQL 语句的请求在 MySQL  中是由一个个的线程去处理的。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/3ad64bfd14540b3660b887b7d1df2326.png" alt=""></p><p>那这些线程会怎么去处理这些请求？会做哪些事情？</p><h2 id="SQL-接口"><a href="#SQL-接口" class="headerlink" title="SQL 接口"></a>SQL 接口</h2><p>MySQL 中处理请求的线程在获取到请求以后获取 SQL 语句去交给 SQL 接口去处理。</p><h2 id="查询解析器"><a href="#查询解析器" class="headerlink" title="查询解析器"></a>查询解析器</h2><p>假如现在有这样的一个 SQL</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT stuName,age,sex FROM students WHERE id&#x3D;1</span><br></pre></td></tr></table></figure><p>但是这个 SQL 是写给我们人看的，机器哪里知道你在说什么？这个时候<code>解析器</code>就上场了。他会将  SQL  接口传递过来的 SQL 语句进行解析，翻译成 MySQL 自己能认识的语言，至于怎么解析的就不需要在深究了，无非是自己一套相关的规则。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/c00db2661a3e52269f8242f84958d27e.png" alt="">现在 SQL 已经被解析成  MySQL  认识的样子的，那下一步是不是就是执行吗？理论上是这样子的，但是 MySQL 的强大远不止于此，他还会帮我们选择最优的查询路径。</p><blockquote><p>什么叫最优查询路径？就是 MySQL 会按照自己认为的效率最高的方式去执行查询</p></blockquote><p>具体是怎么做到的呢？这就要说到  MySQL  的查询优化器了</p><h2 id="MySQL-查询优化器"><a href="#MySQL-查询优化器" class="headerlink" title="MySQL 查询优化器"></a>MySQL 查询优化器</h2><p>查询优化器内部具体怎么实现的我们不需要是关心，我需要知道的是  MySQL  会帮我去使用他自己认为的最好的方式去优化这条  SQL  语句，并生成一条条的执行计划，比如你创建了多个索引，MySQL 会依据<strong>成本最小原则</strong>来选择使用对应的索引，这里的成本主要包括两个方面, IO 成本和 CPU 成本</p><p><strong>IO 成本</strong>: 即从磁盘把数据加载到内存的成本，默认情况下，读取数据页的 IO 成本是 1，MySQL 是以页的形式读取数据的，即当用到某个数据时，并不会只读取这个数据，而会把这个数据相邻的数据也一起读到内存中，这就是有名的程序局部性原理，所以 MySQL 每次会读取一整页，一页的成本就是 1。所以 IO 的成本主要和页的大小有关</p><p><strong>CPU 成本</strong>：将数据读入内存后，还要检测数据是否满足条件和排序等 CPU 操作的成本，显然它与行数有关，默认情况下，检测记录的成本是 0.2。</p><p>MySQL 优化器 会计算 「IO 成本 + CPU」 成本最小的那个索引来执行</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/ade2a8e18e79b487f0c37ae2094c2b9b.png" alt=""></p><p>优化器执行选出最优索引等步骤后，会去调用存储引擎接口，开始去执行被  MySQL  解析过和优化过的 SQL 语句</p><h2 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h2><p>查询优化器<code>会调用</code>存储引擎的接口，去执行  SQL，也就是说真正执行  SQL  的动作是在存储引擎中完成的。数据是被存放在内存或者是磁盘中的（存储引擎是一个非常重要的组件，后面会详细介绍）</p><blockquote><p>本篇文章大家先对存储引擎有一个大致的认识就可以了。</p></blockquote><h2 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h2><p>执行器是一个非常重要的组件，因为前面那些组件的操作最终必须通过执行器去调用存储引擎接口才能被执行。执行器最终最根据一系列的执行计划去调用存储引擎的接口去完成  SQL  的执行</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/57ac5b3bf6e0692f3eb0f60452c44d4d.png" alt=""></p><h2 id="初识存储引擎"><a href="#初识存储引擎" class="headerlink" title="初识存储引擎"></a>初识存储引擎</h2><p>我们以一个更新的SQL语句来说明，SQL 如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UPDATE students SET stuName &#x3D; &#39;小强&#39; WHERE id &#x3D; 1</span><br></pre></td></tr></table></figure><p>当我们系统发出这样的查询去交给 MySQL 的时候，MySQL 会按照我们上面介绍的一系列的流程最终通过执行器调用存储引擎去执行，流程图就是上面那个。在执行这个 SQL 的时候 SQL 语句对应的数据要么是在内存中，要么是在磁盘中，如果直接在磁盘中操作，那这样的随机IO读写的速度肯定让人无法接受的，所以每次在执行 SQL 的时候都会将其数据加载到内存中，这块内存就是 InnoDB 中一个非常重要的组件：<strong>缓冲池</strong> Buffer Pool</p><h2 id="Buffer-Pool"><a href="#Buffer-Pool" class="headerlink" title="Buffer Pool"></a>Buffer Pool</h2><p>Buffer Pool （缓冲池）是 <strong>InnoDB</strong> 存储引擎中非常重要的内存结构，顾名思义，缓冲池其实就是类似  Redis  一样的作用，起到一个缓存的作用，因为我们都知道 <strong>MySQL</strong> 的数据最终是存储在磁盘中的，如果没有这个 Buffer Pool  那么我们每次的数据库请求都会磁盘中查找，这样必然会存在 IO 操作，这肯定是无法接受的。但是有了 Buffer Pool 就是我们第一次在查询的时候会将查询的结果存到  Buffer Pool 中，这样后面再有请求的时候就会先从缓冲池中去查询，如果没有再去磁盘中查找，然后在放到  Buffer Pool 中，如下图</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20dc304d85283efa0fbd47282baf1f91.png" alt=""></p><p>按照上面的那幅图，这条 SQL 语句的执行步骤大致是这样子的</p><ol><li><p>innodb 存储引擎会在缓冲池中查找 id=1 的这条数据是否存在</p></li><li><p>发现不存在，那么就会去磁盘中加载，并将其存放在缓冲池中</p></li><li><p>该条记录会被加上一个独占锁（总不能你在修改的时候别人也在修改吧，这个机制本篇文章不重点介绍，以后会专门写文章来详细讲解）</p></li></ol><h2 id="undo-日志文件：记录数据被修改前的样子"><a href="#undo-日志文件：记录数据被修改前的样子" class="headerlink" title="undo 日志文件：记录数据被修改前的样子"></a>undo 日志文件：记录数据被修改前的样子</h2><p>undo 顾名思义，就是没有做，没发生的意思。undo log  就是没有发生事情（原本事情是什么）的一些日志</p><p>我们刚刚已经说了，在准备更新一条语句的时候，该条语句已经被加载到 Buffer pool 中了，实际上这里还有这样的操作，就是在将该条语句加载到 Buffer Pool 中的时候同时会往 undo 日志文件中插入一条日志，也就是将 id=1 的这条记录的原来的值记录下来。</p><p>这样做的目的是什么？</p><p>Innodb 存储引擎的最大特点就是支持事务，如果本次更新失败，也就是事务提交失败，那么该事务中的所有的操作都必须回滚到执行前的样子，也就是说当事务失败的时候，也不会对原始数据有影响，看图说话</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/9c83b5d3cc27d0903ff3832003fc34b4.png" alt=""></p><p>这里说句额外话，其实 MySQL  也是一个系统，就好比我们平时开发的 java 的功能系统一样，MySQL  使用的是自己相应的语言开发出来的一套系统而已，它根据自己需要的功能去设计对应的功能，它即然能做到哪些事情，那么必然是设计者们当初这么定义或者是根据实际的场景变更演化而来的。所以大家放平心态，把 MySQL 当作一个系统去了解熟悉他。</p><p>到这一步，我们的执行的 SQL 语句已经被加载到 Buffer Pool 中了，然后开始更新这条语句，更新的操作实际是在Buffer Pool中执行的，那问题来了，按照我们平时开发的一套理论<code>缓冲池中的数据和数据库中的数据不一致时候，我们就认为缓存中的数据是脏数据</code>，那此时 Buffer Pool 中的数据岂不是成了脏数据？没错，目前这条数据就是脏数据，Buffer Pool 中的记录是<code>小强</code> 数据库中的记录是<code>旺财</code> ，这种情况 MySQL是怎么处理的呢，继续往下看</p><h2 id="redo-日志文件：记录数据被修改后的样子"><a href="#redo-日志文件：记录数据被修改后的样子" class="headerlink" title="redo 日志文件：记录数据被修改后的样子"></a>redo 日志文件：记录数据被修改后的样子</h2><p>除了从磁盘中加载文件和将操作前的记录保存到 undo 日志文件中，其他的操作是在内存中完成的，内存中的数据的特点就是：断电丢失。如果此时 MySQL 所在的服务器宕机了，那么 Buffer Pool 中的数据会全部丢失的。这个时候 redo 日志文件就需要来大显神通了</p><p><em><strong>画外音：redo 日志文件是 InnoDB 特有的，他是存储引擎级别的，不是 MySQL 级别的</strong></em></p><p>redo 记录的是数据修改之后的值，不管事务是否提交都会记录下来，例如，此时将要做的是<code>update students set stuName=&#39;小强&#39; where id=1;</code> 那么这条操作就会被记录到 redo log buffer 中，啥？怎么又出来一个 redo log buffer ,很简单，MySQL 为了提高效率，所以将这些操作都先放在内存中去完成，然后会在<strong>某个时机</strong>将其持久化到磁盘中。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/7b792d50563093f1bf935bb1a1f0c75e.png" alt=""></p><p>截至目前，我们应该都熟悉了 MySQL 的执行器调用存储引擎是怎么将一条 SQL 加载到缓冲池和记录哪些日志的，流程如下：</p><ol><li><p>准备更新一条 SQL 语句</p></li><li><p>MySQL（innodb）会先去缓冲池（BufferPool）中去查找这条数据，没找到就会去磁盘中查找，如果查找到就会将这条数据加载到缓冲池（BufferPool）中</p></li><li><p>在加载到 Buffer Pool 的同时，会将这条数据的原始记录保存到 undo 日志文件中</p></li><li><p>innodb 会在 Buffer Pool 中执行更新操作</p></li><li><p>更新后的数据会记录在 redo log buffer 中</p></li></ol><p>上面说的步骤都是在正常情况下的操作，但是程序的设计和优化并不仅是为了这些正常情况而去做的，也是为了<strong>那些临界区和极端情况下出现的问题</strong>去优化设计的</p><p>这个时候如果服务器宕机了，那么缓存中的数据还是丢失了。真烦，竟然数据总是丢失，那能不能不要放在内存中，直接保存到磁盘呢？很显然不行，因为在上面也已经介绍了，在内存中的操作目的是为了提高效率。</p><p>此时，如果 MySQL 真的宕机了，那么没关系的，因为 MySQL 会认为本次事务是失败的，所以数据依旧是更新前的样子，并不会有任何的影响。</p><p>好了，语句也更新好了那么需要将更新的值提交啊，也就是需要提交本次的事务了，因为只要事务成功提交了，才会将最后的变更保存到数据库，<strong>在提交事务前</strong>仍然会具有相关的其他操作</p><p>将  <code>redo Log Buffer</code> 中的数据持久化到磁盘中，就是将 redo log buffer 中的数据写入到 redo log 磁盘文件中，一般情况下，redo log Buffer 数据写入磁盘的策略是立即刷入磁盘（<strong>具体策略情况在下面小总结出会详细介绍</strong>）,上图</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/4142b22170304ae2ee0330e70c54e6f3.png" alt=""></p><p>如果 redo log Buffer 刷入磁盘后，数据库服务器宕机了，那我们更新的数据怎么办？此时数据是在内存中，数据岂不是丢失了？不，这次数据就不会丢失了，因为 redo log buffer 中的数据已经被写入到磁盘了，已经被持久化了，就算数据库宕机了，在下次重启的时候 MySQL 也会将 redo 日志文件内容恢复到 Buffer Pool 中（这边我的理解是和  Redis  的持久化机制是差不多的，在  Redis  启动的时候会检查 rdb 或者是 aof 或者是两者都检查，根据持久化的文件来将数据恢复到内存中）</p><p>到此为止，从执行器开始调用存储引擎接口做了哪些事情呢？</p><p>1.准备更新一条 SQL 语句</p><p>2.MySQL（innodb）会先去缓冲池（BufferPool）中去查找这条数据，没找到就会去磁盘中查找，如果查找到就会将这条数据加载</p><p>到缓冲池（BufferPool）中 3.在加载到 Buffer Pool 的同时，会将这条数据的原始记录保存到 undo 日志文件中</p><p>4.innodb 会在 Buffer Pool 中执行更新操作</p><p>5.更新后的数据会记录在 redo log buffer 中</p><h1 id="–到此是前面已经总结过的—"><a href="#–到此是前面已经总结过的—" class="headerlink" title="-–到此是前面已经总结过的—"></a>-–到此是前面已经总结过的—</h1><p>6.MySQL 提交事务的时候，会将 redo log buffer 中的数据写入到 redo 日志文件中 刷磁盘可以通过 innodb_flush_log_at_trx_commit 参数来设置</p><p>值为 0 表示不刷入磁盘</p><p>值为 1 表示立即刷入磁盘</p><p>值为 2 表示先刷到 os cache</p><p>7.myslq 重启的时候会将 redo 日志恢复到缓冲池中</p><p>截止到目前位置，MySQL  的执行器调用存储引擎的接口去执行【执行计划】提供的 SQL 的时候 InnoDB 做了哪些事情也就基本差不多了，但是这还没完。下面还需要介绍下 MySQL 级别的日志文件 <code>bin log</code></p><h2 id="bin-log-日志文件：记录整个操作过程"><a href="#bin-log-日志文件：记录整个操作过程" class="headerlink" title="bin log 日志文件：记录整个操作过程"></a>bin log 日志文件：记录整个操作过程</h2><p>上面介绍到的<code>redo log</code>是  InnoDB  存储引擎特有的日志文件，而<code>bin log</code>属于是  MySQL  级别的日志。<code>redo log</code>记录的东西是偏向于物理性质的，如：“对什么数据，做了什么修改”。<code>bin log</code>是偏向于逻辑性质的，类似于：“对 students 表中的 id 为 1 的记录做了更新操作” 两者的主要特点总结如下:</p><table><thead><tr><th>性质</th><th>redo Log</th><th>bin Log</th></tr></thead><tbody><tr><td>文件大小</td><td>redo log 的大小是固定的（配置中也可以设置，一般默认的就足够了）</td><td>bin log 可通过配置参数<code>max_bin log_size</code>设置每个<code>bin log</code>文件的大小（但是一般不建议修改）。</td></tr><tr><td>实现方式</td><td><code>redo log</code>是<code>InnoDB</code>引擎层实现的（也就是说是 Innodb  存储引起过独有的）</td><td><code>bin log</code>是  MySQL  层实现的，所有引擎都可以使用 <code>bin log</code>日志</td></tr><tr><td>记录方式</td><td>redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。</td><td>bin log 通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上</td></tr><tr><td>使用场景</td><td><code>redo log</code>适用于崩溃恢复(crash-safe)（这一点其实非常类似与 Redis 的持久化特征）</td><td><code>bin log</code> 适用于主从复制和数据恢复</td></tr></tbody></table><p>bin log文件是如何刷入磁盘的?</p><p>bin log 的刷盘是有相关的策略的，策略可以通过<code>sync_bin log</code>来修改，默认为 0，表示先写入 os cache，也就是说在提交事务的时候，数据不会直接到磁盘中，这样如果宕机<code>bin log</code>数据仍然会丢失。所以建议将<code>sync_bin log</code>设置为 1 表示<strong>直接将数据写入到磁盘</strong>文件中。</p><p>刷入 bin log 有以下几种模式</p><p><strong>1、 STATMENT</strong></p><p>基于 SQL 语句的复制(statement-based replication, SBR)，每一条会修改数据的 SQL 语句会记录到 bin log 中</p><p>【优点】：不需要记录每一行的变化，减少了 bin log 日志量，节约了 IO , 从而提高了性能</p><p>【缺点】：在某些情况下会导致主从数据不一致，比如执行sysdate()、slepp()等</p><p><strong>2、ROW</strong></p><p>基于行的复制(row-based replication, RBR)，不记录每条SQL语句的上下文信息，仅需记录哪条数据被修改了</p><p>【优点】：不会出现某些特定情况下的存储过程、或 function、或 trigger 的调用和触发无法被正确复制的问题</p><p>【缺点】：会产生大量的日志，尤其是 alter table 的时候会让日志暴涨</p><p><strong>3、MIXED</strong></p><p>基于 STATMENT 和 ROW 两种模式的混合复制( mixed-based replication, MBR )，一般的复制使用 STATEMENT 模式保存 bin log ，对于 STATEMENT 模式无法复制的操作使用 ROW 模式保存 bin log</p><p>那既然<code>bin log</code>也是日志文件，那它是在什么记录数据的呢？</p><p>其实 MySQL 在提交事务的时候，不仅仅会将 redo log buffer  中的数据写入到<code>redo log</code> 文件中，同时也会将本次修改的数据记录到 bin log文件中，同时会将本次修改的<code>bin log</code>文件名和修改的内容在<code>bin log</code>中的位置记录到<code>redo log</code>中，最后还会在<code>redo log</code>最后写入 commit 标记，这样就表示本次事务被成功的提交了。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/23b09f702fefa6bdcc260790ae6eddb3.png" alt=""></p><p>如果在数据被写入到bin log文件的时候，刚写完，数据库宕机了，数据会丢失吗？</p><p>首先可以确定的是，只要<code>redo log</code>最后没有 commit 标记，说明本次的事务一定是失败的。但是数据是没有丢失了，因为已经被记录到<code>redo log</code>的磁盘文件中了。在 MySQL 重启的时候，就会将 <code>redo log</code> 中的数据恢复（加载）到<code>Buffer Pool</code>中。</p><p>好了，到目前为止，一个更新操作我们基本介绍得差不多，但是你有没有感觉少了哪件事情还没有做？是不是你也发现这个时候被更新记录仅仅是在内存中执行的，哪怕是宕机又恢复了也仅仅是将更新后的记录加载到<code>Buffer Pool</code>中，这个时候 MySQL 数据库中的这条记录依旧是旧值，也就是说内存中的数据在我们看来依旧是脏数据，那这个时候怎么办呢？</p><p>其实 MySQL 会有一个后台线程，它会在某个时机将我们<code>Buffer Pool</code>中的脏数据刷到 MySQL 数据库中，这样就将内存和数据库的数据保持统一了。</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/b66cb96b9b70fe21e8e41cf37d0918d1.png" alt=""></p><h2 id="本文总结"><a href="#本文总结" class="headerlink" title="本文总结"></a>本文总结</h2><p>到此，关于Buffer Pool、Redo Log Buffer 和undo log、redo log、bin log 概念以及关系就基本差不多了。</p><p>我们再回顾下 </p><ol><li><p>Buffer Pool 是 MySQL 的一个非常重要的组件，因为针对数据库的增删改操作都是在 Buffer Pool 中完成的</p></li><li><p>Undo log 记录的是数据操作前的样子</p></li><li><p>redo log 记录的是数据被操作后的样子（redo log 是 Innodb 存储引擎特有）</p></li><li><p>bin log 记录的是整个操作记录（这个对于主从复制具有非常重要的意义）</p></li></ol><p>从准备更新一条数据到事务的提交的流程描述</p><ol><li><p>首先执行器根据 MySQL 的执行计划来查询数据，先是从缓存池中查询数据，如果没有就会去数据库中查询，如果查询到了就将其放到缓存池中</p></li><li><p>在数据被缓存到缓存池的同时，会写入 undo log 日志文件</p></li><li><p>更新的动作是在 BufferPool 中完成的，同时会将更新后的数据添加到 redo log buffer 中</p></li><li><p>完成以后就可以提交事务，在提交的同时会做以下三件事</p></li><li><p>（第一件事）将redo log buffer中的数据刷入到 redo log 文件中</p></li><li><p>（第二件事）将本次操作记录写入到 bin log文件中</p></li><li><p>（第三件事）将 bin log 文件名字和更新内容在 bin log 中的位置记录到redo log中，同时在 redo log 最后添加 commit 标记</p></li></ol><p>至此表示整个更新事务已经完成</p><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>到此为止，系统是如何和 MySQL 数据库打交道，提交一条更新的 SQL 语句到 MySQL，MySQL 执行了哪些流程，做了哪些事情从宏观上都已经讲解完成了。</p><p>本文转自 <a href="https://mp.weixin.qq.com/s/OnGaqyUpB58pC2rqqzIzgw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/OnGaqyUpB58pC2rqqzIzgw</a>，如有侵权，请联系删除。</p>]]></content>
      
      
      
        <tags>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HashMap 源码分析</title>
      <link href="/posts/70ca1f96/"/>
      <url>/posts/70ca1f96/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="HashMap-源码分析"><a href="#HashMap-源码分析" class="headerlink" title="HashMap 源码分析"></a>HashMap 源码分析</h1><blockquote><p>转载自 github 仓库：<a href="https://github.com/ideal-20/Java-Ideal-Interview" target="_blank" rel="noopener">Java-Ideal-Interview</a></p><p>原文地址：<a href="https://github.com/ideal-20/Java-Ideal-Interview/blob/main/docs/java/javase-basis/collection/003-HashMap源码分析（含散列表和红黑树介绍）.md" target="_blank" rel="noopener">https://github.com/ideal-20/Java-Ideal-Interview/blob/main/docs/java/javase-basis/collection/003-HashMap源码分析（含散列表和红黑树介绍）.md</a></p><p>著作权归原作者所有</p><p>如果这篇文件对大家有帮助，请给原作者点个 Star⭐</p></blockquote><h2 id="1-前置知识"><a href="#1-前置知识" class="headerlink" title="1. 前置知识"></a>1. 前置知识</h2><h3 id="1-1-什么是-Map"><a href="#1-1-什么是-Map" class="headerlink" title="1.1 什么是 Map"></a>1.1 什么是 Map</h3><blockquote><p>在实际需求中，我们常常会遇到这样的问题，在诸多的数据中，通过其编号来寻找某一些信息，从而进行查看或者修改，例如通过学号查询学生信息。今天我们所介绍的Map集合就可以很好的帮助我们实现这种需求</p></blockquote><h4 id="1-1-1-概述"><a href="#1-1-1-概述" class="headerlink" title="1.1.1 概述"></a>1.1.1 概述</h4><p>Map是一种存储元素对的集合（元素对分别称作 键 和 值 也称键值对）它将键映射到值的对象。一个映射不能包含重复的键，并且每个键最 多只能映射到一个值。</p><blockquote><p>怎么理解呢？ </p><p>键 (key)：就是你存的值的编号    值 (value)：就是你要存放的数据</p><p>你可以近似的将键理解为下标，值依据键而存储，每个键都有其对应值。这两者是1、1对应的</p><p>但在之前下标是整数，但是Map中键可以使任意类型的对象。</p></blockquote><h4 id="1-1-2-Map集合和Collection集合的区别"><a href="#1-1-2-Map集合和Collection集合的区别" class="headerlink" title="1.1.2 Map集合和Collection集合的区别"></a>1.1.2 Map集合和Collection集合的区别</h4><ul><li>Map集合存储元素是成对出现的，Map集合的键是唯一的，值是可重复的</li><li>Collection集合存储元素是单独出现的，Collection的子类Set是唯一的，List是可重复的。</li><li>Map集合的数据结构值针对键有效，跟值无关，Collection集合的数据结构是针对元素有效</li></ul><h3 id="1-2-什么是散列表"><a href="#1-2-什么是散列表" class="headerlink" title="1.2 什么是散列表"></a>1.2 什么是散列表</h3><p>散列表也叫hash表 ，是根据关键码值而进行直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射也叫散列函数，存放记录的数组叫散列表。</p><blockquote><p>一个通俗的例子是，为了查找电话簿中某人的号码，可以创建一个按照人名首字母顺序排列的表（即建立人名到首字母的一个函数关系），在首字母为W的表中查找“王”姓的电话号码，显然比直接查找就要快得多。这里使用人名作为关键字，“取首字母”是这个例子中散列函数的函数法则，存放首字母的表对应散列表。关键字和函数法则理论上可以任意确定。—— 维基百科</p></blockquote><h4 id="1-2-1-分析一下为什么要用散列表"><a href="#1-2-1-分析一下为什么要用散列表" class="headerlink" title="1.2.1 分析一下为什么要用散列表"></a>1.2.1 分析一下为什么要用散列表</h4><p>哈希表其实就是数组的一种扩展，因为其本质上用的就是数组可以<strong>按照下标随机访问数据</strong>的特点，我们来一步一步看一下</p><p>首先创建一个数组，我们将数组的每一个存储空间看做一个一个箱子或者一个一个桶，存储一些 key-value 的数据如，【张三，20】【李四，30】【王五，40】【赵六，50】【孙七，60】，依次放置于数组中。</p><p>如果按照普通顺序表的查询方式，就需要从开始依次比对查询，但是数据量越多，顺序表查找耗费的时间就越长。在大量数据的情况下，很显然不上算。</p><p>还有很多种数据结构，它们并不关心元素的顺序，能够快速的查找元素数据，其中一种就是：散列表</p><p>下面看看散列表如何做到这么高效处理的</p><h4 id="1-2-2-散列表工作原理"><a href="#1-2-2-散列表工作原理" class="headerlink" title="1.2.2 散列表工作原理"></a>1.2.2 散列表工作原理</h4><p>这次依旧使用 5 个箱子（桶）空间的数组来存储数据，我们开始存第一个数据【张三，20】，散列表会使用哈希函数（Hash算法）计算出 “张三” 的键，也就是字符串 “张三” 的哈希值，例如返回一个  5372 ，将其做取余处理，除数为数组的长度，即：5372 mod 5 = 2，因此将其放在下标（index）为 2 的位置，例如 第二个数据的哈希值为 6386，继续操作 6386 mod 5 = 1，即将其放在下标（index）为 1 的位置，以此类推…..</p><p>但是有一种情况就会出现了，例如我们存储第三个数据【王五，40】的时候，经过哈希函数计算，得出的结果为 5277，5277 mod 5 = 2 ，但是 2 这个位置已经有【张三，20】这个数据存在了，这种存储位置重复了的情况便叫作冲突</p><h4 id="1-2-3-如何解决-Hash-冲突"><a href="#1-2-3-如何解决-Hash-冲突" class="headerlink" title="1.2.3 如何解决 Hash 冲突"></a>1.2.3 如何解决 Hash 冲突</h4><h5 id="1-2-3-1-JDK-1-7"><a href="#1-2-3-1-JDK-1-7" class="headerlink" title="1.2.3.1 JDK 1.7"></a>1.2.3.1 JDK 1.7</h5><p>在 JDK 1.8 之前，HashMap 的底层是数组和链表。因此当出现哈希冲突后，使用<strong>拉链法</strong>解决冲突。</p><p>拉链法，就是将数组的每一个格子（箱子），都看作一个链表，例如下标为 1 的格子，就是一个链表，已经存储了 【张三，20】，若仍有数据哈希值 mod 后等于 1 ，则直接在 1 中的这个链表中追加上这些数据就可以了。</p><div align="center">    <img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20210223162010.png" style="zoom:80%"></div><h5 id="1-2-3-1-JDK-1-8"><a href="#1-2-3-1-JDK-1-8" class="headerlink" title="1.2.3.1 JDK 1.8"></a>1.2.3.1 JDK 1.8</h5><p>JDK 8 做了一些较大的调整，当数组中每个格子里的链表，长度大于阈值（默认为8）时，将链表转化为红黑树，就可以大大的减少搜索时间。</p><p>而且，如果散列表快满的情况下下，还会有机制进行再散列，下面会在源码中深入分析。</p><div align="center">    <img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20210223162050.png" style="zoom:80%"></div><h3 id="1-3-什么是红黑树"><a href="#1-3-什么是红黑树" class="headerlink" title="1.3 什么是红黑树"></a>1.3 什么是红黑树</h3><p>红黑树是一种复杂的树形结构，这里不做过于详细的解释，讲一下其基本的结构，有一个基本的概念。对于理解，还可以参考掘金上的一篇文章（<a href="https://juejin.im/post/5a27c6946fb9a04509096248#comment" target="_blank" rel="noopener">掘金-漫画：什么是红黑树？@程序员小灰</a>）非常不错！</p><p>红黑树就是为了防止二叉树一些极端的情况，例如变成一条线状，或者左右不均衡，从二叉查找树，2-3树 等演变出来的一种树形结构。最主要的目的就是为了保持平衡。保证树的左右分支叶子等基本平衡。</p><p>具体的数据结果演变是比较复杂的，这一篇还是主要讲解 HashMap ，有需要以后会专篇讲解一些常见的数据结构的 Java 版本</p><h2 id="2-源码分析"><a href="#2-源码分析" class="headerlink" title="2. 源码分析"></a>2. 源码分析</h2><h3 id="2-1-类成员"><a href="#2-1-类成员" class="headerlink" title="2.1 类成员"></a>2.1 类成员</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 序列化自动生成的一个码，用来在正反序列化中验证版本一致性。</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">362498820763181265L</span>;   </span><br><span class="line"></span><br><span class="line"><span class="comment">// 默认的初始容量 1 * 2^4 = 16</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_INITIAL_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 最大容量 1 * 2^30</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAXIMUM_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">30</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 默认的加载因子 0.75</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">float</span> DEFAULT_LOAD_FACTOR = <span class="number">0.75f</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 桶的树化阈值，当桶(bucket)上的结点数大于这个值时会转成红黑树，</span></span><br><span class="line"><span class="comment">// 也就是上面提到的长度大于阈值（默认为8）时，将链表转化为红黑树</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TREEIFY_THRESHOLD = <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 桶的链表还原阈值，当桶(bucket)上的结点数小于这个值时树转链表</span></span><br><span class="line"><span class="comment">// 一个道理</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> UNTREEIFY_THRESHOLD = <span class="number">6</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 最小树形化容量阈值，当哈希表中的容量 &gt; 该值时，才允许树形化链表 </span></span><br><span class="line"><span class="comment">// 否则，若桶内元素太多时，则直接扩容，而不是树形化</span></span><br><span class="line"><span class="comment">// 为了避免进行扩容和树形化选择的冲突，这个值不能小于 4 * TREEIFY_THRESHOLD</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MIN_TREEIFY_CAPACITY = <span class="number">64</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 存储元素的数组，总是2的幂次倍</span></span><br><span class="line"><span class="keyword">transient</span> Node&lt;k,v&gt;[] table; </span><br><span class="line"></span><br><span class="line"><span class="comment">// 存放具体元素的集</span></span><br><span class="line"><span class="keyword">transient</span> Set&lt;map.entry&lt;k,v&gt;&gt; entrySet;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 存放元素的个数（不是数组的长度）</span></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> size;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 扩容和修改的计数变量</span></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> modCount;   </span><br><span class="line"></span><br><span class="line"><span class="comment">// 临界值 当实际大小(容量*填充因子)超过临界值时，会进行扩容</span></span><br><span class="line"><span class="keyword">int</span> threshold;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 加载因子</span></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">float</span> loadFactor;</span><br></pre></td></tr></table></figure><p>其中有几个需要强调的内容</p><p><strong>threshold 临界值</strong></p><ul><li>数组扩容的一个临界值，即当数组实际大小（容量 * 填充因子，即：threshold = capacity * loadFactor）超过临界值时，会进行扩容。</li></ul><p><strong>loadFactor加载因子</strong></p><ul><li>加载因子就是表示哈希表中元素填满的程度，当表中元素过多，超过加载因子的值时，哈希表会自动扩容，一般是一倍，这种行为可以称作rehashing（再哈希）。</li><li>加载因子的值设置的越大，添加的元素就会越多，确实空间利用率的到了很大的提升，但是毫无疑问，就面临着哈希冲突的可能性增大，反之，空间利用率造成了浪费，但哈希冲突也减少了，所以我们希望在空间利用率与哈希冲突之间找到一种我们所能接受的平衡，经过一些试验，定在了0.75f。</li></ul><h3 id="2-2-两个节点"><a href="#2-2-两个节点" class="headerlink" title="2.2 两个节点"></a>2.2 两个节点</h3><p>因为一定条件下会转换成红黑树这种数据结果，所以除了普通的 Node 节点，还有 树节点（TreeNode 节点）</p><h4 id="2-2-1-Node-节点"><a href="#2-2-1-Node-节点" class="headerlink" title="2.2.1 Node 节点"></a>2.2.1 Node 节点</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">// 哈希码，用来查找位置以及比对元素是否相同</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> hash;</span><br><span class="line">    <span class="comment">// 键</span></span><br><span class="line">    <span class="keyword">final</span> K key;</span><br><span class="line">    <span class="comment">// 值</span></span><br><span class="line">    V value;</span><br><span class="line">    <span class="comment">// 指向下一个结点</span></span><br><span class="line">    Node&lt;K,V&gt; next;</span><br><span class="line"></span><br><span class="line">    Node(<span class="keyword">int</span> hash, K key, V value, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">        <span class="keyword">this</span>.hash = hash;</span><br><span class="line">        <span class="keyword">this</span>.key = key;</span><br><span class="line">        <span class="keyword">this</span>.value = value;</span><br><span class="line">        <span class="keyword">this</span>.next = next;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> K <span class="title">getKey</span><span class="params">()</span>        </span>&#123; <span class="keyword">return</span> key; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">getValue</span><span class="params">()</span>      </span>&#123; <span class="keyword">return</span> value; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> key + <span class="string">"="</span> + value; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 重写了 hashCode， ^ 是位异或运算符</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> Objects.hashCode(key) ^ Objects.hashCode(value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">setValue</span><span class="params">(V newValue)</span> </span>&#123;</span><br><span class="line">        V oldValue = value;</span><br><span class="line">        value = newValue;</span><br><span class="line">        <span class="keyword">return</span> oldValue;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 重写 equals() 方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (o == <span class="keyword">this</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">if</span> (o <span class="keyword">instanceof</span> Map.Entry) &#123;</span><br><span class="line">            Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o;</span><br><span class="line">            <span class="keyword">if</span> (Objects.equals(key, e.getKey()) &amp;&amp;</span><br><span class="line">                Objects.equals(value, e.getValue()))</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-2-2-TreeNode-节点"><a href="#2-2-2-TreeNode-节点" class="headerlink" title="2.2.2 TreeNode 节点"></a>2.2.2 TreeNode 节点</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">LinkedHashMap</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">// 父节点</span></span><br><span class="line">    TreeNode&lt;K,V&gt; parent;</span><br><span class="line">    <span class="comment">// 左节点</span></span><br><span class="line">    TreeNode&lt;K,V&gt; left;</span><br><span class="line">    <span class="comment">// 右节点</span></span><br><span class="line">    TreeNode&lt;K,V&gt; right;</span><br><span class="line">    TreeNode&lt;K,V&gt; prev;</span><br><span class="line">    <span class="comment">// 判断颜色，默认红色</span></span><br><span class="line">    <span class="keyword">boolean</span> red;</span><br><span class="line">    TreeNode(<span class="keyword">int</span> hash, K key, V val, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">        <span class="keyword">super</span>(hash, key, val, next);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 返回根节点</span></span><br><span class="line">    <span class="function"><span class="keyword">final</span> TreeNode&lt;K,V&gt; <span class="title">root</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (TreeNode&lt;K,V&gt; r = <span class="keyword">this</span>, p;;) &#123;</span><br><span class="line">            <span class="keyword">if</span> ((p = r.parent) == <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> r;</span><br><span class="line">            r = p;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><h3 id="2-3-构造方法"><a href="#2-3-构造方法" class="headerlink" title="2.3 构造方法"></a>2.3 构造方法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指定了具体容量大小和加载因子的构造函数</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (initialCapacity &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal initial capacity: "</span> +</span><br><span class="line">                                           initialCapacity);</span><br><span class="line">    <span class="keyword">if</span> (initialCapacity &gt; MAXIMUM_CAPACITY)</span><br><span class="line">        initialCapacity = MAXIMUM_CAPACITY;</span><br><span class="line">    <span class="keyword">if</span> (loadFactor &lt;= <span class="number">0</span> || Float.isNaN(loadFactor))</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal load factor: "</span> +</span><br><span class="line">                                           loadFactor);</span><br><span class="line">    <span class="keyword">this</span>.loadFactor = loadFactor;</span><br><span class="line">    <span class="keyword">this</span>.threshold = tableSizeFor(initialCapacity);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定了具体容量大小的构造函数</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>(initialCapacity, DEFAULT_LOAD_FACTOR);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 默认无参构造函数</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.loadFactor = DEFAULT_LOAD_FACTOR; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定了 map 的构造函数</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(Map&lt;? extends K, ? extends V&gt; m)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.loadFactor = DEFAULT_LOAD_FACTOR;</span><br><span class="line">    putMapEntries(m, <span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>tableSizeFor</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回一个大于输入参数，且最接近的，2的整数次幂的数</span></span><br><span class="line"><span class="comment"> * 只是一个初始化内容，创建哈希表时，会再重新赋值</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">tableSizeFor</span><span class="params">(<span class="keyword">int</span> cap)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n = cap - <span class="number">1</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">2</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">4</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">8</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">16</span>;</span><br><span class="line">    <span class="keyword">return</span> (n &lt; <span class="number">0</span>) ? <span class="number">1</span> : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>putMapEntries</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">putMapEntries</span><span class="params">(Map&lt;? extends K, ? extends V&gt; m, <span class="keyword">boolean</span> evict)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 拿到给定 Map 的长度</span></span><br><span class="line">    <span class="keyword">int</span> s = m.size();</span><br><span class="line">    <span class="keyword">if</span> (s &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 判断当前实际存储数据的这个 table 是否已经初始化</span></span><br><span class="line">        <span class="keyword">if</span> (table == <span class="keyword">null</span>) &#123; <span class="comment">// pre-size</span></span><br><span class="line">            <span class="comment">// 没初始化，就将 s 处理后设为m的实际元素个数</span></span><br><span class="line">            <span class="keyword">float</span> ft = ((<span class="keyword">float</span>)s / loadFactor) + <span class="number">1.0F</span>;</span><br><span class="line">            <span class="comment">// 防止小于最小容量（阈值）</span></span><br><span class="line">            <span class="keyword">int</span> t = ((ft &lt; (<span class="keyword">float</span>)MAXIMUM_CAPACITY) ?</span><br><span class="line">                    (<span class="keyword">int</span>)ft : MAXIMUM_CAPACITY);</span><br><span class="line">            <span class="comment">// 若大于临界值，则初始化阈值</span></span><br><span class="line">            <span class="keyword">if</span> (t &gt; threshold)</span><br><span class="line">                threshold = tableSizeFor(t);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// table 已初始化，并且给定 Map m 元素个数大于阈值，进行扩容处理</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (s &gt; threshold)</span><br><span class="line">            resize();</span><br><span class="line">        <span class="comment">// 将给定集合 m 中的所有元素添加至HashMap中</span></span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123;</span><br><span class="line">            K key = e.getKey();</span><br><span class="line">            V value = e.getValue();</span><br><span class="line">            <span class="comment">// putVal 方法会在介绍添加相关方法时介绍</span></span><br><span class="line">            putVal(hash(key), key, value, <span class="keyword">false</span>, evict);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-4-添加方法"><a href="#2-4-添加方法" class="headerlink" title="2.4 添加方法"></a>2.4 添加方法</h3><h4 id="2-4-1-put"><a href="#2-4-1-put" class="headerlink" title="2.4.1 put()"></a>2.4.1 put()</h4><p>对于 HashMap ，其提供给外界的公共添加方法只有  put(K key, V value) 一个，其他 put 方法都是供 put(K key, V value) 内部调用的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> putVal(hash(key), key, value, <span class="keyword">false</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关于 putVal 的每个参数和细节下面接着说，看一下第一个参数 hash(key) 首先提一下，在 HashMap 中是如何计算 hash 值的，跳转到 3.1 可看，也可以看完最后去看也可以。</p><p>[3.1 hash() 中的扰动函数如何解决Hash冲突 ※](###3.1 hash() 中的扰动函数如何解决Hash冲突 ※)</p><h4 id="2-4-2-putVal"><a href="#2-4-2-putVal" class="headerlink" title="2.4.2 putVal()"></a>2.4.2 putVal()</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> V <span class="title">putVal</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">boolean</span> onlyIfAbsent,</span></span></span><br><span class="line"><span class="function"><span class="params">               <span class="keyword">boolean</span> evict)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; <span class="keyword">int</span> n, i;</span><br><span class="line">    <span class="comment">// table未初始化（为null）或者长度为0，调用 resize 进行扩容</span></span><br><span class="line">    <span class="keyword">if</span> ((tab = table) == <span class="keyword">null</span> || (n = tab.length) == <span class="number">0</span>)</span><br><span class="line">        n = (tab = resize()).length;</span><br><span class="line">    <span class="comment">// 若桶为空，即无发生碰撞</span></span><br><span class="line">    <span class="comment">// (n - 1) &amp; hash 用来确定元素存放在哪个位置，即哪个桶中</span></span><br><span class="line">    <span class="keyword">if</span> ((p = tab[i = (n - <span class="number">1</span>) &amp; hash]) == <span class="keyword">null</span>)</span><br><span class="line">        <span class="comment">// 新生成结点放入桶中(数组中)</span></span><br><span class="line">        tab[i] = newNode(hash, key, value, <span class="keyword">null</span>);</span><br><span class="line">    <span class="comment">// 若桶中已经存在元素</span></span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        Node&lt;K,V&gt; e; K k;</span><br><span class="line">        <span class="comment">// 若节点 key 存在，就和要插入的key比较</span></span><br><span class="line">        <span class="keyword">if</span> (p.hash == hash &amp;&amp;</span><br><span class="line">            ((k = p.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">            <span class="comment">// 如果key相同就直接覆盖 value</span></span><br><span class="line">            e = p;</span><br><span class="line">        <span class="comment">// hash值不相等，即key不相等，转为红黑树结点</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (p <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">            <span class="comment">// 插入到树中</span></span><br><span class="line">            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(<span class="keyword">this</span>, tab, hash, key, value);</span><br><span class="line">        <span class="comment">// 若是为链表结点</span></span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 遍历找到尾节点插入</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> binCount = <span class="number">0</span>; ; ++binCount) &#123;</span><br><span class="line">                <span class="comment">// 到达链表的尾部</span></span><br><span class="line">                <span class="keyword">if</span> ((e = p.next) == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="comment">// 在尾部插入新结点</span></span><br><span class="line">                    p.next = newNode(hash, key, value, <span class="keyword">null</span>);</span><br><span class="line">                    <span class="comment">// 结点数量达到阈值，转化为红黑树</span></span><br><span class="line">                    <span class="keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD - <span class="number">1</span>) <span class="comment">// -1 for 1st</span></span><br><span class="line">                        treeifyBin(tab, hash);</span><br><span class="line">                    <span class="comment">// 跳出循环</span></span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 遍历的过程中，遇到相同 key 则覆盖 value</span></span><br><span class="line">                <span class="keyword">if</span> (e.hash == hash &amp;&amp;</span><br><span class="line">                    ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">                    <span class="comment">// 相等，跳出循环</span></span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                <span class="comment">// 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表</span></span><br><span class="line">                p = e;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 在桶中找到key值、hash值与插入元素相等的结点</span></span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123; </span><br><span class="line">            <span class="comment">// 记录e的value</span></span><br><span class="line">            V oldValue = e.value;</span><br><span class="line">            <span class="comment">// onlyIfAbsent 为 false 或者旧值为 null</span></span><br><span class="line">            <span class="keyword">if</span> (!onlyIfAbsent || oldValue == <span class="keyword">null</span>)</span><br><span class="line">                <span class="comment">// 用新值替换旧值</span></span><br><span class="line">                e.value = value;</span><br><span class="line">            <span class="comment">// 访问后回调</span></span><br><span class="line">            afterNodeAccess(e);</span><br><span class="line">            <span class="comment">// 返回旧值</span></span><br><span class="line">            <span class="keyword">return</span> oldValue;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 结构性修改</span></span><br><span class="line">    ++modCount;</span><br><span class="line">    <span class="comment">// 超过最大容量，扩容</span></span><br><span class="line">    <span class="keyword">if</span> (++size &gt; threshold)</span><br><span class="line">        resize();</span><br><span class="line">    <span class="comment">// 插入后回调</span></span><br><span class="line">    afterNodeInsertion(evict);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>总结一下大致流程：</strong></p><ul><li>先定位到具体的数组位置，例如叫做 A</li><li>若  A 处没有元素<ul><li>就直接插入</li></ul></li><li>若  A 处 有元素就和待插入的 key 比较<ul><li>若 key 相同就直接覆盖</li><li>若  key 不相同，就判断 p 是否是一个树节点<ul><li>如果是就调用putTreeVal 方法将元素添加进入</li><li>如果不是就遍历链表插入（尾插法）</li></ul></li></ul></li></ul><h3 id="2-5-获取方法"><a href="#2-5-获取方法" class="headerlink" title="2.5 获取方法"></a>2.5 获取方法</h3><h4 id="2-5-1-get"><a href="#2-5-1-get" class="headerlink" title="2.5.1 get()"></a>2.5.1 get()</h4><p>同样 get 方法中也用到了 hash 方法计算 key 的哈希值，同样跳转到 3.1 可看，也可以看完最后去看也可以。</p><p>[3.1 hash() 中的扰动函数如何解决Hash冲突 ※](###3.1 hash() 中的扰动函数如何解决Hash冲突 ※)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt; e;</span><br><span class="line">    <span class="keyword">return</span> (e = getNode(hash(key), key)) == <span class="keyword">null</span> ? <span class="keyword">null</span> : e.value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-5-2-getNode"><a href="#2-5-2-getNode" class="headerlink" title="2.5.2 getNode"></a>2.5.2 getNode</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> Node&lt;K,V&gt; <span class="title">getNode</span><span class="params">(<span class="keyword">int</span> hash, Object key)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; <span class="keyword">int</span> n; K k;</span><br><span class="line">    <span class="comment">// 保证计算出来的哈希值，确定是在哈希表上的</span></span><br><span class="line">    <span class="keyword">if</span> ((tab = table) != <span class="keyword">null</span> &amp;&amp; (n = tab.length) &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">        (first = tab[(n - <span class="number">1</span>) &amp; hash]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 要是直接在桶的首个位置上，直接就可以返回（这个桶中只有一个元素，或者在首个）</span></span><br><span class="line">        <span class="keyword">if</span> (first.hash == hash &amp;&amp; <span class="comment">// always check first node</span></span><br><span class="line">            ((k = first.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">            <span class="keyword">return</span> first;</span><br><span class="line">        <span class="comment">// 桶中不止一个节点</span></span><br><span class="line">        <span class="keyword">if</span> ((e = first.next) != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 在树中 get</span></span><br><span class="line">            <span class="keyword">if</span> (first <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                <span class="keyword">return</span> ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);</span><br><span class="line">            <span class="comment">// 在链表中get</span></span><br><span class="line">            <span class="keyword">do</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (e.hash == hash &amp;&amp;</span><br><span class="line">                    ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">                    <span class="keyword">return</span> e;</span><br><span class="line">            &#125; <span class="keyword">while</span> ((e = e.next) != <span class="keyword">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-6-移除方法"><a href="#2-6-移除方法" class="headerlink" title="2.6 移除方法"></a>2.6 移除方法</h3><h4 id="2-6-1-remove"><a href="#2-6-1-remove" class="headerlink" title="2.6.1 remove()"></a>2.6.1 remove()</h4><p>同样 get 方法中也用到了 hash 方法计算 key 的哈希值，同样跳转到 3.1 可看，也可以看完最后去看也可以。</p><p>[3.1 hash() 中的扰动函数如何解决Hash冲突 ※](###3.1 hash() 中的扰动函数如何解决Hash冲突 ※)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">remove</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt; e;</span><br><span class="line">    <span class="keyword">return</span> (e = removeNode(hash(key), key, <span class="keyword">null</span>, <span class="keyword">false</span>, <span class="keyword">true</span>)) == <span class="keyword">null</span> ?</span><br><span class="line">        <span class="keyword">null</span> : e.value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2.6.2 removeNode()</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> Node&lt;K,V&gt; <span class="title">removeNode</span><span class="params">(<span class="keyword">int</span> hash, Object key, Object value,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">boolean</span> matchValue, <span class="keyword">boolean</span> movable)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; <span class="keyword">int</span> n, index;</span><br><span class="line">    <span class="comment">// 桶不为空，映射的哈希值也存在</span></span><br><span class="line">    <span class="keyword">if</span> ((tab = table) != <span class="keyword">null</span> &amp;&amp; (n = tab.length) &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">        (p = tab[index = (n - <span class="number">1</span>) &amp; hash]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">        Node&lt;K,V&gt; node = <span class="keyword">null</span>, e; K k; V v;</span><br><span class="line">        <span class="comment">// 如果在桶的首位就找到对应元素，记录下来</span></span><br><span class="line">        <span class="keyword">if</span> (p.hash == hash &amp;&amp;</span><br><span class="line">            ((k = p.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">            node = p;</span><br><span class="line">        <span class="comment">// 若不在首位，就去红黑树或者链表中查询了</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> ((e = p.next) != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (p <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key);</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">do</span> &#123;</span><br><span class="line">                    <span class="keyword">if</span> (e.hash == hash &amp;&amp;</span><br><span class="line">                        ((k = e.key) == key ||</span><br><span class="line">                         (key != <span class="keyword">null</span> &amp;&amp; key.equals(k)))) &#123;</span><br><span class="line">                        node = e;</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                    p = e;</span><br><span class="line">                &#125; <span class="keyword">while</span> ((e = e.next) != <span class="keyword">null</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 找到了要删除的节点和值，就分三种情况去删除，链表，红黑树，桶的首位</span></span><br><span class="line">        <span class="keyword">if</span> (node != <span class="keyword">null</span> &amp;&amp; (!matchValue || (v = node.value) == value ||</span><br><span class="line">                             (value != <span class="keyword">null</span> &amp;&amp; value.equals(v)))) &#123;</span><br><span class="line">            <span class="keyword">if</span> (node <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                ((TreeNode&lt;K,V&gt;)node).removeTreeNode(<span class="keyword">this</span>, tab, movable);</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (node == p)</span><br><span class="line">                tab[index] = node.next;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                p.next = node.next;</span><br><span class="line">            ++modCount;</span><br><span class="line">            --size;</span><br><span class="line">            afterNodeRemoval(node);</span><br><span class="line">            <span class="keyword">return</span> node;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-7-扩容方法"><a href="#2-7-扩容方法" class="headerlink" title="2.7 扩容方法"></a>2.7 扩容方法</h3><h4 id="2-7-1-resize"><a href="#2-7-1-resize" class="headerlink" title="2.7.1 resize()"></a>2.7.1 resize()</h4><p>resize 在程序中是非常耗时的。要尽量避免用它。</p><ul><li>其过程中会重新分配 hash ，然后遍历hash表中所有的元素</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> Node&lt;K,V&gt;[] resize() &#123;</span><br><span class="line">    Node&lt;K,V&gt;[] oldTab = table;</span><br><span class="line">    <span class="keyword">int</span> oldCap = (oldTab == <span class="keyword">null</span>) ? <span class="number">0</span> : oldTab.length;</span><br><span class="line">    <span class="keyword">int</span> oldThr = threshold;</span><br><span class="line">    <span class="keyword">int</span> newCap, newThr = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (oldCap &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 超过最大值，不再扩容，没办法了</span></span><br><span class="line">        <span class="keyword">if</span> (oldCap &gt;= MAXIMUM_CAPACITY) &#123;</span><br><span class="line">            threshold = Integer.MAX_VALUE;</span><br><span class="line">            <span class="keyword">return</span> oldTab;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 没超过最大值，就扩充为原来的2倍</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> ((newCap = oldCap &lt;&lt; <span class="number">1</span>) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY)</span><br><span class="line">            newThr = oldThr &lt;&lt; <span class="number">1</span>; <span class="comment">// double threshold</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (oldThr &gt; <span class="number">0</span>) <span class="comment">// initial capacity was placed in threshold</span></span><br><span class="line">        <span class="comment">// 初始化时，threshold 暂时保存 initialCapacity 参数的值</span></span><br><span class="line">        newCap = oldThr;</span><br><span class="line">    <span class="keyword">else</span> &#123; </span><br><span class="line">        <span class="comment">// signifies using defaults</span></span><br><span class="line">        newCap = DEFAULT_INITIAL_CAPACITY;</span><br><span class="line">        newThr = (<span class="keyword">int</span>)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 计算新的resize上限</span></span><br><span class="line">    <span class="keyword">if</span> (newThr == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">float</span> ft = (<span class="keyword">float</span>)newCap * loadFactor;</span><br><span class="line">        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (<span class="keyword">float</span>)MAXIMUM_CAPACITY ? (<span class="keyword">int</span>)ft : Integer.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line">    threshold = newThr;</span><br><span class="line">    <span class="meta">@SuppressWarnings</span>(&#123;<span class="string">"rawtypes"</span>,<span class="string">"unchecked"</span>&#125;)</span><br><span class="line">        Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])<span class="keyword">new</span> Node[newCap];</span><br><span class="line">    table = newTab;</span><br><span class="line">    <span class="keyword">if</span> (oldTab != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 将旧的键值对移动到新的哈希桶数组中</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; oldCap; ++j) &#123;</span><br><span class="line">            Node&lt;K,V&gt; e;</span><br><span class="line">            <span class="keyword">if</span> ((e = oldTab[j]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                oldTab[j] = <span class="keyword">null</span>;</span><br><span class="line">                <span class="comment">// / 无链条，也就是没有下一个，只有自己</span></span><br><span class="line">                <span class="keyword">if</span> (e.next == <span class="keyword">null</span>)</span><br><span class="line">                    newTab[e.hash &amp; (newCap - <span class="number">1</span>)] = e;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (e <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                    <span class="comment">// 拆红黑树，先拆成两个子链表，再分别按需转成红黑树</span></span><br><span class="line">                    ((TreeNode&lt;K,V&gt;)e).split(<span class="keyword">this</span>, newTab, j, oldCap);</span><br><span class="line">                <span class="keyword">else</span> &#123; </span><br><span class="line">                    <span class="comment">// 拆链表，拆成两个子链表并保持原有顺序</span></span><br><span class="line">                    Node&lt;K,V&gt; loHead = <span class="keyword">null</span>, loTail = <span class="keyword">null</span>;</span><br><span class="line">                    Node&lt;K,V&gt; hiHead = <span class="keyword">null</span>, hiTail = <span class="keyword">null</span>;</span><br><span class="line">                    Node&lt;K,V&gt; next;</span><br><span class="line">                    <span class="keyword">do</span> &#123;</span><br><span class="line">                        next = e.next;</span><br><span class="line">                        <span class="comment">// 原索引</span></span><br><span class="line">                        <span class="keyword">if</span> ((e.hash &amp; oldCap) == <span class="number">0</span>) &#123;</span><br><span class="line">                            <span class="keyword">if</span> (loTail == <span class="keyword">null</span>)</span><br><span class="line">                                loHead = e;</span><br><span class="line">                            <span class="keyword">else</span></span><br><span class="line">                                loTail.next = e;</span><br><span class="line">                            loTail = e;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="comment">// 原索引 + oldCap</span></span><br><span class="line">                        <span class="keyword">else</span> &#123;</span><br><span class="line">                            <span class="keyword">if</span> (hiTail == <span class="keyword">null</span>)</span><br><span class="line">                                hiHead = e;</span><br><span class="line">                            <span class="keyword">else</span></span><br><span class="line">                                hiTail.next = e;</span><br><span class="line">                            hiTail = e;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; <span class="keyword">while</span> ((e = next) != <span class="keyword">null</span>);</span><br><span class="line">                    <span class="comment">// 原索引放到新的哈希桶中</span></span><br><span class="line">                    <span class="keyword">if</span> (loTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        loTail.next = <span class="keyword">null</span>;</span><br><span class="line">                        newTab[j] = loHead;</span><br><span class="line">                    &#125;</span><br><span class="line">                    <span class="comment">// 原索引 +oldCap 放到新的哈希桶中</span></span><br><span class="line">                    <span class="keyword">if</span> (hiTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        hiTail.next = <span class="keyword">null</span>;</span><br><span class="line">                        newTab[j + oldCap] = hiHead;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> newTab;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-重点分析"><a href="#3-重点分析" class="headerlink" title="3. 重点分析"></a>3. 重点分析</h2><h3 id="3-1-hash-中的扰动函数如何解决Hash冲突-※"><a href="#3-1-hash-中的扰动函数如何解决Hash冲突-※" class="headerlink" title="3.1 hash() 中的扰动函数如何解决Hash冲突 ※"></a>3.1 hash() 中的扰动函数如何解决Hash冲突 ※</h3><p>看HashMap的put方法源码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//HashMap 源码节选-JDK8</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> putVal(hash(key), key, value, <span class="keyword">false</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而我们的值在返回前需要经过HashMap中的hash方法</p><p>接着定位到hash方法的源码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> h;</span><br><span class="line">    <span class="keyword">return</span> (key == <span class="keyword">null</span>) ? <span class="number">0</span> : (h = key.hashCode()) ^ (h &gt;&gt;&gt; <span class="number">16</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>hash方法的返回结果中是一句三目运算符，键 (key) 为null即返回 0,存在则返回后一句的内容</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(h = key.hashCode()) ^ (h &gt;&gt;&gt; <span class="number">16</span>)</span><br></pre></td></tr></table></figure><p>JDK8中 HashMap——hash 方法中的这段代码叫做 “<strong>扰动函数</strong>”</p><p>我们来分析一下：</p><p>hashCode 是 Object 类中的一个方法，在子类中一般都会重写，而根据我们之前自己给出的程序，暂以 Integer 类型为例，我们来看一下 Integer 中 hashCode 方法的源码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Returns a hash code for this &#123;<span class="doctag">@code</span> Integer&#125;.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span>  a hash code value for this object, equal to the</span></span><br><span class="line"><span class="comment"> *          primitive &#123;<span class="doctag">@code</span> int&#125; value represented by this</span></span><br><span class="line"><span class="comment"> *          &#123;<span class="doctag">@code</span> Integer&#125; object.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> Integer.hashCode(value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Returns a hash code for a &#123;<span class="doctag">@code</span> int&#125; value; compatible with</span></span><br><span class="line"><span class="comment"> * &#123;<span class="doctag">@code</span> Integer.hashCode()&#125;.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> value the value to hash</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 1.8</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> a hash code value for a &#123;<span class="doctag">@code</span> int&#125; value.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">(<span class="keyword">int</span> value)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Integer 中 hashCode 方法的返回值就是这个数本身</p><blockquote><p>注：整数的值因为与整数本身一样唯一，所以它是一个足够好的散列</p></blockquote><p>所以，下面的 A、B 两个式子就是等价的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//注：key为 hash(Object key)参数</span></span><br><span class="line"> </span><br><span class="line">A：(h = key.hashCode()) ^ (h &gt;&gt;&gt; <span class="number">16</span>)</span><br><span class="line"></span><br><span class="line">B：key ^ (key &gt;&gt;&gt; <span class="number">16</span>)</span><br></pre></td></tr></table></figure><p>分析到这一步，我们的式子只剩下位运算了，先不急着算什么，我们先理清思路</p><p>HashSet因为底层使用<strong>哈希表（链表结合数组）</strong>实现，存储时key通过一些运算后得出自己在数组中所处的位置。</p><p>我们在hashCoe方法中返回到了一个等同于本身值的散列值，但是考虑到int类型数据的范围：-2147483648~2147483647 ，着很显然，这些散列值不能直接使用，因为内存是没有办法放得下，一个40亿长度的数组的。所以它使用了对数组长度进行<strong>取模运算</strong>，得余后再作为其数组下标，<strong>indexFor( )</strong> ——JDK7中，就这样出现了，在JDK8中 indexFor()就消失了，而全部使用下面的语句代替，原理是一样的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//JDK8中</span></span><br><span class="line">(tab.length - <span class="number">1</span>) &amp; hash；</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//JDK7中</span></span><br><span class="line">bucketIndex = indexFor(hash, table.length);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">indexFor</span><span class="params">(<span class="keyword">int</span> h, <span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> h &amp; (length - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>提一句，为什么取模运算时我们用 &amp; 而不用 % 呢，因为位运算直接对内存数据进行操作，不需要转成十进制，因此处理速度非常快，这样就导致位运算 &amp; 效率要比取模运算 % 高很多。</p></blockquote><p>看到这里我们就知道了，存储时key需要通过<strong>hash方法</strong>和<strong>indexFor( )</strong>运算，来确定自己的对应下标</p><p>(取模运算，应以JDK8为准，但为了称呼方便，还是按照JDK7的叫法来说，下面的例子均为此，特此提前声明)</p><p>但是先直接看与运算(&amp;)，好像又出现了一些问题，我们举个例子：</p><p>HashMap中初始长度为16，length - 1 = 15；其二进制表示为 00000000 00000000 00000000 00001111</p><p>而与运算计算方式为：遇0则0，我们随便举一个key值</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">        <span class="number">1111</span> <span class="number">1111</span> <span class="number">1010</span> <span class="number">0101</span> <span class="number">1111</span> <span class="number">0000</span> <span class="number">0011</span> <span class="number">1100</span></span><br><span class="line">&amp;       <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">1111</span></span><br><span class="line">----------------------------------------------------</span><br><span class="line">        <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">0000</span> <span class="number">1100</span></span><br></pre></td></tr></table></figure><p>我们将这32位从中分开，左边16位称作高位，右边16位称作低位，可以看到经过&amp;运算后 结果就是高位全部归0，剩下了低位的最后四位。但是问题就来了，我们按照当前初始长度为默认的16，HashCode值为下图两个，可以看到，在不经过扰动计算时，只进行与(&amp;)运算后 Index值均为 12 这也就导致了哈希冲突</p><div align="center">    <img src= "/img/loading.gif" data-lazy-src="images/java-javase-basis-collection-004.jpg" style="zoom:80%"></div><blockquote><p> 哈希冲突的简单理解：计划把一个对象插入到散列表(哈希表)中，但是发现这个位置已经被别的对象所占据了</p></blockquote><p>例子中，两个不同的HashCode值却经过运算后，得到了相同的值，也就代表，他们都需要被放在下标为2的位置</p><p>一般来说，如果数据分布比较广泛，而且存储数据的数组长度比较大，那么哈希冲突就会比较少，否则很高。</p><p>但是，如果像上例中只取最后几位的时候，这可不是什么好事，即使我的数据分布很散乱，但是哈希冲突仍然会很严重。</p><p>别忘了，我们的扰动函数还在前面搁着呢，这个时候它就要发挥强大的作用了,还是使用上面两个发生了哈希冲突的数据，这一次我们加入扰动函数再进行与(&amp;)运算</p><div align="center">    <img src= "/img/loading.gif" data-lazy-src="images/java-javase-basis-collection-005.jpg" style="zoom:80%"></div><blockquote><p>补充 ：&gt;&gt;&gt; 按位右移补零操作符，左操作数的值按右操作数指定的为主右移，移动得到的空位以零填充<br>^ 位异或运算，相同则 0，不同则 1</p></blockquote><p>可以看到，本发生了哈希冲突的两组数据，经过扰动函数处理后，数值变得不再一样了，也就避免了冲突</p><p>其实在<strong>扰动函数</strong>中，将<strong>数据右位移16位</strong>，哈希码的<strong>高位和低位混合</strong>了起来，这也正解决了前面所讲 高位归0，计算只依赖低位最后几位的情况, 这使得高位的一些特征也<strong>对低位产生了影响</strong>，使得<strong>低位的随机性加强</strong>，能更好的<strong>避免冲突</strong></p>]]></content>
      
      
      <categories>
          
          <category> 源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 源码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LinkedList 源码分析</title>
      <link href="/posts/3611deb6/"/>
      <url>/posts/3611deb6/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="LinkedList-源码分析"><a href="#LinkedList-源码分析" class="headerlink" title="LinkedList 源码分析"></a>LinkedList 源码分析</h1><blockquote><p>转载自 github 仓库：<a href="https://github.com/ideal-20/Java-Ideal-Interview" target="_blank" rel="noopener">Java-Ideal-Interview</a></p><p>原文地址：<a href="https://github.com/ideal-20/Java-Ideal-Interview/blob/main/docs/java/javase-basis/collection/002-LinkedList源码分析（重点方法基本分析）.md" target="_blank" rel="noopener">https://github.com/ideal-20/Java-Ideal-Interview/blob/main/docs/java/javase-basis/collection/002-LinkedList源码分析（重点方法基本分析）.md</a></p><p>著作权归原作者所有</p><p>如果这篇文件对大家有帮助，请给原作者点个 Star⭐</p></blockquote><h2 id="1-LinkedList-概述"><a href="#1-LinkedList-概述" class="headerlink" title="1. LinkedList 概述"></a>1. LinkedList 概述</h2><h3 id="1-1-List-是什么？"><a href="#1-1-List-是什么？" class="headerlink" title="1.1  List 是什么？"></a>1.1  List 是什么？</h3><p>List 在 Collection中充当着一个什么样的身份呢？——有序的 collection(也称为序列) </p><p>实现这个接口的用户以对列表中每个元素的插入位置进行精确地控制。用户可以根据元素的整数索引（在列表中的位置）访问元素，并搜索列表中的元素。与 set 不同，列表通常允许重复的元素。</p><h3 id="1-2-LinkedList-是什么？"><a href="#1-2-LinkedList-是什么？" class="headerlink" title="1.2  LinkedList 是什么？"></a>1.2  LinkedList 是什么？</h3><p>LinkedList 的本质就是一个<strong>双向链表</strong>，但是它也可以被当做堆栈、队列或双端队列进行操作。</p><p>其特点为：查询慢，增删快，线程不安全，效率高。</p><h2 id="2-源码分析"><a href="#2-源码分析" class="headerlink" title="2. 源码分析"></a>2. 源码分析</h2><h3 id="2-1-类声明"><a href="#2-1-类声明" class="headerlink" title="2.1 类声明"></a>2.1 类声明</h3><p>先来看一下类的声明，有一个继承（抽象类）和四个接口关系</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LinkedList</span>&lt;<span class="title">E</span>&gt;</span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">AbstractSequentialList</span>&lt;<span class="title">E</span>&gt;</span></span><br><span class="line"><span class="class">    <span class="keyword">implements</span> <span class="title">List</span>&lt;<span class="title">E</span>&gt;, <span class="title">Deque</span>&lt;<span class="title">E</span>&gt;, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span></span></span><br><span class="line"><span class="class"></span>&#123; </span><br><span class="line">    <span class="comment">// 源码具体内容... </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p><code>Deque&lt;E&gt;</code> 它实现了Deque接口，使得 LinkedList 类也具有队列的特性</p></li><li><p><code>Cloneable</code> ：实现它就可以进行克隆（<code>clone()</code>）</p></li><li><p><code>java.io.Serializable</code> ：实现它意味着支持序列化，满足了序列化传输的条件</p></li></ul><h3 id="2-2-成员"><a href="#2-2-成员" class="headerlink" title="2.2 成员"></a>2.2 成员</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 集合的长度</span></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> size = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 双向链表头部节点</span></span><br><span class="line"><span class="keyword">transient</span> Node&lt;E&gt; first;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 双向链表尾部节点</span></span><br><span class="line"><span class="keyword">transient</span> Node&lt;E&gt; last;</span><br></pre></td></tr></table></figure><h3 id="2-3-内部私有类-Node-类"><a href="#2-3-内部私有类-Node-类" class="headerlink" title="2.3 内部私有类 Node 类"></a>2.3 内部私有类 Node 类</h3><p>从源码刚开始就提到了 <code>transient Node&lt;E&gt; first;</code> 等内容，这里就涉及到一个内部私有的类，即 Node 类，它本质就是封装了一个节点类，只要知道链表这种基本的数据结构，这里还是很简单的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">E</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">// 节点值</span></span><br><span class="line">    E item;</span><br><span class="line">    <span class="comment">// 后驱别点</span></span><br><span class="line">    Node&lt;E&gt; next;</span><br><span class="line">    <span class="comment">// 前驱结点</span></span><br><span class="line">    Node&lt;E&gt; prev;</span><br><span class="line"></span><br><span class="line">    Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123;</span><br><span class="line">        <span class="keyword">this</span>.item = element;</span><br><span class="line">        <span class="keyword">this</span>.next = next;</span><br><span class="line">        <span class="keyword">this</span>.prev = prev;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-4-构造方法"><a href="#2-4-构造方法" class="headerlink" title="2.4 构造方法"></a>2.4 构造方法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 无参构造</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">LinkedList</span><span class="params">()</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 带参构造，创建一个包含集合 c 的 LinkedList</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">LinkedList</span><span class="params">(Collection&lt;? extends E&gt; c)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>();</span><br><span class="line">    addAll(c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-5-添加方法"><a href="#2-5-添加方法" class="headerlink" title="2.5 添加方法"></a>2.5 添加方法</h3><h4 id="2-5-1-add-E-e"><a href="#2-5-1-add-E-e" class="headerlink" title="2.5.1 add(E e)"></a>2.5.1 add(E e)</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">    linkLast(e);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>直接跳转到 linkLast 方法中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 链接使 e 作为最后一个元素</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">linkLast</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 拿到当前的尾部节点 last</span></span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; l = last;</span><br><span class="line">    <span class="comment">// new 一个节点出来，通过带参构造赋值，达到添加到尾部的效果</span></span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; newNode = <span class="keyword">new</span> Node&lt;&gt;(l, e, <span class="keyword">null</span>);</span><br><span class="line">    <span class="comment">// 此时不管这个链表只有一个还是多个元素它都是尾部节点</span></span><br><span class="line">    last = newNode;</span><br><span class="line">    <span class="comment">// 根据判断做出不同的操作</span></span><br><span class="line">    <span class="keyword">if</span> (l == <span class="keyword">null</span>)</span><br><span class="line">        first = newNode;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        l.next = newNode;</span><br><span class="line">    size++;</span><br><span class="line">    modCount++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不同情况的讨论</p><ul><li>当前链表为空，添加进来的 node 节点自然就是 first，也是 last，也正因为这一点，在滴啊参构造函数赋值的时候，就已经确定了其 prev 和 next 都为 null</li><li>当前链表不为空，那么添加进来的 node 节点就是 last ，node 的 prev 指向以前的最后一个元素（旧的 last），node 的 next，自然也是 null</li></ul><h4 id="2-5-2-add-int-index-E-element"><a href="#2-5-2-add-int-index-E-element" class="headerlink" title="2.5.2 add(int index, E element)"></a>2.5.2 add(int index, E element)</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 在指定 index 位置添加元素</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> index, E element)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 跳转，检查索引是否处于[0-size]之间</span></span><br><span class="line">    checkPositionIndex(index);</span><br><span class="line"><span class="comment">// 指定下标在尾部，直接调用 linkLast 放在尾部</span></span><br><span class="line">    <span class="keyword">if</span> (index == size)</span><br><span class="line">        linkLast(element);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="comment">// 添加在链表中间</span></span><br><span class="line">        linkBefore(element, node(index));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">checkPositionIndex</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!isPositionIndex(index))</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IndexOutOfBoundsException(outOfBoundsMsg(index));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">isPositionIndex</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> index &gt;= <span class="number">0</span> &amp;&amp; index &lt;= size;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><ul><li>调用 <code>linkBefore(element, node(index))</code>方法中，需要调用 node(int index) 通过传入的 index 来定位到要插入的位置，这个是比较耗时间的</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 在一个非空节点前插入一个元素</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">linkBefore</span><span class="params">(E e, Node&lt;E&gt; succ)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; pred = succ.prev;</span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; newNode = <span class="keyword">new</span> Node&lt;&gt;(pred, e, succ);</span><br><span class="line">    succ.prev = newNode;</span><br><span class="line">    <span class="keyword">if</span> (pred == <span class="keyword">null</span>)</span><br><span class="line">        first = newNode;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        pred.next = newNode;</span><br><span class="line">    size++;</span><br><span class="line">    modCount++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实这里和前面 add 到末尾是没什么区别的，只是多了一个定位插入位置的过程。</p><h4 id="2-5-3-addLast-E-e"><a href="#2-5-3-addLast-E-e" class="headerlink" title="2.5.3 addLast(E e)"></a>2.5.3 addLast(E e)</h4><p>不解释了，和 add(E e) 是一样的，将元素添加到链表尾部</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addLast</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">linkLast(e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-5-4-addFirst-E-e"><a href="#2-5-4-addFirst-E-e" class="headerlink" title="2.5.4 addFirst(E e)"></a>2.5.4 addFirst(E e)</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将元素添加到链表头部</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">linkFirst</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 拿到当前链表的头部节点</span></span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; f = first;</span><br><span class="line">    <span class="comment">// 以头节点做为后继节点</span></span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; newNode = <span class="keyword">new</span> Node&lt;&gt;(<span class="keyword">null</span>, e, f);</span><br><span class="line">    first = newNode;</span><br><span class="line">    <span class="keyword">if</span> (f == <span class="keyword">null</span>)</span><br><span class="line">        last = newNode;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="comment">// 将头节点的前驱指针指向新节点，也就是指向前一个元素</span></span><br><span class="line">        f.prev = newNode;</span><br><span class="line">    size++;</span><br><span class="line">    modCount++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果有了 add(E e) 的理解，就会发现这些都是一回事，这里先拿到的是头部节点，然后再带参构造函数赋值的时候，以头节点做为后继节点</p><ul><li>如果链表为空，则头尾部节点就都是这个新节点 newNode</li><li>如果不为空，则将头节点的前驱指针指向新节点，也就是指向前一个元素</li></ul><h4 id="2-5-5-addAll-Collection-c"><a href="#2-5-5-addAll-Collection-c" class="headerlink" title="2.5.5 addAll(Collection  c )"></a>2.5.5 addAll(Collection  c )</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将集合插入到链表尾部</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">addAll</span><span class="params">(Collection&lt;? extends E&gt; c)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> addAll(size, c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>来直接跳转到逻辑方法中去，addAll(int index, Collection c)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将集合从指定位置开始插入</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">addAll</span><span class="params">(<span class="keyword">int</span> index, Collection&lt;? extends E&gt; c)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 跳转，检查索引是否处于[0-size]之间</span></span><br><span class="line">    checkPositionIndex(index);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 把集合转成数组</span></span><br><span class="line">    Object[] a = c.toArray();</span><br><span class="line">    <span class="keyword">int</span> numNew = a.length;</span><br><span class="line">    <span class="keyword">if</span> (numNew == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    </span><br><span class="line"><span class="comment">// 获取插入位置的前驱和后驱节点</span></span><br><span class="line">    Node&lt;E&gt; pred, succ;</span><br><span class="line">    <span class="comment">// 如果插入位置为尾部。前驱结点自然是尾部节点，后继没有了就是 null</span></span><br><span class="line">    <span class="keyword">if</span> (index == size) &#123;</span><br><span class="line">        succ = <span class="keyword">null</span>;</span><br><span class="line">        pred = last;</span><br><span class="line">    <span class="comment">// 插入位置非尾部，则先通过 node 方法得到后继节点，再拿到前驱结点</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        succ = node(index);</span><br><span class="line">        pred = succ.prev;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历插入数据</span></span><br><span class="line">    <span class="keyword">for</span> (Object o : a) &#123;</span><br><span class="line">        <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>) E e = (E) o;</span><br><span class="line">        <span class="comment">// 创建新节点</span></span><br><span class="line">        Node&lt;E&gt; newNode = <span class="keyword">new</span> Node&lt;&gt;(pred, e, <span class="keyword">null</span>);</span><br><span class="line">        <span class="comment">// 如果插在头部</span></span><br><span class="line">        <span class="keyword">if</span> (pred == <span class="keyword">null</span>)</span><br><span class="line">            first = newNode;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            pred.next = newNode;</span><br><span class="line">        pred = newNode;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// 如果插入在尾部，重置一下 last 节点</span></span><br><span class="line">    <span class="keyword">if</span> (succ == <span class="keyword">null</span>) &#123;</span><br><span class="line">        last = pred;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        pred.next = succ;</span><br><span class="line">        succ.prev = pred;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    size += numNew;</span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-6-获取方法"><a href="#2-6-获取方法" class="headerlink" title="2.6 获取方法"></a>2.6 获取方法</h3><h4 id="2-6-1-get-int-index"><a href="#2-6-1-get-int-index" class="headerlink" title="2.6.1 get(int index)"></a>2.6.1 get(int index)</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *  根据指定索引返回元素</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">get</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 检查index范围是否在size之内</span></span><br><span class="line">    checkElementIndex(index);</span><br><span class="line">    <span class="comment">// 通过 node 方法找到对应的节点然后返回它的值</span></span><br><span class="line">    <span class="keyword">return</span> node(index).item;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">Node&lt;E&gt; <span class="title">node</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 折一半去查找，会高效一些</span></span><br><span class="line"><span class="keyword">if</span> (index &lt; (size &gt;&gt; <span class="number">1</span>)) &#123;</span><br><span class="line">        Node&lt;E&gt; x = first;</span><br><span class="line">        <span class="comment">// 遍历一下</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; index; i++)</span><br><span class="line">            x = x.next;</span><br><span class="line">        <span class="keyword">return</span> x;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        Node&lt;E&gt; x = last;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = size - <span class="number">1</span>; i &gt; index; i--)</span><br><span class="line">            x = x.prev;</span><br><span class="line">        <span class="keyword">return</span> x;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-6-2-获取头结点方法"><a href="#2-6-2-获取头结点方法" class="headerlink" title="2.6.2 获取头结点方法"></a>2.6.2 获取头结点方法</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">getFirst</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; f = first;</span><br><span class="line">    <span class="comment">// 为空抛异常</span></span><br><span class="line">    <span class="keyword">if</span> (f == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NoSuchElementException();</span><br><span class="line">    <span class="keyword">return</span> f.item;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">element</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 为空抛异常</span></span><br><span class="line">    <span class="keyword">return</span> getFirst();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">peek</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; f = first;</span><br><span class="line">    <span class="comment">// 为空返回 null</span></span><br><span class="line">    <span class="keyword">return</span> (f == <span class="keyword">null</span>) ? <span class="keyword">null</span> : f.item;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">peekFirst</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; f = first;</span><br><span class="line">    / 为空返回 <span class="keyword">null</span></span><br><span class="line">    <span class="keyword">return</span> (f == <span class="keyword">null</span>) ? <span class="keyword">null</span> : f.item;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-6-3-获取尾节点方法"><a href="#2-6-3-获取尾节点方法" class="headerlink" title="2.6.3 获取尾节点方法"></a>2.6.3 获取尾节点方法</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">getLast</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; l = last;</span><br><span class="line">    <span class="comment">// 为空返回 null</span></span><br><span class="line">    <span class="keyword">if</span> (l == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NoSuchElementException();</span><br><span class="line">    <span class="keyword">return</span> l.item;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">peekLast</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; l = last;</span><br><span class="line">    <span class="comment">// 为空返回 null</span></span><br><span class="line">    <span class="keyword">return</span> (l == <span class="keyword">null</span>) ? <span class="keyword">null</span> : l.item;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-6-4-根据对象得到索引"><a href="#2-6-4-根据对象得到索引" class="headerlink" title="2.6.4 根据对象得到索引"></a>2.6.4 根据对象得到索引</h4><h5 id="2-6-4-1-从头到尾找"><a href="#2-6-4-1-从头到尾找" class="headerlink" title="2.6.4.1 从头到尾找"></a>2.6.4.1 从头到尾找</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">indexOf</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> index = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (o == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 从 first 遍历 -&gt; next</span></span><br><span class="line">        <span class="keyword">for</span> (Node&lt;E&gt; x = first; x != <span class="keyword">null</span>; x = x.next) &#123;</span><br><span class="line">            <span class="keyword">if</span> (x.item == <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> index;</span><br><span class="line">            index++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 从 first 遍历 -&gt; next</span></span><br><span class="line">        <span class="keyword">for</span> (Node&lt;E&gt; x = first; x != <span class="keyword">null</span>; x = x.next) &#123;</span><br><span class="line">            <span class="keyword">if</span> (o.equals(x.item))</span><br><span class="line">                <span class="keyword">return</span> index;</span><br><span class="line">            index++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="2-6-4-1-从尾到头找"><a href="#2-6-4-1-从尾到头找" class="headerlink" title="2.6.4.1 从尾到头找"></a>2.6.4.1 从尾到头找</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">lastIndexOf</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> index = size;</span><br><span class="line">    <span class="keyword">if</span> (o == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">//从 last 遍历 -&gt; prev</span></span><br><span class="line">        <span class="keyword">for</span> (Node&lt;E&gt; x = last; x != <span class="keyword">null</span>; x = x.prev) &#123;</span><br><span class="line">            index--;</span><br><span class="line">            <span class="keyword">if</span> (x.item == <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> index;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">//从 last 遍历 -&gt; prev</span></span><br><span class="line">        <span class="keyword">for</span> (Node&lt;E&gt; x = last; x != <span class="keyword">null</span>; x = x.prev) &#123;</span><br><span class="line">            index--;</span><br><span class="line">            <span class="keyword">if</span> (o.equals(x.item))</span><br><span class="line">                <span class="keyword">return</span> index;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-6-5-contains-Object-o"><a href="#2-6-5-contains-Object-o" class="headerlink" title="2.6.5 contains(Object o)"></a>2.6.5 contains(Object o)</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *  检查对象 o 是否存在于此链表中</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">contains</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> indexOf(o) != -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-7-删除方法"><a href="#2-7-删除方法" class="headerlink" title="2.7 删除方法"></a>2.7 删除方法</h3><h4 id="2-7-1-remove-int-index"><a href="#2-7-1-remove-int-index" class="headerlink" title="2.7.1 remove(int index)"></a>2.7.1 remove(int index)</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *  删除指定下标元素</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">remove</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 检查index范围</span></span><br><span class="line">    checkElementIndex(index);</span><br><span class="line">    <span class="comment">// 先用 node 找到节点，然后将节点删除</span></span><br><span class="line">    <span class="keyword">return</span> unlink(node(index));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-7-2-remove-Object-o"><a href="#2-7-2-remove-Object-o" class="headerlink" title="2.7.2 remove(Object o)"></a>2.7.2 <strong>remove(Object o)</strong></h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *  删除指定元素</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">remove</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 如果为null</span></span><br><span class="line">    <span class="keyword">if</span> (o == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">//从 first 开始遍历</span></span><br><span class="line">        <span class="keyword">for</span> (Node&lt;E&gt; x = first; x != <span class="keyword">null</span>; x = x.next) &#123;</span><br><span class="line">            <span class="keyword">if</span> (x.item == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">// 从链表中移除找到的元素</span></span><br><span class="line">                unlink(x);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 从 first 开始遍历</span></span><br><span class="line">        <span class="keyword">for</span> (Node&lt;E&gt; x = first; x != <span class="keyword">null</span>; x = x.next) &#123;</span><br><span class="line">            <span class="keyword">if</span> (o.equals(x.item)) &#123;</span><br><span class="line">                <span class="comment">// 从链表中移除找到的元素</span></span><br><span class="line">                unlink(x);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中调用了 <code>unlink(Node&lt;E&gt; x)</code> 方法，来看一下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">E <span class="title">unlink</span><span class="params">(Node&lt;E&gt; x)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> E element = x.item;</span><br><span class="line">    <span class="comment">// 得到后继节点</span></span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; next = x.next;</span><br><span class="line">    <span class="comment">// 得到前驱节点</span></span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; prev = x.prev;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果删除的节点是头节点</span></span><br><span class="line">    <span class="keyword">if</span> (prev == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 令头节点指向该节点的后继节点</span></span><br><span class="line">        first = next;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 不是头结点的话，将前驱节点的后继节点指向后继节点</span></span><br><span class="line">        prev.next = next;</span><br><span class="line">        x.prev = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果删除的节点是尾节点</span></span><br><span class="line">    <span class="keyword">if</span> (next == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">//令尾节点指向该节点的前驱节点</span></span><br><span class="line">        last = prev;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        next.prev = prev;</span><br><span class="line">        x.next = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    x.item = <span class="keyword">null</span>;</span><br><span class="line">    size--;</span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="keyword">return</span> element;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-7-3-删除头结点"><a href="#2-7-3-删除头结点" class="headerlink" title="2.7.3 删除头结点"></a>2.7.3 删除头结点</h4><p>几个方法套娃，最后都是调用的 unlinkFirst() 方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">pop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> removeFirst();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">remove</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> removeFirst();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">removeFirst</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; f = first;</span><br><span class="line">    <span class="keyword">if</span> (f == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NoSuchElementException();</span><br><span class="line">    <span class="keyword">return</span> unlinkFirst(f);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> E <span class="title">unlinkFirst</span><span class="params">(Node&lt;E&gt; f)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// assert f == first &amp;&amp; f != null;</span></span><br><span class="line">    <span class="comment">// 取出头结点中的值，用于方法返回</span></span><br><span class="line">    <span class="keyword">final</span> E element = f.item;</span><br><span class="line">    <span class="comment">// 取出头结点的下一个节点的引用并赋予变量next</span></span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; next = f.next;</span><br><span class="line">    <span class="comment">// 将头结点的item以及next属性设为null，帮助垃圾回收</span></span><br><span class="line">    f.item = <span class="keyword">null</span>;</span><br><span class="line">    f.next = <span class="keyword">null</span>; <span class="comment">// help GC</span></span><br><span class="line">    <span class="comment">// 将next赋予first（将原先节点下一个节点变为头结点）</span></span><br><span class="line">    first = next;</span><br><span class="line">    <span class="comment">// 判断next是否为空，如果为空，则说明原先集合中只有一个元素，需要将last设置为null</span></span><br><span class="line">    <span class="keyword">if</span> (next == <span class="keyword">null</span>)</span><br><span class="line">        last = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="comment">// 如果next不为空，则将next的prev设置为null（因为prev指向原先的头结点，头节点的prev值肯定为null）</span></span><br><span class="line">        next.prev = <span class="keyword">null</span>;</span><br><span class="line">    size--;</span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="keyword">return</span> element;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2.7.4 删除尾结点</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">removeLast</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; l = last;</span><br><span class="line">    <span class="keyword">if</span> (l == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NoSuchElementException();</span><br><span class="line">    <span class="keyword">return</span> unlinkLast(l);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">pollLast</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; l = last;</span><br><span class="line">    <span class="keyword">return</span> (l == <span class="keyword">null</span>) ? <span class="keyword">null</span> : unlinkLast(l);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 与上面 unlinkFirst 同理</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> E <span class="title">unlinkLast</span><span class="params">(Node&lt;E&gt; l)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// assert l == last &amp;&amp; l != null;</span></span><br><span class="line">    <span class="keyword">final</span> E element = l.item;</span><br><span class="line">    <span class="keyword">final</span> Node&lt;E&gt; prev = l.prev;</span><br><span class="line">    l.item = <span class="keyword">null</span>;</span><br><span class="line">    l.prev = <span class="keyword">null</span>; <span class="comment">// help GC</span></span><br><span class="line">    last = prev;</span><br><span class="line">    <span class="keyword">if</span> (prev == <span class="keyword">null</span>)</span><br><span class="line">        first = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        prev.next = <span class="keyword">null</span>;</span><br><span class="line">    size--;</span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="keyword">return</span> element;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 源码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ArrayList 源码分析（含扩容机制分析）</title>
      <link href="/posts/3756e53c/"/>
      <url>/posts/3756e53c/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="一-ArrayList-源码分析（含扩容机制分析）"><a href="#一-ArrayList-源码分析（含扩容机制分析）" class="headerlink" title="一 ArrayList 源码分析（含扩容机制分析）"></a>一 ArrayList 源码分析（含扩容机制分析）</h1><blockquote><p>转载自 github 仓库：<a href="https://github.com/ideal-20/Java-Ideal-Interview" target="_blank" rel="noopener">Java-Ideal-Interview</a></p><p>原文地址：<a href="https://github.com/ideal-20/Java-Ideal-Interview/blob/main/docs/java/javase-basis/collection/001-ArrayList源码分析（含扩容机制等重点问题分析）.md" target="_blank" rel="noopener">https://github.com/ideal-20/Java-Ideal-Interview/blob/main/docs/java/javase-basis/collection/001-ArrayList源码分析（含扩容机制等重点问题分析）.md</a></p><p>著作权归原作者所有</p><p>如果这篇文件对大家有帮助，请给原作者点个 Star⭐</p></blockquote><h2 id="1-ArrayList-概述"><a href="#1-ArrayList-概述" class="headerlink" title="1. ArrayList 概述"></a>1. ArrayList 概述</h2><h3 id="1-1-List-是什么？"><a href="#1-1-List-是什么？" class="headerlink" title="1.1  List 是什么？"></a>1.1  List 是什么？</h3><p>List 在 Collection中充当着一个什么样的身份呢？——有序的 collection(也称为序列) </p><p>实现这个接口的用户以对列表中每个元素的插入位置进行精确地控制。用户可以根据元素的整数索引（在列表中的位置）访问元素，并搜索列表中的元素。与 set 不同，列表通常允许重复的元素。</p><h3 id="1-2-ArrayList-是什么？"><a href="#1-2-ArrayList-是什么？" class="headerlink" title="1.2  ArrayList 是什么？"></a>1.2  ArrayList 是什么？</h3><p><code>ArrayList</code> 的底层就是一个数组，依赖其扩容机制（后面会提到）它能够实现容量的动态增长，所以 ArrayList 就是数据结构中顺序表的一种具体实现。</p><p>其特点为：查询快，增删慢，线程不安全，效率高。</p><h3 id="1-3-顺序表的优缺点"><a href="#1-3-顺序表的优缺点" class="headerlink" title="1.3 顺序表的优缺点"></a>1.3 顺序表的优缺点</h3><p><strong>优点：</strong></p><ol><li>逻辑与物理顺序一致，顺序表能够按照下标直接<strong>快速的存取元素</strong></li><li>无须为了表示表中元素之间的逻辑关系而增加额外的存储空间</li></ol><p><strong>缺点：</strong></p><ol><li><p>线性表长度需要初始定义，常常难以确定存储空间的容量，所以只能以降低效率的代价使用扩容机制</p></li><li><p>插入和<strong>删除操作需要移动大量的元素，效率较低</strong></p></li></ol><h3 id="1-4-时间复杂度证明"><a href="#1-4-时间复杂度证明" class="headerlink" title="1.4 时间复杂度证明"></a>1.4 时间复杂度证明</h3><p><strong>读取</strong>：</p><p>还记的这个公式吗？</p><p>$$Loc(a_i) = Loc(a_1) + (i -1)*L$$</p><p>通过这个公式我们可以在任何时候计算出线性表中任意位置的地址，并且对于计算机所使用的时间都是相同的，即一个常数，这也就意味着，它的时间复杂度为 O(1)</p><p><strong>插入和删除</strong>：</p><p>我们以插入为例子</p><ul><li><p>首先最好的情况是这样的，元素在末尾的位置插入，这样无论该元素进行什么操作，均不会对其他元素产生什么影响，所以它的时间复杂度为 O(1) </p></li><li><p>那么最坏的情况又是这样的，元素正好插入到第一个位置上，这就意味着后面的所有元素全部需要移动一个位置，所以时间复杂度为 O(n)</p></li><li><p>平均的情况呢，由于在每一个位置插入的概率都是相同的，而插入越靠前移动的元素越多，所以平均情况就与中间那个值的一定次数相等，为 (n - 1) / 2 ，平均时间复杂度还是 O(n)</p></li></ul><p><strong>总结</strong>：</p><p>读取数据的时候，它的时间复杂度为 O(1)，插入和删除数据的时候，它的时间复杂度为 O(n)，所以线性表中的顺序表更加适合处理一些元素个数比较稳定，查询读取多的问题</p><h2 id="2-核心源码分析"><a href="#2-核心源码分析" class="headerlink" title="2. 核心源码分析"></a>2. 核心源码分析</h2><h3 id="2-1-类声明"><a href="#2-1-类声明" class="headerlink" title="2.1 类声明"></a>2.1 类声明</h3><p>先来看一下类的声明，有一个继承（抽象类）和四个接口关系</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ArrayList</span>&lt;<span class="title">E</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractList</span>&lt;<span class="title">E</span>&gt;</span></span><br><span class="line"><span class="class">        <span class="keyword">implements</span> <span class="title">List</span>&lt;<span class="title">E</span>&gt;, <span class="title">RandomAccess</span>, <span class="title">Cloneable</span>, <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span></span></span><br><span class="line"><span class="class"></span>&#123; </span><br><span class="line">    <span class="comment">// 源码具体内容... </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p><code>RandomAccess</code> 是一个标志接口（Marker）只要 List 集合实现这个接口，就能支持快速随机访问（通过元素序号快速获取元素对象 —— <code>get(int index)</code>）</p></li><li><p><code>Cloneable</code> ：实现它就可以进行克隆（<code>clone()</code>）</p></li><li><p><code>java.io.Serializable</code> ：实现它意味着支持序列化，满足了序列化传输的条件</p></li></ul><h3 id="2-2-类成员"><a href="#2-2-类成员" class="headerlink" title="2.2 类成员"></a>2.2 类成员</h3><p>下面接着看一些成员属性</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 序列化自动生成的一个码，用来在正反序列化中验证版本一致性。</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">8683452581122892189L</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 默认初始容量大小为10</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_CAPACITY = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 指定 ArrayList 容量为0（空实例）时，返回此空数组</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Object[] EMPTY_ELEMENTDATA = &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 与 EMPTY_ELEMENTDATA 的区别是，它是默认返回的，而前者是用户指定容量为 0 才返回</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 具体存放元素的数组</span></span><br><span class="line"><span class="comment"> * 保存添加到 ArrayList 中的元素数据（第一次添加元素时，会扩容到 DEFAULT_CAPACITY = 10 ） </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">transient</span> Object[] elementData; <span class="comment">// non-private to simplify nested class access</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ArrayList 实际所含元素个数（大小）</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> size;</span><br></pre></td></tr></table></figure><h3 id="2-4-构造方法"><a href="#2-4-构造方法" class="headerlink" title="2.4 构造方法"></a>2.4 构造方法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 带参构造函数，参数为用户指定的初始容量</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ArrayList</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (initialCapacity &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 参数大于0，创建 initialCapacity 大小的数组</span></span><br><span class="line">        <span class="keyword">this</span>.elementData = <span class="keyword">new</span> Object[initialCapacity];</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (initialCapacity == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 参数为0，创建空数组（成员中有定义）</span></span><br><span class="line">        <span class="keyword">this</span>.elementData = EMPTY_ELEMENTDATA;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 其他情况，直接抛异常</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal Capacity: "</span>+</span><br><span class="line">                                           initialCapacity);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 默认无参构造函数，初始值为 0</span></span><br><span class="line"><span class="comment"> * 也说明 DEFAULT_CAPACITY = 10 这个容量</span></span><br><span class="line"><span class="comment"> * 不是在构造函数初始化的时候设定的（而是在添加第一个元素的时候）</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ArrayList</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 构造一个包含指定 collection 的元素的列表</span></span><br><span class="line"><span class="comment"> * 这些元素是按照该 collection 的迭代器返回它们的顺序排列的。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ArrayList</span><span class="params">(Collection&lt;? extends E&gt; c)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 将给定的集合转成数组</span></span><br><span class="line">    elementData = c.toArray();</span><br><span class="line">    <span class="comment">// 如果数组长度不为 0</span></span><br><span class="line">    <span class="keyword">if</span> ((size = elementData.length) != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// elementData 如果不是 Object 类型的数据，返回的就不是 Object 类型的数组</span></span><br><span class="line">        <span class="keyword">if</span> (elementData.getClass() != Object[]<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">            // 将不是 <span class="title">Object</span> 类型的 <span class="title">elementData</span> 数组，赋值给一个新的 <span class="title">Object</span> 类型的数组</span></span><br><span class="line"><span class="class">            <span class="title">elementData</span> </span>= Arrays.copyOf(elementData, size, Object[]<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 数组长度为 0 ，用空数组代替</span></span><br><span class="line">        <span class="keyword">this</span>.elementData = EMPTY_ELEMENTDATA;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-5-最小化实例容量方法"><a href="#2-5-最小化实例容量方法" class="headerlink" title="2.5 最小化实例容量方法"></a>2.5 最小化实例容量方法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 最小化实例容量方法，可以根据实际元素个数，将数组容量优化，防止浪费</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">trimToSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="comment">// 数组容量大于实际元素个数（例如10个元素，却有15个容量）</span></span><br><span class="line">    <span class="keyword">if</span> (size &lt; elementData.length) &#123;</span><br><span class="line">        <span class="comment">// 根据元素实际个数，重新最小化实例容量</span></span><br><span class="line">        elementData = (size == <span class="number">0</span>)</span><br><span class="line">            ? EMPTY_ELEMENTDATA</span><br><span class="line">            : Arrays.copyOf(elementData, size);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-5-扩容方法"><a href="#2-5-扩容方法" class="headerlink" title="2.5 扩容方法"></a>2.5 扩容方法</h3><p>这里只是按照顺序介绍，后面还会专门针对扩容进行一个分析</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 增加ArrayList实例的容量，如果有必要，确保它至少可以保存由最小容量参数指定的元素数量。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ensureCapacity</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//如果元素数组不为默认的空，则 minExpand 的值为0，反之值为10</span></span><br><span class="line">    <span class="keyword">int</span> minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA)</span><br><span class="line">        <span class="comment">// any size if not default element table</span></span><br><span class="line">        ? <span class="number">0</span></span><br><span class="line">        <span class="comment">// larger than default for default empty table. It's already</span></span><br><span class="line">        <span class="comment">// supposed to be at default size.</span></span><br><span class="line">        : DEFAULT_CAPACITY;</span><br><span class="line">    <span class="comment">// 如果最小容量大于已有的最大容量</span></span><br><span class="line">    <span class="keyword">if</span> (minCapacity &gt; minExpand) &#123;</span><br><span class="line">        ensureExplicitCapacity(minCapacity);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 计算最小扩容量（被调用）</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">calculateCapacity</span><span class="params">(Object[] elementData, <span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">     <span class="comment">// 如果元素数组为默认的空</span></span><br><span class="line">    <span class="keyword">if</span> (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;</span><br><span class="line">        <span class="comment">// 获取“默认的容量”和“传入参数 minCapacity ”两者之间的最大值</span></span><br><span class="line">        <span class="keyword">return</span> Math.max(DEFAULT_CAPACITY, minCapacity);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> minCapacity;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 得到最小扩容量</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">ensureCapacityInternal</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">    ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 判断是否需要扩容</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">ensureExplicitCapacity</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="comment">// overflow-conscious code</span></span><br><span class="line">    <span class="comment">// 如果最小容量比数组的长度还大</span></span><br><span class="line">    <span class="keyword">if</span> (minCapacity - elementData.length &gt; <span class="number">0</span>)</span><br><span class="line">        <span class="comment">// 就调用grow方法进行扩容</span></span><br><span class="line">        grow(minCapacity);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 要分配的最大数组大小</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAX_ARRAY_SIZE = Integer.MAX_VALUE - <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ArrayList 扩容的核心方法</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">grow</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 将当前元素数组长度定义为 oldCapacity 旧容量</span></span><br><span class="line">    <span class="keyword">int</span> oldCapacity = elementData.length;</span><br><span class="line">    <span class="comment">// 新容量更新为旧容量的1.5倍</span></span><br><span class="line">    <span class="comment">// oldCapacity &gt;&gt; 1 为按位右移一位，相当于 oldCapacity 除以2的1次幂</span></span><br><span class="line">    <span class="keyword">int</span> newCapacity = oldCapacity + (oldCapacity &gt;&gt; <span class="number">1</span>);</span><br><span class="line">    <span class="comment">// 然后检查新容量是否大于最小需要容量，若还小，就把最小需要容量当作数组的新容量</span></span><br><span class="line">    <span class="keyword">if</span> (newCapacity - minCapacity &lt; <span class="number">0</span>)</span><br><span class="line">        newCapacity = minCapacity;</span><br><span class="line">    <span class="comment">// 再检查新容量是否超出了ArrayList 所定义的最大容量</span></span><br><span class="line">    <span class="keyword">if</span> (newCapacity - MAX_ARRAY_SIZE &gt; <span class="number">0</span>)</span><br><span class="line">        <span class="comment">// 若超出，则调用hugeCapacity()</span></span><br><span class="line">        newCapacity = hugeCapacity(minCapacity);</span><br><span class="line">    elementData = Arrays.copyOf(elementData, newCapacity);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 比较minCapacity和 MAX_ARRAY_SIZE</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">hugeCapacity</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (minCapacity &lt; <span class="number">0</span>) <span class="comment">// overflow</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> OutOfMemoryError();</span><br><span class="line">    <span class="keyword">return</span> (minCapacity &gt; MAX_ARRAY_SIZE) ?</span><br><span class="line">        Integer.MAX_VALUE :</span><br><span class="line">    MAX_ARRAY_SIZE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-6-常规方法"><a href="#2-6-常规方法" class="headerlink" title="2.6 常规方法"></a>2.6 常规方法</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回元素数量</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">size</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> size;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 此列表元素数量为 0 则返回 true</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isEmpty</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> size == <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 此列表含有指定元素，则返回true</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">contains</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> indexOf(o) &gt;= <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回此列表中元素首次出现位置的索引</span></span><br><span class="line"><span class="comment"> * 若不包含此元素，则返回 -1</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">indexOf</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (o == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++)</span><br><span class="line">            <span class="keyword">if</span> (elementData[i]==<span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> i;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 本质就是循环 equals 比对</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++)</span><br><span class="line">            <span class="keyword">if</span> (o.equals(elementData[i]))</span><br><span class="line">                <span class="keyword">return</span> i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回此列表中指定元素的最后一次出现的索引</span></span><br><span class="line"><span class="comment"> * 如果此列表不包含元素，则返回 -1</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">lastIndexOf</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (o == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = size-<span class="number">1</span>; i &gt;= <span class="number">0</span>; i--)</span><br><span class="line">            <span class="keyword">if</span> (elementData[i]==<span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> i;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 逆向循环 equals 比对</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = size-<span class="number">1</span>; i &gt;= <span class="number">0</span>; i--)</span><br><span class="line">            <span class="keyword">if</span> (o.equals(elementData[i]))</span><br><span class="line">                <span class="keyword">return</span> i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回 ArrayList 实例的浅拷贝</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">clone</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        ArrayList&lt;?&gt; v = (ArrayList&lt;?&gt;) <span class="keyword">super</span>.clone();</span><br><span class="line">        <span class="comment">// 实现数组的复制，参数为被复制者的参数</span></span><br><span class="line">        v.elementData = Arrays.copyOf(elementData, size);</span><br><span class="line">        v.modCount = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span> v;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (CloneNotSupportedException e) &#123;</span><br><span class="line">        <span class="comment">// this shouldn't happen, since we are Cloneable</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> InternalError(e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回一个包含此列表中所有元素的数组（理解为将集合转为数组即可）</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> Object[] toArray() &#123;</span><br><span class="line">    <span class="keyword">return</span> Arrays.copyOf(elementData, size);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将list转化为你所需要类型的数组，然后返回</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line"><span class="keyword">public</span> &lt;T&gt; T[] toArray(T[] a) &#123;</span><br><span class="line">    <span class="keyword">if</span> (a.length &lt; size)</span><br><span class="line">        <span class="comment">// Make a new array of a's runtime type, but my contents:</span></span><br><span class="line">        <span class="keyword">return</span> (T[]) Arrays.copyOf(elementData, size, a.getClass());</span><br><span class="line">    <span class="comment">// 复制用法，下面专题会讲解此内容</span></span><br><span class="line">    System.arraycopy(elementData, <span class="number">0</span>, a, <span class="number">0</span>, size);</span><br><span class="line">    <span class="keyword">if</span> (a.length &gt; size)</span><br><span class="line">        a[size] = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">return</span> a;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Positional Access Operations</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line"><span class="function">E <span class="title">elementData</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (E) elementData[index];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 返回此列表中指定位置的元素。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">get</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// index 范围检查</span></span><br><span class="line">    rangeCheck(index);</span><br><span class="line">    <span class="keyword">return</span> elementData(index);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 用指定的元素替换此列表中指定位置的元素。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">set</span><span class="params">(<span class="keyword">int</span> index, E element)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// index 范围检查</span></span><br><span class="line">    rangeCheck(index);</span><br><span class="line"><span class="comment">// 根据 index 找到想替换的旧元素</span></span><br><span class="line">    E oldValue = elementData(index);</span><br><span class="line">    <span class="comment">// 替换元素</span></span><br><span class="line">    elementData[index] = element;</span><br><span class="line">    <span class="keyword">return</span> oldValue;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将指定的元素追加到此列表的末尾。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 确认 list 容量，尝试容量加 1，看看有无必要扩容</span></span><br><span class="line">    ensureCapacityInternal(size + <span class="number">1</span>);  <span class="comment">// Increments modCount!!</span></span><br><span class="line">    <span class="comment">// 赋值</span></span><br><span class="line">    elementData[size++] = e;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 在此列表中的指定位置插入指定的元素</span></span><br><span class="line"><span class="comment"> * 再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> index, E element)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 调用 rangeCheckForAdd 对 index 进行范围检查</span></span><br><span class="line">    rangeCheckForAdd(index);</span><br><span class="line"><span class="comment">// 保证容量足够</span></span><br><span class="line">    ensureCapacityInternal(size + <span class="number">1</span>);  <span class="comment">// Increments modCount!!</span></span><br><span class="line">    <span class="comment">// 自己复制自己，然后达到 index 之后全部元素向后挪一位的效果</span></span><br><span class="line">    System.arraycopy(elementData, index, elementData, index + <span class="number">1</span>,</span><br><span class="line">                     size - index);</span><br><span class="line">    <span class="comment">// 然后将 index 赋值为指定的元素</span></span><br><span class="line">    elementData[index] = element;</span><br><span class="line">    size++;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 移除该列表中指定位置的元素。 将任何后续元素移动到左侧（从其索引中减去一个元素）。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">remove</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 调用 rangeCheckForAdd 对 index 进行范围检查</span></span><br><span class="line">    rangeCheck(index);</span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="comment">// 找到待移除的值</span></span><br><span class="line">    E oldValue = elementData(index);</span><br><span class="line"><span class="comment">// 计算出需要移动元素的数量</span></span><br><span class="line">    <span class="keyword">int</span> numMoved = size - index - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (numMoved &gt; <span class="number">0</span>)</span><br><span class="line">        <span class="comment">// 同样复制自己，使得被移除元素右侧的元素整体向左移动</span></span><br><span class="line">        System.arraycopy(elementData, index+<span class="number">1</span>, elementData, index,</span><br><span class="line">                         numMoved);</span><br><span class="line">    elementData[--size] = <span class="keyword">null</span>; <span class="comment">// clear to let GC do its work</span></span><br><span class="line">    <span class="keyword">return</span> oldValue;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 从集合中移除第一次出现的指定元素</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">remove</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (o == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> index = <span class="number">0</span>; index &lt; size; index++)</span><br><span class="line">            <span class="keyword">if</span> (elementData[index] == <span class="keyword">null</span>) &#123;</span><br><span class="line">                fastRemove(index);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 也很简单，就是一个循环 equals 判断，然后移除</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> index = <span class="number">0</span>; index &lt; size; index++)</span><br><span class="line">            <span class="keyword">if</span> (o.equals(elementData[index])) &#123;</span><br><span class="line">                fastRemove(index);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 跳过范围检查的删除方式，与remove(Object o)相同</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">fastRemove</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="keyword">int</span> numMoved = size - index - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (numMoved &gt; <span class="number">0</span>)</span><br><span class="line">        System.arraycopy(elementData, index+<span class="number">1</span>, elementData, index,</span><br><span class="line">                         numMoved);</span><br><span class="line">    elementData[--size] = <span class="keyword">null</span>; <span class="comment">// clear to let GC do its work</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 从列表中删除所有元素。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">modCount++;</span><br><span class="line">    <span class="comment">// clear to let GC do its work</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++)</span><br><span class="line">        <span class="comment">// 元素全部设为 null</span></span><br><span class="line">        elementData[i] = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">// 长度设为 0</span></span><br><span class="line">    size = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 按指定集合的Iterator返回的顺序</span></span><br><span class="line"><span class="comment"> * 将指定集合中的所有元素追加到此列表的末尾。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">addAll</span><span class="params">(Collection&lt;? extends E&gt; c)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 转为数组</span></span><br><span class="line">    Object[] a = c.toArray();</span><br><span class="line">    <span class="comment">// 拿到待添加指定数组的长度</span></span><br><span class="line">    <span class="keyword">int</span> numNew = a.length;</span><br><span class="line">    <span class="comment">// 确认 list 容量，尝试容量加上 numNew，看看有无必要扩容</span></span><br><span class="line">    ensureCapacityInternal(size + numNew);  <span class="comment">// Increments modCount</span></span><br><span class="line">    <span class="comment">// 利用 arraycopy 指定数组a的元素追加到当前数组 elementData 后</span></span><br><span class="line">    System.arraycopy(a, <span class="number">0</span>, elementData, size, numNew);</span><br><span class="line">    size += numNew;</span><br><span class="line">    <span class="keyword">return</span> numNew != <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 按指定集合的Iterator返回的顺序</span></span><br><span class="line"><span class="comment"> * 将指定集合中的所有元素添加到此列表中，从指定位置开始</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">addAll</span><span class="params">(<span class="keyword">int</span> index, Collection&lt;? extends E&gt; c)</span> </span>&#123; </span><br><span class="line">    rangeCheckForAdd(index);</span><br><span class="line">    Object[] a = c.toArray();</span><br><span class="line">    <span class="keyword">int</span> numNew = a.length;</span><br><span class="line">    ensureCapacityInternal(size + numNew);  <span class="comment">// Increments modCount</span></span><br><span class="line"><span class="comment">// 计算需要移动的元素</span></span><br><span class="line">    <span class="keyword">int</span> numMoved = size - index;</span><br><span class="line">    <span class="keyword">if</span> (numMoved &gt; <span class="number">0</span>)</span><br><span class="line">        <span class="comment">// 实现元素指定位置的插入，本质还是 arraycopy 自身</span></span><br><span class="line">        System.arraycopy(elementData, index, elementData, index + numNew,</span><br><span class="line">                         numMoved);</span><br><span class="line"></span><br><span class="line">    System.arraycopy(a, <span class="number">0</span>, elementData, index, numNew);</span><br><span class="line">    size += numNew;</span><br><span class="line">    <span class="keyword">return</span> numNew != <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 删除指定索引范围内的元素（fromIndex - toIndex）</span></span><br><span class="line"><span class="comment"> * 将任何后续元素移动到左侧（减少其索引）。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">removeRange</span><span class="params">(<span class="keyword">int</span> fromIndex, <span class="keyword">int</span> toIndex)</span> </span>&#123;</span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="keyword">int</span> numMoved = size - toIndex;</span><br><span class="line">    System.arraycopy(elementData, toIndex, elementData, fromIndex,</span><br><span class="line">                     numMoved);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// clear to let GC do its work</span></span><br><span class="line">    <span class="keyword">int</span> newSize = size - (toIndex-fromIndex);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = newSize; i &lt; size; i++) &#123;</span><br><span class="line">        elementData[i] = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    size = newSize;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 检查给定的索引是否在范围内。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">rangeCheck</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 下标越界就直接抛异常</span></span><br><span class="line">    <span class="keyword">if</span> (index &gt;= size)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IndexOutOfBoundsException(outOfBoundsMsg(index));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 另一个版本，针对add 和 addAll使用</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">rangeCheckForAdd</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (index &gt; size || index &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IndexOutOfBoundsException(outOfBoundsMsg(index));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 与上面套娃使用</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> String <span class="title">outOfBoundsMsg</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"Index: "</span>+index+<span class="string">", Size: "</span>+size;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 从此列表中删除指定集合中包含的所有元素。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">removeAll</span><span class="params">(Collection&lt;?&gt; c)</span> </span>&#123;</span><br><span class="line">    Objects.requireNonNull(c);</span><br><span class="line">    <span class="keyword">return</span> batchRemove(c, <span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 仅保留此列表中包含在指定集合中的元素。即删掉没有的部分</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">retainAll</span><span class="params">(Collection&lt;?&gt; c)</span> </span>&#123;</span><br><span class="line">    Objects.requireNonNull(c);</span><br><span class="line">    <span class="keyword">return</span> batchRemove(c, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 删除的具体逻辑，下面会有专题讲解</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">batchRemove</span><span class="params">(Collection&lt;?&gt; c, <span class="keyword">boolean</span> complement)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Object[] elementData = <span class="keyword">this</span>.elementData;</span><br><span class="line">    <span class="keyword">int</span> r = <span class="number">0</span>, w = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">boolean</span> modified = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (; r &lt; size; r++)</span><br><span class="line">            <span class="comment">// 通过循环判断数组中有没有指定数组中的每一个值，complement 是参数传递的</span></span><br><span class="line">            <span class="keyword">if</span> (c.contains(elementData[r]) == complement)</span><br><span class="line">                <span class="comment">// 就将原数组的r位置的数据覆盖掉w位置的数据</span></span><br><span class="line">                <span class="comment">// r位置的数据不变，并其w自增，r自增</span></span><br><span class="line">                <span class="comment">// 否则，r自增，w不自增</span></span><br><span class="line">                <span class="comment">// 本质：把需要移除的数据都替换掉，不需要移除的数据前移</span></span><br><span class="line">                elementData[w++] = elementData[r];</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">// Preserve behavioral compatibility with AbstractCollection,</span></span><br><span class="line">        <span class="comment">// even if c.contains() throws.</span></span><br><span class="line">        <span class="keyword">if</span> (r != size) &#123;</span><br><span class="line">            System.arraycopy(elementData, r,</span><br><span class="line">                             elementData, w,</span><br><span class="line">                             size - r);</span><br><span class="line">            w += size - r;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (w != size) &#123;</span><br><span class="line">            <span class="comment">// clear to let GC do its work</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = w; i &lt; size; i++)</span><br><span class="line">                elementData[i] = <span class="keyword">null</span>;</span><br><span class="line">            modCount += size - w;</span><br><span class="line">            size = w;</span><br><span class="line">            modified = <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> modified;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// writeObject readObject 序列化相关的省略</span></span><br><span class="line">   </span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 列表迭代器：List集合特有的迭代器</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ListIterator&lt;E&gt; <span class="title">listIterator</span><span class="params">(<span class="keyword">int</span> index)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (index &lt; <span class="number">0</span> || index &gt; size)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IndexOutOfBoundsException(<span class="string">"Index: "</span>+index);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ListItr(index);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> ListIterator&lt;E&gt; <span class="title">listIterator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ListItr(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// foreach 遍历等同于 iterator</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Iterator&lt;E&gt; <span class="title">iterator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> Itr();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">Itr</span> <span class="keyword">implements</span> <span class="title">Iterator</span>&lt;<span class="title">E</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">// 下一个要访问的元素下标</span></span><br><span class="line">    <span class="keyword">int</span> cursor; </span><br><span class="line">    <span class="comment">// 上一个要访问的元素下标</span></span><br><span class="line">    <span class="keyword">int</span> lastRet = -<span class="number">1</span>; </span><br><span class="line">    <span class="comment">// 代表对 ArrayList 修改次数的期望值，初始值为 modCount</span></span><br><span class="line">    <span class="keyword">int</span> expectedModCount = modCount;</span><br><span class="line"></span><br><span class="line">    Itr() &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 下标如果</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasNext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> cursor != size;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 刚开始cursor = 0，lastRet = -1</span></span><br><span class="line"><span class="comment">     * 整个过程结束 cursor 和 lastRet 都会自增 1</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> E <span class="title">next</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 跳转本质是判断 modCount 是否等于 expectedModCount</span></span><br><span class="line">        checkForComodification();</span><br><span class="line">        <span class="keyword">int</span> i = cursor;</span><br><span class="line">       <span class="comment">// 判断 cursor 是否超过集合大小和数组长度</span></span><br><span class="line">        <span class="keyword">if</span> (i &gt;= size)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> NoSuchElementException();</span><br><span class="line">        Object[] elementData = ArrayList.<span class="keyword">this</span>.elementData;</span><br><span class="line">        <span class="keyword">if</span> (i &gt;= elementData.length)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ConcurrentModificationException();</span><br><span class="line">        cursor = i + <span class="number">1</span>;</span><br><span class="line">        <span class="comment">// 将 cursor 赋值给 lastRet，然后把此下标处的元素返回</span></span><br><span class="line">        <span class="keyword">return</span> (E) elementData[lastRet = i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 先判断 lastRet 的值是否小于 0</span></span><br><span class="line">        <span class="keyword">if</span> (lastRet &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException();</span><br><span class="line">        <span class="comment">// 跳转本质是判断 modCount 是否等于 expectedModCount</span></span><br><span class="line">        checkForComodification();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 直接调用 ArrayList 的 remove 方法删除下标为 lastRet 的元素</span></span><br><span class="line">            ArrayList.<span class="keyword">this</span>.remove(lastRet);</span><br><span class="line">            cursor = lastRet;</span><br><span class="line">            lastRet = -<span class="number">1</span>;</span><br><span class="line">            expectedModCount = modCount;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IndexOutOfBoundsException ex) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ConcurrentModificationException();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// forEachRemaining 略</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">checkForComodification</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (modCount != expectedModCount)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> ConcurrentModificationException();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-重点内容分析"><a href="#3-重点内容分析" class="headerlink" title="3. 重点内容分析"></a>3. 重点内容分析</h2><h3 id="3-1-扩容机制再分析"><a href="#3-1-扩容机制再分析" class="headerlink" title="3.1 扩容机制再分析"></a>3.1 扩容机制再分析</h3><h4 id="3-1-1-ArrayList-是如何被初始化的"><a href="#3-1-1-ArrayList-是如何被初始化的" class="headerlink" title="3.1.1 ArrayList 是如何被初始化的"></a>3.1.1 ArrayList 是如何被初始化的</h4><p>ArrayList 提供了 1 个无参构造和 2 个带参构造来初始化 ArrayList ，我们在创建 ArrayList  时，经常使用无参构造的方式，其本质就是初始化了一个空数组，直到向数组内真的添加元素的时候才会真的去分配容量。例如：向数组中添加第一个元素，数组容量扩充为 10 </p><blockquote><p>补充：JDK7 无参构造 初始化 ArrayList 对象时，直接创建了长度是 10 的 Object[] 数组elementData </p></blockquote><h4 id="3-1-2-扩容机制流程分析（无参构造为例）"><a href="#3-1-2-扩容机制流程分析（无参构造为例）" class="headerlink" title="3.1.2 扩容机制流程分析（无参构造为例）"></a>3.1.2 扩容机制流程分析（无参构造为例）</h4><h5 id="3-1-2-1-add"><a href="#3-1-2-1-add" class="headerlink" title="3.1.2.1 add()"></a>3.1.2.1 add()</h5><p>一般来说，都是通过 add 方法触发扩容机制，我们拿最简单的尾部追加的 add() 方法举例</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将指定的元素追加到此列表的末尾。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 确认 list 容量，尝试容量加 1，看看有无必要扩容</span></span><br><span class="line">    ensureCapacityInternal(size + <span class="number">1</span>);  <span class="comment">// Increments modCount!!</span></span><br><span class="line">    <span class="comment">// 赋值</span></span><br><span class="line">    elementData[size++] = e;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>核心要点就这一句 <code>ensureCapacityInternal(size + 1);</code> </p><h5 id="3-1-2-2-ensureCapacityInternal"><a href="#3-1-2-2-ensureCapacityInternal" class="headerlink" title="3.1.2.2 ensureCapacityInternal()"></a>3.1.2.2 ensureCapacityInternal()</h5><p>追踪进去</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 得到最小扩容量</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">ensureCapacityInternal</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">    ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>方法内调用了 <code>ensureExplicitCapacity()</code> 方法，参数是 <code>calculateCapacity(elementData, minCapacity)</code></p><p>先来分析一下这个参数的结果是什么，聚焦到 <code>calculateCapacity()</code> 方法中去</p><h5 id="3-1-2-3-calculateCapacity"><a href="#3-1-2-3-calculateCapacity" class="headerlink" title="3.1.2.3 calculateCapacity()"></a>3.1.2.3 calculateCapacity()</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 计算最小扩容量（被调用）</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">calculateCapacity</span><span class="params">(Object[] elementData, <span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">     <span class="comment">// 如果元素数组为默认的空</span></span><br><span class="line">    <span class="keyword">if</span> (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;</span><br><span class="line">        <span class="comment">// 获取“默认的容量”和“传入参数 minCapacity ”两者之间的最大值</span></span><br><span class="line">        <span class="keyword">return</span> Math.max(DEFAULT_CAPACITY, minCapacity);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> minCapacity;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也很简单，就是为了计算出一个最小扩容量，当元素为初次初始化时，数组还没进过扩容，是一个空数组，所以会走 if 这个判断，而且当时传入的 size + 1 也就是 minCapacity 的值为 0 + 1 = 1 ，经过一个取大值的操作，与默认的 DEFAULT_CAPACITY 进行比对，自然返回的就是 10。</p><p>如果数组已经不是为空了，就直接返回一个 minCapacity （size + 1）就可以了</p><h5 id="3-1-2-4-ensureExplicitCapacity"><a href="#3-1-2-4-ensureExplicitCapacity" class="headerlink" title="3.1.2.4 ensureExplicitCapacity"></a>3.1.2.4 ensureExplicitCapacity</h5><p>ensureCapacityInternal 方法内调用了 <code>ensureExplicitCapacity(参数已经计算出来了)</code> 方法</p><p>继续去看它</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 判断是否需要扩容</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">ensureExplicitCapacity</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="comment">// overflow-conscious code</span></span><br><span class="line">    <span class="comment">// 如果最小容量比数组的长度还大</span></span><br><span class="line">    <span class="keyword">if</span> (minCapacity - elementData.length &gt; <span class="number">0</span>)</span><br><span class="line">        <span class="comment">// 就调用grow方法进行扩容</span></span><br><span class="line">        grow(minCapacity);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此方法的核心就是 if 判断这个数组需不需要扩容，可以分为三种情况</p><ul><li><p>add 第 1 个元素时：此时数组还只是一个被初始化过的空数组，minCapacity 经过 <code>calculateCapacity</code> 计算会返回 DEFAULT_CAPACITY 的默认值 10，而 elementData.length 也自然是 0，所以 minCapacity - elementData.length &gt; 0 是成立的，直接进入 <code>grow(minCapacity);</code> 开始扩容。</p></li><li><p>add 第 2 到 10 个元素的时候（以 2 举例）：此时 minCapacity  = size + 1 = 1 + 1 = 2 ，而 elementData.length 已经在添加第 1 个元素后等于 10 了。所以 minCapacity - elementData.length &gt; 0 就不成立了，所以不会进入  <code>grow(minCapacity);</code> ，也不会扩容</p><ul><li>添加第 3 … 10 个元素的时候，都是一样的。</li></ul></li><li><p>add 第 11 个元素的时候，minCapacity  变成了 11，比 10 还要大，所以又一次进去扩容了</p></li></ul><h5 id="3-1-2-5-grow"><a href="#3-1-2-5-grow" class="headerlink" title="3.1.2.5 grow()"></a>3.1.2.5 grow()</h5><p>这里是真正去执行扩容逻辑的代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 要分配的最大数组大小</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAX_ARRAY_SIZE = Integer.MAX_VALUE - <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ArrayList 扩容的核心方法</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">grow</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 将当前元素数组长度定义为 oldCapacity 旧容量</span></span><br><span class="line">    <span class="keyword">int</span> oldCapacity = elementData.length;</span><br><span class="line">    <span class="comment">// 新容量更新为旧容量的1.5倍</span></span><br><span class="line">    <span class="comment">// oldCapacity &gt;&gt; 1 为按位右移一位，相当于 oldCapacity 除以2的1次幂</span></span><br><span class="line">    <span class="keyword">int</span> newCapacity = oldCapacity + (oldCapacity &gt;&gt; <span class="number">1</span>);</span><br><span class="line">    <span class="comment">// 然后检查新容量是否大于最小需要容量，若还小，就把最小需要容量当作数组的新容量</span></span><br><span class="line">    <span class="keyword">if</span> (newCapacity - minCapacity &lt; <span class="number">0</span>)</span><br><span class="line">        newCapacity = minCapacity;</span><br><span class="line">    <span class="comment">// 再检查新容量是否超出了ArrayList 所定义的最大容量</span></span><br><span class="line">    <span class="keyword">if</span> (newCapacity - MAX_ARRAY_SIZE &gt; <span class="number">0</span>)</span><br><span class="line">        <span class="comment">// 若超出，则调用hugeCapacity()</span></span><br><span class="line">        newCapacity = hugeCapacity(minCapacity);</span><br><span class="line">    elementData = Arrays.copyOf(elementData, newCapacity);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>扩容的核心就是这句：<code>int</code></p><p><code>newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);</code></p><p>本质就是扩容 1.5 倍，而且其中使用了移位运算，这里从计算的角度上来看，相当于 oldCapacity 除以 2 的 1 次幂（偶数除以 2 刚好除尽，奇数丢掉小数部分）。使用按位右移，效率会高很多</p><blockquote><p><code>&gt;&gt;</code> 按位右移运算符：最高位为 0，左边补齐 0，最高位是 1，左边补齐 1</p><ul><li>快速计算：把 <code>&gt;&gt;</code> 左边的数据 除以 2 的移动次幂：例如 -24 &gt;&gt; 2 即：-24  / 2 ^ 2 = -6</li></ul><p>—— 此项目 【001-Java基础知识】 章节中有具体介绍</p></blockquote><p>扩容后，需要对这个新容量的范围进行一个判断，不能小于最小需要容量，也不能大于定义的最大容量，分情况细细看一下（以 1 和 11 举例，是因为这两种都是刚好需要扩容的）</p><ul><li><p>add 第 1 个元素的时候，数组还为空，所以无论是 oldCapacity 还是 newCapacity 都是 0，经过第一次判断后，newCapacity = minCapacity 执行了，此时 newCapacity  为 10，第二个判断不会进入，它不可能大于数组的最大容量。</p></li><li><p>add 第 11 个元素的时候，oldCapacity  为 10，newCapacity = 10 + 10/2 = 15，大于 minCapacity  =  11，第一个判断不会进入，同时它肯定也没有大于数组最大 size，不会进入 。数组容量此时就扩为 15，add 方法中会返回一个 true，size 也增加成 11。</p></li><li><p>后面都是同样的道理 …</p></li></ul><h5 id="3-1-2-6-hugeCapacity"><a href="#3-1-2-6-hugeCapacity" class="headerlink" title="3.1.2.6 hugeCapacity()"></a>3.1.2.6 hugeCapacity()</h5><p>这个方法就是在 newCapacity 大于 MAX_ARRAY_SIZE 的时候，开始判断 minCapacity 和 MAX_ARRAY_SIZE 谁大，然后赋予不同的值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 比较minCapacity和 MAX_ARRAY_SIZE</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">hugeCapacity</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (minCapacity &lt; <span class="number">0</span>) <span class="comment">// overflow</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> OutOfMemoryError();</span><br><span class="line">    <span class="keyword">return</span> (minCapacity &gt; MAX_ARRAY_SIZE) ?</span><br><span class="line">        Integer.MAX_VALUE :</span><br><span class="line">    MAX_ARRAY_SIZE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-2-System-arraycopy-和-Arrays-copyOf-复制方法"><a href="#3-2-System-arraycopy-和-Arrays-copyOf-复制方法" class="headerlink" title="3.2 System.arraycopy() 和 Arrays.copyOf() 复制方法"></a>3.2 System.arraycopy() 和 Arrays.copyOf() 复制方法</h3><p>在前面的方法中，大量的用到了这两个方法，基本但凡涉及到元素移动的都会用到。</p><h4 id="3-2-1-System-arraycopy"><a href="#3-2-1-System-arraycopy" class="headerlink" title="3.2.1 System.arraycopy()"></a>3.2.1 System.arraycopy()</h4><p>拿 add 方法中的举例</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 在此列表中的指定位置插入指定的元素</span></span><br><span class="line"><span class="comment"> * 再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> index, E element)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 调用 rangeCheckForAdd 对 index 进行范围检查</span></span><br><span class="line">    rangeCheckForAdd(index);</span><br><span class="line"><span class="comment">// 保证容量足够</span></span><br><span class="line">    ensureCapacityInternal(size + <span class="number">1</span>);  <span class="comment">// Increments modCount!!</span></span><br><span class="line">    <span class="comment">// 自己复制自己，然后达到 index 之后全部元素向后挪一位的效果</span></span><br><span class="line">    System.arraycopy(elementData, index, elementData, index + <span class="number">1</span>,</span><br><span class="line">                     size - index);</span><br><span class="line">    <span class="comment">// 然后将 index 赋值为指定的元素</span></span><br><span class="line">    elementData[index] = element;</span><br><span class="line">    size++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>arraycopy 是 System类 中的一个方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 数组复制</span></span><br><span class="line"><span class="comment"> * src - 源数组。</span></span><br><span class="line"><span class="comment"> * srcPos - 源数组中的起始位置。</span></span><br><span class="line"><span class="comment"> * dest - 目标数组。 </span></span><br><span class="line"><span class="comment"> * destPos - 目的地数据中的起始位置。 </span></span><br><span class="line"><span class="comment"> * length - 要复制的数组元素的数量。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">arraycopy</span><span class="params">(Object src, <span class="keyword">int</span> srcPos, Object dest, <span class="keyword">int</span> destPos, <span class="keyword">int</span> length)</span></span></span><br></pre></td></tr></table></figure><p>举例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span>[] arr = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>];</span><br><span class="line">    arr[<span class="number">0</span>] = <span class="number">11</span>;</span><br><span class="line">    arr[<span class="number">1</span>] = <span class="number">22</span>;</span><br><span class="line">    arr[<span class="number">2</span>] = <span class="number">33</span>;</span><br><span class="line">    arr[<span class="number">3</span>] = <span class="number">44</span>;</span><br><span class="line">    arr[<span class="number">4</span>] = <span class="number">55</span>;</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">"前："</span> + Arrays.toString(arr));</span><br><span class="line">    <span class="comment">// 指定下标后向后挪动一位</span></span><br><span class="line">    System.arraycopy(arr, <span class="number">1</span>, arr, <span class="number">2</span>, <span class="number">4</span>);</span><br><span class="line">    <span class="comment">// 指定下标处替换元素</span></span><br><span class="line">    arr[<span class="number">1</span>] = <span class="number">666</span>;</span><br><span class="line">    System.out.println(<span class="string">"后："</span> + Arrays.toString(arr));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果：</p><p>前：[11, 22, 33, 44, 55, 0, 0, 0, 0, 0]<br>后：[11, 666, 22, 33, 44, 55, 0, 0, 0, 0]</p><p>这样就实现了 add 中的一个指定下标插入操作（不考虑扩容）</p><h4 id="3-2-2-Arrays-copyOf"><a href="#3-2-2-Arrays-copyOf" class="headerlink" title="3.2.2  Arrays.copyOf()"></a>3.2.2  Arrays.copyOf()</h4><p>所以，可以简单的认为，这个方法的目的只要是为了给原数组扩容。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span>[] arr1 = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span>[] arr2 = Arrays.copyOf(arr1, <span class="number">5</span>);</span><br><span class="line">    <span class="keyword">int</span>[] arr3 = Arrays.copyOf(arr1, <span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">    System.out.println(Arrays.toString(arr1));</span><br><span class="line">    System.out.println(Arrays.toString(arr2));</span><br><span class="line">    System.out.println(Arrays.toString(arr3));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果：</p><p>[1, 2, 3, 4, 5]<br>[1, 2, 3, 4, 5]<br>[1, 2, 3, 4, 5, 0, 0, 0, 0, 0]</p><h3 id="3-3-removeAll-和-retainAll-中的-batchRemove-方法"><a href="#3-3-removeAll-和-retainAll-中的-batchRemove-方法" class="headerlink" title="3.3 removeAll() 和 retainAll() 中的 batchRemove() 方法"></a>3.3 removeAll() 和 retainAll() 中的 batchRemove() 方法</h3><p>在 removeAll() 和 retainAll() 方法中，都调用了  batchRemove()方法，区别只是传参不同，就能实现两种不同的正反删除效果</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 从此列表中删除指定集合中包含的所有元素。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">removeAll</span><span class="params">(Collection&lt;?&gt; c)</span> </span>&#123;</span><br><span class="line">    Objects.requireNonNull(c);</span><br><span class="line">    <span class="keyword">return</span> batchRemove(c, <span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 仅保留此列表中包含在指定集合中的元素。即删掉没有的部分</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">retainAll</span><span class="params">(Collection&lt;?&gt; c)</span> </span>&#123;</span><br><span class="line">    Objects.requireNonNull(c);</span><br><span class="line">    <span class="keyword">return</span> batchRemove(c, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>来重点看一下这个方法的源码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 删除的具体逻辑，下面会有专题讲解</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">batchRemove</span><span class="params">(Collection&lt;?&gt; c, <span class="keyword">boolean</span> complement)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> Object[] elementData = <span class="keyword">this</span>.elementData;</span><br><span class="line">    <span class="keyword">int</span> r = <span class="number">0</span>, w = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">boolean</span> modified = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (; r &lt; size; r++)</span><br><span class="line">            <span class="keyword">if</span> (c.contains(elementData[r]) == complement)</span><br><span class="line">                elementData[w++] = elementData[r];</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (r != size) &#123;</span><br><span class="line">            System.arraycopy(elementData, r,</span><br><span class="line">                             elementData, w,</span><br><span class="line">                             size - r);</span><br><span class="line">            w += size - r;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (w != size) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = w; i &lt; size; i++)</span><br><span class="line">                elementData[i] = <span class="keyword">null</span>;</span><br><span class="line">            modCount += size - w;</span><br><span class="line">            size = w;</span><br><span class="line">            modified = <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> modified;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>解释一下刚开始的那些字段</p><ul><li><p>size ：原数组长度</p></li><li><p>elementData： 原数组</p></li><li><p>modCount ： 从父类继承过来的变量，作用是记录着集合的修改次数。</p></li></ul><p>来看第一个关键代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (; r &lt; size; r++)</span><br><span class="line"><span class="keyword">if</span> (c.contains(elementData[r]) == complement)</span><br><span class="line">elementData[w++] = elementData[r];</span><br></pre></td></tr></table></figure><p>我们以 removeAll() 为例，意图从此列表中删除指定集合中包含的所有元素。即，有的就删，没有的就不删。</p><p>所以 complement 经过参数传递过来自然是 false，所以参数指定数组中不含有原数组指定位置下标的数据的时候，就将 elementData[r] 位置的数据覆盖掉 elementData[w++] 位置的数据，r 根据循环++自增，w 根据变量 w++ 自增，若 if 表达式不成立则，r 自增，w 不自增。</p><p>举例：原数组：[1, 2, 3, 4, 5, 6, 7, 8, 9] ，指定参数数组： [a, b, c, 3, 5, 8, f]（<a href="https://blog.csdn.net/weixin_40841731/article/details/85263889" target="_blank" rel="noopener">例子参考自</a>）重新排版</p><table><thead><tr><th>循环次数</th><th>r</th><th>w</th><th>布尔值</th><th>赋值语句</th><th>替换后的数组值</th><th>说明</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>0</td><td>true</td><td>elementData[0]=elementData[0]</td><td>[1, 2, 3, 4, 5, 6, 7, 8, 9]</td><td>1 替换 1，r++ ，w++</td></tr><tr><td>2</td><td>1</td><td>1</td><td>true</td><td>elementData[1]=elementData[1]</td><td>[1, 2, 3, 4, 5, 6, 7, 8, 9]</td><td>2 替换 2，r++ ，w++</td></tr><tr><td>3</td><td>2</td><td>2</td><td>false</td><td></td><td>[1, 2, 3, 4, 5, 6, 7, 8, 9]</td><td></td></tr><tr><td>4</td><td>3</td><td>2</td><td>true</td><td>elementData[2]=elementData[3]</td><td>[1, 2, 4, 4, 5, 6, 7, 8, 9]</td><td>4 替换 3，r++ ，w++</td></tr><tr><td>5</td><td>4</td><td>3</td><td>false</td><td></td><td>[1, 2, 4, 4, 5, 6, 7, 8, 9]</td><td></td></tr><tr><td>6</td><td>5</td><td>3</td><td>true</td><td>elementData[3]=elementData[5]</td><td>[1, 2, 4, 6, 5, 6, 7, 8, 9]</td><td>6 替换 4，r++ ，w++</td></tr><tr><td>7</td><td>6</td><td>4</td><td>true</td><td>elementData[4]=elementData[6]</td><td>[1, 2, 4, 6, 7, 6, 7, 8, 9]</td><td>7 替换 5，r++ ，w++</td></tr><tr><td>8</td><td>7</td><td>5</td><td>false</td><td></td><td>[1, 2, 4, 6, 7, 6, 7, 8, 9]</td><td></td></tr><tr><td>9</td><td>8</td><td>5</td><td>true</td><td>elementData[5]=elementData[8]</td><td>[1, 2, 4, 6, 7, 9, 7, 8, 9]</td><td>9 替换 6，r++ ，w++</td></tr><tr><td></td><td>9</td><td>6</td><td></td><td></td><td></td><td></td></tr></tbody></table><p>自己走一遍上面的逻辑，就能深刻的感受得到</p><p><strong>这步的作用：</strong>把需要移除的数据都替换掉，不需要移除的数据前移。（这步的处理尤为重要！）</p><p>接下来进入 finally 中，这一段是最终肯定会执行的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (r != size) &#123;</span><br><span class="line">    System.arraycopy(elementData, r,elementData, w,size - r);</span><br><span class="line">    w += size - r;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (w != size) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = w; i &lt; size; i++)</span><br><span class="line">        elementData[i] = <span class="keyword">null</span>;</span><br><span class="line">    modCount += size - w;</span><br><span class="line">    size = w;</span><br><span class="line">    modified = <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先判断 r 是否等于 size，如果上面的循环正常执行结束，r 和 size 应该是相同的，所以肯定不会走上面，第一个 if 判断的目的就是为了解决某种异常情况下（异常，并发修改）导致的 for 循环未结束，此时 r != size 所以通过 arraycopy 将添加的元素追加到w索引后面。</p><p>而第二个 if ，主要是为了把 w 之后没处理过的给删掉，这样就可以达到目的了。</p><p>例如上面表格的例子，最后 w = 6，也就是 [1, 2, 4, 6, 7, 9, 7, 8, 9] 中从下标为 6 的元素 7 开始删除，将 7，8，9 赋值为 null 后面会被 GC 清理掉。最后得到的结果 [1, 2, 4, 6, 7, 9] 就是清除过的了 。</p><h3 id="3-4-并发修改异常问题探索"><a href="#3-4-并发修改异常问题探索" class="headerlink" title="3.4 并发修改异常问题探索"></a>3.4 并发修改异常问题探索</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建集合对象</span></span><br><span class="line">    List list = <span class="keyword">new</span> ArrayList();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 存储元素</span></span><br><span class="line">    list.add(<span class="string">"I"</span>);</span><br><span class="line">    list.add(<span class="string">"love"</span>);</span><br><span class="line">    list.add(<span class="string">"you"</span>);</span><br><span class="line"></span><br><span class="line">    Iterator it = list.iterator();</span><br><span class="line">    <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">        String s = (String) it.next();</span><br><span class="line">        <span class="keyword">if</span> (<span class="string">"love"</span>.equals(s)) &#123;</span><br><span class="line">            list.add(<span class="string">"❤"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//运行结果(节选)</span></span><br><span class="line">Exception in thread <span class="string">"main"</span> java.util.ConcurrentModificationException</span><br></pre></td></tr></table></figure><p>使用增强for或者迭代器遍历集合的时候，如果对集合进行 list的 remove 和 add 操作，会出现 ConcurrentModificationException 并发修改异常的问题。</p><h4 id="3-4-1-原因解释："><a href="#3-4-1-原因解释：" class="headerlink" title="3.4.1 原因解释："></a>3.4.1 原因解释：</h4><p>当我们对集合进行遍历的时候，我们会获取当前集合的迭代对象</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//List为例，获取集合的迭代对象</span></span><br><span class="line">Iterator it = list.iterator();</span><br></pre></td></tr></table></figure><p>这个迭代对象中，封装了迭代器的方法与集合本身的一些方法，当我们在迭代中使用集合本身的add / remove方法的时候，就产生了ConcurrentModificationException异常，通俗的说就是，在判断 equals 成功后，执行了 list 的 add / remove 方法， 操作集合中元素或者删除增加了，但是迭代器不清楚，所以就报错，如果迭代器中含有这一种方法（假设），我们是用迭代器添加元素就不会有问题了。</p><p><strong>详细解释</strong>：</p><ul><li><p>开始时，cursor 指向下标为 0 的元素，lastRet 指向下标为 -1 的元素，每次调用 next 方法，cursor 和 lastRet 会分别自增 1。</p></li><li><p>当突然 ArrayList 的 remove 方法被调用（不是 Itr 的 remove），会导致被删除元素后面的所有元素都会往前移动一位，且 modCount 这个修改次数会增加，继续循环，去执行 next 方法，而 next 方法中首先判断的就是 modCount 和 expectedModCount 是否相等，很明显由于 ArrayList  的操作，导致 modCount  变化，两者现在已经不等了，所以出现异常</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">checkForComodification</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (modCount != expectedModCount)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ConcurrentModificationException();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>针对这个问题，我们给出两个解决方案</p><h4 id="3-4-2-解决方案："><a href="#3-4-2-解决方案：" class="headerlink" title="3.4.2 解决方案："></a>3.4.2 解决方案：</h4><h5 id="3-4-2-1-方式1：迭代器迭代元素，迭代器修改元素"><a href="#3-4-2-1-方式1：迭代器迭代元素，迭代器修改元素" class="headerlink" title="3.4.2.1 方式1：迭代器迭代元素，迭代器修改元素"></a>3.4.2.1 方式1：迭代器迭代元素，迭代器修改元素</h5><p>我们假想如果Iterator迭代器中有添加或者删除等功能就好了，但很遗憾并没有，但是它的子接口 ListIterator 却拥有 add 这个功能（ListIterator 拥有 add、set、remove 方法，Iterator 拥有 remove 方法，这里只演示 add 方法，remove 方法就用原来的 Iterator .remove()  ）</p><p>ListIterator 的 add()和 Iterator  的 remove() 可以使用的原因都是因为，方法进行了添加删除操作后，都会执行 expectedModCount = modCount 这样的赋值操作，相当于告诉迭代器我进行了修改操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建集合对象</span></span><br><span class="line">    List list = <span class="keyword">new</span> ArrayList();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 存储元素</span></span><br><span class="line">    list.add(<span class="string">"I"</span>);</span><br><span class="line">    list.add(<span class="string">"love"</span>);</span><br><span class="line">    list.add(<span class="string">"you"</span>);</span><br><span class="line"></span><br><span class="line">    ListIterator lit = list.listIterator();</span><br><span class="line">    <span class="keyword">while</span> (lit.hasNext()) &#123;</span><br><span class="line">        String s = (String) lit.next();</span><br><span class="line">        <span class="keyword">if</span> (<span class="string">"love"</span>.equals(s)) &#123;</span><br><span class="line">            <span class="comment">// add 、remove 都是可以的</span></span><br><span class="line">            lit.add(<span class="string">"❤"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.print(s + <span class="string">" "</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    System.out.println();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (Object l : list)&#123;</span><br><span class="line">    System.out.print(l + <span class="string">" "</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//运行结果</span></span><br><span class="line">I love you</span><br><span class="line">I love ❤ you</span><br></pre></td></tr></table></figure><h5 id="3-4-2-1-方式2：集合遍历元素，集合修改元素（普通for）"><a href="#3-4-2-1-方式2：集合遍历元素，集合修改元素（普通for）" class="headerlink" title="3.4.2.1 方式2：集合遍历元素，集合修改元素（普通for）"></a>3.4.2.1 方式2：集合遍历元素，集合修改元素（普通for）</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.ListIterator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo2</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//创建集合对象</span></span><br><span class="line">        List list = <span class="keyword">new</span> ArrayList();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//存储元素</span></span><br><span class="line">        list.add(<span class="string">"I"</span>);</span><br><span class="line">        list.add(<span class="string">"love"</span>);</span><br><span class="line">        list.add(<span class="string">"you"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> x = <span class="number">0</span>; x &lt; list.size(); x++)&#123;</span><br><span class="line">            String s = (String)list.get(x);</span><br><span class="line">            <span class="keyword">if</span> (<span class="string">"love"</span>.equals(s))&#123;</span><br><span class="line">                list.add(<span class="string">"❤"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.print(s + <span class="string">" "</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//运行结果</span></span><br><span class="line">I love you ❤</span><br></pre></td></tr></table></figure><p>两者均可以解决并发修改异常的问题，但是通过运行结果也可以看出，方法一添加后，在本次遍历中不会输出添加的结果，而方法二却可以。</p><p>补充：增强for循环实现将集合进行遍历，也产生了并发修改异常，这是因为增强for在底层也是调用的集合本身的 remove</p><h4 id="3-4-3-iterator-remove-的弊端"><a href="#3-4-3-iterator-remove-的弊端" class="headerlink" title="3.4.3 iterator.remove() 的弊端"></a>3.4.3 iterator.remove() 的弊端</h4><ul><li>Iterator 只有 remove() 方法，add 方法在 ListIterator  中有</li><li>remove 之前必须先调用 next，remove 开始就对 lastRet 做了不能小于 0 的校验，而l astRet 初始化值为 -1</li><li>next 后只能调用一次 remove，因为 remove 会将 lastRet 重新初始化为 -1</li></ul>]]></content>
      
      
      <categories>
          
          <category> 源码分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 源码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ES-Mapping和聚合查询</title>
      <link href="/posts/a64dc9af/"/>
      <url>/posts/a64dc9af/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="Mapping和聚合查询"><a href="#Mapping和聚合查询" class="headerlink" title="Mapping和聚合查询"></a>Mapping和聚合查询</h2><h2 id="1-Mapping"><a href="#1-Mapping" class="headerlink" title="1. Mapping"></a>1. Mapping</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>mapping 就是 ES 数据字段 field 的 type 元数据，ES在创建索引的时候，dynamic-mapping 会自动的为不同的数据制定相应的 mapping，mapping 中包含了字段的类型、搜索方式（<code>exact value</code> 或者 <code>full text</code>）、分词器等。</p><h3 id="查看-mapping"><a href="#查看-mapping" class="headerlink" title="查看 mapping"></a>查看 mapping</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_mapping</span><br></pre></td></tr></table></figure><h3 id="Dunamic-mapping"><a href="#Dunamic-mapping" class="headerlink" title="Dunamic mapping"></a>Dunamic mapping</h3><ol><li>“ElasticSearch”: text/keyword</li><li>123456: long</li><li>123.123: double</li><li>true false: boolean</li><li>2020-05-20: date</li></ol><blockquote><p>为啥 price是 long类型而不是 integer？因为ES 的mapping type是由JSON分析器检测数据类型，而JSON 没有隐式类型转换（integer =&gt; long  or  float =&gt; double）,所以 dynamic-mapping 会西安则一个比较宽的数据类型。</p></blockquote><h3 id="搜索方式"><a href="#搜索方式" class="headerlink" title="搜索方式"></a>搜索方式</h3><ul><li>exact value 精确搜索：在倒排索引过程中，分词器会将 field作为一个整体创建到索引中。</li><li>full text 全文检索：分词、近义词同义词、混淆词、大小写、词性、过滤、时态转换等（normaliztion）\</li></ul><h3 id="ES-数据类型"><a href="#ES-数据类型" class="headerlink" title="ES 数据类型"></a>ES 数据类型</h3><h4 id="核心类型"><a href="#核心类型" class="headerlink" title="核心类型"></a>核心类型</h4><ol><li><p>数字类型：</p><ol><li>long, integer, short, byte, double, float, half_float, scaled_float</li><li>在满足需求的情况下，尽可能选择范围小的数据类型</li></ol></li><li><p>字符串：string</p><ol><li><p>keyword：适用于索引结构化的字段，可以用于过滤、排序、聚合。keywoed类型的字段只能通过精确值（exact value）搜索到。ID 应该用 keyword</p></li><li><p>text: 当一个字段要被全文搜索的，比如 Email内容、产品描述、这些字段应该使用 text 类型。设置 text 类型以后，字段内容会被分析，在生成倒排索引以前，字符串会被解析器分成一个一个词项。text 类型的字段不用于排序，很少用于聚合。</p><blockquote><p>ES不会为 text创建索引的原因：字段数据会占用大量堆空间，尤其是加载高基数 text 字段时。字段数据一旦加载到堆中，就在该段的生命周期内保持在那里。同样，加载字段数据是一个昂贵的过程，可能导致用户遇到延迟问题。这也就是默认情况下禁用字段数据的原因。</p></blockquote><p>有时，在同一字段中同时具有全文本（text）和关键字（keyword）版本会很有用：一个用于全文本搜索，另一个用于聚合和排序。</p></li></ol></li><li><p>date（时间类型）: exact value</p></li><li><p>布尔类型：boolean</p></li><li><p>binary（二进制）：binary</p></li><li><p>range （区间类型）：integer_range、float_range、long_range、double_range、date_range</p></li></ol><h4 id="复杂类型"><a href="#复杂类型" class="headerlink" title="复杂类型"></a>复杂类型</h4><ol><li>Object：用于单个JSON对象</li><li>Nested: 用于JSON数组对象</li></ol><h4 id="地理位置"><a href="#地理位置" class="headerlink" title="地理位置"></a>地理位置</h4><ol><li>Geo-point: 纬度/经度积分</li><li>Geo-shape: 用于多边形等复杂形状</li></ol><h4 id="特有类型"><a href="#特有类型" class="headerlink" title="特有类型"></a>特有类型</h4><ol><li>IP地址：ip用于 IPv4 和 IPv6 地址</li><li>Completion：提供自动完成建议</li><li>Token_count: 计算字符串中令牌的数量</li><li>Murmur3: 在索引时计算值的哈希并将其存储在索引中</li><li>Annotated-text: 索引包含特殊标记的文本（通常用于标识命名实体）</li><li>Percolator: 接受来自 query-dsl 的查询</li><li>Join: 为统一索引内的文档定义父/子关系</li><li>Rank fearures: 记录数字功能以提高查询时的点击率。</li><li>Dense vector：记录浮点值的密集向量</li><li>Sparse vector: 记录浮点值的稀疏向量</li><li>Search-as-you-type: 针对查询优化的文本字段，以实现按需输入的完成</li><li>Alias: 为现有字段定义别名。</li><li>Flattened: 允许将整个JSON对象索引为单个字段。</li><li>Shape：shape对于任意笛卡尔几何。</li><li>Histogram: histogram用于百分位数聚合的预聚合数值。</li><li>Constant keyword：keyword当所有文档都具有相同值时的情况的专业化。</li></ol><h3 id="Array-数组"><a href="#Array-数组" class="headerlink" title="Array 数组"></a>Array 数组</h3><p>在 ElasticSearch中，数组不需要专用的字段数据类型。默认情况下，任何字段都可以包含零个或多个值，但是，数组中的所有值都必须具有相同的数据类型。</p><h3 id="ES7-新增"><a href="#ES7-新增" class="headerlink" title="ES7 新增"></a>ES7 新增</h3><ol><li>Date_nanos: date plus 纳秒</li><li>Fratures</li><li>Vactor</li></ol><h3 id="手工创建-mapping"><a href="#手工创建-mapping" class="headerlink" title="手工创建 mapping"></a>手工创建 mapping</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">PUT /product</span><br><span class="line">&#123;</span><br><span class="line">  "mappings":&#123;</span><br><span class="line">    "properties": &#123;</span><br><span class="line">      "field": &#123;</span><br><span class="line">        "mapping_parameter": "parameter_value"</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Mapping-parameters"><a href="#Mapping-parameters" class="headerlink" title="Mapping parameters"></a>Mapping parameters</h3><ol><li><p>index: 是否对当前字段创建索引，默认 true，如果不创建索引，该字段不会通过索引被搜索到，但是仍然会在 source 元数据中展示</p></li><li><p>analyzer: 指定分析器（character filter、tokenizer、Token filters）</p></li><li><p>boost: 对当前字段相关度的评分权重，默认 1</p></li><li><p>coerce：是否允许强制类型转换 true “1” =&gt; 1   false “1” =&lt; 1</p></li><li><p>copy_to:</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">"field": &#123;</span><br><span class="line">  "type": "text",</span><br><span class="line">  "copy_to": "other_field_name"</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>doc_values: 为了提升排序和聚合效率，默认为 true，如果确定不需要对字段进行排序或聚合，也不需要通过脚本访问字段值，则可以禁用doc值节省磁盘空间（不支持 text 和 annotated_text）</p></li><li><p>dynamic: 控制是否可以动态添加新字段</p><ol><li>true 新检测到的字段将添加到映射中（默认）</li><li>false 新检测到的字段将被忽略。这些字段将不会被索引，因此将无法搜索，但仍会出现在_source返回的匹配项中。这些字段不会添加到映射中，必须显式添加新字段</li><li>strict 如果检测到新字段，则会引发异常并拒绝文档。必须将新字段显示添加到映射中。</li></ol></li><li><p>eager_global_ordinals：用于聚合的字段上，优化聚合性能。</p><blockquote><p>frozen indices (冻结索引)：有些索引的使用率很高，会被保存在内存中，有些使用率特别低，宁愿在使用的时候再重新创建，在使用完毕丢弃数据，Forzen indices 的数据命中频率小，不适用于高搜索负载，数据不会被保存在内存中，堆空间占用比普通索引少的多，Forzen indices 是只读的，请求可能是秒级或者分钟级。eager_global_ordinals 不适用于 Frozen indices    </p></blockquote></li><li><p>enable：是否创建倒排索引，可以对字段操作，也可以对索引操作，如果不创建索引，仍然可以检索并在 _source 元数据中展示，谨慎使用，该状态无法更改。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  "mappings": &#123;</span><br><span class="line">  "enabled": false</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  "mappings": &#123;</span><br><span class="line">    "properties": &#123;</span><br><span class="line">  "session_data": &#123;</span><br><span class="line">      "type": "object",</span><br><span class="line">      "enabled": false</span><br><span class="line">  &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>fielddata: 查询时内存数据结构，在首次用当前字段聚合、排序或者在脚本中使用时，需要字段为 fielddata 数据结构，并且创建倒排索引保存到堆中</p></li><li><p>fields: 给 field 创建多字段，用于不同目的（全文检索或者聚合分析排序）</p></li><li><p>format：格式化</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">"date": &#123;</span><br><span class="line">  "type": "date",</span><br><span class="line">  "format": "yyyy-MM-dd"</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>ignore_above: 超出长度将被忽略</p></li><li><p>ignore_malformed: 忽略类型错误</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  "mappings": &#123;</span><br><span class="line">    "properties": &#123;</span><br><span class="line">      "number_one": &#123;</span><br><span class="line">        "type": "integer",</span><br><span class="line">        "ignore_malformed": true</span><br><span class="line">      &#125;,</span><br><span class="line">      "number_two": &#123;</span><br><span class="line">        "type": "integer"</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  "text": "Some text value",</span><br><span class="line">  "number_one": "foo"</span><br><span class="line">&#125;</span><br><span class="line">// 虽然有异常，但是不抛出</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index/_doc/2</span><br><span class="line">&#123;</span><br><span class="line">  "text": "Some text value",</span><br><span class="line">  "number_two": "foo"</span><br><span class="line">&#125;</span><br><span class="line">// 有异常：数据格式不对</span><br></pre></td></tr></table></figure></li><li><p>index_options: 控制将哪些信息添加到反向索引中以进行搜索和突出显示。仅用于text 字段</p></li><li><p>index_phrases: 提升exact_value 查询速递，但是要消耗更多磁盘空间</p></li><li><p>index_prefixes: 前缀搜索</p><ol><li><p>min_chars: 前缀最小长度，&gt;0, 默认2 （包含）</p></li><li><p>max_chars: 前缀最大长度, &lt;20，默认5 （包含）</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">"index_prefixes": &#123;</span><br><span class="line">  "min_chars": 1,</span><br><span class="line">  "max_chars": 10</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li><li><p>meta: 附加元数据</p></li><li><p>normalizer</p></li><li><p>norms: 是否禁用评分（在 filter 和聚合字段上应该禁用）</p></li><li><p>null_value: 为 null值设置默认值</p><blockquote><p>“null_value”: “NULL”</p></blockquote></li><li><p>position_increment_gap</p></li><li><p>proterties: 除了 mapping 还可用于 objet 的属性设置</p></li><li><p>search_analyzer: 设置单独的查询时分析器</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  "settings": &#123;</span><br><span class="line">    "analysis": &#123;</span><br><span class="line">      "filter": &#123;</span><br><span class="line">        "autocomplete_filter": &#123;</span><br><span class="line">          "type": "edge_ngram",</span><br><span class="line">          "min_gram": 1,</span><br><span class="line">          "max_gram": 20</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      "analyzer": &#123;</span><br><span class="line">        "autocomplete": &#123;</span><br><span class="line">          "type": "custom",</span><br><span class="line">          "tokenizer": "standard",</span><br><span class="line">          "filter": [</span><br><span class="line">            "lowercase",</span><br><span class="line">            "autocomplete_filter"</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  "mappings": &#123;</span><br><span class="line">    "properties": &#123;</span><br><span class="line">      "text": &#123;</span><br><span class="line">        "type": "text",</span><br><span class="line">        "analyzer": "autocomplete",</span><br><span class="line">        "search_analyzer": "standard"</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  "text": "Quick Brown Fox"</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET my_index/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "match": &#123;</span><br><span class="line">      "text": &#123;</span><br><span class="line">        "query": "Quick Bar",</span><br><span class="line">        "operator": "and"</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>similarity: 为字段设置相关度算法，支持 BM25、 classic ( TF-IDF )、boolean</p></li><li><p>store: 设置字段是否仅查询</p></li><li><p>term_vector</p></li></ol><h2 id="2-聚合查询"><a href="#2-聚合查询" class="headerlink" title="2. 聚合查询"></a>2. 聚合查询</h2><h3 id="bucket-和-metirc"><a href="#bucket-和-metirc" class="headerlink" title="bucket 和 metirc:"></a>bucket 和 metirc:</h3><h3 id="语法："><a href="#语法：" class="headerlink" title="语法："></a>语法：</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">aggs</span>: &#123;</span><br><span class="line">  code...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="group-by"><a href="#group-by" class="headerlink" title="group by"></a>group by</h3><ol><li>以 tag 维度每个产品的数量，即每个标签</li><li>在的基础上增加筛选条件: 统计价格大于 1999 的数据</li></ol><h3 id="avg"><a href="#avg" class="headerlink" title="avg"></a>avg</h3><ul><li>价格大于 1999 的 每个 tag 产品的平均价格</li></ul><h3 id="分组聚合"><a href="#分组聚合" class="headerlink" title="分组聚合"></a>分组聚合</h3><p>按照千元机： 1000以下 中端机： 2000-3000 高端机：3000 以上分组聚合，分别计算数量</p>]]></content>
      
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Curator使用教程</title>
      <link href="/posts/bb75348e/"/>
      <url>/posts/bb75348e/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="Zookeeper客户端Curator使用详解"><a href="#Zookeeper客户端Curator使用详解" class="headerlink" title="Zookeeper客户端Curator使用详解"></a>Zookeeper客户端Curator使用详解</h1><blockquote><p>本文转载自 <a href="http://www.throwable.club/2018/12/16/zookeeper-curator-usage/" target="_blank" rel="noopener">http://www.throwable.club/2018/12/16/zookeeper-curator-usage/</a></p><p>著作权归原作者所有</p></blockquote><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Curator是Netflix公司开源的一套zookeeper客户端框架，解决了很多Zookeeper客户端非常底层的细节开发工作，包括连接重连、反复注册Watcher和NodeExistsException异常等等。Patrixck Hunt（Zookeeper）以一句“Guava is to Java that Curator to Zookeeper”给Curator予高度评价。</p><h3 id="引子和趣闻："><a href="#引子和趣闻：" class="headerlink" title="引子和趣闻："></a>引子和趣闻：</h3><p>Zookeeper名字的由来是比较有趣的，下面的片段摘抄自《从PAXOS到ZOOKEEPER分布式一致性原理与实践》一书：</p><p>Zookeeper最早起源于雅虎的研究院的一个研究小组。在当时，研究人员发现，在雅虎内部很多大型的系统需要依赖一个类似的系统进行分布式协调，但是这些系统往往存在分布式单点问题。所以雅虎的开发人员就试图开发一个通用的无单点问题的分布式协调框架。在立项初期，考虑到很多项目都是用动物的名字来命名的(例如著名的Pig项目)，雅虎的工程师希望给这个项目也取一个动物的名字。时任研究院的首席科学家Raghu Ramakrishnan开玩笑说：再这样下去，我们这儿就变成动物园了。此话一出，大家纷纷表示就叫动物园管理员吧——因为各个以动物命名的分布式组件放在一起，雅虎的整个分布式系统看上去就像一个大型的动物园了，而Zookeeper正好用来进行分布式环境的协调——于是，Zookeeper的名字由此诞生了。</p><p>Curator无疑是Zookeeper客户端中的瑞士军刀，它译作”馆长”或者’‘管理者’’，不知道是不是开发小组有意而为之，笔者猜测有可能这样命名的原因是说明Curator就是Zookeeper的馆长(脑洞有点大：Curator就是动物园的园长)。</p><p>Curator包含了几个包：</p><ul><li><strong>curator-framework</strong>：对zookeeper的底层api的一些封装。</li><li><strong>curator-client</strong>：提供一些客户端的操作，例如重试策略等。</li><li><strong>curator-recipes</strong>：封装了一些高级特性，如：Cache事件监听、选举、分布式锁、分布式计数器、分布式Barrier等。</li></ul><p>Maven依赖(使用curator的版本：2.12.0，对应Zookeeper的版本为：3.4.x，<strong>如果跨版本会有兼容性问题，很有可能导致节点操作失败</strong>)：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.curator<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>curator-framework<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.12.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.curator<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>curator-recipes<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.12.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="Curator的基本Api"><a href="#Curator的基本Api" class="headerlink" title="Curator的基本Api"></a>Curator的基本Api</h2><h3 id="创建会话"><a href="#创建会话" class="headerlink" title="创建会话"></a>创建会话</h3><ol><li><p>使用静态工程方法创建客户端</p><p>一个例子如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">RetryPolicy retryPolicy = <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>);</span><br><span class="line">CuratorFramework client =</span><br><span class="line">CuratorFrameworkFactory.newClient(</span><br><span class="line">connectionInfo,</span><br><span class="line"><span class="number">5000</span>,</span><br><span class="line"><span class="number">3000</span>,</span><br><span class="line">retryPolicy);</span><br></pre></td></tr></table></figure><p>newClient静态工厂方法包含四个主要参数：</p><table><thead><tr><th>参数名</th><th>说明</th></tr></thead><tbody><tr><td>connectionString</td><td>服务器列表，格式host1:port1,host2:port2,…</td></tr><tr><td>retryPolicy</td><td>重试策略,内建有四种重试策略,也可以自行实现RetryPolicy接口</td></tr><tr><td>sessionTimeoutMs</td><td>会话超时时间，单位毫秒，默认60000ms</td></tr><tr><td>connectionTimeoutMs</td><td>连接创建超时时间，单位毫秒，默认60000ms</td></tr></tbody></table></li><li><p>使用Fluent风格的Api创建会话</p><p>核心参数变为流式设置，一个列子如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">RetryPolicy retryPolicy = <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>);</span><br><span class="line">CuratorFramework client =</span><br><span class="line">    CuratorFrameworkFactory.builder()</span><br><span class="line">    .connectString(connectionInfo)</span><br><span class="line">    .sessionTimeoutMs(<span class="number">5000</span>)</span><br><span class="line">    .connectionTimeoutMs(<span class="number">5000</span>)</span><br><span class="line">    .retryPolicy(retryPolicy)</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></li></ol><ol start="3"><li><p>创建包含隔离命名空间的会话</p><p>为了实现不同的Zookeeper业务之间的隔离，需要为每个业务分配一个独立的命名空间（<strong>NameSpace</strong>），即指定一个Zookeeper的根路径（官方术语：<strong><em>为Zookeeper添加“Chroot”特性</em></strong>）。例如（下面的例子）当客户端指定了独立命名空间为“/base”，那么该客户端对Zookeeper上的数据节点的操作都是基于该目录进行的。通过设置Chroot可以将客户端应用与Zookeeper服务端的一课子树相对应，在多个应用共用一个Zookeeper集群的场景下，这对于实现不同应用之间的相互隔离十分有意义。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">RetryPolicy retryPolicy = <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>);</span><br><span class="line">CuratorFramework client =</span><br><span class="line">CuratorFrameworkFactory.builder()</span><br><span class="line">.connectString(connectionInfo)</span><br><span class="line">.sessionTimeoutMs(<span class="number">5000</span>)</span><br><span class="line">.connectionTimeoutMs(<span class="number">5000</span>)</span><br><span class="line">.retryPolicy(retryPolicy)</span><br><span class="line">.namespace(<span class="string">"base"</span>)</span><br><span class="line">.build();</span><br></pre></td></tr></table></figure></li></ol><h3 id="启动客户端"><a href="#启动客户端" class="headerlink" title="启动客户端"></a>启动客户端</h3><p>当创建会话成功，得到client的实例然后可以直接调用其start( )方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.start();</span><br></pre></td></tr></table></figure><h3 id="数据节点操作"><a href="#数据节点操作" class="headerlink" title="数据节点操作"></a>数据节点操作</h3><h4 id="创建数据节点"><a href="#创建数据节点" class="headerlink" title="创建数据节点"></a>创建数据节点</h4><p><strong>Zookeeper的节点创建模式</strong>：</p><ul><li>PERSISTENT：持久化</li><li>PERSISTENT_SEQUENTIAL：持久化并且带序列号</li><li>EPHEMERAL：临时</li><li>EPHEMERAL_SEQUENTIAL：临时并且带序列号</li></ul><p><strong>创建一个节点，初始内容为空</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.create().forPath(<span class="string">"path"</span>);</span><br></pre></td></tr></table></figure><p>注意：如果没有设置节点属性，节点创建模式默认为持久化节点，内容默认为空</p><p><strong>创建一个节点，附带初始化内容</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.create().forPath(<span class="string">"path"</span>,<span class="string">"init"</span>.getBytes());</span><br></pre></td></tr></table></figure><p><strong>创建一个节点，指定创建模式（临时节点），内容为空</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.create().withMode(CreateMode.EPHEMERAL).forPath(<span class="string">"path"</span>);</span><br></pre></td></tr></table></figure><p><strong>创建一个节点，指定创建模式（临时节点），附带初始化内容</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.create().withMode(CreateMode.EPHEMERAL).forPath(<span class="string">"path"</span>,<span class="string">"init"</span>.getBytes());</span><br></pre></td></tr></table></figure><p><strong>创建一个节点，指定创建模式（临时节点），附带初始化内容，并且自动递归创建父节点</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">client.create()</span><br><span class="line">      .creatingParentContainersIfNeeded()</span><br><span class="line">      .withMode(CreateMode.EPHEMERAL)</span><br><span class="line">      .forPath(<span class="string">"path"</span>,<span class="string">"init"</span>.getBytes());</span><br></pre></td></tr></table></figure><p>这个creatingParentContainersIfNeeded()接口非常有用，因为一般情况开发人员在创建一个子节点必须判断它的父节点是否存在，如果不存在直接创建会抛出NoNodeException，使用creatingParentContainersIfNeeded()之后Curator能够自动递归创建所有所需的父节点。</p><h4 id="删除数据节点"><a href="#删除数据节点" class="headerlink" title="删除数据节点"></a>删除数据节点</h4><p><strong>删除一个节点</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.delete().forPath(<span class="string">"path"</span>);</span><br></pre></td></tr></table></figure><p>注意，此方法只能删除<strong>叶子节点</strong>，否则会抛出异常。</p><p><strong>删除一个节点，并且递归删除其所有的子节点</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.delete().deletingChildrenIfNeeded().forPath(<span class="string">"path"</span>);</span><br></pre></td></tr></table></figure><p><strong>删除一个节点，强制指定版本进行删除</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.delete().withVersion(<span class="number">10086</span>).forPath(<span class="string">"path"</span>);</span><br></pre></td></tr></table></figure><p><strong>删除一个节点，强制保证删除</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.delete().guaranteed().forPath(<span class="string">"path"</span>);</span><br></pre></td></tr></table></figure><p>guaranteed()接口是一个保障措施，只要客户端会话有效，那么Curator会在后台持续进行删除操作，直到删除节点成功。</p><p><strong>注意：</strong>上面的多个流式接口是可以自由组合的，例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.delete().guaranteed().deletingChildrenIfNeeded().withVersion(<span class="number">10086</span>).forPath(<span class="string">"path"</span>);</span><br></pre></td></tr></table></figure><h4 id="读取数据节点数据"><a href="#读取数据节点数据" class="headerlink" title="读取数据节点数据"></a>读取数据节点数据</h4><p><strong>读取一个节点的数据内容</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.getData().forPath(<span class="string">"path"</span>);</span><br></pre></td></tr></table></figure><p>注意，此方法返的返回值是byte[ ];</p><p><strong>读取一个节点的数据内容，同时获取到该节点的stat</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Stat stat = <span class="keyword">new</span> Stat();</span><br><span class="line">client.getData().storingStatIn(stat).forPath(<span class="string">"path"</span>);</span><br></pre></td></tr></table></figure><h4 id="更新数据节点数据"><a href="#更新数据节点数据" class="headerlink" title="更新数据节点数据"></a>更新数据节点数据</h4><p><strong>更新一个节点的数据内容</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.setData().forPath(<span class="string">"path"</span>,<span class="string">"data"</span>.getBytes());</span><br></pre></td></tr></table></figure><p>注意：该接口会返回一个Stat实例</p><p><strong>更新一个节点的数据内容，强制指定版本进行更新</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.setData().withVersion(<span class="number">10086</span>).forPath(<span class="string">"path"</span>,<span class="string">"data"</span>.getBytes());</span><br></pre></td></tr></table></figure><h4 id="检查节点是否存在"><a href="#检查节点是否存在" class="headerlink" title="检查节点是否存在"></a>检查节点是否存在</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.checkExists().forPath(<span class="string">"path"</span>);</span><br></pre></td></tr></table></figure><p>注意：该方法返回一个Stat实例，用于检查ZNode是否存在的操作. 可以调用额外的方法(监控或者后台处理)并在最后调用<code>forPath()</code>指定要操作的ZNode</p><h4 id="获取某个节点的所有子节点路径"><a href="#获取某个节点的所有子节点路径" class="headerlink" title="获取某个节点的所有子节点路径"></a>获取某个节点的所有子节点路径</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client.getChildren().forPath(<span class="string">"path"</span>);</span><br></pre></td></tr></table></figure><p>注意：该方法的返回值为List,获得ZNode的子节点Path列表。 可以调用额外的方法(监控、后台处理或者获取状态watch, background or get stat) 并在最后调用forPath()指定要操作的父ZNode</p><h4 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h4><p>CuratorFramework的实例包含inTransaction( )接口方法，调用此方法开启一个ZooKeeper事务. 可以复合create, setData, check, and/or delete 等操作然后调用commit()作为一个原子操作提交。一个例子如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">client.inTransaction().check().forPath(<span class="string">"path"</span>)</span><br><span class="line">      .and()</span><br><span class="line">      .create().withMode(CreateMode.EPHEMERAL).forPath(<span class="string">"path"</span>,<span class="string">"data"</span>.getBytes())</span><br><span class="line">      .and()</span><br><span class="line">      .setData().withVersion(<span class="number">10086</span>).forPath(<span class="string">"path"</span>,<span class="string">"data2"</span>.getBytes())</span><br><span class="line">      .and()</span><br><span class="line">      .commit();</span><br></pre></td></tr></table></figure><h4 id="异步接口"><a href="#异步接口" class="headerlink" title="异步接口"></a>异步接口</h4><p>上面提到的创建、删除、更新、读取等方法都是同步的，Curator提供异步接口，引入了<strong>BackgroundCallback</strong>接口用于处理异步接口调用之后服务端返回的结果信息。<strong>BackgroundCallback</strong>接口中一个重要的回调值为CuratorEvent，里面包含事件类型、响应吗和节点的详细信息。</p><p><strong>CuratorEventType</strong></p><table><thead><tr><th align="center">事件类型</th><th align="center">对应CuratorFramework实例的方法</th></tr></thead><tbody><tr><td align="center">CREATE</td><td align="center">#create()</td></tr><tr><td align="center">DELETE</td><td align="center">#delete()</td></tr><tr><td align="center">EXISTS</td><td align="center">#checkExists()</td></tr><tr><td align="center">GET_DATA</td><td align="center">#getData()</td></tr><tr><td align="center">SET_DATA</td><td align="center">#setData()</td></tr><tr><td align="center">CHILDREN</td><td align="center">#getChildren()</td></tr><tr><td align="center">SYNC</td><td align="center">#sync(String,Object)</td></tr><tr><td align="center">GET_ACL</td><td align="center">#getACL()</td></tr><tr><td align="center">SET_ACL</td><td align="center">#setACL()</td></tr><tr><td align="center">WATCHED</td><td align="center">#Watcher(Watcher)</td></tr><tr><td align="center">CLOSING</td><td align="center">#close()</td></tr></tbody></table><p><strong>响应码(#getResultCode())</strong></p><table><thead><tr><th align="center">响应码</th><th align="center">意义</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">OK，即调用成功</td></tr><tr><td align="center">-4</td><td align="center">ConnectionLoss，即客户端与服务端断开连接</td></tr><tr><td align="center">-110</td><td align="center">NodeExists，即节点已经存在</td></tr><tr><td align="center">-112</td><td align="center">SessionExpired，即会话过期</td></tr></tbody></table><p>一个异步创建节点的例子如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Executor executor = Executors.newFixedThreadPool(<span class="number">2</span>);</span><br><span class="line">client.create()</span><br><span class="line">      .creatingParentsIfNeeded()</span><br><span class="line">      .withMode(CreateMode.EPHEMERAL)</span><br><span class="line">      .inBackground((curatorFramework, curatorEvent) -&gt; &#123;      System.out.println(String.format(<span class="string">"eventType:%s,resultCode:%s"</span>,curatorEvent.getType(),curatorEvent.getResultCode()));</span><br><span class="line">      &#125;,executor)</span><br><span class="line">      .forPath(<span class="string">"path"</span>);</span><br></pre></td></tr></table></figure><p>注意：如果#inBackground()方法不指定executor，那么会默认使用Curator的EventThread去进行异步处理。</p><h2 id="Curator食谱-高级特性"><a href="#Curator食谱-高级特性" class="headerlink" title="Curator食谱(高级特性)"></a>Curator食谱(高级特性)</h2><p><strong>提醒：首先你必须添加curator-recipes依赖，下文仅仅对recipes一些特性的使用进行解释和举例，不打算进行源码级别的探讨</strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.curator<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>curator-recipes<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.12.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>重要提醒：强烈推荐使用ConnectionStateListener监控连接的状态，当连接状态为LOST，curator-recipes下的所有Api将会失效或者过期，尽管后面所有的例子都没有使用到ConnectionStateListener。</strong></p><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>Zookeeper原生支持通过注册Watcher来进行事件监听，但是开发者需要反复注册(Watcher只能单次注册单次使用)。Cache是Curator中对事件监听的包装，可以看作是对事件监听的本地缓存视图，能够自动为开发者处理反复注册监听。Curator提供了三种Watcher(Cache)来监听结点的变化。</p><h4 id="Path-Cache"><a href="#Path-Cache" class="headerlink" title="Path Cache"></a>Path Cache</h4><p>Path Cache用来监控一个ZNode的子节点. 当一个子节点增加， 更新，删除时， Path Cache会改变它的状态， 会包含最新的子节点， 子节点的数据和状态，而状态的更变将通过PathChildrenCacheListener通知。</p><p>实际使用时会涉及到四个类：</p><ul><li>PathChildrenCache</li><li>PathChildrenCacheEvent</li><li>PathChildrenCacheListener</li><li>ChildData</li></ul><p>通过下面的构造函数创建Path Cache:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">PathChildrenCache</span><span class="params">(CuratorFramework client, String path, <span class="keyword">boolean</span> cacheData)</span></span></span><br></pre></td></tr></table></figure><p>想使用cache，必须调用它的<code>start</code>方法，使用完后调用<code>close</code>方法。 可以设置StartMode来实现启动的模式，</p><p>StartMode有下面几种：</p><ol><li>NORMAL：正常初始化。</li><li>BUILD_INITIAL_CACHE：在调用<code>start()</code>之前会调用<code>rebuild()</code>。</li><li>POST_INITIALIZED_EVENT： 当Cache初始化数据后发送一个PathChildrenCacheEvent.Type#INITIALIZED事件</li></ol><p><code>public void addListener(PathChildrenCacheListener listener)</code>可以增加listener监听缓存的变化。</p><p><code>getCurrentData()</code>方法返回一个<code>List&lt;ChildData&gt;</code>对象，可以遍历所有的子节点。</p><p><strong>设置/更新、移除其实是使用client (CuratorFramework)来操作, 不通过PathChildrenCache操作：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PathCacheDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/example/pathCache"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">TestingServer server = <span class="keyword">new</span> TestingServer();</span><br><span class="line">CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">client.start();</span><br><span class="line">PathChildrenCache cache = <span class="keyword">new</span> PathChildrenCache(client, PATH, <span class="keyword">true</span>);</span><br><span class="line">cache.start();</span><br><span class="line">PathChildrenCacheListener cacheListener = (client1, event) -&gt; &#123;</span><br><span class="line">System.out.println(<span class="string">"事件类型："</span> + event.getType());</span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">null</span> != event.getData()) &#123;</span><br><span class="line">System.out.println(<span class="string">"节点数据："</span> + event.getData().getPath() + <span class="string">" = "</span> + <span class="keyword">new</span> String(event.getData().getData()));</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line">cache.getListenable().addListener(cacheListener);</span><br><span class="line">client.create().creatingParentsIfNeeded().forPath(<span class="string">"/example/pathCache/test01"</span>, <span class="string">"01"</span>.getBytes());</span><br><span class="line">Thread.sleep(<span class="number">10</span>);</span><br><span class="line">client.create().creatingParentsIfNeeded().forPath(<span class="string">"/example/pathCache/test02"</span>, <span class="string">"02"</span>.getBytes());</span><br><span class="line">Thread.sleep(<span class="number">10</span>);</span><br><span class="line">client.setData().forPath(<span class="string">"/example/pathCache/test01"</span>, <span class="string">"01_V2"</span>.getBytes());</span><br><span class="line">Thread.sleep(<span class="number">10</span>);</span><br><span class="line"><span class="keyword">for</span> (ChildData data : cache.getCurrentData()) &#123;</span><br><span class="line">System.out.println(<span class="string">"getCurrentData:"</span> + data.getPath() + <span class="string">" = "</span> + <span class="keyword">new</span> String(data.getData()));</span><br><span class="line">&#125;</span><br><span class="line">client.delete().forPath(<span class="string">"/example/pathCache/test01"</span>);</span><br><span class="line">Thread.sleep(<span class="number">10</span>);</span><br><span class="line">client.delete().forPath(<span class="string">"/example/pathCache/test02"</span>);</span><br><span class="line">Thread.sleep(<span class="number">1000</span> * <span class="number">5</span>);</span><br><span class="line">cache.close();</span><br><span class="line">client.close();</span><br><span class="line">System.out.println(<span class="string">"OK!"</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>注意：</strong>如果new PathChildrenCache(client, PATH, true)中的参数cacheData值设置为false，则示例中的event.getData().getData()、data.getData()将返回null，cache将不会缓存节点数据。</p><p><strong>注意：</strong>示例中的Thread.sleep(10)可以注释掉，但是注释后事件监听的触发次数会不全，这可能与PathCache的实现原理有关，不能太过频繁的触发事件！</p><h4 id="Node-Cache"><a href="#Node-Cache" class="headerlink" title="Node Cache"></a>Node Cache</h4><p>Node Cache与Path Cache类似，Node Cache只是监听某一个特定的节点。它涉及到下面的三个类：</p><ul><li><code>NodeCache</code> - Node Cache实现类</li><li><code>NodeCacheListener</code> - 节点监听器</li><li><code>ChildData</code> - 节点数据</li></ul><p><strong>注意：</strong>使用cache，依然要调用它的<code>start()</code>方法，使用完后调用<code>close()</code>方法。</p><p>getCurrentData()将得到节点当前的状态，通过它的状态可以得到当前的值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NodeCacheDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/example/cache"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">TestingServer server = <span class="keyword">new</span> TestingServer();</span><br><span class="line">CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">client.start();</span><br><span class="line">client.create().creatingParentsIfNeeded().forPath(PATH);</span><br><span class="line"><span class="keyword">final</span> NodeCache cache = <span class="keyword">new</span> NodeCache(client, PATH);</span><br><span class="line">NodeCacheListener listener = () -&gt; &#123;</span><br><span class="line">ChildData data = cache.getCurrentData();</span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">null</span> != data) &#123;</span><br><span class="line">System.out.println(<span class="string">"节点数据："</span> + <span class="keyword">new</span> String(cache.getCurrentData().getData()));</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">System.out.println(<span class="string">"节点被删除!"</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line">cache.getListenable().addListener(listener);</span><br><span class="line">cache.start();</span><br><span class="line">client.setData().forPath(PATH, <span class="string">"01"</span>.getBytes());</span><br><span class="line">Thread.sleep(<span class="number">100</span>);</span><br><span class="line">client.setData().forPath(PATH, <span class="string">"02"</span>.getBytes());</span><br><span class="line">Thread.sleep(<span class="number">100</span>);</span><br><span class="line">client.delete().deletingChildrenIfNeeded().forPath(PATH);</span><br><span class="line">Thread.sleep(<span class="number">1000</span> * <span class="number">2</span>);</span><br><span class="line">cache.close();</span><br><span class="line">client.close();</span><br><span class="line">System.out.println(<span class="string">"OK!"</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>注意：</strong>示例中的Thread.sleep(10)可以注释，但是注释后事件监听的触发次数会不全，这可能与NodeCache的实现原理有关，不能太过频繁的触发事件！</p><p><strong>注意：</strong>NodeCache只能监听一个节点的状态变化。</p><h4 id="Tree-Cache"><a href="#Tree-Cache" class="headerlink" title="Tree Cache"></a>Tree Cache</h4><p>Tree Cache可以监控整个树上的所有节点，类似于PathCache和NodeCache的组合，主要涉及到下面四个类：</p><ul><li>TreeCache - Tree Cache实现类</li><li>TreeCacheListener - 监听器类</li><li>TreeCacheEvent - 触发的事件类</li><li>ChildData - 节点数据</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeCacheDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/example/cache"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">TestingServer server = <span class="keyword">new</span> TestingServer();</span><br><span class="line">CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">client.start();</span><br><span class="line">client.create().creatingParentsIfNeeded().forPath(PATH);</span><br><span class="line">TreeCache cache = <span class="keyword">new</span> TreeCache(client, PATH);</span><br><span class="line">TreeCacheListener listener = (client1, event) -&gt;</span><br><span class="line">System.out.println(<span class="string">"事件类型："</span> + event.getType() +</span><br><span class="line"><span class="string">" | 路径："</span> + (<span class="keyword">null</span> != event.getData() ? event.getData().getPath() : <span class="keyword">null</span>));</span><br><span class="line">cache.getListenable().addListener(listener);</span><br><span class="line">cache.start();</span><br><span class="line">client.setData().forPath(PATH, <span class="string">"01"</span>.getBytes());</span><br><span class="line">Thread.sleep(<span class="number">100</span>);</span><br><span class="line">client.setData().forPath(PATH, <span class="string">"02"</span>.getBytes());</span><br><span class="line">Thread.sleep(<span class="number">100</span>);</span><br><span class="line">client.delete().deletingChildrenIfNeeded().forPath(PATH);</span><br><span class="line">Thread.sleep(<span class="number">1000</span> * <span class="number">2</span>);</span><br><span class="line">cache.close();</span><br><span class="line">client.close();</span><br><span class="line">System.out.println(<span class="string">"OK!"</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>注意：</strong>在此示例中没有使用Thread.sleep(10)，但是事件触发次数也是正常的。</p><p><strong>注意：</strong>TreeCache在初始化(调用<code>start()</code>方法)的时候会回调<code>TreeCacheListener</code>实例一个事TreeCacheEvent，而回调的TreeCacheEvent对象的Type为INITIALIZED，ChildData为null，此时<code>event.getData().getPath()</code>很有可能导致空指针异常，这里应该主动处理并避免这种情况。</p><h3 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h3><p>在分布式计算中， <strong>leader elections</strong>是很重要的一个功能， 这个选举过程是这样子的： 指派一个进程作为组织者，将任务分发给各节点。 在任务开始前， 哪个节点都不知道谁是leader(领导者)或者coordinator(协调者). 当选举算法开始执行后， 每个节点最终会得到一个唯一的节点作为任务leader. 除此之外， 选举还经常会发生在leader意外宕机的情况下，新的leader要被选举出来。</p><p>在zookeeper集群中，leader负责写操作，然后通过Zab协议实现follower的同步，leader或者follower都可以处理读操作。</p><p>Curator 有两种leader选举的recipe,分别是<strong>LeaderSelector</strong>和<strong>LeaderLatch</strong>。</p><p>前者是所有存活的客户端不间断的轮流做Leader，大同社会。后者是一旦选举出Leader，除非有客户端挂掉重新触发选举，否则不会交出领导权。某党?</p><h4 id="LeaderLatch"><a href="#LeaderLatch" class="headerlink" title="LeaderLatch"></a>LeaderLatch</h4><p>LeaderLatch有两个构造函数：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">LeaderLatch</span><span class="params">(CuratorFramework client, String latchPath)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">LeaderLatch</span><span class="params">(CuratorFramework client, String latchPath,  String id)</span></span></span><br></pre></td></tr></table></figure><p>LeaderLatch的启动：</p><p><strong>leaderLatch.start( );</strong></p><p>一旦启动，LeaderLatch会和其它使用相同latch path的其它LeaderLatch交涉，然后其中一个最终会被选举为leader，可以通过<code>hasLeadership</code>方法查看LeaderLatch实例是否leader：</p><p><strong>leaderLatch.hasLeadership( );</strong> //返回true说明当前实例是leader</p><p>类似JDK的CountDownLatch， LeaderLatch在请求成为leadership会block(阻塞)，一旦不使用LeaderLatch了，必须调用<code>close</code>方法。 如果它是leader,会释放leadership， 其它的参与者将会选举一个leader。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">await</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException,EOFException</span></span><br><span class="line"><span class="function"><span class="comment">/*Causes the current thread to wait until this instance acquires leadership</span></span></span><br><span class="line"><span class="function"><span class="comment">unless the thread is interrupted or closed.*/</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">await</span><span class="params">(<span class="keyword">long</span> timeout,TimeUnit unit)</span><span class="keyword">throws</span> InterruptedException</span></span><br></pre></td></tr></table></figure><p><strong>异常处理：</strong> LeaderLatch实例可以增加ConnectionStateListener来监听网络连接问题。 当 SUSPENDED 或 LOST 时, leader不再认为自己还是leader。当LOST后连接重连后RECONNECTED,LeaderLatch会删除先前的ZNode然后重新创建一个。LeaderLatch用户必须考虑导致leadership丢失的连接问题。 强烈推荐你使用ConnectionStateListener。</p><p>一个LeaderLatch的使用例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LeaderLatchDemo</span> <span class="keyword">extends</span> <span class="title">BaseConnectionInfo</span> </span>&#123;</span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">static</span> String PATH = <span class="string">"/francis/leader"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> CLIENT_QTY = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">List&lt;CuratorFramework&gt; clients = Lists.newArrayList();</span><br><span class="line">List&lt;LeaderLatch&gt; examples = Lists.newArrayList();</span><br><span class="line">TestingServer server=<span class="keyword">new</span> TestingServer();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; CLIENT_QTY; i++) &#123;</span><br><span class="line">CuratorFramework client</span><br><span class="line">= CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">20000</span>, <span class="number">3</span>));</span><br><span class="line">clients.add(client);</span><br><span class="line">LeaderLatch latch = <span class="keyword">new</span> LeaderLatch(client, PATH, <span class="string">"Client #"</span> + i);</span><br><span class="line">latch.addListener(<span class="keyword">new</span> LeaderLatchListener() &#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">isLeader</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line">System.out.println(<span class="string">"I am Leader"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">notLeader</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line">System.out.println(<span class="string">"I am not Leader"</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line">examples.add(latch);</span><br><span class="line">client.start();</span><br><span class="line">latch.start();</span><br><span class="line">&#125;</span><br><span class="line">Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">LeaderLatch currentLeader = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">for</span> (LeaderLatch latch : examples) &#123;</span><br><span class="line"><span class="keyword">if</span> (latch.hasLeadership()) &#123;</span><br><span class="line">currentLeader = latch;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(<span class="string">"current leader is "</span> + currentLeader.getId());</span><br><span class="line">System.out.println(<span class="string">"release the leader "</span> + currentLeader.getId());</span><br><span class="line">currentLeader.close();</span><br><span class="line"></span><br><span class="line">Thread.sleep(<span class="number">5000</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (LeaderLatch latch : examples) &#123;</span><br><span class="line"><span class="keyword">if</span> (latch.hasLeadership()) &#123;</span><br><span class="line">currentLeader = latch;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(<span class="string">"current leader is "</span> + currentLeader.getId());</span><br><span class="line">System.out.println(<span class="string">"release the leader "</span> + currentLeader.getId());</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line"><span class="keyword">for</span> (LeaderLatch latch : examples) &#123;</span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">null</span> != latch.getState())</span><br><span class="line">CloseableUtils.closeQuietly(latch);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (CuratorFramework client : clients) &#123;</span><br><span class="line">CloseableUtils.closeQuietly(client);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以添加test module的依赖方便进行测试，不需要启动真实的zookeeper服务端：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.curator<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>curator-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.12.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>首先我们创建了10个LeaderLatch，启动后它们中的一个会被选举为leader。 因为选举会花费一些时间，start后并不能马上就得到leader。<br>通过<code>hasLeadership</code>查看自己是否是leader， 如果是的话返回true。<br>可以通过<code>.getLeader().getId()</code>可以得到当前的leader的ID。<br>只能通过<code>close</code>释放当前的领导权。<br><code>await</code>是一个阻塞方法， 尝试获取leader地位，但是未必能上位。</p><h4 id="LeaderSelector"><a href="#LeaderSelector" class="headerlink" title="LeaderSelector"></a>LeaderSelector</h4><p>LeaderSelector使用的时候主要涉及下面几个类：</p><ul><li>LeaderSelector</li><li>LeaderSelectorListener</li><li>LeaderSelectorListenerAdapter</li><li>CancelLeadershipException</li></ul><p>核心类是LeaderSelector，它的构造函数如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">LeaderSelector</span><span class="params">(CuratorFramework client, String mutexPath,LeaderSelectorListener listener)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">LeaderSelector</span><span class="params">(CuratorFramework client, String mutexPath, ThreadFactory threadFactory, Executor executor, LeaderSelectorListener listener)</span></span></span><br></pre></td></tr></table></figure><p>类似LeaderLatch,LeaderSelector必须<code>start</code>: <code>leaderSelector.start();</code> 一旦启动，当实例取得领导权时你的listener的<code>takeLeadership()</code>方法被调用。而takeLeadership()方法只有领导权被释放时才返回。 当你不再使用LeaderSelector实例时，应该调用它的close方法。</p><p><strong>异常处理</strong> LeaderSelectorListener类继承ConnectionStateListener。LeaderSelector必须小心连接状态的改变。如果实例成为leader, 它应该响应SUSPENDED 或 LOST。 当 SUSPENDED 状态出现时， 实例必须假定在重新连接成功之前它可能不再是leader了。 如果LOST状态出现， 实例不再是leader， takeLeadership方法返回。</p><p><strong>重要</strong>: 推荐处理方式是当收到SUSPENDED 或 LOST时抛出CancelLeadershipException异常.。这会导致LeaderSelector实例中断并取消执行takeLeadership方法的异常.。这非常重要， 你必须考虑扩展LeaderSelectorListenerAdapter. LeaderSelectorListenerAdapter提供了推荐的处理逻辑。</p><p>下面的一个例子摘抄自官方：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LeaderSelectorAdapter</span> <span class="keyword">extends</span> <span class="title">LeaderSelectorListenerAdapter</span> <span class="keyword">implements</span> <span class="title">Closeable</span> </span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> String name;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> LeaderSelector leaderSelector;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger leaderCount = <span class="keyword">new</span> AtomicInteger();</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">LeaderSelectorAdapter</span><span class="params">(CuratorFramework client, String path, String name)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.name = name;</span><br><span class="line">leaderSelector = <span class="keyword">new</span> LeaderSelector(client, path, <span class="keyword">this</span>);</span><br><span class="line">leaderSelector.autoRequeue();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">leaderSelector.start();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">leaderSelector.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">takeLeadership</span><span class="params">(CuratorFramework client)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="keyword">final</span> <span class="keyword">int</span> waitSeconds = (<span class="keyword">int</span>) (<span class="number">5</span> * Math.random()) + <span class="number">1</span>;</span><br><span class="line">System.out.println(name + <span class="string">" is now the leader. Waiting "</span> + waitSeconds + <span class="string">" seconds..."</span>);</span><br><span class="line">System.out.println(name + <span class="string">" has been leader "</span> + leaderCount.getAndIncrement() + <span class="string">" time(s) before."</span>);</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">Thread.sleep(TimeUnit.SECONDS.toMillis(waitSeconds));</span><br><span class="line">&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">System.err.println(name + <span class="string">" was interrupted."</span>);</span><br><span class="line">Thread.currentThread().interrupt();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">System.out.println(name + <span class="string">" relinquishing leadership.\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>你可以在takeLeadership进行任务的分配等等，并且不要返回，如果你想要要此实例一直是leader的话可以加一个死循环。调用 <code>leaderSelector.autoRequeue();</code>保证在此实例释放领导权之后还可能获得领导权。 在这里我们使用AtomicInteger来记录此client获得领导权的次数， 它是”fair”， 每个client有平等的机会获得领导权。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LeaderSelectorDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">static</span> String PATH = <span class="string">"/francis/leader"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> CLIENT_QTY = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">List&lt;CuratorFramework&gt; clients = Lists.newArrayList();</span><br><span class="line">List&lt;LeaderSelectorAdapter&gt; examples = Lists.newArrayList();</span><br><span class="line">TestingServer server = <span class="keyword">new</span> TestingServer();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; CLIENT_QTY; i++) &#123;</span><br><span class="line">CuratorFramework client</span><br><span class="line">= CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">20000</span>, <span class="number">3</span>));</span><br><span class="line">clients.add(client);</span><br><span class="line">LeaderSelectorAdapter selectorAdapter = <span class="keyword">new</span> LeaderSelectorAdapter(client, PATH, <span class="string">"Client #"</span> + i);</span><br><span class="line">examples.add(selectorAdapter);</span><br><span class="line">client.start();</span><br><span class="line">selectorAdapter.start();</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(<span class="string">"Press enter/return to quit\n"</span>);</span><br><span class="line"><span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(System.in)).readLine();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">System.out.println(<span class="string">"Shutting down..."</span>);</span><br><span class="line"><span class="keyword">for</span> (LeaderSelectorAdapter exampleClient : examples) &#123;</span><br><span class="line">CloseableUtils.closeQuietly(exampleClient);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (CuratorFramework client : clients) &#123;</span><br><span class="line">CloseableUtils.closeQuietly(client);</span><br><span class="line">&#125;</span><br><span class="line">CloseableUtils.closeQuietly(server);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对比可知，LeaderLatch必须调用<code>close()</code>方法才会释放领导权，而对于LeaderSelector，通过<code>LeaderSelectorListener</code>可以对领导权进行控制， 在适当的时候释放领导权，这样每个节点都有可能获得领导权。从而，LeaderSelector具有更好的灵活性和可控性，建议有LeaderElection应用场景下优先使用LeaderSelector。</p><h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><p><strong>提醒：</strong></p><p>1.推荐使用ConnectionStateListener监控连接的状态，因为当连接LOST时你不再拥有锁</p><p>2.分布式的锁全局同步， 这意味着任何一个时间点不会有两个客户端都拥有相同的锁。</p><h4 id="可重入共享锁—Shared-Reentrant-Lock"><a href="#可重入共享锁—Shared-Reentrant-Lock" class="headerlink" title="可重入共享锁—Shared Reentrant Lock"></a>可重入共享锁—Shared Reentrant Lock</h4><p><strong>Shared意味着锁是全局可见的</strong>， 客户端都可以请求锁。 Reentrant和JDK的ReentrantLock类似，即可重入， 意味着同一个客户端在拥有锁的同时，可以多次获取，不会被阻塞。 它是由类<code>InterProcessMutex</code>来实现。 它的构造函数为：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">InterProcessMutex</span><span class="params">(CuratorFramework client, String path)</span></span></span><br></pre></td></tr></table></figure><p>通过<code>acquire()</code>获得锁，并提供超时机制：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">acquire</span><span class="params">()</span></span></span><br><span class="line"><span class="function">Acquire the mutex - blocking until it's available. Note: the same thread can call acquire</span></span><br><span class="line"><span class="function">re-entrantly. Each call to acquire must be balanced by a call to <span class="title">release</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">acquire</span><span class="params">(<span class="keyword">long</span> time,TimeUnit unit)</span></span></span><br><span class="line"><span class="function">Acquire the mutex - blocks until it's available or the given time expires. Note: the same thread can call acquire re-entrantly. Each call to acquire that returns <span class="keyword">true</span> must be balanced by a call to <span class="title">release</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">Parameters:</span></span><br><span class="line"><span class="function">time - time to wait</span></span><br><span class="line"><span class="function">unit - time unit</span></span><br><span class="line"><span class="function">Returns:</span></span><br><span class="line"><span class="function"><span class="keyword">true</span> <span class="keyword">if</span> the mutex was acquired, <span class="keyword">false</span> <span class="keyword">if</span> not</span></span><br></pre></td></tr></table></figure><p>通过<code>release()</code>方法释放锁。 InterProcessMutex 实例可以重用。</p><p><strong>Revoking</strong> ZooKeeper recipes wiki定义了可协商的撤销机制。 为了撤销mutex, 调用下面的方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">makeRevocable</span><span class="params">(RevocationListener&lt;T&gt; listener)</span></span></span><br><span class="line"><span class="function">将锁设为可撤销的. 当别的进程或线程想让你释放锁时Listener会被调用。</span></span><br><span class="line"><span class="function">Parameters:</span></span><br><span class="line"><span class="function">listener - the listener</span></span><br></pre></td></tr></table></figure><p>如果你请求撤销当前的锁， 调用<code>attemptRevoke()</code>方法,注意锁释放时<code>RevocationListener</code>将会回调。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">attemptRevoke</span><span class="params">(CuratorFramework client,String path)</span> <span class="keyword">throws</span> Exception</span></span><br><span class="line"><span class="function">Utility to mark a lock <span class="keyword">for</span> revocation. Assuming that the lock has been registered</span></span><br><span class="line"><span class="function">with a RevocationListener, it will get called and the lock should be released. Note,</span></span><br><span class="line"><span class="function">however, that revocation is cooperative.</span></span><br><span class="line"><span class="function">Parameters:</span></span><br><span class="line"><span class="function">client - the client</span></span><br><span class="line"><span class="function">path - the path of the lock - usually from something like InterProcessMutex.<span class="title">getParticipantNodes</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure><p><strong>二次提醒：错误处理</strong> 还是强烈推荐你使用<code>ConnectionStateListener</code>处理连接状态的改变。 当连接LOST时你不再拥有锁。</p><p>首先让我们创建一个模拟的共享资源， 这个资源期望只能单线程的访问，否则会有并发问题。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FakeLimitedResource</span> </span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> AtomicBoolean inUse = <span class="keyword">new</span> AtomicBoolean(<span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">use</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line"><span class="comment">// 真实环境中我们会在这里访问/维护一个共享的资源</span></span><br><span class="line"><span class="comment">//这个例子在使用锁的情况下不会非法并发异常IllegalStateException</span></span><br><span class="line"><span class="comment">//但是在无锁的情况由于sleep了一段时间，很容易抛出异常</span></span><br><span class="line"><span class="keyword">if</span> (!inUse.compareAndSet(<span class="keyword">false</span>, <span class="keyword">true</span>)) &#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Needs to be used by one client at a time"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">Thread.sleep((<span class="keyword">long</span>) (<span class="number">3</span> * Math.random()));</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">inUse.set(<span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后创建一个<code>InterProcessMutexDemo</code>类， 它负责请求锁， 使用资源，释放锁这样一个完整的访问过程。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InterProcessMutexDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> InterProcessMutex lock;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> FakeLimitedResource resource;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> String clientName;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">InterProcessMutexDemo</span><span class="params">(CuratorFramework client, String lockPath, FakeLimitedResource resource, String clientName)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.resource = resource;</span><br><span class="line"><span class="keyword">this</span>.clientName = clientName;</span><br><span class="line"><span class="keyword">this</span>.lock = <span class="keyword">new</span> InterProcessMutex(client, lockPath);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doWork</span><span class="params">(<span class="keyword">long</span> time, TimeUnit unit)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (!lock.acquire(time, unit)) &#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(clientName + <span class="string">" could not acquire the lock"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">System.out.println(clientName + <span class="string">" get the lock"</span>);</span><br><span class="line">resource.use(); <span class="comment">//access resource exclusively</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">System.out.println(clientName + <span class="string">" releasing the lock"</span>);</span><br><span class="line">lock.release(); <span class="comment">// always release the lock in a finally block</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> QTY = <span class="number">5</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> REPETITIONS = QTY * <span class="number">10</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/examples/locks"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="keyword">final</span> FakeLimitedResource resource = <span class="keyword">new</span> FakeLimitedResource();</span><br><span class="line">ExecutorService service = Executors.newFixedThreadPool(QTY);</span><br><span class="line"><span class="keyword">final</span> TestingServer server = <span class="keyword">new</span> TestingServer();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; QTY; ++i) &#123;</span><br><span class="line"><span class="keyword">final</span> <span class="keyword">int</span> index = i;</span><br><span class="line">Callable&lt;Void&gt; task = <span class="keyword">new</span> Callable&lt;Void&gt;() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Void <span class="title">call</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">client.start();</span><br><span class="line"><span class="keyword">final</span> InterProcessMutexDemo example = <span class="keyword">new</span> InterProcessMutexDemo(client, PATH, resource, <span class="string">"Client "</span> + index);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; REPETITIONS; ++j) &#123;</span><br><span class="line">example.doWork(<span class="number">10</span>, TimeUnit.SECONDS);</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">CloseableUtils.closeQuietly(client);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line">service.submit(task);</span><br><span class="line">&#125;</span><br><span class="line">service.shutdown();</span><br><span class="line">service.awaitTermination(<span class="number">10</span>, TimeUnit.MINUTES);</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">CloseableUtils.closeQuietly(server);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码也很简单，生成10个client， 每个client重复执行10次 请求锁–访问资源–释放锁的过程。每个client都在独立的线程中。 结果可以看到，锁是随机的被每个实例排他性的使用。</p><p>既然是可重用的，你可以在一个线程中多次调用<code>acquire()</code>,在线程拥有锁时它总是返回true。</p><p><strong>你不应该在多个线程中用同一个<code>InterProcessMutex</code></strong>， 你可以在每个线程中都生成一个新的InterProcessMutex实例，它们的path都一样，这样它们可以共享同一个锁。</p><h4 id="不可重入共享锁—Shared-Lock"><a href="#不可重入共享锁—Shared-Lock" class="headerlink" title="不可重入共享锁—Shared Lock"></a>不可重入共享锁—Shared Lock</h4><p>这个锁和上面的<code>InterProcessMutex</code>相比，就是少了Reentrant的功能，也就意味着它不能在同一个线程中重入。这个类是<code>InterProcessSemaphoreMutex</code>,使用方法和<code>InterProcessMutex</code>类似</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InterProcessSemaphoreMutexDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> InterProcessSemaphoreMutex lock;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> FakeLimitedResource resource;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> String clientName;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">InterProcessSemaphoreMutexDemo</span><span class="params">(CuratorFramework client, String lockPath, FakeLimitedResource resource, String clientName)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.resource = resource;</span><br><span class="line"><span class="keyword">this</span>.clientName = clientName;</span><br><span class="line"><span class="keyword">this</span>.lock = <span class="keyword">new</span> InterProcessSemaphoreMutex(client, lockPath);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doWork</span><span class="params">(<span class="keyword">long</span> time, TimeUnit unit)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (!lock.acquire(time, unit))</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(clientName + <span class="string">" 不能得到互斥锁"</span>);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(clientName + <span class="string">" 已获取到互斥锁"</span>);</span><br><span class="line"><span class="keyword">if</span> (!lock.acquire(time, unit))</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(clientName + <span class="string">" 不能得到互斥锁"</span>);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(clientName + <span class="string">" 再次获取到互斥锁"</span>);</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">System.out.println(clientName + <span class="string">" get the lock"</span>);</span><br><span class="line">resource.use(); <span class="comment">//access resource exclusively</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">System.out.println(clientName + <span class="string">" releasing the lock"</span>);</span><br><span class="line">lock.release(); <span class="comment">// always release the lock in a finally block</span></span><br><span class="line">lock.release(); <span class="comment">// 获取锁几次 释放锁也要几次</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> QTY = <span class="number">5</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> REPETITIONS = QTY * <span class="number">10</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/examples/locks"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="keyword">final</span> FakeLimitedResource resource = <span class="keyword">new</span> FakeLimitedResource();</span><br><span class="line">ExecutorService service = Executors.newFixedThreadPool(QTY);</span><br><span class="line"><span class="keyword">final</span> TestingServer server = <span class="keyword">new</span> TestingServer();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; QTY; ++i) &#123;</span><br><span class="line"><span class="keyword">final</span> <span class="keyword">int</span> index = i;</span><br><span class="line">Callable&lt;Void&gt; task = <span class="keyword">new</span> Callable&lt;Void&gt;() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Void <span class="title">call</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">client.start();</span><br><span class="line"><span class="keyword">final</span> InterProcessSemaphoreMutexDemo example = <span class="keyword">new</span> InterProcessSemaphoreMutexDemo(client, PATH, resource, <span class="string">"Client "</span> + index);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; REPETITIONS; ++j) &#123;</span><br><span class="line">example.doWork(<span class="number">10</span>, TimeUnit.SECONDS);</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">CloseableUtils.closeQuietly(client);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line">service.submit(task);</span><br><span class="line">&#125;</span><br><span class="line">service.shutdown();</span><br><span class="line">service.awaitTermination(<span class="number">10</span>, TimeUnit.MINUTES);</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">CloseableUtils.closeQuietly(server);</span><br><span class="line">&#125;</span><br><span class="line">Thread.sleep(Integer.MAX_VALUE);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行后发现，有且只有一个client成功获取第一个锁(第一个<code>acquire()</code>方法返回true)，然后它自己阻塞在第二个<code>acquire()</code>方法，获取第二个锁超时；其他所有的客户端都阻塞在第一个<code>acquire()</code>方法超时并且抛出异常。</p><p>这样也就验证了<code>InterProcessSemaphoreMutex</code>实现的锁是不可重入的。</p><h4 id="可重入读写锁—Shared-Reentrant-Read-Write-Lock"><a href="#可重入读写锁—Shared-Reentrant-Read-Write-Lock" class="headerlink" title="可重入读写锁—Shared Reentrant Read Write Lock"></a>可重入读写锁—Shared Reentrant Read Write Lock</h4><p>类似JDK的<strong>ReentrantReadWriteLock</strong>。一个读写锁管理一对相关的锁。一个负责读操作，另外一个负责写操作。读操作在写锁没被使用时可同时由多个进程使用，而写锁在使用时不允许读(阻塞)。</p><p>此锁是可重入的。<strong>一个拥有写锁的线程可重入读锁，但是读锁却不能进入写锁</strong>。这也意味着<strong>写锁可以降级成读锁， 比如请求写锁 —&gt;请求读锁—&gt;释放读锁 —-&gt;释放写锁</strong>。从读锁升级成写锁是不行的。</p><p>可重入读写锁主要由两个类实现：<code>InterProcessReadWriteLock</code>、<code>InterProcessMutex</code>。使用时首先创建一个<code>InterProcessReadWriteLock</code>实例，然后再根据你的需求得到读锁或者写锁，读写锁的类型是<code>InterProcessMutex</code>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ReentrantReadWriteLockDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> InterProcessReadWriteLock lock;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> InterProcessMutex readLock;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> InterProcessMutex writeLock;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> FakeLimitedResource resource;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> String clientName;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ReentrantReadWriteLockDemo</span><span class="params">(CuratorFramework client, String lockPath, FakeLimitedResource resource, String clientName)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.resource = resource;</span><br><span class="line"><span class="keyword">this</span>.clientName = clientName;</span><br><span class="line">lock = <span class="keyword">new</span> InterProcessReadWriteLock(client, lockPath);</span><br><span class="line">readLock = lock.readLock();</span><br><span class="line">writeLock = lock.writeLock();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">doWork</span><span class="params">(<span class="keyword">long</span> time, TimeUnit unit)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="comment">// 注意只能先得到写锁再得到读锁，不能反过来！！！</span></span><br><span class="line"><span class="keyword">if</span> (!writeLock.acquire(time, unit)) &#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(clientName + <span class="string">" 不能得到写锁"</span>);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(clientName + <span class="string">" 已得到写锁"</span>);</span><br><span class="line"><span class="keyword">if</span> (!readLock.acquire(time, unit)) &#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(clientName + <span class="string">" 不能得到读锁"</span>);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(clientName + <span class="string">" 已得到读锁"</span>);</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">resource.use(); <span class="comment">// 使用资源</span></span><br><span class="line">Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">System.out.println(clientName + <span class="string">" 释放读写锁"</span>);</span><br><span class="line">readLock.release();</span><br><span class="line">writeLock.release();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> QTY = <span class="number">5</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> REPETITIONS = QTY ;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/examples/locks"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="keyword">final</span> FakeLimitedResource resource = <span class="keyword">new</span> FakeLimitedResource();</span><br><span class="line">ExecutorService service = Executors.newFixedThreadPool(QTY);</span><br><span class="line"><span class="keyword">final</span> TestingServer server = <span class="keyword">new</span> TestingServer();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; QTY; ++i) &#123;</span><br><span class="line"><span class="keyword">final</span> <span class="keyword">int</span> index = i;</span><br><span class="line">Callable&lt;Void&gt; task = <span class="keyword">new</span> Callable&lt;Void&gt;() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Void <span class="title">call</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">client.start();</span><br><span class="line"><span class="keyword">final</span> ReentrantReadWriteLockDemo example = <span class="keyword">new</span> ReentrantReadWriteLockDemo(client, PATH, resource, <span class="string">"Client "</span> + index);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; REPETITIONS; ++j) &#123;</span><br><span class="line">example.doWork(<span class="number">10</span>, TimeUnit.SECONDS);</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">CloseableUtils.closeQuietly(client);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line">service.submit(task);</span><br><span class="line">&#125;</span><br><span class="line">service.shutdown();</span><br><span class="line">service.awaitTermination(<span class="number">10</span>, TimeUnit.MINUTES);</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">CloseableUtils.closeQuietly(server);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="信号量—Shared-Semaphore"><a href="#信号量—Shared-Semaphore" class="headerlink" title="信号量—Shared Semaphore"></a>信号量—Shared Semaphore</h4><p>一个计数的信号量类似JDK的Semaphore。 JDK中Semaphore维护的一组许可(<strong>permits</strong>)，而Curator中称之为租约(<strong>Lease</strong>)。 有两种方式可以决定semaphore的最大租约数。第一种方式是用户给定path并且指定最大LeaseSize。第二种方式用户给定path并且使用<code>SharedCountReader</code>类。<strong>如果不使用SharedCountReader, 必须保证所有实例在多进程中使用相同的(最大)租约数量,否则有可能出现A进程中的实例持有最大租约数量为10，但是在B进程中持有的最大租约数量为20，此时租约的意义就失效了。</strong></p><p>这次调用<code>acquire()</code>会返回一个租约对象。 客户端必须在finally中close这些租约对象，否则这些租约会丢失掉。 但是， 但是，如果客户端session由于某种原因比如crash丢掉， 那么这些客户端持有的租约会自动close， 这样其它客户端可以继续使用这些租约。 租约还可以通过下面的方式返还：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">returnAll</span><span class="params">(Collection&lt;Lease&gt; leases)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">returnLease</span><span class="params">(Lease lease)</span></span></span><br></pre></td></tr></table></figure><p>注意你可以一次性请求多个租约，如果Semaphore当前的租约不够，则请求线程会被阻塞。 同时还提供了超时的重载方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Lease <span class="title">acquire</span><span class="params">()</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Collection&lt;Lease&gt; <span class="title">acquire</span><span class="params">(<span class="keyword">int</span> qty)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Lease <span class="title">acquire</span><span class="params">(<span class="keyword">long</span> time, TimeUnit unit)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Collection&lt;Lease&gt; <span class="title">acquire</span><span class="params">(<span class="keyword">int</span> qty, <span class="keyword">long</span> time, TimeUnit unit)</span></span></span><br></pre></td></tr></table></figure><p>Shared Semaphore使用的主要类包括下面几个：</p><ul><li><code>InterProcessSemaphoreV2</code></li><li><code>Lease</code></li><li><code>SharedCountReader</code></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InterProcessSemaphoreDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAX_LEASE = <span class="number">10</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/examples/locks"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">FakeLimitedResource resource = <span class="keyword">new</span> FakeLimitedResource();</span><br><span class="line"><span class="keyword">try</span> (TestingServer server = <span class="keyword">new</span> TestingServer()) &#123;</span><br><span class="line"></span><br><span class="line">CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">client.start();</span><br><span class="line"></span><br><span class="line">InterProcessSemaphoreV2 semaphore = <span class="keyword">new</span> InterProcessSemaphoreV2(client, PATH, MAX_LEASE);</span><br><span class="line">Collection&lt;Lease&gt; leases = semaphore.acquire(<span class="number">5</span>);</span><br><span class="line">System.out.println(<span class="string">"get "</span> + leases.size() + <span class="string">" leases"</span>);</span><br><span class="line">Lease lease = semaphore.acquire();</span><br><span class="line">System.out.println(<span class="string">"get another lease"</span>);</span><br><span class="line"></span><br><span class="line">resource.use();</span><br><span class="line"></span><br><span class="line">Collection&lt;Lease&gt; leases2 = semaphore.acquire(<span class="number">5</span>, <span class="number">10</span>, TimeUnit.SECONDS);</span><br><span class="line">System.out.println(<span class="string">"Should timeout and acquire return "</span> + leases2);</span><br><span class="line"></span><br><span class="line">System.out.println(<span class="string">"return one lease"</span>);</span><br><span class="line">semaphore.returnLease(lease);</span><br><span class="line">System.out.println(<span class="string">"return another 5 leases"</span>);</span><br><span class="line">semaphore.returnAll(leases);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先我们先获得了5个租约， 最后我们把它还给了semaphore。 接着请求了一个租约，因为semaphore还有5个租约，所以请求可以满足，返回一个租约，还剩4个租约。 然后再请求一个租约，因为租约不够，<strong>阻塞到超时，还是没能满足，返回结果为null(租约不足会阻塞到超时，然后返回null，不会主动抛出异常；如果不设置超时时间，会一致阻塞)。</strong></p><p>上面说讲的锁都是公平锁(fair)。 总ZooKeeper的角度看， 每个客户端都按照请求的顺序获得锁，不存在非公平的抢占的情况。</p><h4 id="多共享锁对象-—Multi-Shared-Lock"><a href="#多共享锁对象-—Multi-Shared-Lock" class="headerlink" title="多共享锁对象 —Multi Shared Lock"></a>多共享锁对象 —Multi Shared Lock</h4><p>Multi Shared Lock是一个锁的容器。 当调用<code>acquire()</code>， 所有的锁都会被<code>acquire()</code>，如果请求失败，所有的锁都会被release。 同样调用release时所有的锁都被release(<strong>失败被忽略</strong>)。 基本上，它就是组锁的代表，在它上面的请求释放操作都会传递给它包含的所有的锁。</p><p>主要涉及两个类：</p><ul><li><code>InterProcessMultiLock</code></li><li><code>InterProcessLock</code></li></ul><p>它的构造函数需要包含的锁的集合，或者一组ZooKeeper的path。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">InterProcessMultiLock</span><span class="params">(List&lt;InterProcessLock&gt; locks)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">InterProcessMultiLock</span><span class="params">(CuratorFramework client, List&lt;String&gt; paths)</span></span></span><br></pre></td></tr></table></figure><p>用法和Shared Lock相同。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MultiSharedLockDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH1 = <span class="string">"/examples/locks1"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH2 = <span class="string">"/examples/locks2"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">FakeLimitedResource resource = <span class="keyword">new</span> FakeLimitedResource();</span><br><span class="line"><span class="keyword">try</span> (TestingServer server = <span class="keyword">new</span> TestingServer()) &#123;</span><br><span class="line">CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">client.start();</span><br><span class="line"></span><br><span class="line">InterProcessLock lock1 = <span class="keyword">new</span> InterProcessMutex(client, PATH1);</span><br><span class="line">InterProcessLock lock2 = <span class="keyword">new</span> InterProcessSemaphoreMutex(client, PATH2);</span><br><span class="line"></span><br><span class="line">InterProcessMultiLock lock = <span class="keyword">new</span> InterProcessMultiLock(Arrays.asList(lock1, lock2));</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!lock.acquire(<span class="number">10</span>, TimeUnit.SECONDS)) &#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"could not acquire the lock"</span>);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(<span class="string">"has got all lock"</span>);</span><br><span class="line"></span><br><span class="line">System.out.println(<span class="string">"has got lock1: "</span> + lock1.isAcquiredInThisProcess());</span><br><span class="line">System.out.println(<span class="string">"has got lock2: "</span> + lock2.isAcquiredInThisProcess());</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">resource.use(); <span class="comment">//access resource exclusively</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">System.out.println(<span class="string">"releasing the lock"</span>);</span><br><span class="line">lock.release(); <span class="comment">// always release the lock in a finally block</span></span><br><span class="line">&#125;</span><br><span class="line">System.out.println(<span class="string">"has got lock1: "</span> + lock1.isAcquiredInThisProcess());</span><br><span class="line">System.out.println(<span class="string">"has got lock2: "</span> + lock2.isAcquiredInThisProcess());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>新建一个<code>InterProcessMultiLock</code>， 包含一个重入锁和一个非重入锁。 调用<code>acquire()</code>后可以看到线程同时拥有了这两个锁。 调用<code>release()</code>看到这两个锁都被释放了。</p><p><strong>最后再重申一次， 强烈推荐使用ConnectionStateListener监控连接的状态，当连接状态为LOST，锁将会丢失。</strong></p><h3 id="分布式计数器"><a href="#分布式计数器" class="headerlink" title="分布式计数器"></a>分布式计数器</h3><p>顾名思义，计数器是用来计数的, 利用ZooKeeper可以实现一个集群共享的计数器。 只要使用相同的path就可以得到最新的计数器值， 这是由ZooKeeper的一致性保证的。Curator有两个计数器， 一个是用int来计数(<code>SharedCount</code>)，一个用long来计数(<code>DistributedAtomicLong</code>)。</p><h4 id="分布式int计数器—SharedCount"><a href="#分布式int计数器—SharedCount" class="headerlink" title="分布式int计数器—SharedCount"></a>分布式int计数器—SharedCount</h4><p>这个类使用int类型来计数。 主要涉及三个类。</p><ul><li>SharedCount</li><li>SharedCountReader</li><li>SharedCountListener</li></ul><p><code>SharedCount</code>代表计数器， 可以为它增加一个<code>SharedCountListener</code>，当计数器改变时此Listener可以监听到改变的事件，而<code>SharedCountReader</code>可以读取到最新的值， 包括字面值和带版本信息的值VersionedValue。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SharedCounterDemo</span> <span class="keyword">implements</span> <span class="title">SharedCountListener</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> QTY = <span class="number">5</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/examples/counter"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, Exception </span>&#123;</span><br><span class="line"><span class="keyword">final</span> Random rand = <span class="keyword">new</span> Random();</span><br><span class="line">SharedCounterDemo example = <span class="keyword">new</span> SharedCounterDemo();</span><br><span class="line"><span class="keyword">try</span> (TestingServer server = <span class="keyword">new</span> TestingServer()) &#123;</span><br><span class="line">CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">client.start();</span><br><span class="line"></span><br><span class="line">SharedCount baseCount = <span class="keyword">new</span> SharedCount(client, PATH, <span class="number">0</span>);</span><br><span class="line">baseCount.addListener(example);</span><br><span class="line">baseCount.start();</span><br><span class="line"></span><br><span class="line">List&lt;SharedCount&gt; examples = Lists.newArrayList();</span><br><span class="line">ExecutorService service = Executors.newFixedThreadPool(QTY);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; QTY; ++i) &#123;</span><br><span class="line"><span class="keyword">final</span> SharedCount count = <span class="keyword">new</span> SharedCount(client, PATH, <span class="number">0</span>);</span><br><span class="line">examples.add(count);</span><br><span class="line">Callable&lt;Void&gt; task = () -&gt; &#123;</span><br><span class="line">count.start();</span><br><span class="line">Thread.sleep(rand.nextInt(<span class="number">10000</span>));</span><br><span class="line">System.out.println(<span class="string">"Increment:"</span> + count.trySetCount(count.getVersionedValue(), count.getCount() + rand.nextInt(<span class="number">10</span>)));</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;;</span><br><span class="line">service.submit(task);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">service.shutdown();</span><br><span class="line">service.awaitTermination(<span class="number">10</span>, TimeUnit.MINUTES);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; QTY; ++i) &#123;</span><br><span class="line">examples.get(i).close();</span><br><span class="line">&#125;</span><br><span class="line">baseCount.close();</span><br><span class="line">&#125;</span><br><span class="line">Thread.sleep(Integer.MAX_VALUE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">stateChanged</span><span class="params">(CuratorFramework arg0, ConnectionState arg1)</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"State changed: "</span> + arg1.toString());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">countHasChanged</span><span class="params">(SharedCountReader sharedCount, <span class="keyword">int</span> newCount)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"Counter's value is changed to "</span> + newCount);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，我们使用<code>baseCount</code>来监听计数值(<code>addListener</code>方法来添加SharedCountListener )。 任意的SharedCount， 只要使用相同的path，都可以得到这个计数值。 然后我们使用5个线程为计数值增加一个10以内的随机数。相同的path的SharedCount对计数值进行更改，将会回调给<code>baseCount</code>的SharedCountListener。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">count.trySetCount(count.getVersionedValue(), count.getCount() + rand.nextInt(10))</span><br></pre></td></tr></table></figure><p>这里我们使用<code>trySetCount</code>去设置计数器。 <strong>第一个参数提供当前的VersionedValue,如果期间其它client更新了此计数值， 你的更新可能不成功， 但是这时你的client更新了最新的值，所以失败了你可以尝试再更新一次。 而<code>setCount</code>是强制更新计数器的值</strong>。</p><p>注意计数器必须<code>start</code>,使用完之后必须调用<code>close</code>关闭它。</p><p>强烈推荐使用<code>ConnectionStateListener</code>。 在本例中<code>SharedCountListener</code>扩展<code>ConnectionStateListener</code>。</p><h4 id="分布式long计数器—DistributedAtomicLong"><a href="#分布式long计数器—DistributedAtomicLong" class="headerlink" title="分布式long计数器—DistributedAtomicLong"></a>分布式long计数器—DistributedAtomicLong</h4><p>再看一个Long类型的计数器。 除了计数的范围比<code>SharedCount</code>大了之外， 它首先尝试使用乐观锁的方式设置计数器， 如果不成功(比如期间计数器已经被其它client更新了)， 它使用<code>InterProcessMutex</code>方式来更新计数值。</p><p>可以从它的内部实现<code>DistributedAtomicValue.trySet()</code>中看出：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">AtomicValue&lt;<span class="keyword">byte</span>[]&gt;   trySet(MakeValue makeValue) <span class="keyword">throws</span> Exception</span><br><span class="line"> &#123;</span><br><span class="line">     MutableAtomicValue&lt;<span class="keyword">byte</span>[]&gt;  result = <span class="keyword">new</span> MutableAtomicValue&lt;<span class="keyword">byte</span>[]&gt;(<span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">     tryOptimistic(result, makeValue);</span><br><span class="line">     <span class="keyword">if</span> ( !result.succeeded() &amp;&amp; (mutex != <span class="keyword">null</span>) )</span><br><span class="line">     &#123;</span><br><span class="line">         tryWithMutex(result, makeValue);</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">return</span> result;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>此计数器有一系列的操作：</p><ul><li>get(): 获取当前值</li><li>increment()： 加一</li><li>decrement(): 减一</li><li>add()： 增加特定的值</li><li>subtract(): 减去特定的值</li><li>trySet(): 尝试设置计数值</li><li>forceSet(): 强制设置计数值</li></ul><p>你<strong>必须</strong>检查返回结果的<code>succeeded()</code>， 它代表此操作是否成功。 如果操作成功， <code>preValue()</code>代表操作前的值， <code>postValue()</code>代表操作后的值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistributedAtomicLongDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> QTY = <span class="number">5</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/examples/counter"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, Exception </span>&#123;</span><br><span class="line">List&lt;DistributedAtomicLong&gt; examples = Lists.newArrayList();</span><br><span class="line"><span class="keyword">try</span> (TestingServer server = <span class="keyword">new</span> TestingServer()) &#123;</span><br><span class="line">CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">client.start();</span><br><span class="line">ExecutorService service = Executors.newFixedThreadPool(QTY);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; QTY; ++i) &#123;</span><br><span class="line"><span class="keyword">final</span> DistributedAtomicLong count = <span class="keyword">new</span> DistributedAtomicLong(client, PATH, <span class="keyword">new</span> RetryNTimes(<span class="number">10</span>, <span class="number">10</span>));</span><br><span class="line"></span><br><span class="line">examples.add(count);</span><br><span class="line">Callable&lt;Void&gt; task = () -&gt; &#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">AtomicValue&lt;Long&gt; value = count.increment();</span><br><span class="line">System.out.println(<span class="string">"succeed: "</span> + value.succeeded());</span><br><span class="line"><span class="keyword">if</span> (value.succeeded())</span><br><span class="line">System.out.println(<span class="string">"Increment: from "</span> + value.preValue() + <span class="string">" to "</span> + value.postValue());</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;;</span><br><span class="line">service.submit(task);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">service.shutdown();</span><br><span class="line">service.awaitTermination(<span class="number">10</span>, TimeUnit.MINUTES);</span><br><span class="line">Thread.sleep(Integer.MAX_VALUE);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="分布式队列"><a href="#分布式队列" class="headerlink" title="分布式队列"></a>分布式队列</h3><p>使用Curator也可以简化Ephemeral Node (<strong>临时节点</strong>)的操作。Curator也提供ZK Recipe的分布式队列实现。 利用ZK的 PERSISTENTS_EQUENTIAL节点， 可以保证放入到队列中的项目是按照顺序排队的。 如果单一的消费者从队列中取数据， 那么它是先入先出的，这也是队列的特点。 如果你严格要求顺序，你就的使用单一的消费者，可以使用Leader选举只让Leader作为唯一的消费者。</p><p>但是， 根据Netflix的Curator作者所说， ZooKeeper真心不适合做Queue，或者说ZK没有实现一个好的Queue，详细内容可以看 <a href="https://cwiki.apache.org/confluence/display/CURATOR/TN4" target="_blank" rel="noopener">Tech Note 4</a>， 原因有五：</p><ol><li>ZK有1MB 的传输限制。 实践中ZNode必须相对较小，而队列包含成千上万的消息，非常的大。</li><li>如果有很多节点，ZK启动时相当的慢。 而使用queue会导致好多ZNode. 你需要显著增大 initLimit 和 syncLimit.</li><li>ZNode很大的时候很难清理。Netflix不得不创建了一个专门的程序做这事。</li><li>当很大量的包含成千上万的子节点的ZNode时， ZK的性能变得不好</li><li>ZK的数据库完全放在内存中。 大量的Queue意味着会占用很多的内存空间。</li></ol><p>尽管如此， Curator还是创建了各种Queue的实现。 如果Queue的数据量不太多，数据量不太大的情况下，酌情考虑，还是可以使用的。</p><h4 id="分布式队列—DistributedQueue"><a href="#分布式队列—DistributedQueue" class="headerlink" title="分布式队列—DistributedQueue"></a>分布式队列—DistributedQueue</h4><p>DistributedQueue是最普通的一种队列。 它设计以下四个类：</p><ul><li>QueueBuilder - 创建队列使用QueueBuilder,它也是其它队列的创建类</li><li>QueueConsumer - 队列中的消息消费者接口</li><li>QueueSerializer - 队列消息序列化和反序列化接口，提供了对队列中的对象的序列化和反序列化</li><li>DistributedQueue - 队列实现类</li></ul><p>QueueConsumer是消费者，它可以接收队列的数据。处理队列中的数据的代码逻辑可以放在QueueConsumer.consumeMessage()中。</p><p>正常情况下先将消息从队列中移除，再交给消费者消费。但这是两个步骤，不是原子的。可以调用Builder的lockPath()消费者加锁，当消费者消费数据时持有锁，这样其它消费者不能消费此消息。如果消费失败或者进程死掉，消息可以交给其它进程。这会带来一点性能的损失。最好还是单消费者模式使用队列。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistributedQueueDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/example/queue"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">TestingServer server = <span class="keyword">new</span> TestingServer();</span><br><span class="line">CuratorFramework clientA = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">clientA.start();</span><br><span class="line">CuratorFramework clientB = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">clientB.start();</span><br><span class="line">DistributedQueue&lt;String&gt; queueA;</span><br><span class="line">QueueBuilder&lt;String&gt; builderA = QueueBuilder.builder(clientA, createQueueConsumer(<span class="string">"A"</span>), createQueueSerializer(), PATH);</span><br><span class="line">queueA = builderA.buildQueue();</span><br><span class="line">queueA.start();</span><br><span class="line"></span><br><span class="line">DistributedQueue&lt;String&gt; queueB;</span><br><span class="line">QueueBuilder&lt;String&gt; builderB = QueueBuilder.builder(clientB, createQueueConsumer(<span class="string">"B"</span>), createQueueSerializer(), PATH);</span><br><span class="line">queueB = builderB.buildQueue();</span><br><span class="line">queueB.start();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">queueA.put(<span class="string">" test-A-"</span> + i);</span><br><span class="line">Thread.sleep(<span class="number">10</span>);</span><br><span class="line">queueB.put(<span class="string">" test-B-"</span> + i);</span><br><span class="line">&#125;</span><br><span class="line">Thread.sleep(<span class="number">1000</span> * <span class="number">10</span>);<span class="comment">// 等待消息消费完成</span></span><br><span class="line">queueB.close();</span><br><span class="line">queueA.close();</span><br><span class="line">clientB.close();</span><br><span class="line">clientA.close();</span><br><span class="line">System.out.println(<span class="string">"OK!"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 队列消息序列化实现类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> QueueSerializer&lt;String&gt; <span class="title">createQueueSerializer</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> QueueSerializer&lt;String&gt;() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] serialize(String item) &#123;</span><br><span class="line"><span class="keyword">return</span> item.getBytes();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">deserialize</span><span class="params">(<span class="keyword">byte</span>[] bytes)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> String(bytes);</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 定义队列消费者</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> QueueConsumer&lt;String&gt; <span class="title">createQueueConsumer</span><span class="params">(<span class="keyword">final</span> String name)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> QueueConsumer&lt;String&gt;() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">stateChanged</span><span class="params">(CuratorFramework client, ConnectionState newState)</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"连接状态改变: "</span> + newState.name());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">consumeMessage</span><span class="params">(String message)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"消费消息("</span> + name + <span class="string">"): "</span> + message);</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>例子中定义了两个分布式队列和两个消费者，因为PATH是相同的，会存在消费者抢占消费消息的情况。</p><h4 id="带Id的分布式队列—DistributedIdQueue"><a href="#带Id的分布式队列—DistributedIdQueue" class="headerlink" title="带Id的分布式队列—DistributedIdQueue"></a>带Id的分布式队列—DistributedIdQueue</h4><p>DistributedIdQueue和上面的队列类似，<strong>但是可以为队列中的每一个元素设置一个ID</strong>。 可以通过ID把队列中任意的元素移除。 它涉及几个类：</p><ul><li>QueueBuilder</li><li>QueueConsumer</li><li>QueueSerializer</li><li>DistributedQueue</li></ul><p>通过下面方法创建：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">builder.buildIdQueue()</span><br></pre></td></tr></table></figure><p>放入元素时：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">queue.put(aMessage, messageId);</span><br></pre></td></tr></table></figure><p>移除元素时：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int numberRemoved &#x3D; queue.remove(messageId);</span><br></pre></td></tr></table></figure><p>在这个例子中， 有些元素还没有被消费者消费前就移除了，这样消费者不会收到删除的消息。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistributedIdQueueDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/example/queue"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">TestingServer server = <span class="keyword">new</span> TestingServer();</span><br><span class="line">CuratorFramework client = <span class="keyword">null</span>;</span><br><span class="line">DistributedIdQueue&lt;String&gt; queue = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">client.getCuratorListenable().addListener((client1, event) -&gt; System.out.println(<span class="string">"CuratorEvent: "</span> + event.getType().name()));</span><br><span class="line"></span><br><span class="line">client.start();</span><br><span class="line">QueueConsumer&lt;String&gt; consumer = createQueueConsumer();</span><br><span class="line">QueueBuilder&lt;String&gt; builder = QueueBuilder.builder(client, consumer, createQueueSerializer(), PATH);</span><br><span class="line">queue = builder.buildIdQueue();</span><br><span class="line">queue.start();</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">queue.put(<span class="string">" test-"</span> + i, <span class="string">"Id"</span> + i);</span><br><span class="line">Thread.sleep((<span class="keyword">long</span>) (<span class="number">15</span> * Math.random()));</span><br><span class="line">queue.remove(<span class="string">"Id"</span> + i);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Thread.sleep(<span class="number">20000</span>);</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">CloseableUtils.closeQuietly(queue);</span><br><span class="line">CloseableUtils.closeQuietly(client);</span><br><span class="line">CloseableUtils.closeQuietly(server);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> QueueSerializer&lt;String&gt; <span class="title">createQueueSerializer</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> QueueSerializer&lt;String&gt;() &#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] serialize(String item) &#123;</span><br><span class="line"><span class="keyword">return</span> item.getBytes();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">deserialize</span><span class="params">(<span class="keyword">byte</span>[] bytes)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> String(bytes);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> QueueConsumer&lt;String&gt; <span class="title">createQueueConsumer</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> QueueConsumer&lt;String&gt;() &#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">stateChanged</span><span class="params">(CuratorFramework client, ConnectionState newState)</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"connection new state: "</span> + newState.name());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">consumeMessage</span><span class="params">(String message)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"consume one message: "</span> + message);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="优先级分布式队列—DistributedPriorityQueue"><a href="#优先级分布式队列—DistributedPriorityQueue" class="headerlink" title="优先级分布式队列—DistributedPriorityQueue"></a>优先级分布式队列—DistributedPriorityQueue</h4><p>优先级队列对队列中的元素按照优先级进行排序。 <strong>Priority越小， 元素越靠前， 越先被消费掉</strong>。 它涉及下面几个类：</p><ul><li>QueueBuilder</li><li>QueueConsumer</li><li>QueueSerializer</li><li>DistributedPriorityQueue</li></ul><p>通过builder.buildPriorityQueue(minItemsBeforeRefresh)方法创建。 当优先级队列得到元素增删消息时，它会暂停处理当前的元素队列，然后刷新队列。minItemsBeforeRefresh指定刷新前当前活动的队列的最小数量。 主要设置你的程序可以容忍的不排序的最小值。</p><p>放入队列时需要指定优先级：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">queue.put(aMessage, priority);</span><br></pre></td></tr></table></figure><p>例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistributedPriorityQueueDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/example/queue"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">TestingServer server = <span class="keyword">new</span> TestingServer();</span><br><span class="line">CuratorFramework client = <span class="keyword">null</span>;</span><br><span class="line">DistributedPriorityQueue&lt;String&gt; queue = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">client.getCuratorListenable().addListener((client1, event) -&gt; System.out.println(<span class="string">"CuratorEvent: "</span> + event.getType().name()));</span><br><span class="line"></span><br><span class="line">client.start();</span><br><span class="line">QueueConsumer&lt;String&gt; consumer = createQueueConsumer();</span><br><span class="line">QueueBuilder&lt;String&gt; builder = QueueBuilder.builder(client, consumer, createQueueSerializer(), PATH);</span><br><span class="line">queue = builder.buildPriorityQueue(<span class="number">0</span>);</span><br><span class="line">queue.start();</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line"><span class="keyword">int</span> priority = (<span class="keyword">int</span>) (Math.random() * <span class="number">100</span>);</span><br><span class="line">System.out.println(<span class="string">"test-"</span> + i + <span class="string">" priority:"</span> + priority);</span><br><span class="line">queue.put(<span class="string">"test-"</span> + i, priority);</span><br><span class="line">Thread.sleep((<span class="keyword">long</span>) (<span class="number">50</span> * Math.random()));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Thread.sleep(<span class="number">20000</span>);</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">CloseableUtils.closeQuietly(queue);</span><br><span class="line">CloseableUtils.closeQuietly(client);</span><br><span class="line">CloseableUtils.closeQuietly(server);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> QueueSerializer&lt;String&gt; <span class="title">createQueueSerializer</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> QueueSerializer&lt;String&gt;() &#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] serialize(String item) &#123;</span><br><span class="line"><span class="keyword">return</span> item.getBytes();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">deserialize</span><span class="params">(<span class="keyword">byte</span>[] bytes)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> String(bytes);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> QueueConsumer&lt;String&gt; <span class="title">createQueueConsumer</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> QueueConsumer&lt;String&gt;() &#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">stateChanged</span><span class="params">(CuratorFramework client, ConnectionState newState)</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"connection new state: "</span> + newState.name());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">consumeMessage</span><span class="params">(String message)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">System.out.println(<span class="string">"consume one message: "</span> + message);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有时候你可能会有错觉，优先级设置并没有起效。那是因为优先级是对于队列积压的元素而言，如果消费速度过快有可能出现在后一个元素入队操作之前前一个元素已经被消费，这种情况下DistributedPriorityQueue会退化为DistributedQueue。</p><h4 id="分布式延迟队列—DistributedDelayQueue"><a href="#分布式延迟队列—DistributedDelayQueue" class="headerlink" title="分布式延迟队列—DistributedDelayQueue"></a>分布式延迟队列—DistributedDelayQueue</h4><p>JDK中也有DelayQueue，不知道你是否熟悉。 DistributedDelayQueue也提供了类似的功能， 元素有个delay值， 消费者隔一段时间才能收到元素。 涉及到下面四个类。</p><ul><li>QueueBuilder</li><li>QueueConsumer</li><li>QueueSerializer</li><li>DistributedDelayQueue</li></ul><p>通过下面的语句创建：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">QueueBuilder&lt;MessageType&gt;    builder &#x3D; QueueBuilder.builder(client, consumer, serializer, path);</span><br><span class="line">... more builder method calls as needed ...</span><br><span class="line">DistributedDelayQueue&lt;MessageType&gt; queue &#x3D; builder.buildDelayQueue();</span><br></pre></td></tr></table></figure><p>放入元素时可以指定<code>delayUntilEpoch</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">queue.put(aMessage, delayUntilEpoch);</span><br></pre></td></tr></table></figure><p>注意<code>delayUntilEpoch</code>不是离现在的一个时间间隔， 比如20毫秒，而是未来的一个时间戳，如 System.currentTimeMillis() + 10秒。 如果delayUntilEpoch的时间已经过去，消息会立刻被消费者接收。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistributedDelayQueueDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/example/queue"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">TestingServer server = <span class="keyword">new</span> TestingServer();</span><br><span class="line">CuratorFramework client = <span class="keyword">null</span>;</span><br><span class="line">DistributedDelayQueue&lt;String&gt; queue = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">client.getCuratorListenable().addListener((client1, event) -&gt; System.out.println(<span class="string">"CuratorEvent: "</span> + event.getType().name()));</span><br><span class="line"></span><br><span class="line">client.start();</span><br><span class="line">QueueConsumer&lt;String&gt; consumer = createQueueConsumer();</span><br><span class="line">QueueBuilder&lt;String&gt; builder = QueueBuilder.builder(client, consumer, createQueueSerializer(), PATH);</span><br><span class="line">queue = builder.buildDelayQueue();</span><br><span class="line">queue.start();</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">queue.put(<span class="string">"test-"</span> + i, System.currentTimeMillis() + <span class="number">10000</span>);</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(<span class="keyword">new</span> Date().getTime() + <span class="string">": already put all items"</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Thread.sleep(<span class="number">20000</span>);</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">CloseableUtils.closeQuietly(queue);</span><br><span class="line">CloseableUtils.closeQuietly(client);</span><br><span class="line">CloseableUtils.closeQuietly(server);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> QueueSerializer&lt;String&gt; <span class="title">createQueueSerializer</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> QueueSerializer&lt;String&gt;() &#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] serialize(String item) &#123;</span><br><span class="line"><span class="keyword">return</span> item.getBytes();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">deserialize</span><span class="params">(<span class="keyword">byte</span>[] bytes)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> String(bytes);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> QueueConsumer&lt;String&gt; <span class="title">createQueueConsumer</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> QueueConsumer&lt;String&gt;() &#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">stateChanged</span><span class="params">(CuratorFramework client, ConnectionState newState)</span> </span>&#123;</span><br><span class="line">System.out.println(<span class="string">"connection new state: "</span> + newState.name());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">consumeMessage</span><span class="params">(String message)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">System.out.println(<span class="keyword">new</span> Date().getTime() + <span class="string">": consume one message: "</span> + message);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="SimpleDistributedQueue"><a href="#SimpleDistributedQueue" class="headerlink" title="SimpleDistributedQueue"></a>SimpleDistributedQueue</h4><p>前面虽然实现了各种队列，但是你注意到没有，这些队列并没有实现类似JDK一样的接口。 <code>SimpleDistributedQueue</code>提供了和JDK基本一致的接口(但是没有实现Queue接口)。 创建很简单：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">SimpleDistributedQueue</span><span class="params">(CuratorFramework client,String path)</span></span></span><br></pre></td></tr></table></figure><p>增加元素：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public boolean offer(byte[] data) throws Exception</span><br></pre></td></tr></table></figure><p>删除元素：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] take() <span class="keyword">throws</span> Exception</span><br></pre></td></tr></table></figure><p>另外还提供了其它方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] peek() <span class="keyword">throws</span> Exception</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] poll(<span class="keyword">long</span> timeout, TimeUnit unit) <span class="keyword">throws</span> Exception</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] poll() <span class="keyword">throws</span> Exception</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] remove() <span class="keyword">throws</span> Exception</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] element() <span class="keyword">throws</span> Exception</span><br></pre></td></tr></table></figure><p>没有<code>add</code>方法， 多了<code>take</code>方法。</p><p><code>take</code>方法在成功返回之前会被阻塞。 而<code>poll</code>方法在队列为空时直接返回null。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleDistributedQueueDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/example/queue"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">TestingServer server = <span class="keyword">new</span> TestingServer();</span><br><span class="line">CuratorFramework client = <span class="keyword">null</span>;</span><br><span class="line">SimpleDistributedQueue queue;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">client.getCuratorListenable().addListener((client1, event) -&gt; System.out.println(<span class="string">"CuratorEvent: "</span> + event.getType().name()));</span><br><span class="line">client.start();</span><br><span class="line">queue = <span class="keyword">new</span> SimpleDistributedQueue(client, PATH);</span><br><span class="line">Producer producer = <span class="keyword">new</span> Producer(queue);</span><br><span class="line">Consumer consumer = <span class="keyword">new</span> Consumer(queue);</span><br><span class="line"><span class="keyword">new</span> Thread(producer, <span class="string">"producer"</span>).start();</span><br><span class="line"><span class="keyword">new</span> Thread(consumer, <span class="string">"consumer"</span>).start();</span><br><span class="line">Thread.sleep(<span class="number">20000</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">CloseableUtils.closeQuietly(client);</span><br><span class="line">CloseableUtils.closeQuietly(server);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> SimpleDistributedQueue queue;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Producer</span><span class="params">(SimpleDistributedQueue queue)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.queue = queue;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">boolean</span> flag = queue.offer((<span class="string">"zjc-"</span> + i).getBytes());</span><br><span class="line"><span class="keyword">if</span> (flag) &#123;</span><br><span class="line">System.out.println(<span class="string">"发送一条消息成功："</span> + <span class="string">"zjc-"</span> + i);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">System.out.println(<span class="string">"发送一条消息失败："</span> + <span class="string">"zjc-"</span> + i);</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Consumer</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> SimpleDistributedQueue queue;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Consumer</span><span class="params">(SimpleDistributedQueue queue)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.queue = queue;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">byte</span>[] datas = queue.take();</span><br><span class="line">System.out.println(<span class="string">"消费一条消息成功："</span> + <span class="keyword">new</span> String(datas, <span class="string">"UTF-8"</span>));</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是实际上发送了100条消息，消费完第一条之后，后面的消息无法消费，目前没找到原因。查看一下官方文档推荐的demo使用下面几个Api：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">Creating a SimpleDistributedQueue</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">SimpleDistributedQueue</span><span class="params">(CuratorFramework client,</span></span></span><br><span class="line"><span class="function"><span class="params">                              String path)</span></span></span><br><span class="line"><span class="function">Parameters:</span></span><br><span class="line"><span class="function">client - the client</span></span><br><span class="line"><span class="function">path - path to store queue nodes</span></span><br><span class="line"><span class="function">Add to the queue</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">offer</span><span class="params">(<span class="keyword">byte</span>[] data)</span></span></span><br><span class="line"><span class="function">             <span class="keyword">throws</span> Exception</span></span><br><span class="line"><span class="function">Inserts data into queue.</span></span><br><span class="line"><span class="function">Parameters:</span></span><br><span class="line"><span class="function">data - the data</span></span><br><span class="line"><span class="function">Returns:</span></span><br><span class="line"><span class="function"><span class="keyword">true</span> <span class="keyword">if</span> data was successfully added</span></span><br><span class="line"><span class="function">Take from the queue</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">byte</span>[] <span class="title">take</span><span class="params">()</span></span></span><br><span class="line"><span class="function">           <span class="keyword">throws</span> Exception</span></span><br><span class="line"><span class="function">Removes the head of the queue and returns it, blocks until it succeeds.</span></span><br><span class="line"><span class="function">Returns:</span></span><br><span class="line"><span class="function">The former head of the queue</span></span><br><span class="line"><span class="function">NOTE: see the Javadoc <span class="keyword">for</span> additional methods</span></span><br></pre></td></tr></table></figure><p>但是实际使用发现还是存在消费阻塞问题。</p><h3 id="分布式屏障—Barrier"><a href="#分布式屏障—Barrier" class="headerlink" title="分布式屏障—Barrier"></a>分布式屏障—Barrier</h3><p>分布式Barrier是这样一个类： 它会阻塞所有节点上的等待进程，直到某一个被满足， 然后所有的节点继续进行。</p><p>比如赛马比赛中， 等赛马陆续来到起跑线前。 一声令下，所有的赛马都飞奔而出。</p><h4 id="DistributedBarrier"><a href="#DistributedBarrier" class="headerlink" title="DistributedBarrier"></a>DistributedBarrier</h4><p><code>DistributedBarrier</code>类实现了栅栏的功能。 它的构造函数如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">DistributedBarrier</span><span class="params">(CuratorFramework client, String barrierPath)</span></span></span><br><span class="line"><span class="function">Parameters:</span></span><br><span class="line"><span class="function">client - client</span></span><br><span class="line"><span class="function">barrierPath - path to use as the barrier</span></span><br></pre></td></tr></table></figure><p>首先你需要设置栅栏，它将阻塞在它上面等待的线程:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setBarrier();</span><br></pre></td></tr></table></figure><p>然后需要阻塞的线程调用方法等待放行条件:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public void waitOnBarrier()</span><br></pre></td></tr></table></figure><p>当条件满足时，移除栅栏，所有等待的线程将继续执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">removeBarrier();</span><br></pre></td></tr></table></figure><p><strong>异常处理</strong> DistributedBarrier 会监控连接状态，当连接断掉时<code>waitOnBarrier()</code>方法会抛出异常。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistributedBarrierDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> QTY = <span class="number">5</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/examples/barrier"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="keyword">try</span> (TestingServer server = <span class="keyword">new</span> TestingServer()) &#123;</span><br><span class="line">CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">client.start();</span><br><span class="line">ExecutorService service = Executors.newFixedThreadPool(QTY);</span><br><span class="line">DistributedBarrier controlBarrier = <span class="keyword">new</span> DistributedBarrier(client, PATH);</span><br><span class="line">controlBarrier.setBarrier();</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; QTY; ++i) &#123;</span><br><span class="line"><span class="keyword">final</span> DistributedBarrier barrier = <span class="keyword">new</span> DistributedBarrier(client, PATH);</span><br><span class="line"><span class="keyword">final</span> <span class="keyword">int</span> index = i;</span><br><span class="line">Callable&lt;Void&gt; task = () -&gt; &#123;</span><br><span class="line">Thread.sleep((<span class="keyword">long</span>) (<span class="number">3</span> * Math.random()));</span><br><span class="line">System.out.println(<span class="string">"Client #"</span> + index + <span class="string">" waits on Barrier"</span>);</span><br><span class="line">barrier.waitOnBarrier();</span><br><span class="line">System.out.println(<span class="string">"Client #"</span> + index + <span class="string">" begins"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;;</span><br><span class="line">service.submit(task);</span><br><span class="line">&#125;</span><br><span class="line">Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">System.out.println(<span class="string">"all Barrier instances should wait the condition"</span>);</span><br><span class="line">controlBarrier.removeBarrier();</span><br><span class="line">service.shutdown();</span><br><span class="line">service.awaitTermination(<span class="number">10</span>, TimeUnit.MINUTES);</span><br><span class="line"></span><br><span class="line">Thread.sleep(<span class="number">20000</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个例子创建了<code>controlBarrier</code>来设置栅栏和移除栅栏。 我们创建了5个线程，在此Barrier上等待。 最后移除栅栏后所有的线程才继续执行。</p><p>如果你开始不设置栅栏，所有的线程就不会阻塞住。</p><h4 id="双栅栏—DistributedDoubleBarrier"><a href="#双栅栏—DistributedDoubleBarrier" class="headerlink" title="双栅栏—DistributedDoubleBarrier"></a>双栅栏—DistributedDoubleBarrier</h4><p>双栅栏允许客户端在计算的开始和结束时同步。当足够的进程加入到双栅栏时，进程开始计算， 当计算完成时，离开栅栏。 双栅栏类是<code>DistributedDoubleBarrier</code>。 构造函数为:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">DistributedDoubleBarrier</span><span class="params">(CuratorFramework client,</span></span></span><br><span class="line"><span class="function"><span class="params">                                String barrierPath,</span></span></span><br><span class="line"><span class="function"><span class="params">                                <span class="keyword">int</span> memberQty)</span></span></span><br><span class="line"><span class="function">Creates the barrier abstraction. memberQty is the number of members in the barrier. When <span class="title">enter</span><span class="params">()</span> is called, it blocks until</span></span><br><span class="line"><span class="function">all members have entered. When <span class="title">leave</span><span class="params">()</span> is called, it blocks until all members have left.</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">Parameters:</span></span><br><span class="line"><span class="function">client - the client</span></span><br><span class="line"><span class="function">barrierPath - path to use</span></span><br><span class="line"><span class="function">memberQty - the number of members in the barrier</span></span><br></pre></td></tr></table></figure><p><code>memberQty</code>是成员数量，当<code>enter()</code>方法被调用时，成员被阻塞，直到所有的成员都调用了<code>enter()</code>。 当<code>leave()</code>方法被调用时，它也阻塞调用线程，直到所有的成员都调用了<code>leave()</code>。 就像百米赛跑比赛， 发令枪响， 所有的运动员开始跑，等所有的运动员跑过终点线，比赛才结束。</p><p>DistributedDoubleBarrier会监控连接状态，当连接断掉时<code>enter()</code>和<code>leave()</code>方法会抛出异常。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistributedDoubleBarrierDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> QTY = <span class="number">5</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PATH = <span class="string">"/examples/barrier"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="keyword">try</span> (TestingServer server = <span class="keyword">new</span> TestingServer()) &#123;</span><br><span class="line">CuratorFramework client = CuratorFrameworkFactory.newClient(server.getConnectString(), <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">client.start();</span><br><span class="line">ExecutorService service = Executors.newFixedThreadPool(QTY);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; QTY; ++i) &#123;</span><br><span class="line"><span class="keyword">final</span> DistributedDoubleBarrier barrier = <span class="keyword">new</span> DistributedDoubleBarrier(client, PATH, QTY);</span><br><span class="line"><span class="keyword">final</span> <span class="keyword">int</span> index = i;</span><br><span class="line">Callable&lt;Void&gt; task = () -&gt; &#123;</span><br><span class="line"></span><br><span class="line">Thread.sleep((<span class="keyword">long</span>) (<span class="number">3</span> * Math.random()));</span><br><span class="line">System.out.println(<span class="string">"Client #"</span> + index + <span class="string">" enters"</span>);</span><br><span class="line">barrier.enter();</span><br><span class="line">System.out.println(<span class="string">"Client #"</span> + index + <span class="string">" begins"</span>);</span><br><span class="line">Thread.sleep((<span class="keyword">long</span>) (<span class="number">3000</span> * Math.random()));</span><br><span class="line">barrier.leave();</span><br><span class="line">System.out.println(<span class="string">"Client #"</span> + index + <span class="string">" left"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;;</span><br><span class="line">service.submit(task);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">service.shutdown();</span><br><span class="line">service.awaitTermination(<span class="number">10</span>, TimeUnit.MINUTES);</span><br><span class="line">Thread.sleep(Integer.MAX_VALUE);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Curator </tag>
            
            <tag> 分布式 </tag>
            
            <tag> java </tag>
            
            <tag> zookeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Curator实现Zookeeper注册中心（官方文档翻译）</title>
      <link href="/posts/7de3e7aa/"/>
      <url>/posts/7de3e7aa/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h1><h2 id="什么是服务发现？"><a href="#什么是服务发现？" class="headerlink" title="什么是服务发现？"></a>什么是服务发现？</h2><p>在SOA /分布式系统中，服务需要相互查找。 也就是说，Web服务可能需要找到缓存服务，等等。DNS可以用于此目的，但是对于不断变化的服务而言，它还远远不够灵活。 服务发现系统提供了以下机制：</p><ul><li>服务以记录其可用性</li><li>查找特定服务的单个实例</li><li>通知服务实例何时更改</li></ul><h2 id="Curator-服务发现"><a href="#Curator-服务发现" class="headerlink" title="Curator 服务发现"></a>Curator 服务发现</h2><h3 id="服务实例-ServiceInstance"><a href="#服务实例-ServiceInstance" class="headerlink" title="服务实例 ( ServiceInstance )"></a>服务实例 ( ServiceInstance )</h3><p>服务实例由类 <code>ServiceInstance</code> 表示。 <code>ServiceInstance</code> 具有名称，ID，地址，端口和/或SSL端口，以及可选的有效负载（用户定义）。 <code>ServiceInstance</code>通过以下方式序列化并存储在 <code>ZooKeeper</code> 中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">base path</span><br><span class="line">       |_______ service A name</span><br><span class="line">                    |__________ instance 1 id --&gt; (serialized ServiceInstance)</span><br><span class="line">                    |__________ instance 2 id --&gt; (serialized ServiceInstance)</span><br><span class="line">                    |__________ ...</span><br><span class="line">       |_______ service B name</span><br><span class="line">                    |__________ instance 1 id --&gt; (serialized ServiceInstance)</span><br><span class="line">                    |__________ instance 2 id --&gt; (serialized ServiceInstance)</span><br><span class="line">                    |__________ ...</span><br><span class="line">       |_______ ...</span><br></pre></td></tr></table></figure><h3 id="服务提供者（-ServiceProvider-）"><a href="#服务提供者（-ServiceProvider-）" class="headerlink" title="服务提供者（ ServiceProvider ）"></a>服务提供者（ ServiceProvider ）</h3><p>主要的抽象类是 <code>ServiceProvider</code> 。 它封装了特定命名服务的发现服务以及提供者策略。 提供者策略是一种用于为给定服务从一组实例中选择一个实例的方案。 共有三种捆绑策略：<code>Round Robin</code>，<code>Random</code>和<code>Sticky</code>（始终选择相同的策略）。</p><p>通过使用<code>ServiceProviderBuilder</code>分配<code>ServiceProvider</code>。 您可以从<code>ServiceDiscovery</code>获得<code>ServiceProviderBuilder</code>（请参见下文）。<code>ServiceProviderBuilder</code>允许您设置服务名称和其他几个可选值。</p><p>必须通过调用 <code>start()</code> 来启动<code>ServiceProvider</code>。 完成后，您应该调用 <code>close()</code>。 <code>ServiceProvider</code>中的唯一方法是：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ServiceInstance&lt;T&gt; <span class="title">getInstance</span><span class="params">()</span></span></span><br><span class="line"><span class="function">                            <span class="keyword">throws</span> Exception</span></span><br><span class="line"><span class="function">原文：Return an instance <span class="keyword">for</span> a single use. IMPORTANT: users should not hold on to the instance</span></span><br><span class="line"><span class="function">译文：返回一个实例供单次使用。 重要说明：用户不应坚持使用实例</span></span><br><span class="line"><span class="function">原文：returned. A fresh instance should always be retrieved.</span></span><br><span class="line"><span class="function">译文：returned. 应始终检索一个新实例。</span></span><br><span class="line"><span class="function">Returns:</span></span><br><span class="line"><span class="function">原文：the instance to use</span></span><br><span class="line"><span class="function">译文：要使用的实例</span></span><br></pre></td></tr></table></figure><p><strong>注意：</strong>使用<code>Curator 2.x（Zookeeper 3.4.x）</code>时，必须由应用程序缓存并重用服务提供者对象。 由于无法在<code>Zookeeper 3.4.x</code>中删除由服务提供者添加的内部<code>NamespaceWatcher</code>对象，因此为每个对相同服务的调用创建一个新的服务提供者最终将耗尽<code>JVM</code>的内存。</p><h3 id="服务发现（ServiceDiscovery）"><a href="#服务发现（ServiceDiscovery）" class="headerlink" title="服务发现（ServiceDiscovery）"></a>服务发现（ServiceDiscovery）</h3><p>为了分配 <code>ServiceProvider</code>，您必须具有 <code>ServiceDiscovery</code>。 它由 <code>ServiceDiscoveryBuilder</code> 创建。</p><p>您必须在对象上调用 <code>start()</code>，并在完成后调用 <code>close()</code>。</p><h3 id="实例稳定性（Instance-Stability）"><a href="#实例稳定性（Instance-Stability）" class="headerlink" title="实例稳定性（Instance Stability）"></a>实例稳定性（Instance Stability）</h3><p>如果特定实例发生<code>I/O</code>错误等，则应调用传入该实例的<code>ServiceProvider.noteError()</code>。 <code>ServiceProvider</code>将暂时认为有错误的实例为“关闭”。 关闭实例的阈值和超时是通过<code>DownInstancePolicy</code>设置的，可以将其传递给<code>ServiceProviderBuilder</code>（注意：如果未指定默认值，则使用默认的<code>DownInstancePolicy</code>）。</p><hr><h3 id="Low-Level-APIs"><a href="#Low-Level-APIs" class="headerlink" title="Low Level APIs"></a>Low Level APIs</h3><p>对于大多数目的，<code>ServiceProvider API</code> 就是您所需要的。 但是，对于更细粒度的控制，可以使用以下方法：</p><h4 id="注册-取消注册服务（Registering-Unregistering-Services）"><a href="#注册-取消注册服务（Registering-Unregistering-Services）" class="headerlink" title="注册/取消注册服务（Registering/Unregistering Services）"></a>注册/取消注册服务（Registering/Unregistering Services）</h4><p>通常，您将应用程序的服务描述符传递给<code>ServiceDiscovery</code>构造函数，它将自动注册/取消注册。 但是，如果您需要手动执行此操作，请使用以下方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">registerService</span><span class="params">(ServiceInstance&lt;T&gt; service)</span></span></span><br><span class="line"><span class="function">                    <span class="keyword">throws</span> Exception</span></span><br><span class="line"><span class="function">原文：Register/re-register/update a service instance</span></span><br><span class="line"><span class="function">译文：注册/重新注册/更新服务实例</span></span><br><span class="line"><span class="function">Parameters:</span></span><br><span class="line"><span class="function">原文：service - service to add</span></span><br><span class="line"><span class="function">译文：服务-要添加的服务</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">unregisterService</span><span class="params">(ServiceInstance&lt;T&gt; service)</span></span></span><br><span class="line"><span class="function">                      <span class="keyword">throws</span> Exception</span></span><br><span class="line"><span class="function">原文：Unregister/remove a service instance</span></span><br><span class="line"><span class="function">译文：取消注册/删除服务实例</span></span><br><span class="line"><span class="function">Parameters:</span></span><br><span class="line"><span class="function">service - the service</span></span><br></pre></td></tr></table></figure><h4 id="查询服务（Querying-for-Services）"><a href="#查询服务（Querying-for-Services）" class="headerlink" title="查询服务（Querying for Services）"></a>查询服务（Querying for Services）</h4><p>您可以查询所有服务名称，特定服务的所有实例或单个服务实例。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Collection&lt;String&gt; <span class="title">queryForNames</span><span class="params">()</span></span></span><br><span class="line"><span class="function">                              <span class="keyword">throws</span> Exception</span></span><br><span class="line"><span class="function">原文：Return the names of all known services</span></span><br><span class="line"><span class="function">译文：返回所有已知服务的名称</span></span><br><span class="line"><span class="function">Returns:</span></span><br><span class="line"><span class="function">原文：list of service names</span></span><br><span class="line"><span class="function">译文：服务名称列表</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Collection&lt;ServiceInstance&lt;T&gt;&gt; queryForInstances(String name)</span><br><span class="line">                                            <span class="keyword">throws</span> Exception</span><br><span class="line">原文：Return all known instances <span class="keyword">for</span> the given service</span><br><span class="line">译文：返回给定服务的所有已知实例</span><br><span class="line">Parameters:</span><br><span class="line">原文：name - name of the service</span><br><span class="line">译文：名称-服务名称</span><br><span class="line">Returns:</span><br><span class="line">原文：<span class="function">list of <span class="title">instances</span> <span class="params">(or an empty list)</span></span></span><br><span class="line"><span class="function">译文：实例列表（或空列表）</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ServiceInstance&lt;T&gt; <span class="title">queryForInstance</span><span class="params">(String name,</span></span></span><br><span class="line"><span class="function"><span class="params">                                         String id)</span></span></span><br><span class="line"><span class="function">                                 <span class="keyword">throws</span> Exception</span></span><br><span class="line"><span class="function">原文：Return a service instance POJO</span></span><br><span class="line"><span class="function">译文：返回服务实例POJO</span></span><br><span class="line"><span class="function">Parameters:</span></span><br><span class="line"><span class="function">原文：name - name of the service</span></span><br><span class="line"><span class="function">译文：名称-服务名称</span></span><br><span class="line"><span class="function">原文：id - ID of the instance</span></span><br><span class="line"><span class="function">译文：id-实例的ID</span></span><br><span class="line"><span class="function">Returns:</span></span><br><span class="line"><span class="function">原文：the instance or <span class="keyword">null</span> <span class="keyword">if</span> not found</span></span><br><span class="line"><span class="function">译文：实例；如果未找到，则为<span class="keyword">null</span></span></span><br></pre></td></tr></table></figure><h4 id="服务缓存（Service-Cache）"><a href="#服务缓存（Service-Cache）" class="headerlink" title="服务缓存（Service Cache）"></a>服务缓存（Service Cache）</h4><p>以上每个查询方法都直接调用<code>ZooKeeper</code>。 如果您不仅仅需要偶尔查询服务，还可以使用<code>ServiceCache</code>。 它将特定服务的实例列表缓存在内存中。 它使用监视程序来使列表保持最新。</p><p>您可以通过<code>ServiceDiscovery.serviceCacheBuilder()</code>返回的构建器分配<code>ServiceCache</code>。 必须通过调用<code>start()</code>来启动<code>ServiceCache</code>对象，完成后，您应该调用<code>close()</code>。 您可以通过调用以下命令获取服务的当前已知实例列表：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Collection&lt;ServiceInstance&lt;T&gt;&gt; getInstances()</span><br><span class="line">Return the current list of instances. NOTE: there is no guarantee of freshness. This is merely the last known list of instances. However, the list is updated via a ZooKeeper watcher so it should be fresh within a window of a second or two.</span><br><span class="line">返回当前实例列表。 注意：不能保证新鲜度。 这只是实例的最后已知列表。 但是，该列表是通过ZooKeeper监视程序更新的，因此应在一两秒钟的时间内刷新。</span><br></pre></td></tr></table></figure><p><code>ServiceCache</code>支持一个侦听器，当Watcher更新实例列表时，该侦听器会收到通知：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Listener for changes to a service cache</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ServiceCacheListener</span> <span class="keyword">extends</span> <span class="title">ConnectionStateListener</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Called when the cache has changed (instances added/deleted, etc.)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cacheChanged</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="服务发现Server（Service-Discovery-Server）"><a href="#服务发现Server（Service-Discovery-Server）" class="headerlink" title="服务发现Server（Service Discovery Server）"></a>服务发现Server（Service Discovery Server）</h1><h2 id="Packaging"><a href="#Packaging" class="headerlink" title="Packaging"></a>Packaging</h2><p><code>Curator Service Discovery</code>在<code>Maven Central</code>中以其自己的软件包提供：<code>curator-x-discovery-server</code></p><h2 id="简介（Description）"><a href="#简介（Description）" class="headerlink" title="简介（Description）"></a>简介（Description）</h2><p>服务发现服务器将非<code>Java</code>或旧版应用程序与<code>Curator Service Discovery</code>桥接。 它公开了<code>RESTful Web</code>服务以注册，删除，查询等服务。</p><p>服务发现服务器提供了<code>JAX-RS</code>组件，可以将其合并到您选择的容器（Tomcat，Jetty等）中。 您还可以选择任何<code>JAX-RS</code>提供程序（Jersey，RESTEasy等）。</p><h2 id="部署服务器（Deploying-the-Server）"><a href="#部署服务器（Deploying-the-Server）" class="headerlink" title="部署服务器（Deploying the Server）"></a>部署服务器（Deploying the Server）</h2><p>服务器必须与<code>JAX-RS</code>实现（Jersey等）和容器（Tomcat，Jetty等）结合使用。</p><p>需要注入几个单例：</p><ul><li>ServiceDiscovery</li><li>DiscoveryContext</li><li>JsonServiceInstanceMarshaller</li><li>JsonServiceInstancesMarshaller</li><li>JsonServiceNamesMarshaller</li></ul><p>另外，必须注入<code>JAX-RS Resource</code>类。 由于大多数<code>JAX-RS</code>实现的编写方式，您必须创建一个具体的类，以使用您的有效负载类型对此进行扩展。 具体的类应具有您要使用的基本路径。 因为<code>JAX-RS</code>实现可以为每个请求创建资源的新实例，所以您的具体类必须使用上下文解析器访问<code>DiscoveryContext</code>。 或者，如果您使用的是<code>IoC</code>框架，则可以通过这种方式访问它。</p><p>这是没有有效负载（即 <code>Void payload</code>）的版本：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Path</span>(<span class="string">"/"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyResource</span> <span class="keyword">extends</span> <span class="title">DiscoveryResource</span>&lt;<span class="title">Void</span>&gt; </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MyResource</span><span class="params">(@Context ContextResolver&lt;DiscoveryContext&lt;Void&gt;&gt; resolver)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// note: this may not work with all JAX-RS implementations</span></span><br><span class="line">    <span class="keyword">super</span>(resolver.getContext(DiscoveryContext<span class="class">.<span class="keyword">class</span>))</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="REST"><a href="#REST" class="headerlink" title="REST"></a>REST</h2><p>客户端必须进行适当的REST调用才能注册自己并发送定期心跳。 他们还可以通过REST调用找到服务：</p><h3 id="putService"><a href="#putService" class="headerlink" title="putService"></a>putService</h3><p><strong>Method:</strong> PUT<br><strong>Path:</strong> v1/service/{name}/{id}<br><strong>Request Entity:</strong> ServiceInstance<br><strong>Response Entity:</strong> n/a<br><strong>Description:</strong> {name} is the service name, {id} is the instance id. The request entity is a <em>ServiceInstance</em>. This method registers a service instance. If the ServiceType is STATIC, the instance is registered only for the pre-defined period (defined in the DiscoveryContext). STATIC services must call putService at least once per period. PERMANENT services are registered until they are manually deleted.</p><h3 id="removeService"><a href="#removeService" class="headerlink" title="removeService"></a>removeService</h3><p><strong>Method:</strong> DELETE<br><strong>Path:</strong> v1/service/{name}/{id}<br><strong>Request Entity:</strong> n/a<br><strong>Response Entity:</strong> n/a<br><strong>Description:</strong> {name} is the service name, {id} is the instance id. The specified service is deleted/unregistered.</p><h3 id="get"><a href="#get" class="headerlink" title="get"></a>get</h3><p><strong>Method:</strong> GET<br><strong>Path:</strong> v1/service/{name}/{id}<br><strong>Request Entity:</strong> n/a<br><strong>Response Entity:</strong> ServiceInstance<br><strong>Description:</strong> {name} is the service name, {id} is the instance id. Returns the complete <em>ServiceInstance</em> for the specified service. 404 is returned if not found.</p><h3 id="getAllNames"><a href="#getAllNames" class="headerlink" title="getAllNames"></a>getAllNames</h3><p><strong>Method:</strong> GET<br><strong>Path:</strong> v1/service<br><strong>Request Entity:</strong> n/a<br><strong>Response Entity:</strong> ServiceNames<br><strong>Description:</strong> Returns all currently registered service names.</p><h3 id="getAll"><a href="#getAll" class="headerlink" title="getAll"></a>getAll</h3><p><strong>Method:</strong> GET<br><strong>Path:</strong> v1/service/{name}<br><strong>Request Entity:</strong> n/a<br><strong>Response Entity:</strong> ServiceInstances<br><strong>Description:</strong> {name} is the service name. Returns all service instances for the named service.</p><h3 id="getAny"><a href="#getAny" class="headerlink" title="getAny"></a>getAny</h3><p><strong>Method:</strong> GET<br><strong>Path:</strong> v1/anyservice/{name}<br><strong>Request Entity:</strong> n/a<br><strong>Response Entity:</strong> ServiceInstance<br><strong>Description:</strong> {name} is the service name. Return a random instance from the given service or 404.</p><h3 id="JSON-specs"><a href="#JSON-specs" class="headerlink" title="JSON specs"></a>JSON specs</h3><p>The JSON specifications for the REST entities are documented here: <a href="https://git-wip-us.apache.org/repos/asf?p=curator.git;a=blob_plain;f=curator-x-discovery-server/README.txt;hb=HEAD" target="_blank" rel="noopener">https://git-wip-us.apache.org/repos/asf?p=curator.git;a=blob_plain;f=curator-x-discovery-server/README.txt;hb=HEAD</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Curator </tag>
            
            <tag> Zookeeper </tag>
            
            <tag> Java </tag>
            
            <tag> 注册中心 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux中检查本地系统上的开放端口列表的方法</title>
      <link href="/posts/a10ff556/"/>
      <url>/posts/a10ff556/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="Linux中检查本地系统上的开放端口列表的方法"><a href="#Linux中检查本地系统上的开放端口列表的方法" class="headerlink" title="Linux中检查本地系统上的开放端口列表的方法"></a>Linux中检查本地系统上的开放端口列表的方法</h1><p>在 Linux 中 如果想要查看本地系统上的开放端口，一般使用以下几种命令进行查看</p><p>本文转载自 <a href="https://linux.cn/" target="_blank" rel="noopener">Linux中国</a> 。原文链接：<a href="https://linux.cn/article-10736-1.html" target="_blank" rel="noopener">Linux中检查本地系统上的开放端口列表的方法</a></p><p>你可以使用以下四个命令来完成这个工作。这些命令是非常出名的并被 Linux 管理员广泛使用。</p><p><code>netstat</code>：netstat (“network statistics”) 是一个显示网络连接（进和出）相关信息命令行工具，例如：路由表, 伪装连接,多点传送成员和网络端口。</p><p><code>nmap</code>：Nmap (“Network Mapper”) 是一个网络探索与安全审计的开源工具。它旨在快速扫描大型网络。</p><p><code>ss</code>： ss 被用于转储套接字统计信息。它也可以类似 netstat 使用。相比其他工具它可以展示更多的TCP状态信息。</p><p><code>lsof</code>： lsof 是 List Open File 的缩写. 它用于输出被某个进程打开的所有文件。</p><h2 id="如何使用-Linux-命令-netstat-检查系统中的开放端口列表"><a href="#如何使用-Linux-命令-netstat-检查系统中的开放端口列表" class="headerlink" title="如何使用 Linux 命令 netstat 检查系统中的开放端口列表"></a>如何使用 Linux 命令 netstat 检查系统中的开放端口列表</h2><p>它可以列出所有的 tcp、udp 连接和所有的 unix 套接字连接。</p><p>它用于发现发现网络问题，确定网络连接数量。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">netstat -tplugn</span><br><span class="line">Active Internet connections (only servers)</span><br><span class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name</span><br><span class="line">tcp        0      0 0.0.0.0:25              0.0.0.0:*               LISTEN      2038/master</span><br><span class="line">tcp        0      0 127.0.0.1:199           0.0.0.0:*               LISTEN      1396/snmpd</span><br><span class="line">tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      1398/httpd</span><br><span class="line">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1388/sshd</span><br><span class="line">tcp6       0      0 :::25                   :::*                    LISTEN      2038/master</span><br><span class="line">tcp6       0      0 :::22                   :::*                    LISTEN      1388/sshd</span><br><span class="line">udp        0      0 0.0.0.0:39136           0.0.0.0:*                           1396/snmpd</span><br><span class="line">udp        0      0 0.0.0.0:56130           0.0.0.0:*                           1396/snmpd</span><br><span class="line">udp        0      0 0.0.0.0:40105           0.0.0.0:*                           1396/snmpd</span><br><span class="line">udp        0      0 0.0.0.0:11584           0.0.0.0:*                           1396/snmpd</span><br><span class="line">udp        0      0 0.0.0.0:30105           0.0.0.0:*                           1396/snmpd</span><br><span class="line">udp        0      0 0.0.0.0:50656           0.0.0.0:*                           1396/snmpd</span><br><span class="line">udp        0      0 0.0.0.0:1632            0.0.0.0:*                           1396/snmpd</span><br><span class="line">udp        0      0 0.0.0.0:28265           0.0.0.0:*                           1396/snmpd</span><br><span class="line">udp        0      0 0.0.0.0:40764           0.0.0.0:*                           1396/snmpd</span><br><span class="line">udp        0      0 10.90.56.21:123         0.0.0.0:*                           895/ntpd</span><br><span class="line">udp        0      0 127.0.0.1:123           0.0.0.0:*                           895/ntpd</span><br><span class="line">udp        0      0 0.0.0.0:123             0.0.0.0:*                           895/ntpd</span><br><span class="line">udp        0      0 0.0.0.0:53390           0.0.0.0:*                           1396/snmpd</span><br><span class="line">udp        0      0 0.0.0.0:161             0.0.0.0:*                           1396/snmpd</span><br><span class="line">udp6       0      0 :::123                  :::*                                895/ntpd</span><br><span class="line">IPv6/IPv4 Group Memberships</span><br><span class="line">Interface       RefCnt Group</span><br><span class="line">--------------- ------ ---------------------</span><br><span class="line">lo              1      224.0.0.1</span><br><span class="line">eth0            1      224.0.0.1</span><br><span class="line">lo              1      ff02::1</span><br><span class="line">lo              1      ff01::1</span><br><span class="line">eth0            1      ff02::1</span><br><span class="line">eth0            1      ff01::1</span><br></pre></td></tr></table></figure><p>也可以使用下边的命令来检查特定的端口</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> <span class="comment"># netstat -tplugn | grep :22</span></span></span><br><span class="line">tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1388/sshd</span><br><span class="line">tcp6       0      0 :::22                   :::*                    LISTEN      1388/sshd</span><br></pre></td></tr></table></figure><h2 id="如何使用-Linux-命令-ss-检查系统中的开放端口列表？"><a href="#如何使用-Linux-命令-ss-检查系统中的开放端口列表？" class="headerlink" title="如何使用 Linux 命令 ss 检查系统中的开放端口列表？"></a>如何使用 Linux 命令 ss 检查系统中的开放端口列表？</h2><p><code>ss</code> 被用于转储套接字统计信息。它也可以显示类似 <code>netstat</code> 的信息。相比其他工具它可以展示更多的 TCP 状态信息。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ss -lntu</span></span><br><span class="line">Netid  State      Recv-Q Send-Q                     Local Address:Port                                    Peer Address:Port</span><br><span class="line">udp    UNCONN     0      0                                      *:39136                                              *:*</span><br><span class="line">udp    UNCONN     0      0                                      *:56130                                              *:*</span><br><span class="line">udp    UNCONN     0      0                                      *:40105                                              *:*</span><br><span class="line">udp    UNCONN     0      0                                      *:11584                                              *:*</span><br><span class="line">udp    UNCONN     0      0                                      *:30105                                              *:*</span><br><span class="line">udp    UNCONN     0      0                                      *:50656                                              *:*</span><br><span class="line">udp    UNCONN     0      0                                      *:1632                                               *:*</span><br><span class="line">udp    UNCONN     0      0                                      *:28265                                              *:*</span><br><span class="line">udp    UNCONN     0      0                                      *:40764                                              *:*</span><br><span class="line">udp    UNCONN     0      0                            10.90.56.21:123                                                *:*</span><br><span class="line">udp    UNCONN     0      0                              127.0.0.1:123                                                *:*</span><br><span class="line">udp    UNCONN     0      0                                      *:123                                                *:*</span><br><span class="line">udp    UNCONN     0      0                                      *:53390                                              *:*</span><br><span class="line">udp    UNCONN     0      0                                      *:161                                                *:*</span><br><span class="line">udp    UNCONN     0      0                                     :::123                                               :::*</span><br><span class="line">tcp    LISTEN     0      100                                    *:25                                                 *:*</span><br><span class="line">tcp    LISTEN     0      128                            127.0.0.1:199                                                *:*</span><br><span class="line">tcp    LISTEN     0      128                                    *:80                                                 *:*</span><br><span class="line">tcp    LISTEN     0      128                                    *:22                                                 *:*</span><br><span class="line">tcp    LISTEN     0      100                                   :::25                                                :::*</span><br><span class="line">tcp    LISTEN     0      128                                   :::22                                                :::*</span><br></pre></td></tr></table></figure><p>也可以使用下面的命令检查特定的端口。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ss -lntu | grep <span class="string">':25'</span></span></span><br><span class="line">tcp    LISTEN     0      100       *:25                    *:*</span><br><span class="line">tcp    LISTEN     0      100      :::25                   :::*</span><br></pre></td></tr></table></figure><h2 id="如何使用-Linux-命令-nmap-检查系统中的开放端口列表？"><a href="#如何使用-Linux-命令-nmap-检查系统中的开放端口列表？" class="headerlink" title="如何使用 Linux 命令 nmap 检查系统中的开放端口列表？"></a>如何使用 Linux 命令 nmap 检查系统中的开放端口列表？</h2><p>虽然 <code>Nmap</code> 通常用于安全审计，但许多系统和网络管理员发现它对于日常工作也非常有用，例如网络资产清点、管理服务升级计划以及监控主机或服务正常运行时间。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">nmap -sTU -O localhost</span><br><span class="line">Starting Nmap 6.40 ( http://nmap.org ) at 2019-03-20 09:57 CDT</span><br><span class="line">Nmap scan report for localhost (127.0.0.1)</span><br><span class="line">Host is up (0.00028s latency).</span><br><span class="line">Other addresses for localhost (not scanned): 127.0.0.1</span><br><span class="line">Not shown: 1994 closed ports</span><br><span class="line">PORT    STATE SERVICE</span><br><span class="line">22/tcp  open  ssh</span><br><span class="line">25/tcp  open  smtp</span><br><span class="line">80/tcp  open  http</span><br><span class="line">199/tcp open  smux</span><br><span class="line">123/udp open  ntp</span><br><span class="line">161/udp open  snmp</span><br><span class="line">Device type: general purpose</span><br><span class="line">Running: Linux 3.X</span><br><span class="line">OS CPE: cpe:/o:linux:linux_kernel:3</span><br><span class="line">OS details: Linux 3.7 - 3.9</span><br><span class="line">Network Distance: 0 hops</span><br><span class="line">OS detection performed. Please report any incorrect results at http://nmap.org/submit/ .</span><br><span class="line">Nmap done: 1 IP address (1 host up) scanned in 1.93 seconds</span><br></pre></td></tr></table></figure><p>你也可以使用下面的命令检查特定的端口。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nmap -sTU -O localhost | grep 123</span><br><span class="line">123/udp open  ntp</span><br></pre></td></tr></table></figure><h2 id="如何使用-Linux-命令-lsof-检查系统中的开放端口列表？"><a href="#如何使用-Linux-命令-lsof-检查系统中的开放端口列表？" class="headerlink" title="如何使用 Linux 命令 lsof 检查系统中的开放端口列表？"></a>如何使用 Linux 命令 lsof 检查系统中的开放端口列表？</h2><p>它向你显示系统上打开的文件列表以及打开它们的进程。还会向你显示与文件相关的其他信息。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> lsof -i</span></span><br><span class="line">COMMAND   PID   USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME</span><br><span class="line">ntpd      895    ntp   16u  IPv4   18481      0t0  UDP *:ntp</span><br><span class="line">ntpd      895    ntp   17u  IPv6   18482      0t0  UDP *:ntp</span><br><span class="line">ntpd      895    ntp   18u  IPv4   18487      0t0  UDP localhost:ntp</span><br><span class="line">ntpd      895    ntp   20u  IPv4   23020      0t0  UDP CentOS7.2daygeek.com:ntp</span><br><span class="line">sshd     1388   root    3u  IPv4   20065      0t0  TCP *:ssh (LISTEN)</span><br><span class="line">sshd     1388   root    4u  IPv6   20067      0t0  TCP *:ssh (LISTEN)</span><br><span class="line">snmpd    1396   root    6u  IPv4   22739      0t0  UDP *:snmp</span><br><span class="line">snmpd    1396   root    7u  IPv4   22729      0t0  UDP *:40105</span><br><span class="line">snmpd    1396   root    8u  IPv4   22730      0t0  UDP *:50656</span><br><span class="line">snmpd    1396   root    9u  IPv4   22731      0t0  UDP *:pammratc</span><br><span class="line">snmpd    1396   root   10u  IPv4   22732      0t0  UDP *:30105</span><br><span class="line">snmpd    1396   root   11u  IPv4   22733      0t0  UDP *:40764</span><br><span class="line">snmpd    1396   root   12u  IPv4   22734      0t0  UDP *:53390</span><br><span class="line">snmpd    1396   root   13u  IPv4   22735      0t0  UDP *:28265</span><br><span class="line">snmpd    1396   root   14u  IPv4   22736      0t0  UDP *:11584</span><br><span class="line">snmpd    1396   root   15u  IPv4   22737      0t0  UDP *:39136</span><br><span class="line">snmpd    1396   root   16u  IPv4   22738      0t0  UDP *:56130</span><br><span class="line">snmpd    1396   root   17u  IPv4   22740      0t0  TCP localhost:smux (LISTEN)</span><br><span class="line">httpd    1398   root    3u  IPv4   20337      0t0  TCP *:http (LISTEN)</span><br><span class="line">master   2038   root   13u  IPv4   21638      0t0  TCP *:smtp (LISTEN)</span><br><span class="line">master   2038   root   14u  IPv6   21639      0t0  TCP *:smtp (LISTEN)</span><br><span class="line">sshd     9052   root    3u  IPv4 1419955      0t0  TCP CentOS7.2daygeek.com:ssh-&gt;Ubuntu18-04.2daygeek.com:11408 (ESTABLISHED)</span><br><span class="line">httpd   13371 apache    3u  IPv4   20337      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd   13372 apache    3u  IPv4   20337      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd   13373 apache    3u  IPv4   20337      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd   13374 apache    3u  IPv4   20337      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd   13375 apache    3u  IPv4   20337      0t0  TCP *:http (LISTEN)</span><br></pre></td></tr></table></figure><p>也可以使用下面的命令检查特定的端口。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> lsof -i:80</span></span><br><span class="line">COMMAND   PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME</span><br><span class="line">httpd    1398   root    3u  IPv4  20337      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd   13371 apache    3u  IPv4  20337      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd   13372 apache    3u  IPv4  20337      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd   13373 apache    3u  IPv4  20337      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd   13374 apache    3u  IPv4  20337      0t0  TCP *:http (LISTEN)</span><br><span class="line">httpd   13375 apache    3u  IPv4  20337      0t0  TCP *:http (LISTEN)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch 查询语法</title>
      <link href="/posts/ccf4c8c4/"/>
      <url>/posts/ccf4c8c4/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="ElasticSearch-查询语法"><a href="#ElasticSearch-查询语法" class="headerlink" title="ElasticSearch 查询语法"></a>ElasticSearch 查询语法</h1><h2 id="SearchTimeout"><a href="#SearchTimeout" class="headerlink" title="SearchTimeout"></a>SearchTimeout</h2><ol><li>设置： 默认没有 timeout ， 如果设置了 timeout ，那么会执行 timeout 机制</li><li>timeout 机制：假设用户查询结果有 1W 条数据，但是需要 10’’ 才能查询完毕，但是用户设置了 1s的 timeout, 那么不管当前一共查询到了多少数据，都会在 1s 后 ES 将停止查询，并返回当前数据。</li><li>用法：GET /_search?timeout=1s/ms/m</li></ol><h2 id="ES-常用查询"><a href="#ES-常用查询" class="headerlink" title="ES 常用查询"></a>ES 常用查询</h2><ol><li><p>Query String:</p><ol><li>查询所有：GET /product/_search</li><li>带参数：GET /product/_search?q=name:xiaomi</li><li>分页：GET /product/_search?from=0&amp;size=2&amp;sort=price:asc</li></ol></li><li><p>Query DSL:</p><ol><li><p>match_all: 匹配所有</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query":&#123;</span><br><span class="line">    "match_all": &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>match： name 中包含  <code>nfc</code></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query":&#123;</span><br><span class="line">    "match":&#123;</span><br><span class="line">      "name": "nfc"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>sort: 按照价格倒序进行排序</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "match":&#123;</span><br><span class="line">      "name": "nfc"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  "sort":[</span><br><span class="line">    &#123;</span><br><span class="line">      "price": "desc"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>multi_match: 根据多个字段查询一个关键词，name 和 desc 中包含 <code>nfc</code> 的doc</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "multi_match": &#123;</span><br><span class="line">      "query": "nfc",</span><br><span class="line">      "fields": ["name","desc"]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  "sort"[</span><br><span class="line">    &#123;</span><br><span class="line">      "price": "desc"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>_source 元数据：想要查询多个字段，例子中为只查询 <code>name</code> 和 <code>price</code> 字段</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "match": &#123;</span><br><span class="line">      "name": "nfc"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  "_source": ["name","price"]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>分页 （deep-paging）: 查询第一页 （每页两条数据）</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "match_all": &#123;&#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  "from": 0,</span><br><span class="line">  "size": 2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li><li><p>Full-text queries: 全文检索</p><ol><li><p>query-term: 不会被分词</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "term": &#123;</span><br><span class="line">      "name": "nfc"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>match 和 term 区别</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "term": &#123;</span><br><span class="line">      "name": "nfc phone" 这里因为没有分词，所以查询没有结果</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "bool": &#123;</span><br><span class="line">      "must": [</span><br><span class="line">        &#123;"term": &#123;"name": "nfc"&#125;&#125;,</span><br><span class="line">        &#123;"term": &#123;"name": "phone"&#125;&#125;,</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "terms": &#123;</span><br><span class="line">      "name": ["nfc","phone"]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "match": &#123;</span><br><span class="line">      "name": "nfc phone"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>全文检索</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "match": &#123;</span><br><span class="line">      "name": "xiaomi nfc zhineng phone"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>验证分词</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GET /_analyze</span><br><span class="line">&#123;</span><br><span class="line">  "analyzer": "standard",</span><br><span class="line">  "text": "xiaomi nfc zhineng phone"</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li></ol><ol start="4"><li><p>Phrase search：短语搜索，和全文检索相反， <code>nfc phone</code> 会作为一个短语去检索</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "match_phrase": &#123;</span><br><span class="line">      "name": "nfc_phone"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Query and filter: 查询和过滤</p><ol><li><p>bool :  可以组合多个查询条件，bool 查询也是采用 <code>more_matches_is_better</code> 的机制，因此满足 <code>must</code> 和 <code>should</code> 子句的文档将会合并起来计算分值。</p><ul><li><p>must: 必须满足</p><p>子句（查询）必须出现在匹配的文档中，并将有助于得分。</p></li><li><p><strong>filter: 过滤器 不计算相关度分数，cache</strong> ※</p><p>子句（查询）必须出现在匹配的文档中，但是不像 <code>must</code> 查询的分数将被忽略。Filter 子句在 <code>filter</code> 上下文中执行，这意味着计分被忽略，并且子句被考虑用于缓存。</p></li><li><p>should：可能满足 or</p><p>子句（查询）应出现在匹配的文档中。</p></li><li><p><strong>must_not: 必须不满足 不计算相关度分数 not</strong></p><p>子句（查询）不得出现在匹配的文档中。子句在过滤器上下文中执行，这意味着计分被忽略，并且子句被视为用于缓存。由于忽略计分，0 因此将返回所有文档的分数。</p></li><li><p><strong>minimum_should_match</strong></p></li></ul></li><li><p>案例</p><ul><li><p>demo 案例</p><p>首先筛选 <code>name</code> 包含 <code>xiaomi phone</code> 并且价格大于 1999 的数据 （不排序）</p><p>然后搜索 <code>name</code> 包含 <code>xiaomi</code> 并且 <code>desc</code> 包含 <code>shouji</code></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "bool": &#123;</span><br><span class="line">      "must": [</span><br><span class="line">        &#123;</span><br><span class="line">          "match": &#123;</span><br><span class="line">            "name": "xiaomi"</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          "match": &#123;</span><br><span class="line">            "desc": "shouji"</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      "filter": [</span><br><span class="line">        &#123;</span><br><span class="line">          "match_phrase": &#123;</span><br><span class="line">            "name": "xiaomi phone"</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          "range": &#123;</span><br><span class="line">            "price": &#123;</span><br><span class="line">              "gt": 1999</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>bool 多条件 <code>name</code> 包含 <code>xiaomi</code> 不包含 <code>erji</code> 描述里包不包含 <code>nfc</code> 都可以，价钱要大于等于 4999</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "bool": &#123;</span><br><span class="line">      "must": [</span><br><span class="line">        &#123;</span><br><span class="line">          "match": &#123;</span><br><span class="line">            "name": "xiaomi"</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      "must_not": [</span><br><span class="line">        &#123;</span><br><span class="line">          "match": &#123;</span><br><span class="line">            "name": "erji"</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      "should": [</span><br><span class="line">        &#123;</span><br><span class="line">          "match": &#123;</span><br><span class="line">            "desc": "nfc"</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      "filter": [</span><br><span class="line">        &#123;</span><br><span class="line">          "range": &#123;</span><br><span class="line">            "price": &#123;</span><br><span class="line">              "gt": 4999</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>嵌套查询</p><ol><li><p>minimum_should_match: 参数指定 should 返回的文档必须匹配的子句的数量或百分比。如果 bool 查询包含至少一个 should 子句，而没有 must 或 filter 子句，则默认值为 1。 否则，默认值为 0</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "bool": &#123;</span><br><span class="line">      "must": [</span><br><span class="line">        &#123;</span><br><span class="line">          "match": &#123;</span><br><span class="line">            "name": "nfc"</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      "should": [</span><br><span class="line">        &#123;</span><br><span class="line">          "range": &#123;</span><br><span class="line">            "price": &#123;</span><br><span class="line">              "gt": 1999</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          "range": &#123;</span><br><span class="line">            "price": &#123;</span><br><span class="line">              "gt": 3999</span><br><span class="line">         &#125;</span><br><span class="line">          &#125;</span><br><span class="line">     &#125;</span><br><span class="line">      ],</span><br><span class="line">      "minimum_should_match": 1</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>案例：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "bool": &#123;</span><br><span class="line">      "filter": &#123;</span><br><span class="line">        "bool": &#123;</span><br><span class="line">          "should": [</span><br><span class="line">            &#123;</span><br><span class="line">              "range": &#123;</span><br><span class="line">                "price": &#123;</span><br><span class="line">                  "gt": 1999</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">              "range": &#123;</span><br><span class="line">                "price": &#123;</span><br><span class="line">                  "gt": 3999</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          "must": [</span><br><span class="line">            &#123;</span><br><span class="line">              "match": &#123;</span><br><span class="line">                "name": "nfc"</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li></ol></li><li><p>Compound queries: 组合查询</p><ol><li><p>想要一台带 NFC 功能的 或者 小米的手机 但是不要耳机</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> product </span><br><span class="line"><span class="keyword">WHERE</span> (<span class="string">`name`</span> <span class="keyword">LIKE</span> <span class="string">"%xiaomi%"</span> <span class="keyword">OR</span> <span class="string">`name`</span> <span class="keyword">LIKE</span> <span class="string">'%nfc%'</span>)</span><br><span class="line"><span class="keyword">AND</span> <span class="string">`name`</span> <span class="keyword">NOT</span> <span class="keyword">LIKE</span> <span class="string">'%erji%'</span>;</span><br></pre></td></tr></table></figure><p>Query DSL 写法</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "constant_score": &#123;</span><br><span class="line">      "filter": &#123;</span><br><span class="line">        "bool": &#123;</span><br><span class="line">          "should": [</span><br><span class="line">            &#123;</span><br><span class="line">              "term": &#123;</span><br><span class="line">                "name": "xiaomi"</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">              "term": &#123;</span><br><span class="line">                "name": "nfc"</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          ],</span><br><span class="line">          "must_not": [</span><br><span class="line">            &#123;</span><br><span class="line">              "term": &#123;</span><br><span class="line">                "name": "erji"</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      "boost": 1.2</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>搜索一台 xiaomi nfc phone 或者一台满足 是一台手机 并且 价格 小于等于 2999</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> product</span><br><span class="line"><span class="keyword">WHERE</span> <span class="string">`name`</span> <span class="keyword">LIKE</span> <span class="string">'%xiaomi nfc phone%'</span></span><br><span class="line"><span class="keyword">OR</span> (</span><br><span class="line"><span class="string">`name`</span> <span class="keyword">LIKE</span> <span class="string">'%erji%'</span></span><br><span class="line">    <span class="keyword">AND</span> <span class="string">`price`</span> &gt; <span class="number">399</span></span><br><span class="line">    <span class="keyword">AND</span> <span class="string">`price`</span> &lt;= <span class="number">999</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>Query DSL 写法</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "constant_score": &#123;</span><br><span class="line">      "filter": &#123;</span><br><span class="line">        "bool": &#123;</span><br><span class="line">          "should": [</span><br><span class="line">            &#123;</span><br><span class="line">              "match_phrase": &#123;</span><br><span class="line">                "name": "xiaomi nfc phone"</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">              "bool": &#123;</span><br><span class="line">                "must": [</span><br><span class="line">                  &#123;</span><br><span class="line">                    "term": &#123;</span><br><span class="line">                      "name": "phone"</span><br><span class="line">                    &#125;</span><br><span class="line">                  &#125;,</span><br><span class="line">                  &#123;</span><br><span class="line">                    "range": &#123;</span><br><span class="line">                      "price": &#123;</span><br><span class="line">                        "lte": 2999</span><br><span class="line">                      &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                  &#125;</span><br><span class="line">                ]</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li><li><p>Highlight Search</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">GET /product/_search</span><br><span class="line">&#123;</span><br><span class="line">  "query": &#123;</span><br><span class="line">    "match_phrase": &#123;</span><br><span class="line">      "name": "nfc phone"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  "highlight": &#123;</span><br><span class="line">    "fields": &#123;</span><br><span class="line">      "name": &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h2 id="Deeping-paging-图解"><a href="#Deeping-paging-图解" class="headerlink" title="Deeping paging 图解"></a>Deeping paging 图解</h2><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20201124183336.png" alt=""></p><ol><li>解释：当你的数据超过1W，不要使用</li><li>返回结果不要超过1000个， 500个以下为宜</li><li>解决办法：<ol><li>尽量避免深度分页查询</li><li>使用 Scroll search （只能下一页，没办法上一页，不适合实时查询）</li></ol></li></ol><h2 id="Scroll-search-图解"><a href="#Scroll-search-图解" class="headerlink" title="Scroll search 图解"></a>Scroll search 图解</h2><p>​    解决 deep paging 问题</p><h2 id="filter-缓存原理：-图解"><a href="#filter-缓存原理：-图解" class="headerlink" title="filter 缓存原理： 图解"></a>filter 缓存原理： 图解</h2><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20201124183445.png" alt=""></p>]]></content>
      
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch分布式文档系统</title>
      <link href="/posts/80f71596/"/>
      <url>/posts/80f71596/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="ES-分布式文档系统"><a href="#ES-分布式文档系统" class="headerlink" title="ES 分布式文档系统"></a>ES 分布式文档系统</h1><h2 id="1-ES-如何实现高可用（生产环境均为一台机器一个节点）"><a href="#1-ES-如何实现高可用（生产环境均为一台机器一个节点）" class="headerlink" title="1. ES 如何实现高可用（生产环境均为一台机器一个节点）"></a>1. ES 如何实现高可用（生产环境均为一台机器一个节点）</h2><ol><li>ES 在分配单个索引的分片时会将每个分片尽可能分配到更多的节点上。但是，实际情况取决于集群拥有的分片和索引的数量以及他们的大小，不一定总是能均匀的分布</li><li>ES 不允许 Primary 和它的 Replica 放在同一个节点中，并且同一个节点不接受完全相同的两个 Replica</li><li>同一个节点允许多个索引的分片同时存在</li></ol><h2 id="2-容错机制"><a href="#2-容错机制" class="headerlink" title="2. 容错机制"></a>2. 容错机制</h2><ol><li><p>什么是容错</p><ol><li>傻x的代码你可以看懂，牛x的代码你也能看懂</li><li>只能看懂自己的代码，容错性低</li><li>PS： 各种情况（支持的情况越多，容错性越好）下，都能保证 work 正常运行</li><li>换到 ES 上就是，再局部出错异常的情况下，保证服务正常运行并且有自行恢复能力。</li></ol></li><li><p>ES-node</p><blockquote><p>两个配置： node.master 和 node.data</p><ol><li><p>node.master = true            node.data = true</p><p>这是ES 节点默认配置，即作为候选节点又作为数据节点，这样的节点一旦被选举为 Master，压力是比较大的，通常来说 Master 节点应该只承担较为轻量级的任务，比如创建删除索引，分片均衡等</p></li><li><p>node.master = true            node.data = false</p><p>只作为候选节点，不作为数据节点，可参选 Master 节点，当选后成为真正的 Master 节点</p></li><li><p>node.master = false            node.data = false</p><p>既不当候选节点，也不作为数据节点，那就是仅协调节点，负责负载均衡</p></li><li><p>node.master = false            node.data = data</p><p>不作为候选节点，但是作为数据节点，这样的节点主要负责数据存储和查询服务</p></li></ol></blockquote><ol><li><p>Master: 主节点，每个集群都有且只有一个</p><blockquote><p>尽量避免 Master 节点 <code>node.data = true</code></p></blockquote></li><li><p>voting: 投票节点</p><blockquote><p><code>node.voting_only = true</code> (仅投票节点，即使配置了 <code>data.master = true</code> ,也不会参选，但是仍然可以作为数据节点)</p></blockquote></li><li><p>coordinating: 协调节点</p><blockquote><p>每个节点都隐式的是一个协调节点，如果同时设置了 <code>data.master = false</code> 和 <code>data.data = false</code> ,那么这个节点将成为仅协调节点。</p></blockquote></li><li><p>Master-eligible node: 候选节点</p></li><li><p>Data node: 数据节点</p></li><li><p>Ingest node:</p></li><li><p>Machine learning node: 机器学习节点</p></li></ol></li></ol><h2 id="3-图解容错机制"><a href="#3-图解容错机制" class="headerlink" title="3. 图解容错机制"></a>3. 图解容错机制</h2><ol><li>第一步：Master 选举 （假如宕机节点是 Master ）</li><li>第二步：Replica 容错，新的（或者原有）Master 节点将丢失的 Primary 对应的某个副本提升为 Primary</li><li>第三步：Master 节点会尝试重启故障机</li><li>第四步：数据同步，Master会将宕机期间丢失的数据同步到重启机器对应的分片上去</li></ol><h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h2><ol><li>每台节点的 shard 数量越少，每个Shard 分配的CPU、内存和 IO 资源越多，单个 Shard 的性能越好，当一台机器一个 Shard 时，单个 Shard 性能最好。</li><li>稳定的 Master 节点对于集群健康非常重要！理论上讲，应该尽可能的减轻 Master 节点的压力，分片数量越多，Master 节点维护管理 Shard 的任务越重，并且节点可能就要承担更多的数据转发任务，可增加 “仅协调” 节点来缓解 Master 节点和Data 节点的压力，但是在集群中添加过多的仅协调节点会增加整个集群的负担，因为选择的主节点必须等待每个节点的集群状态更新确认。</li><li>反过来说，在相同资源分配相同的前提下，Shard 数量越少，单个Shard 的体积越大，查询性能越低，速度越慢，这个取舍应根据实际集群状况和结合应用场景等因素综合考虑。</li><li>数据节点和Master 节点一定要分开，集群规模越大，这样做的意义也就越大。</li><li>数据节点处理与数据相关的操作，例如 CRUD ，搜索和聚合。这些操作是 I/O ，内存和 CPU 密集型的，所以他们需要更高配置的服务器以及更高的带宽，并且集群的性能冗余非常重要。</li><li>由于投票节点不参与 Master 竞选，所以和真正的 Master 节点相比，他需要的内存和 CPU 较少。但是，所有候选节点以及仅投票节点都可能是数据节点，所以他们都需要快速稳定低延迟的网络。</li><li>高可用性（HA）集群至少需要三个主节点，其中至少两个不是仅投票节点。即使其中一个节点发生故障，这样的集群也将能够选举一个主节点。生产环境最好设置3台仅 Master 候选节点 (<code>node.master = true node.data = true</code>）</li><li>为了保证集群仍然可用，集群不能同时停止投票配置中的一半或更多节点。只要有一半以上的投票节点可用，集群仍然可以正常工作。这意味着，如果存在三个或四个主节点合格的节点，则群集可以容忍其中一个节点不可用。如果有两个或更少的主机资格节点，则他们必须都保持可用</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch集群安装，搭建以及简单的CURD</title>
      <link href="/posts/97a9c70e/"/>
      <url>/posts/97a9c70e/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="ES集群安装，搭建以及简单的CURD"><a href="#ES集群安装，搭建以及简单的CURD" class="headerlink" title="ES集群安装，搭建以及简单的CURD"></a>ES集群安装，搭建以及简单的CURD</h1><h2 id="1-安装环境"><a href="#1-安装环境" class="headerlink" title="1. 安装环境"></a>1. 安装环境</h2><h3 id="1-安装ES"><a href="#1-安装ES" class="headerlink" title="1. 安装ES"></a>1. 安装ES</h3><blockquote><p>ES的开发模式和生产模式</p><ol><li>开发模式：默认配置（未配置发现设置），用于学习阶段</li><li>生产模式：会触发ES的引导检查，学习阶段不建议修改集群相关配置</li></ol></blockquote><ol><li><p>JDK -&gt; 依赖</p></li><li><p>下载 -&gt; elastic.co</p></li><li><p>启动 -&gt; ./elasticsearch -d</p><blockquote><p>-d 后台启动</p></blockquote></li><li><p>验证 -&gt; <a href="http://localhost:9200/" target="_blank" rel="noopener">http://localhost:9200/</a></p></li></ol><h3 id="2-安装Kibana"><a href="#2-安装Kibana" class="headerlink" title="2. 安装Kibana"></a>2. 安装Kibana</h3><blockquote><p>从6.0.0 版本开始，Kibana仅支持64位操作系统</p></blockquote><ol><li><p>下载：elastic.co</p></li><li><p>启动：依然是开箱即用</p><blockquote><p>Linux: ./kibana</p><p>Windows: ./kibana</p></blockquote></li><li><p>验证：<a href="http://localhost:5601/" target="_blank" rel="noopener">http://localhost:5601/</a></p></li></ol><h2 id="2-集群健康值检查"><a href="#2-集群健康值检查" class="headerlink" title="2. 集群健康值检查"></a>2. 集群健康值检查</h2><h3 id="1-健康值检查"><a href="#1-健康值检查" class="headerlink" title="1. 健康值检查"></a>1. 健康值检查</h3><ol><li>_cat/health</li><li>_cluster/health</li></ol><h3 id="2-健康值状态"><a href="#2-健康值状态" class="headerlink" title="2. 健康值状态"></a>2. 健康值状态</h3><ol><li>Green：所有 Primary 和 Replica 均为 active ，集群健康</li><li>Yellow：至少一个 Replica 不可用，但所有 Primary 均为 active ，数据仍然可以保证其完整性</li><li>Red：至少有一个 Primary 为不可用状态，数据不完整，集群不可用</li></ol><h2 id="3-基本-CRUD"><a href="#3-基本-CRUD" class="headerlink" title="3. 基本 CRUD"></a>3. 基本 CRUD</h2><ol><li><p>创建索引：(索引全部小写）</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PUT /product?pretty</span><br></pre></td></tr></table></figure></li><li><p>查询索引：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /product</span><br></pre></td></tr></table></figure></li><li><p>删除索引：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE /product?pretty</span><br></pre></td></tr></table></figure></li><li><p>插入数据：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">PUT /product/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">    "name" : "xiaomi phone",</span><br><span class="line">    "desc" :  "shouji zhong de zhandouji",</span><br><span class="line">    "price" :  3999,</span><br><span class="line">    "tags": [ "xingjiabi", "fashao", "buka" ]</span><br><span class="line">&#125;</span><br><span class="line">PUT /product/_doc/2</span><br><span class="line">&#123;</span><br><span class="line">    "name" : "xiaomi nfc phone",</span><br><span class="line">    "desc" :  "zhichi quangongneng nfc,shouji zhong de jianjiji",</span><br><span class="line">    "price" :  4999,</span><br><span class="line">    "tags": [ "xingjiabi", "fashao", "gongjiaoka" ]</span><br><span class="line">&#125;</span><br><span class="line">PUT /product/_doc/3</span><br><span class="line">&#123;</span><br><span class="line">    "name" : "nfc phone",</span><br><span class="line">    "desc" :  "shouji zhong de hongzhaji",</span><br><span class="line">    "price" :  2999,</span><br><span class="line">    "tags": [ "xingjiabi", "fashao", "menjinka" ]</span><br><span class="line">&#125;</span><br><span class="line">PUT /product/_doc/4</span><br><span class="line">&#123;</span><br><span class="line">    "name" : "xiaomi erji",</span><br><span class="line">    "desc" :  "erji zhong de huangmenji",</span><br><span class="line">    "price" :  999,</span><br><span class="line">    "tags": [ "low", "bufangshui", "yinzhicha" ]</span><br><span class="line">&#125;</span><br><span class="line">PUT /product/_doc/5</span><br><span class="line">&#123;</span><br><span class="line">    "name" : "hongmi erji",</span><br><span class="line">    "desc" :  "erji zhong de kendeji",</span><br><span class="line">    "price" :  399,</span><br><span class="line">    "tags": [ "lowbee", "xuhangduan", "zhiliangx" ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>更新数据：</p><ol><li><p>全量替换</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">PUT /product/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">    "name" : "xiaomi phone",</span><br><span class="line">    "desc" :  "shouji zhong de zhandouji",</span><br><span class="line">    "price" :  13999,</span><br><span class="line">    "tags": [ "xingjiabi", "fashao", "buka" ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>指定字段更新</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST /product/_doc/1/_update</span><br><span class="line">&#123;</span><br><span class="line">  "doc":&#123;</span><br><span class="line">    "price":123456</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li><li><p>删除数据</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE /product/_doc/1</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch核心概念</title>
      <link href="/posts/8f9d7b23/"/>
      <url>/posts/8f9d7b23/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="Elasticsearch-核心概念"><a href="#Elasticsearch-核心概念" class="headerlink" title="Elasticsearch 核心概念"></a>Elasticsearch 核心概念</h1><h2 id="1-什么是搜索"><a href="#1-什么是搜索" class="headerlink" title="1. 什么是搜索"></a>1. 什么是搜索</h2><p>百度、垂直搜索（站内搜索）</p><p>搜索：通过一个关键词或一段描述，得到你想要的（相关度高）的结果</p><h2 id="2-如何实现搜索功能"><a href="#2-如何实现搜索功能" class="headerlink" title="2. 如何实现搜索功能"></a>2. 如何实现搜索功能</h2><p>关系型数据库：性能差、不可靠、结果不准确（相关度低）</p><h2 id="3-倒排索引、Lucene-和全文检索"><a href="#3-倒排索引、Lucene-和全文检索" class="headerlink" title="3.倒排索引、Lucene 和全文检索"></a>3.倒排索引、Lucene 和全文检索</h2><h3 id="1-倒排索引的数据结构"><a href="#1-倒排索引的数据结构" class="headerlink" title="#1. 倒排索引的数据结构"></a>#1. 倒排索引的数据结构</h3><ol><li>包含这个关键词的 <code>document list</code></li><li>关键词在每个doc中出现的次数 <code>TF term frequency</code></li><li>关键词在整个索引中出现的次数 <code>IDF inverse doc frequency</code></li><li>关键词在当前doc中出现的次数</li><li>每个doc 的长度，越长相关度越低</li><li>包含这个关键词的所有doc 的平均长度</li></ol><h3 id="2-Lucene"><a href="#2-Lucene" class="headerlink" title="#2. Lucene:"></a>#2. Lucene:</h3><p>jar包，帮我们创建倒排索引，提供了复杂的API</p><h3 id="3-如果用-Lucene-做集群实现搜索，会有那些问题"><a href="#3-如果用-Lucene-做集群实现搜索，会有那些问题" class="headerlink" title="#3. 如果用 Lucene 做集群实现搜索，会有那些问题"></a>#3. 如果用 Lucene 做集群实现搜索，会有那些问题</h3><ol><li>节点如果宕机，节点数据丢失，后果不堪设想，可用性差</li><li>自己维护，麻烦（自己创建、管理索引），单台节点的承载请求的能力是有限的，需要人工来做负载（雨露均沾）</li></ol><h3 id="4-Elasticsearch"><a href="#4-Elasticsearch" class="headerlink" title="#4. Elasticsearch"></a>#4. Elasticsearch</h3><blockquote><p>分布式、高性能、高可用、可伸缩、易维护、ES≠搜索引擎</p></blockquote><ol><li>分布式的搜索、存储和数据分析引擎</li><li>优点：<ol><li>面向开发者友好、屏蔽了Lucene的复杂特性，集群自动发现（Cluster Discovery）</li><li>自动维护数据在多个节点上的建立</li><li>会帮我做搜索请求的负载均衡</li><li>自动维护冗余副本，保证了部分节点宕机的情况下仍然不会有任何数据丢失</li><li>ES基于Lucene提供了很多高级功能：符合查询、聚合分析、基于地理位置</li><li>对于大公司、可以构建几百台服务器的大型分布式集群、处理PB级别数据；对于小公司，开箱即用，门槛低上手简单。 </li><li>相对于传统数据库，提供了全文检索，同义词处理，相关度排名。聚合分析以及海量数据的近实时（NTR）处理，这些传统数据库完全做不到。</li></ol></li><li>应用领域<ol><li>百度（全文检索、高亮、搜索推荐）</li><li>各大网站的用户行为日志（用户点击、浏览、收藏、评论）</li><li>BI（Buniness Intelligence 商业智能），数据分析：数据挖掘统计。</li><li>GitHub： 代码托管平台，几千亿行代码</li><li>ELK：Elasticsearch （数据存储）、Logstash（日志采集）、Kibana（可视化）</li></ol></li></ol><h2 id="5-ES核心概念："><a href="#5-ES核心概念：" class="headerlink" title="5. ES核心概念："></a>5. ES核心概念：</h2><ol><li><p>Cluster（集群）：每个集群至少包含两个节点</p></li><li><p>Node：集群中的每个节点，一个节点不代表一台服务器</p></li><li><p>Field：一个数据字段，与 index 和 type 一起，可以定位一个 doc</p></li><li><p>Document：ES 最小的数据单元 JSON</p></li><li><p>Type：逻辑上的数据分类</p></li><li><p>Index：一类相同或类似的 doc ，比如一个员工索引，商品索引</p><blockquote><p>DOC &lt;&gt; row type &lt;&gt;  table index &lt;&gt; db</p></blockquote></li></ol><h2 id="6-Shard-分片"><a href="#6-Shard-分片" class="headerlink" title="6. Shard 分片"></a>6. Shard 分片</h2><ol><li><p>一个 index 包含多个shard，默认 5P，默认每一个P分配一个R，P的数量在创建索引的时候设置，如果想修改，需要重建索引。</p><blockquote><p>P: Primary Shard 可读可写</p><p>R: Replica Shard 只读</p></blockquote></li><li><p>每个 Shard 都是一个 Lucene 示例，有完整的创建索引的处理请求能力</p></li><li><p>ES 会自动在 nodes 上为我们做 shard 均衡</p></li><li><p>一个doc是不可能同时存在于多个PShard中的，但是可以存在于多个RShard中</p></li><li><p>P 和 对应的R不能同时存在于同一个节点上，所以最低的可用配置是两个节点，互为主备</p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一个简单的页面分页显隐算法</title>
      <link href="/posts/7a6cb371/"/>
      <url>/posts/7a6cb371/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>一天，前端同学找我，说页面的分页组件算法应该怎么写，他已经写懵了，并且找了 Element 组件的源码查看分页组件，发现Element 分页组件移植过来有些问题，而且 Element 分页组件的算法很烂。然后我就写了一个分页算法出来</p><h1 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h1><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>原理很简单，就是通过计算开始渲染和结束渲染的盒子下标，然后除最小页码和最大页码外，此外的，均不进行渲染</p><h2 id="JavaScript-实现方式"><a href="#JavaScript-实现方式" class="headerlink" title="JavaScript 实现方式"></a>JavaScript 实现方式</h2><p>鄙人 Js 学的很烂，求轻喷。。。。😀</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 常量：总共页面显示的盒子数</span></span><br><span class="line"><span class="keyword">var</span> SHOW_PAGE_NUM = <span class="number">9</span>;</span><br><span class="line"><span class="comment">// 常量：当选中中间页码，前后渲染的盒子数量</span></span><br><span class="line"><span class="keyword">var</span> CENTER_AROUND_NUM = <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行方法</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">main</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="comment">// 当前页码</span></span><br><span class="line">    <span class="keyword">let</span> position = <span class="number">1</span>;</span><br><span class="line">    <span class="comment">// 总页数</span></span><br><span class="line">    <span class="keyword">let</span> pageCount = <span class="number">15</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// pageCount 是页码总数，position 是当前页码</span></span><br><span class="line">    process(pageCount, position);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">process</span>(<span class="params">pageCount, position</span>) </span>&#123;</span><br><span class="line">    position--;</span><br><span class="line">    <span class="keyword">let</span> pagesList = [];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1. 计算position 前可放几个显示页</span></span><br><span class="line">    <span class="keyword">let</span> beforeSize = position - <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 计算position 后可放几个显示页</span></span><br><span class="line">    <span class="keyword">let</span> afterSize = pageCount - <span class="number">1</span> - <span class="number">1</span> - position;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 1. 当 beforeSize &lt;= CENTER_AROUND_NUM 时前边页码渲染</span></span><br><span class="line"><span class="comment">     * 2. 当 afterSize &lt;= CENTER_AROUND_NUM 时后边页码渲染</span></span><br><span class="line"><span class="comment">     * 3. 其他情况 两边渲染</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 开始渲染的盒子下标</span></span><br><span class="line">    <span class="keyword">let</span> startPosition;</span><br><span class="line">    <span class="comment">// 最后被渲染盒子的下标</span></span><br><span class="line">    <span class="keyword">let</span> endPosition;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 计算下标</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (pageCount &lt;= SHOW_PAGE_NUM) &#123;</span><br><span class="line">        startPosition = <span class="number">0</span>;</span><br><span class="line">        endPosition = pageCount - <span class="number">1</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (beforeSize &lt;= CENTER_AROUND_NUM) &#123;</span><br><span class="line">        startPosition = <span class="number">0</span>;</span><br><span class="line">        endPosition = CENTER_AROUND_NUM * <span class="number">2</span> + <span class="number">1</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (afterSize &lt;= CENTER_AROUND_NUM) &#123;</span><br><span class="line">        startPosition = pageCount - <span class="number">1</span> - <span class="number">1</span> - CENTER_AROUND_NUM * <span class="number">2</span>;</span><br><span class="line">        endPosition = pageCount - <span class="number">1</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        startPosition = position - <span class="number">3</span>;</span><br><span class="line">        endPosition = position + <span class="number">3</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 渲染盒子</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; pageCount; i++) &#123;</span><br><span class="line">        <span class="keyword">let</span> pg = &#123;&#125;;</span><br><span class="line">        pg.pagePosition = i + <span class="number">1</span>;</span><br><span class="line">        pg.isShow = (i == <span class="number">0</span> || i == pageCount - <span class="number">1</span> || i &gt;= startPosition &amp;&amp; i &lt;= endPosition);</span><br><span class="line">        pagesList.push(pg);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 打印输出</span></span><br><span class="line">    <span class="built_in">console</span>.log(pagesList);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Java-代码实现方式"><a href="#Java-代码实现方式" class="headerlink" title="Java 代码实现方式"></a>Java 代码实现方式</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.StringJoiner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PageTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> SHOW_PAGE_NUM = <span class="number">9</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> CENTER_AROUND_NUM = <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> position = <span class="number">1</span>;</span><br><span class="line">        process(<span class="number">15</span>, position).forEach(System.out::println);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> List&lt;Pages&gt; <span class="title">process</span><span class="params">(<span class="keyword">int</span> pageCount, <span class="keyword">int</span> position)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 转换为下标</span></span><br><span class="line">        position--;</span><br><span class="line"></span><br><span class="line">        List&lt;Pages&gt; pagesList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 计算position 前可放几个显示页</span></span><br><span class="line">        <span class="keyword">int</span> beforeSize = position - <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 计算position 后可放几个显示页</span></span><br><span class="line">        <span class="keyword">int</span> afterSize = pageCount - <span class="number">1</span> - <span class="number">1</span> - position;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 1. 当 beforeSize &lt;= CENTER_AROUND_NUM 时前边页码渲染</span></span><br><span class="line"><span class="comment">         * 2. 当 afterSize &lt;= CENTER_AROUND_NUM 时后边页码渲染</span></span><br><span class="line"><span class="comment">         * 3. 其他情况 两边渲染</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> startPosition;</span><br><span class="line">        <span class="keyword">int</span> endPosition;</span><br><span class="line">        <span class="keyword">if</span> (pageCount &lt;= SHOW_PAGE_NUM) &#123;</span><br><span class="line">            startPosition = <span class="number">0</span>;</span><br><span class="line">            endPosition = pageCount - <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (beforeSize &lt;= CENTER_AROUND_NUM) &#123;</span><br><span class="line">            startPosition = <span class="number">0</span>;</span><br><span class="line">            endPosition = CENTER_AROUND_NUM * <span class="number">2</span> + <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (afterSize &lt;= CENTER_AROUND_NUM) &#123;</span><br><span class="line">            startPosition = pageCount - <span class="number">1</span> - <span class="number">1</span> - CENTER_AROUND_NUM * <span class="number">2</span>;</span><br><span class="line">            endPosition = pageCount - <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            startPosition = position - <span class="number">3</span>;</span><br><span class="line">            endPosition = position + <span class="number">3</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; pageCount; i++) &#123;</span><br><span class="line">            Pages pg = <span class="keyword">new</span> Pages();</span><br><span class="line">            pg.pagePosition = i + <span class="number">1</span>;</span><br><span class="line">            pg.isShow = (i == <span class="number">0</span> || i == pageCount - <span class="number">1</span> || i &gt;= startPosition &amp;&amp; i &lt;= endPosition);</span><br><span class="line">            pagesList.add(pg);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> pagesList;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Pages</span> </span>&#123;</span><br><span class="line">        <span class="keyword">public</span> Integer pagePosition;</span><br><span class="line">        <span class="keyword">public</span> Boolean isShow;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            return new StringJoiner(", ", Pages.class.getSimpleName() + "[", "]")</span><br><span class="line">                    .add(<span class="string">"pagePosition="</span> + pagePosition)</span><br><span class="line">                    .add(<span class="string">"isShow="</span> + isShow)</span><br><span class="line">                    .toString();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 算法 </tag>
            
            <tag> 分页 </tag>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HBase 集群安装</title>
      <link href="/posts/34ad406f/"/>
      <url>/posts/34ad406f/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="Hbase-安装"><a href="#Hbase-安装" class="headerlink" title="Hbase 安装"></a>Hbase 安装</h1><p>以三台机器搭建集群环境为例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hbase1 10.10.3.129</span><br><span class="line"></span><br><span class="line">hbase2 10.10.3.130</span><br><span class="line"></span><br><span class="line">hbase3 10.10.3.131</span><br></pre></td></tr></table></figure><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><h3 id="创建相关用户"><a href="#创建相关用户" class="headerlink" title="创建相关用户"></a>创建相关用户</h3><blockquote><p>三台机器操作方式相同</p></blockquote><p>创建zookeeper、Hbase、Hadoop用户,并设置密码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# useradd zookeeper</span><br><span class="line">[root@localhost opt]# passwd zookeeper</span><br><span class="line">[root@localhost opt]# useradd hadoop</span><br><span class="line">[root@localhost opt]# passwd hadoop</span><br><span class="line">[root@localhost opt]# useradd hbase</span><br><span class="line">[root@localhost opt]# passwd hbase</span><br></pre></td></tr></table></figure><p>将此三个用户加入到 sudoers 中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# vim /etc/sudoers</span><br></pre></td></tr></table></figure><h3 id="Hosts-与-免密"><a href="#Hosts-与-免密" class="headerlink" title="Hosts 与 免密"></a>Hosts 与 免密</h3><blockquote><p>三台机器操作方式相同</p></blockquote><p>编辑hosts</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# vim &#x2F;etc&#x2F;hosts</span><br></pre></td></tr></table></figure><p>在文件末尾增加以下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hbase1 10.10.3.129</span><br><span class="line">hbase2 10.10.3.130</span><br><span class="line">hbase3 10.10.3.131</span><br></pre></td></tr></table></figure><p>编辑hostname</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# vim /etc/sysconfig/network</span><br></pre></td></tr></table></figure><p>填入以下内容(根据相应IP对应关系，在相应hosts上配置)</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">HOSTNAME</span>=<span class="string">hbase1</span></span><br></pre></td></tr></table></figure><p>免密</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# ssh-keygen</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/root/.ssh/id_rsa): </span><br><span class="line">Enter passphrase (empty for no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved in /root/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /root/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:F142fovQQib0Kgl/WL/USKPv8z/8Xfb0O5/dD/wA+Fo root@localhost.localdomain</span><br><span class="line">The key's randomart image is:</span><br><span class="line">+---[RSA 2048]----+</span><br><span class="line">|        .        |</span><br><span class="line">|       . .       |</span><br><span class="line">|    .   o B +    |</span><br><span class="line">|     o + X @ .   |</span><br><span class="line">|      = S X = .  |</span><br><span class="line">|       o + = = . |</span><br><span class="line">|          o E.= +|</span><br><span class="line">|         ..o  oBO|</span><br><span class="line">|          oo...=/|</span><br><span class="line">+----[SHA256]-----+</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# ssh-copy-id hbase1</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"</span><br><span class="line">The authenticity of host 'hbase1 (10.10.3.129)' can't be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:GkgGCNlxc55obBDytcgmvK5kJXR5wHuhKejQwr/yxfg.</span><br><span class="line">ECDSA key fingerprint is MD5:1f:70:01:4a:06:a8:66:e7:88:47:bf:4c:0f:30:5b:52.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line">root@hbase1's password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   "ssh 'hbase1'"</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# ssh-copy-id hbase2</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"</span><br><span class="line">The authenticity of host 'hbase2 (10.10.3.130)' can't be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:GkgGCNlxc55obBDytcgmvK5kJXR5wHuhKejQwr/yxfg.</span><br><span class="line">ECDSA key fingerprint is MD5:1f:70:01:4a:06:a8:66:e7:88:47:bf:4c:0f:30:5b:52.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line">root@hbase2's password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   "ssh 'hbase2'"</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# ssh-copy-id hbase3</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"</span><br><span class="line">The authenticity of host 'hbase3 (10.10.3.131)' can't be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:GkgGCNlxc55obBDytcgmvK5kJXR5wHuhKejQwr/yxfg.</span><br><span class="line">ECDSA key fingerprint is MD5:1f:70:01:4a:06:a8:66:e7:88:47:bf:4c:0f:30:5b:52.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line">root@hbase3's password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   "ssh 'hbase3'"</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br></pre></td></tr></table></figure><p>分别切换到hadoop用户，执行上方免密操作，方式相同</p><h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h3><blockquote><p>三台机器操作方式相同</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# systemctl stop firewalld</span><br><span class="line">[root@localhost ~]# systemctl disable firewalld</span><br></pre></td></tr></table></figure><h3 id="JDK-1-8"><a href="#JDK-1-8" class="headerlink" title="JDK 1.8"></a>JDK 1.8</h3><blockquote><p>三台机器操作方式相同</p></blockquote><p>下载 JDK1.8 安装包</p><p>放置到 <code>/opt</code> 下并解压</p><p>重命名文件夹为 <code>jdk</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# tar -zxvf jdk-8u251-linux-x64.tar.gz</span><br><span class="line">[root@localhost opt]# mv /opt/jdk1.8.0_251 /opt/jdk</span><br></pre></td></tr></table></figure><p>配置环境变量</p><p>编辑 <code>/etc/profile</code></p><p>在文件末尾增加两行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> jdk 相关</span></span><br><span class="line">export JAVA_HOME=/opt/jdk</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure><p>加载新配置的环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="重启机器"><a href="#重启机器" class="headerlink" title="重启机器"></a>重启机器</h3><blockquote><p>三台机器操作方式相同</p></blockquote><h2 id="安装-Zookeeper"><a href="#安装-Zookeeper" class="headerlink" title="安装 Zookeeper"></a>安装 Zookeeper</h2><blockquote><p>三台机器操作方式相同</p></blockquote><p>下载 Zookeeper 安装包</p><p>放置到 <code>/opt</code> 下并解压</p><p>重命名文件夹为 <code>zookeeper</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz</span><br><span class="line">[root@localhost opt]# mv /opt/apache-zookeeper-3.5.7-bin /opt/zookeeper</span><br></pre></td></tr></table></figure><p>配置环境变量</p><p>编辑 <code>/etc/profile</code></p><p>在文件末尾增加</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> zookeeper相关</span></span><br><span class="line">export ZOOKEEPER_HOME=/opt/zookeeper</span><br></pre></td></tr></table></figure><p>加载新配置的环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# source /etc/profile</span><br></pre></td></tr></table></figure><p>创建数据存放路径，日志存放路径，创建zookeeper ID文件，并赋权。其中 <code>your id</code>为你的zookeeper节点ID，需保证三台不重复，且为数字</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# mkdir -p /data/zookeeper</span><br><span class="line">[root@localhost opt]# mkdir -p /var/log/zookeeper</span><br><span class="line">[root@localhost opt]# echo "your id" &gt; /data/zookeeper/myid</span><br><span class="line">[root@localhost opt]# chown -R zookeeper:zookeeper /data/zookeeper</span><br><span class="line">[root@localhost opt]# chown -R zookeeper:zookeeper /var/log/zookeeper</span><br><span class="line">[root@localhost opt]# chown -R zookeeper:zookeeper /opt/zookeeper</span><br></pre></td></tr></table></figure><p>创建 zookeeper 配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# cp $ZOOKEEPER_HOME/conf/zoo_sample.cfg $ZOOKEEPER_HOME/conf/zoo.cfg</span><br></pre></td></tr></table></figure><p>编辑 zookeeper 配置文件，修改 <code>dataDir</code> 参数</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">dataDir</span>=<span class="string">/data/zookeeper</span></span><br></pre></td></tr></table></figure><p>编辑 zookeeper 配置文件，增加以下参数(server.id 为你上方的 zookeeper 节点ID)</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">server.1</span>=<span class="string">hbase1:2888:3888</span></span><br><span class="line"><span class="meta">server.2</span>=<span class="string">hbase2:2888:3888</span></span><br><span class="line"><span class="meta">server.3</span>=<span class="string">hbase3:2888:3888</span></span><br></pre></td></tr></table></figure><h2 id="安装-Hadoop"><a href="#安装-Hadoop" class="headerlink" title="安装 Hadoop"></a>安装 Hadoop</h2><blockquote><p>此操作三台相同，三台是相同的配置文件</p></blockquote><p>下载 Hadoop 安装包</p><p>放置到 <code>/opt</code> 下并解压</p><p>重命名文件夹为 <code>hadoop</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# tar -zxvf hadoop-2.8.1.tar.gz</span><br><span class="line">[root@localhost opt]# mv /opt/hadoop-2.8.1 /opt/hadoop</span><br></pre></td></tr></table></figure><p>配置环境变量</p><p>编辑 <code>/etc/profile</code></p><p>在文件末尾增加</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> hadoop 相关</span></span><br><span class="line">export HADOOP_HOME=/opt/hadoop</span><br><span class="line">export HADOOP_PREFIX=$HADOOP_HOME</span><br><span class="line">export HADOOP_MAPRED_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_HDFS_HOME=$HADOOP_HOME</span><br><span class="line">export YARN_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin</span><br><span class="line">export HADOOP_INSTALL=$HADOOP_HOME</span><br></pre></td></tr></table></figure><p>加载新配置的环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# source /etc/profile</span><br></pre></td></tr></table></figure><h4 id="编辑-Hadoop-相关配置文件"><a href="#编辑-Hadoop-相关配置文件" class="headerlink" title="编辑 Hadoop 相关配置文件"></a>编辑 Hadoop 相关配置文件</h4><h5 id="slaves"><a href="#slaves" class="headerlink" title="slaves"></a>slaves</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# vim $HADOOP_HOME/etc/hadoop/slaves</span><br></pre></td></tr></table></figure><p>填入 ip 与hosts的映射关系</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hbase1 10.10.3.129</span><br><span class="line">hbase2 10.10.3.130</span><br><span class="line">hbase3 10.10.3.131</span><br></pre></td></tr></table></figure><h5 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# vim $HADOOP_HOME/etc/hadoop/hdfs-site.xml</span><br></pre></td></tr></table></figure><p>完整配置文件如下</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hbase1,hbase2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.hbase1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hbase1:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.hbase1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hbase1:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.hbase2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hbase2:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.hbase2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hbase2:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://hbase1:8485;hbase2:8485;hbase3:8485/mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/hadoop/hdfs/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/hadoop/hdfs/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/hadoop/hdfs/journalnode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.qjournal.start-segment.timeout.ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hbase1:2181,hbase2:2181,hbase3:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h5 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# vim $HADOOP_HOME/etc/hadoop/core-site.xml</span><br></pre></td></tr></table></figure><p>完整配置文件如下</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.session-timeout.ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>30000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h5 id="hadoop-env-sh"><a href="#hadoop-env-sh" class="headerlink" title="hadoop-env.sh"></a>hadoop-env.sh</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# vim $HADOOP_HOME/etc/hadoop/hadoop-env.sh</span><br></pre></td></tr></table></figure><p>在文件头部填入以下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_NAMENODE_OPTS=" -Xms1024m -Xmx1024m -XX:+UseParallelGC"</span><br><span class="line">export HADOOP_DATANODE_OPTS=" -Xms1024m -Xmx1024m"</span><br><span class="line">export HADOOP_LOG_DIR=/var/log/hadoop</span><br></pre></td></tr></table></figure><h4 id="创建相关文件夹"><a href="#创建相关文件夹" class="headerlink" title="创建相关文件夹"></a>创建相关文件夹</h4><p>创建数据存放路径，日志存放路径，并赋权。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# mkdir -p /data/hadoop/hdfs</span><br><span class="line">[root@localhost opt]# mkdir -p /data/hadoop/hdfs/journalnode</span><br><span class="line">[root@localhost opt]# mkdir -p /var/log/hadoop</span><br><span class="line">[root@localhost opt]# chown -R hadoop:hadoop /data/hadoop</span><br><span class="line">[root@localhost opt]# chown -R hadoop:hadoop /var/log/hadoop</span><br><span class="line">[root@localhost opt]# chown -R hadoop:hadoop /opt/hadoop</span><br></pre></td></tr></table></figure><h2 id="安装HBase"><a href="#安装HBase" class="headerlink" title="安装HBase"></a>安装HBase</h2><blockquote><p>此操作三台相同，三台是相同的配置文件</p></blockquote><p>下载 HBase安装包</p><p>放置到 <code>/opt</code> 下并解压</p><p>重命名文件夹为 <code>hbase</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# tar -zxvf hbase-2.3.0-bin.tar.gz</span><br><span class="line">[root@localhost opt]# mv /opt/hbase-2.3.0 /opt/hbase</span><br></pre></td></tr></table></figure><p>配置环境变量</p><p>编辑 <code>/etc/profile</code></p><p>在文件末尾增加</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> hbase相关</span></span><br><span class="line">export HBASE_HOME=/opt/hbase</span><br><span class="line">export PATH=$PATH:$HBASE_HOME/bin</span><br></pre></td></tr></table></figure><p>加载新配置的环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# source /etc/profile</span><br></pre></td></tr></table></figure><h4 id="编辑相关配置文件"><a href="#编辑相关配置文件" class="headerlink" title="编辑相关配置文件"></a>编辑相关配置文件</h4><h5 id="hdfs-site-xml-1"><a href="#hdfs-site-xml-1" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h5><p>将hadoop下的hdfs-xite.xml 复制或软链接一份到  <code>$HBASE_HOME/conf</code> 下。这里建议软连接</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# ln -s /opt/hadoop/etc/hadoop/hdfs-site.xml /opt/hbase/conf/hdfs-site.xml</span><br></pre></td></tr></table></figure><h5 id="hbase-site-xml"><a href="#hbase-site-xml" class="headerlink" title="hbase-site.xml"></a>hbase-site.xml</h5><p>在原文件中增加如下内容</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/hbase/zookeeper<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hbase1,hbase2,hbase3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h5 id="hbase-env-sh"><a href="#hbase-env-sh" class="headerlink" title="hbase-env.sh"></a>hbase-env.sh</h5><p>修改配置文件中 <code>HBASE_CLASSPATH</code> 内容，如有注释，请先取消注释</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export HBASE_CLASSPATH=/opt/hadoop/etc/hadoop</span><br><span class="line">export HBASE_LOG_DIR=/var/log/hbase</span><br><span class="line">export HBASE_MANAGES_ZK=false</span><br></pre></td></tr></table></figure><h4 id="创建相关文件夹-1"><a href="#创建相关文件夹-1" class="headerlink" title="创建相关文件夹"></a>创建相关文件夹</h4><p>创建数据存放路径，日志存放路径，并赋权。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# mkdir -p /data/hbase</span><br><span class="line">[root@localhost opt]# mkdir -p /data/hbase/zookeeper</span><br><span class="line">[root@localhost opt]# mkdir -p /var/log/hbase</span><br><span class="line">[root@localhost opt]# chown -R hbase:hbase /data/hbase</span><br><span class="line">[root@localhost opt]# chown -R hbase:hbase /var/log/hbase</span><br><span class="line">[root@localhost opt]# chown -R hbase:hbase /opt/hbase</span><br></pre></td></tr></table></figure><h2 id="初始化-Zookeeper"><a href="#初始化-Zookeeper" class="headerlink" title="初始化 Zookeeper"></a>初始化 Zookeeper</h2><blockquote><p>此操作三台相同</p><p>启动前请注意关闭防火墙</p></blockquote><p>切换到 zookeeper 用户</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# su - zookeeper</span><br></pre></td></tr></table></figure><p>启动 Zookeeper 服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[zookeeper@localhost ~]# $ZOOKEEPER_HOME/bin/zkServer.sh start</span><br></pre></td></tr></table></figure><p>然后查看Zookeeper集群状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[zookeeper@localhost ~]# $ZOOKEEPER_HOME/bin/zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost.</span><br><span class="line">Mode: leader</span><br></pre></td></tr></table></figure><p>查看返回信息，如果集群中显示有两个 <code>follower</code> 和一个 <code>leader</code> ，说明集群启动成功</p><h2 id="初始化HDFS"><a href="#初始化HDFS" class="headerlink" title="初始化HDFS"></a>初始化HDFS</h2><blockquote><p>三台机器操作相同</p></blockquote><p>切换到 hadoop 用户</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# su - hadoop</span><br></pre></td></tr></table></figure><h3 id="1-启动-journalnode-服务"><a href="#1-启动-journalnode-服务" class="headerlink" title="1. 启动 journalnode 服务"></a>1. 启动 journalnode 服务</h3><blockquote><p>三台机器操作相同</p></blockquote><p>启动 journalnode 服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh start journalnode</span><br></pre></td></tr></table></figure><p>然后查看相关进程信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost ~]# jps</span><br><span class="line">2410 Jps</span><br><span class="line">15231 JournalNode</span><br></pre></td></tr></table></figure><p>查看返回信息，如果显示了 <code>JournalNode</code> 进程，且查看日志没有发现相关错误信息，说明 <code>JournalNode</code> 启动成功</p><p>查看 <code>JournalNode</code>  日志信息(后边的 <code>hbase1</code> 是你的主机名称，其他两台根据实际情况更换主机名即可)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost ~]# /var/log/hadoop/hadoop-hadoop-journalnode-hbase1.log</span><br></pre></td></tr></table></figure><h3 id="2-初始化-Namenode"><a href="#2-初始化-Namenode" class="headerlink" title="2. 初始化 Namenode"></a>2. 初始化 Namenode</h3><p>在第一台机器上，也就是 <code>hbase1</code> 上，执行以下代码进行初始化</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 初始化主namenode</span></span><br><span class="line">[hadoop@hbase1 ~]# hdfs namenode -format</span><br></pre></td></tr></table></figure><p>如果没有相关错误信息，且初始化成功结束，说明主 <code>namenode</code> 初始化成功</p><p>然后启动刚初始化的 <code>namenode</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start namenode</span><br></pre></td></tr></table></figure><p>在第二台机器上，也就是 <code>hbase2</code> 上，执行以下代码进行初始化</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 初始化备namenode</span></span><br><span class="line">[hadoop@hbase2 ~]# hdfs namenode -bootstrapStandby</span><br></pre></td></tr></table></figure><p>接下来关闭第一台刚启动的 <code>namenode</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs stop namenode</span><br></pre></td></tr></table></figure><p>然后初始化 <code>JournalNode</code>  中的记录，在第一台 <code>namenode</code> 上执行以下命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]# hdfs namenode -initializeSharedEdits</span><br></pre></td></tr></table></figure><p>启动刚初始化好的两台 <code>namenode</code>  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start namenode</span><br></pre></td></tr></table></figure><p>然后在两台<code>namenode</code>分别查看相关进程信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]$ jps</span><br><span class="line">15792 NameNode</span><br><span class="line">2648 Jps</span><br><span class="line">15231 JournalNode</span><br></pre></td></tr></table></figure><p>查看返回信息，如果显示了 <code>namenode</code>  进程，且查看日志没有发现相关错误信息，说明 <code>namenode</code>  启动成功</p><p>查看 <code>namenode</code>  日志信息(后边的 <code>hbase1</code> 是你的主机名称，其他两台根据实际情况更换主机名即可)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]# /var/log/hadoop/hadoop-hadoop-namenode-hbase1.log</span><br></pre></td></tr></table></figure><h3 id="3-初始化-zkfc"><a href="#3-初始化-zkfc" class="headerlink" title="3. 初始化 zkfc"></a>3. 初始化 zkfc</h3><p>在第一台机器上，也就是 <code>hbase1</code> 上，执行以下代码进行初始化</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 初始化zkfc</span></span><br><span class="line">[hadoop@hbase1 ~]# hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure><p>如果没有相关错误信息，且初始化成功结束，查看 <code>zookeeper</code> 中相关信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看zookeeper中相关信息</span></span><br><span class="line">[hadoop@hbase1 ~]# $ZOOKEEPER_HOME/bin/zkCli.sh</span><br><span class="line">Connecting to localhost:2181</span><br><span class="line">[zk: localhost:2181(CONNECTED) 0] ls /</span><br><span class="line">[hadoop-ha, zookeeper]</span><br></pre></td></tr></table></figure><p>可以看到多出了一个 <code>hadoop-ha</code> 目录，说明初始化正确</p><p>接下来停止两台 <code>namenode</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs stop namenode</span><br></pre></td></tr></table></figure><p>然后启动两台 <code>namenode</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start namenode</span><br></pre></td></tr></table></figure><p>通过浏览器访问 <code>&lt;hostname&gt;:50070</code> 可以看到两台 <code>namenode</code> 现在都处于 <code>standby</code> 状态</p><p>两台启动 <code>zkfc</code> </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start zkfc</span><br></pre></td></tr></table></figure><p>然后在两台<code>namenode</code>分别查看相关进程信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]$ jps</span><br><span class="line">15792 NameNode</span><br><span class="line">15908 DFSZKFailoverController</span><br><span class="line">5339 Jps</span><br><span class="line">15231 JournalNode</span><br></pre></td></tr></table></figure><p>查看返回信息，如果显示了 <code>DFSZKFailoverController</code>  进程，且查看日志没有发现相关错误信息，说明 <code>zkfc</code> 启动成功</p><p>查看 <code>namenode</code>  日志信息(后边的 <code>hbase1</code> 是你的主机名称，其他两台根据实际情况更换主机名即可)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]# /var/log/hadoop/hadoop-hadoop-namenode-hbase1.log</span><br></pre></td></tr></table></figure><p>通过浏览器访问 <code>&lt;hostname&gt;:50070</code> 可以看到两台 <code>namenode</code> 其中一台处于 <code>active</code> 状态，另一台处于 <code>standby</code> 状态，说明 <code>zkfc</code>  初始化工作完成</p><h3 id="4-启动-DataNode"><a href="#4-启动-DataNode" class="headerlink" title="4. 启动 DataNode"></a>4. 启动 DataNode</h3><p>在三台机器，执行以下代码进行启动 <code>datanode</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动 datanode</span></span><br><span class="line">[hadoop@hbase1(hbase2,hbase3) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start datanode</span><br></pre></td></tr></table></figure><p>然后在三台<code>datanode</code>分别查看相关进程信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]$ jps</span><br><span class="line">15792 NameNode</span><br><span class="line">15908 DFSZKFailoverController</span><br><span class="line">5339 Jps</span><br><span class="line">16014 DataNode</span><br><span class="line">15231 JournalNode</span><br></pre></td></tr></table></figure><p>查看返回信息，如果显示了 <code>DataNode</code>  进程，且查看日志没有发现相关错误信息，说明 <code>DataNode</code>  启动成功</p><p>查看 <code>DataNode</code>  日志信息(后边的 <code>hbase1</code> 是你的主机名称，其他两台根据实际情况更换主机名即可)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]# /var/log/hadoop/hadoop-hadoop-datanode-hbase1.log</span><br></pre></td></tr></table></figure><h2 id="初始化-HBase"><a href="#初始化-HBase" class="headerlink" title="初始化 HBase"></a>初始化 HBase</h2><blockquote><p>在首次启动 HBase 之前，请保证 hdfs 所有服务都处于开启状态，zookeeper 处于开启状态</p></blockquote><p>将 hbase 用户添加到 supergroup 组中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# groupadd supergroup</span><br><span class="line">[root@localhost ~]# groupmems -g supergroup -a hbase</span><br></pre></td></tr></table></figure><p>切换到 hbase 用户</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# su - hbase</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动 HMaster,只在第一台执行</span></span><br><span class="line">[hbase@hbase1 ~]# $HBASE_HOME/bin/hbase-daemon.sh start master</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动 HRegionserver，三台都执行</span></span><br><span class="line">[hbase@hbase1(hbase2,hbase3) ~]# $HBASE_HOME/bin/hbase-daemon.sh start regionserver</span><br></pre></td></tr></table></figure><p>然后在三台机器分别查看相关进程信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hbase@hbase1 zookeeper]$ jps</span><br><span class="line">32628 HMaster</span><br><span class="line">5991 Jps</span><br><span class="line">3309 Main</span><br><span class="line">32383 HRegionServer</span><br></pre></td></tr></table></figure><p>查看返回信息，如果在第一台显示了 <code>Hmaster</code> 并且这三台都显示了 <code>HRegionServer</code>  进程，且查看日志没有发现相关错误信息，说明 <code>HRegionServer</code>  启动成功</p><p>查看 <code>HRegionServer</code>  日志信息(后边的 <code>hbase1</code> 是你的主机名称，其他两台根据实际情况更换主机名即可)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看 HMaster 日志信息</span></span><br><span class="line">[hbase@hbase1 ~]# tail -f /var/log/hbase/hbase-hbase-master-hbase1.log</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看 HRegionserver 日志信息</span></span><br><span class="line">[hbase@hbase1(hbase2,hbase3) ~]# tail -f /var/log/hbase/hbase-hbase-regionserver-hbase1.log</span><br></pre></td></tr></table></figure><h2 id="启动顺序"><a href="#启动顺序" class="headerlink" title="启动顺序"></a>启动顺序</h2><blockquote><p>注意：启动时必须按照启动顺序启动，否则可能会出现某些未知的启动失败的情况</p></blockquote><h3 id="Zookeeper-相关"><a href="#Zookeeper-相关" class="headerlink" title="Zookeeper 相关"></a>Zookeeper 相关</h3><p>先启动 <code>zookeeper</code> 。注意先切换到 zookeeper 用户后再进行启动！</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[zookeeper@hbase1(hbase2,hbase3) ~]# $ZOOKEEPER_HOME/bin/zkServer.sh start</span><br></pre></td></tr></table></figure><h3 id="Hadoop-相关"><a href="#Hadoop-相关" class="headerlink" title="Hadoop 相关"></a>Hadoop 相关</h3><p>再启动 <code>journalnode</code> 。注意先切换到 hadoop 用户后再进行启动！(hbase1,hbase2)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh start journalnode</span><br></pre></td></tr></table></figure><p>再启动 <code>namenode</code> 。注意先切换到 hadoop 用户后再进行启动！(hbase1,hbase2)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start namenode</span><br></pre></td></tr></table></figure><p>再启动 <code>zkfc</code> 。注意先切换到 hadoop 用户后再进行启动！(hbase1,hbase2)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start zkfc</span><br></pre></td></tr></table></figure><p>再启动 <code>datanode</code> 。注意先切换到 hadoop 用户后再进行启动！(hbase1,hbase2,hbase3)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2,hbase3) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start datanode</span><br></pre></td></tr></table></figure><h3 id="HBase-相关"><a href="#HBase-相关" class="headerlink" title="HBase 相关"></a>HBase 相关</h3><p>再启动 <code>HMaster</code> 。注意先切换到 hbase 用户后再进行启动！(hbase1)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hbase@hbase1 ~]# $HBASE_HOME/bin/hbase-daemon.sh start master</span><br></pre></td></tr></table></figure><p>再启动 <code>HRegionServer</code> 。注意先切换到 hbase 用户后再进行启动！(hbase1,hbase2,hbase3)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hbase@hbase1(hbase2,hbase3) ~]# $HBASE_HOME/bin/hbase-daemon.sh start regionserver</span><br></pre></td></tr></table></figure><h2 id="关闭顺序"><a href="#关闭顺序" class="headerlink" title="关闭顺序"></a>关闭顺序</h2><blockquote><p>关闭顺序请参照启动顺序，反着来一边就可以</p></blockquote><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Zookeeper相关</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动zookeeper集群</span></span><br><span class="line"><span class="meta">$</span><span class="bash">ZOOKEEPER_HOME/bin/zkServer.sh start</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看zookeeper集群状态</span></span><br><span class="line"><span class="meta">$</span><span class="bash">ZOOKEEPER_HOME/bin/zkServer.sh status</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 停止zookeeper集群</span></span><br><span class="line"><span class="meta">$</span><span class="bash">ZOOKEEPER_HOME/bin/zkServer.sh stop</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Hadoop相关</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动journalnode</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh start journalnode</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 停止journalnode</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh stop journalnode</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动namenode</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start namenode</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 停止namenode</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs stop namenode</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动zkfc</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start zkfc</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 停止zkfc</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs stop zkfc</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动datanode</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start datanode</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 停止datanode</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs stop datanode</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> HBase相关</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动HMaster</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HBASE_HOME/bin/hbase-daemon.sh start master</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 停止HMaster</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HBASE_HOME/bin/hbase-daemon.sh stop master</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动HRegionServer</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HBASE_HOME/bin/hbase-daemon.sh start regionserver</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 停止HRegionServer</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HBASE_HOME/bin/hbase-daemon.sh stop regionserver</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Druid SQL解析工具的使用</title>
      <link href="/posts/6d9855d0/"/>
      <url>/posts/6d9855d0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>最近在项目运行过程中，需要对标准SQL进行解析，然后对SQL进行改写，在各种查找对比后选中了Alibaba Druid来进行解析SQL（如非特制，以下均简称 Druid）</p><p>Druid官方的wiki说的还算明白，但可惜的是没有相关API文档。</p><h1 id="官方文档"><a href="#官方文档" class="headerlink" title="官方文档"></a>官方文档</h1><h2 id="1-SQL-Parser"><a href="#1-SQL-Parser" class="headerlink" title="1. SQL Parser"></a>1. SQL Parser</h2><p>如需查看原文：<a href="https://github.com/alibaba/druid/wiki/SQL-Parser" target="_blank" rel="noopener">SQL Parser</a></p><h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h3><p>SQL Parser是Druid的一个重要组成部分，Druid内置使用SQL Parser来实现防御SQL注入（<a href="https://github.com/alibaba/druid/wiki/%E7%AE%80%E4%BB%8B_WallFilter" target="_blank" rel="noopener">WallFilter</a>）、合并统计没有参数化的SQL(<a href="https://github.com/alibaba/druid/wiki/%E9%85%8D%E7%BD%AE_StatFilter" target="_blank" rel="noopener">StatFilter</a>的mergeSql)、<a href="https://github.com/alibaba/druid/wiki/SQL%E6%A0%BC%E5%BC%8F%E5%8C%96" target="_blank" rel="noopener">SQL格式化</a>、分库分表。</p><h4 id="1-1-和Antlr生成Parser的区别"><a href="#1-1-和Antlr生成Parser的区别" class="headerlink" title="1.1. 和Antlr生成Parser的区别"></a>1.1. 和Antlr生成Parser的区别</h4><p>和Antlr生成的SQL有很大不同的是，Druid SQL Parser性能非常好，可以用于生产环境直接对SQL进行分析处理。</p><h4 id="1-2-Druid-SQL-Parser的使用场景"><a href="#1-2-Druid-SQL-Parser的使用场景" class="headerlink" title="1.2. Druid SQL Parser的使用场景"></a>1.2. Druid SQL Parser的使用场景</h4><ul><li>MySql SQL全量统计</li><li>Hive/<a href="https://www.aliyun.com/product/odps" target="_blank" rel="noopener">ODPS</a> SQL执行安全审计</li><li>分库分表SQL解析引擎</li><li>数据库引擎的SQL Parser</li></ul><h3 id="2-各种语法支持"><a href="#2-各种语法支持" class="headerlink" title="2. 各种语法支持"></a>2. 各种语法支持</h3><p>Druid的sql parser是目前支持各种数据语法最完备的SQL Parser。目前对各种数据库的支持如下：</p><table><thead><tr><th>数据库</th><th>DML</th><th>DDL</th></tr></thead><tbody><tr><td><a href="https://www.aliyun.com/product/odps" target="_blank" rel="noopener">odps</a></td><td>完全支持</td><td>完全支持</td></tr><tr><td>mysql</td><td>完全支持</td><td>完全支持</td></tr><tr><td>postgresql</td><td>完全支持</td><td>完全支持</td></tr><tr><td>oracle</td><td>支持大部分</td><td>支持大部分</td></tr><tr><td>sql server</td><td>支持常用的</td><td>支持常用的ddl</td></tr><tr><td>db2</td><td>支持常用的</td><td>支持常用的ddl</td></tr><tr><td>hive</td><td>支持常用的</td><td>支持常用的ddl</td></tr></tbody></table><p>druid还缺省支持sql-92标准的语法，所以也部分支持其他数据库的sql语法。</p><h3 id="3-性能"><a href="#3-性能" class="headerlink" title="3. 性能"></a>3. 性能</h3><p>Druid的SQL Parser是手工编写，性能非常好，目标就是在生产环境运行时使用的SQL Parser，性能比antlr、javacc之类工具生成的Parser快10倍甚至100倍以上。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">ID</span>, <span class="keyword">NAME</span>, AGE <span class="keyword">FROM</span> <span class="keyword">USER</span> <span class="keyword">WHERE</span> <span class="keyword">ID</span> = ?</span><br></pre></td></tr></table></figure><p>这样的SQL，druid parser处理大约是600纳秒，也就是说单线程每秒可以处理1500万次以上。在1.1.3~1.1.4版本中，SQL Parser的性能有极大提升，完全可以适用于生产环境中对SQL进行处理。</p><h4 id="3-1-测试代码看这里"><a href="#3-1-测试代码看这里" class="headerlink" title="3.1. 测试代码看这里"></a>3.1. 测试代码看这里</h4><p><a href="https://github.com/alibaba/druid/blob/master/src/test/java/com/alibaba/druid/benckmark/sql/MySqlPerfTest.java" target="_blank" rel="noopener">MySqlPerfTest.java</a></p><h3 id="4-Druid-SQL-Parser的代码结构"><a href="#4-Druid-SQL-Parser的代码结构" class="headerlink" title="4. Druid SQL Parser的代码结构"></a>4. Druid SQL Parser的代码结构</h3><p>Druid SQL Parser分三个模块：</p><ul><li>Parser</li><li>AST</li><li>Visitor</li></ul><h4 id="4-1-parser"><a href="#4-1-parser" class="headerlink" title="4.1. parser"></a>4.1. parser</h4><p>parser是将输入文本转换为ast（抽象语法树），parser有包括两个部分，Parser和Lexer，其中Lexer实现词法分析，Parser实现语法分析。</p><h4 id="4-2-AST"><a href="#4-2-AST" class="headerlink" title="4.2. AST"></a>4.2. AST</h4><p>AST是Abstract Syntax Tree的缩写，也就是抽象语法树。AST是parser输出的结果。下面是获得抽象语法树的一个例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> String dbType = JdbcConstants.MYSQL; <span class="comment">// 可以是ORACLE、POSTGRESQL、SQLSERVER、ODPS等</span></span><br><span class="line">String sql = <span class="string">"select * from t"</span>;</span><br><span class="line">List&lt;SQLStatement&gt; stmtList = SQLUtils.parseStatements(sql, dbType);</span><br></pre></td></tr></table></figure><ul><li>Druid SQL AST介绍 <a href="https://github.com/alibaba/druid/wiki/Druid_SQL_AST" target="_blank" rel="noopener">https://github.com/alibaba/druid/wiki/Druid_SQL_AST</a></li></ul><h4 id="4-3-Visitor"><a href="#4-3-Visitor" class="headerlink" title="4.3. Visitor"></a>4.3. Visitor</h4><p>Visitor是遍历AST的手段，是处理AST最方便的模式，Visitor是一个接口，有缺省什么都没做的实现VistorAdapter。</p><p>我们可以实现不同的Visitor来满足不同的需求，Druid内置提供了如下Visitor: </p><ul><li>OutputVisitor用来把AST输出为字符串</li><li><a href="https://github.com/alibaba/druid/wiki/%E7%AE%80%E4%BB%8B_WallFilter" target="_blank" rel="noopener">WallVisitor</a> 来分析SQL语意来防御SQL注入攻击</li><li>ParameterizedOutputVisitor用来合并未参数化的SQL进行统计</li><li><a href="https://github.com/alibaba/druid/wiki/EvalVisitor" target="_blank" rel="noopener">EvalVisitor</a> 用来对SQL表达式求值</li><li>ExportParameterVisitor用来提取SQL中的变量参数</li><li><a href="https://github.com/alibaba/druid/wiki/SchemaStatVisitor" target="_blank" rel="noopener">SchemaStatVisitor</a> 用来统计SQL中使用的表、字段、过滤条件、排序表达式、分组表达式</li><li><a href="https://github.com/alibaba/druid/wiki/SQL_Format" target="_blank" rel="noopener">SQL格式化</a> Druid内置了基于语义的SQL格式化功能</li></ul><h4 id="4-4-自定义Visitor"><a href="#4-4-自定义Visitor" class="headerlink" title="4.4. 自定义Visitor"></a>4.4. 自定义Visitor</h4><p>每种方言的Visitor都有一个缺省的VisitorAdapter，使得编写自定义的Visitor更方便。<br><a href="https://github.com/alibaba/druid/wiki/SQL_Parser_Demo_visitor" target="_blank" rel="noopener">https://github.com/alibaba/druid/wiki/SQL_Parser_Demo_visitor</a></p><h4 id="4-5-自定义visitor示例"><a href="#4-5-自定义visitor示例" class="headerlink" title="4.5 自定义visitor示例"></a>4.5 自定义visitor示例</h4><h5 id="1-实现自己的Visitor"><a href="#1-实现自己的Visitor" class="headerlink" title="1. 实现自己的Visitor"></a>1. 实现自己的Visitor</h5><h6 id="1-1-Oracle版本"><a href="#1-1-Oracle版本" class="headerlink" title="1.1 Oracle版本"></a>1.1 Oracle版本</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ExportTableAliasVisitor</span> <span class="keyword">extends</span> <span class="title">OracleASTVisitorAdapter</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, SQLTableSource&gt; aliasMap = <span class="keyword">new</span> HashMap&lt;String, SQLTableSource&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">visit</span><span class="params">(OracleSelectTableReference x)</span> </span>&#123;</span><br><span class="line">        String alias = x.getAlias();</span><br><span class="line">        aliasMap.put(alias, x);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String, SQLTableSource&gt; <span class="title">getAliasMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> aliasMap;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="1-2-MySql版本"><a href="#1-2-MySql版本" class="headerlink" title="1.2 MySql版本"></a>1.2 MySql版本</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ExportTableAliasVisitor</span> <span class="keyword">extends</span> <span class="title">MySqlASTVisitorAdapter</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, SQLTableSource&gt; aliasMap = <span class="keyword">new</span> HashMap&lt;String, SQLTableSource&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">visit</span><span class="params">(SQLExprTableSource x)</span> </span>&#123;</span><br><span class="line">        String alias = x.getAlias();</span><br><span class="line">        aliasMap.put(alias, x);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String, SQLTableSource&gt; <span class="title">getAliasMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> aliasMap;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="1-3-POSTGRESQL版本"><a href="#1-3-POSTGRESQL版本" class="headerlink" title="1.3 POSTGRESQL版本"></a>1.3 POSTGRESQL版本</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ExportTableAliasVisitor</span> <span class="keyword">extends</span> <span class="title">PGASTVisitorAdapter</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, SQLTableSource&gt; aliasMap = <span class="keyword">new</span> HashMap&lt;String, SQLTableSource&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">visit</span><span class="params">(SQLExprTableSource x)</span> </span>&#123;</span><br><span class="line">        String alias = x.getAlias();</span><br><span class="line">        aliasMap.put(alias, x);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String, SQLTableSource&gt; <span class="title">getAliasMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> aliasMap;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="2-使用Visitor"><a href="#2-使用Visitor" class="headerlink" title="2. 使用Visitor"></a>2. 使用Visitor</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">finnal String dbType = JdbcConstants.ORACLE; <span class="comment">// JdbcConstants.MYSQL或者JdbcConstants.POSTGRESQL</span></span><br><span class="line">String sql = <span class="string">"select * from mytable a where a.id = 3"</span>;</span><br><span class="line">List&lt;SQLStatement&gt; stmtList = SQLUtils.parseStatements(sql, dbType);</span><br><span class="line"></span><br><span class="line">ExportTableAliasVisitor visitor = <span class="keyword">new</span> ExportTableAliasVisitor();</span><br><span class="line"><span class="keyword">for</span> (SQLStatement stmt : stmtList) &#123;</span><br><span class="line">    stmt.accept(visitor);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">SQLTableSource tableSource = visitor.getAliasMap().get(<span class="string">"a"</span>);</span><br><span class="line">System.out.println(tableSource);</span><br></pre></td></tr></table></figure><h4 id="4-6-方言"><a href="#4-6-方言" class="headerlink" title="4.6. 方言"></a>4.6. 方言</h4><p>SQL-92、SQL-99等都是标准SQL，mysql/oracle/pg/sqlserver/odps等都是方言，也就是dialect。parser/ast/visitor都需要针对不同的方言进行特别处理。</p><h3 id="5-SchemaRepository"><a href="#5-SchemaRepository" class="headerlink" title="5. SchemaRepository"></a>5. SchemaRepository</h3><p>Druid SQL Parser内置了一个SchemaRepository，在内存中缓存SQL Schema信息，用于SQL语义解析中的ColumnResolve等操作。<br><a href="https://github.com/alibaba/druid/wiki/SQL_Schema_Repository" target="_blank" rel="noopener">https://github.com/alibaba/druid/wiki/SQL_Schema_Repository</a></p><h3 id="6-SQL翻译"><a href="#6-SQL翻译" class="headerlink" title="6. SQL翻译"></a>6. SQL翻译</h3><p>可以基于Druid SQL Parser之上构造Oracle SQL到其他数据的SQL翻译。比如Aliyun提供的Oracle到MySql的<a href="https://rainbow-expert.aliyun.com/sqltransform.htm" target="_blank" rel="noopener">SQL翻译功能</a>，就是基于Druid基础上实现的。<a href="https://rainbow-expert.aliyun.com/sqltransform.htm" target="_blank" rel="noopener">https://rainbow-expert.aliyun.com/sqltransform.htm</a></p><h2 id="2-SQL-Formatter"><a href="#2-SQL-Formatter" class="headerlink" title="2. SQL Formatter"></a>2. SQL Formatter</h2><p>Druid SQL Parser提供了格式化代码的工具类。这个是基于语义分析做的SQL格式化功能，比其他的SQL格式化做的更智能，效果更好。</p><h3 id="格式化的工具类API"><a href="#格式化的工具类API" class="headerlink" title="格式化的工具类API"></a>格式化的工具类API</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.alibaba.druid.sql;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SQLUtils</span> </span>&#123;</span><br><span class="line">    <span class="function">String <span class="title">format</span><span class="params">(String sq, String dbType)</span></span>;</span><br><span class="line">    <span class="function">String <span class="title">format</span><span class="params">(String sq, String dbType, FormatOption option)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>其中dbType支持mysql/postgresql/odps/oracle/db2/sqlserver</li><li>option缺省有SQLUtils.DEFAULT_FORMAT_OPTION（大写）、SQLUtils.DEFAULT_LCASE_FORMAT_OPTION（小写）两种可以选择，也可按需要定制化。</li></ul><h3 id="MySQL-格式化"><a href="#MySQL-格式化" class="headerlink" title="MySQL 格式化"></a>MySQL 格式化</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.druid.sql.SQLUtils;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.druid.util.JdbcConstants;</span><br><span class="line"></span><br><span class="line">String sql = <span class="string">"update t set name = 'x' where id &lt; 100 limit 10"</span>;</span><br><span class="line">String result = SQLUtils.format(sql, JdbcConstants.MYSQL);</span><br><span class="line">System.out.println(result); <span class="comment">// 缺省大写格式</span></span><br><span class="line"></span><br><span class="line">String result_lcase = SQLUtils.format(sql</span><br><span class="line">                         , JdbcConstants.MYSQL</span><br><span class="line">                         , SQLUtils.DEFAULT_LCASE_FORMAT_OPTION);</span><br><span class="line">System.out.println(result_lcase); <span class="comment">// 小写格式</span></span><br></pre></td></tr></table></figure><p>输出格式化后的结果：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 这是缺省的大写格式</span></span><br><span class="line"><span class="keyword">UPDATE</span> t</span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">name</span> = <span class="string">'x'</span></span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">id</span> &lt; <span class="number">100</span></span><br><span class="line"><span class="keyword">LIMIT</span> <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 这是小写格式</span></span><br><span class="line"><span class="keyword">update</span> t</span><br><span class="line"><span class="keyword">set</span> <span class="keyword">name</span> = <span class="string">'x'</span></span><br><span class="line"><span class="keyword">where</span> <span class="keyword">id</span> &lt; <span class="number">100</span></span><br><span class="line"><span class="keyword">limit</span> <span class="number">10</span></span><br></pre></td></tr></table></figure><h2 id="3-SQL-Schema-Repository"><a href="#3-SQL-Schema-Repository" class="headerlink" title="3. SQL Schema Repository"></a>3. SQL Schema Repository</h2><h3 id="1-简介-1"><a href="#1-简介-1" class="headerlink" title="1. 简介"></a>1. 简介</h3><p>Druid SQL Parser内置了一个SchemaRepository，在内存中缓存SQL Schema信息，用于SQL语义解析中的ColumnResolve等操作。</p><h3 id="2-如何使用SchemaRepository"><a href="#2-如何使用SchemaRepository" class="headerlink" title="2. 如何使用SchemaRepository"></a>2. 如何使用SchemaRepository</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.druid.sql.repository.SchemaRepository;</span><br><span class="line"></span><br><span class="line"><span class="comment">// SchemaRepository是和数据库类型相关的，构造时需要传入dbType</span></span><br><span class="line"><span class="keyword">final</span> String dbType = JdbcConstants.MYSQL;</span><br><span class="line">SchemaRepository repository = <span class="keyword">new</span> SchemaRepository(dbType);</span><br><span class="line"></span><br><span class="line">repository.console(<span class="string">"use sc00;"</span>);</span><br><span class="line"></span><br><span class="line">String sql = <span class="string">"CREATE TABLE `test1` (\n"</span> +</span><br><span class="line">        <span class="string">"  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_tinyint` tinyint(4) DEFAULT '1' COMMENT 'tinyint',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_smallint` smallint(6) DEFAULT 0 COMMENT 'smallint',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_mediumint` mediumint(9) DEFAULT NULL COMMENT 'mediumint',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_int` int(11) DEFAULT NULL COMMENT 'int',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_bigint` bigint(20) DEFAULT NULL COMMENT 'bigint',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_decimal` decimal(10,3) DEFAULT NULL COMMENT 'decimal',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_date` date DEFAULT '0000-00-00' COMMENT 'date',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_datetime` datetime DEFAULT '0000-00-00 00:00:00' COMMENT 'datetime',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_timestamp` timestamp NULL DEFAULT NULL COMMENT 'timestamp'  ON UPDATE CURRENT_TIMESTAMP ,\n"</span> +</span><br><span class="line">        <span class="string">"  `c_time` time DEFAULT NULL COMMENT 'time',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_char` char(10) DEFAULT NULL COMMENT 'char',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_varchar` varchar(10) DEFAULT 'hello' COMMENT 'varchar',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_blob` blob COMMENT 'blob',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_text` text COMMENT 'text',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_mediumtext` mediumtext COMMENT 'mediumtext',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_longblob` longblob COMMENT 'longblob',\n"</span> +</span><br><span class="line">        <span class="string">"  PRIMARY KEY (`id`,`c_tinyint`),\n"</span> +</span><br><span class="line">        <span class="string">"  UNIQUE KEY `uk_a` (`c_varchar`,`c_mediumint`),\n"</span> +</span><br><span class="line">        <span class="string">"  KEY `k_c` (`c_tinyint`,`c_int`),\n"</span> +</span><br><span class="line">        <span class="string">"  KEY `k_d` (`c_char`,`c_bigint`)\n"</span> +</span><br><span class="line">        <span class="string">") ENGINE=InnoDB AUTO_INCREMENT=1769503 DEFAULT CHARSET=utf8mb4 COMMENT='10000000'"</span>;</span><br><span class="line"></span><br><span class="line">repository.console(sql);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在如下的代码中可以知道repository中已经存在表test1</span></span><br><span class="line">MySqlCreateTableStatement createTableStmt = (MySqlCreateTableStatement) repository.findTable(<span class="string">"test1"</span>).getStatement();</span><br><span class="line">assertEquals(<span class="number">21</span>, createTableStmt.getTableElementList().size());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过执行命令"show columns from test1"可以获得mysql console风格的输出</span></span><br><span class="line">assertEquals(<span class="string">"+--------------+---------------+------+-----+---------------------+-----------------------------+\n"</span> +</span><br><span class="line">        <span class="string">"| Field        | Type          | Null | Key | Default             | Extra                       |\n"</span> +</span><br><span class="line">        <span class="string">"+--------------+---------------+------+-----+---------------------+-----------------------------+\n"</span> +</span><br><span class="line">        <span class="string">"| id           | bigint(20)    | NO   | PRI | NULL                | auto_increment              |\n"</span> +</span><br><span class="line">        <span class="string">"| c_tinyint    | tinyint(4)    | YES  | PRI | 1                   |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_smallint   | smallint(6)   | YES  |     | 0                   |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_mediumint  | mediumint(9)  | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_int        | int(11)       | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_bigint     | bigint(20)    | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_decimal    | decimal(10,3) | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_date       | date          | YES  |     | 0000-00-00          |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_datetime   | datetime      | YES  |     | 0000-00-00 00:00:00 |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_timestamp  | timestamp     | YES  |     | NULL                | on update CURRENT_TIMESTAMP |\n"</span> +</span><br><span class="line">        <span class="string">"| c_time       | time          | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_char       | char(10)      | YES  | MUL | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_varchar    | varchar(10)   | YES  | MUL | hello               |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_blob       | blob          | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_text       | text          | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_mediumtext | mediumtext    | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_longblob   | longblob      | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"+--------------+---------------+------+-----+---------------------+-----------------------------+\n"</span>, </span><br><span class="line">repository.console(<span class="string">"show columns from test1"</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行alter语句，修改repository中内容</span></span><br><span class="line">repository.console(<span class="string">"alter table test1 drop column c_decimal;"</span>);</span><br><span class="line">assertEquals(<span class="number">20</span>, createTableStmt.getTableElementList().size());</span><br><span class="line"></span><br><span class="line">assertEquals(<span class="string">"+--------------+--------------+------+-----+---------------------+-----------------------------+\n"</span> +</span><br><span class="line">        <span class="string">"| Field        | Type         | Null | Key | Default             | Extra                       |\n"</span> +</span><br><span class="line">        <span class="string">"+--------------+--------------+------+-----+---------------------+-----------------------------+\n"</span> +</span><br><span class="line">        <span class="string">"| id           | bigint(20)   | NO   | PRI | NULL                | auto_increment              |\n"</span> +</span><br><span class="line">        <span class="string">"| c_tinyint    | tinyint(4)   | YES  | PRI | 1                   |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_smallint   | smallint(6)  | YES  |     | 0                   |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_mediumint  | mediumint(9) | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_int        | int(11)      | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_bigint     | bigint(20)   | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_date       | date         | YES  |     | 0000-00-00          |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_datetime   | datetime     | YES  |     | 0000-00-00 00:00:00 |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_timestamp  | timestamp    | YES  |     | NULL                | on update CURRENT_TIMESTAMP |\n"</span> +</span><br><span class="line">        <span class="string">"| c_time       | time         | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_char       | char(10)     | YES  | MUL | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_varchar    | varchar(10)  | YES  | MUL | hello               |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_blob       | blob         | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_text       | text         | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_mediumtext | mediumtext   | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_longblob   | longblob     | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"+--------------+--------------+------+-----+---------------------+-----------------------------+\n"</span>, </span><br><span class="line">repository.console(<span class="string">"show columns from test1"</span>));</span><br></pre></td></tr></table></figure><h3 id="3-Column-Resolve"><a href="#3-Column-Resolve" class="headerlink" title="3. Column Resolve"></a>3. Column Resolve</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> String dbType = JdbcConstants.MYSQL;</span><br><span class="line"></span><br><span class="line">SchemaRepository repository = <span class="keyword">new</span> SchemaRepository(dbType);</span><br><span class="line"></span><br><span class="line">repository.console(<span class="string">"create table t_emp(emp_id bigint, name varchar(20));"</span>);</span><br><span class="line">repository.console(<span class="string">"create table t_org(org_id bigint, name varchar(20));"</span>);</span><br><span class="line"></span><br><span class="line">String sql = <span class="string">"SELECT emp_id, a.name AS emp_name, org_id, b.name AS org_name\n"</span> +</span><br><span class="line">        <span class="string">"FROM t_emp a\n"</span> +</span><br><span class="line">        <span class="string">"\tINNER JOIN t_org b ON a.emp_id = b.org_id"</span>;</span><br><span class="line"></span><br><span class="line">List&lt;SQLStatement&gt; stmtList = SQLUtils.parseStatements(sql, dbType);</span><br><span class="line">assertEquals(<span class="number">1</span>, stmtList.size());</span><br><span class="line"></span><br><span class="line">SQLSelectStatement stmt = (SQLSelectStatement) stmtList.get(<span class="number">0</span>);</span><br><span class="line">SQLSelectQueryBlock queryBlock = stmt.getSelect().getQueryBlock();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 大小写不敏感</span></span><br><span class="line">assertNotNull(queryBlock.findTableSource(<span class="string">"A"</span>));</span><br><span class="line">assertSame(queryBlock.findTableSource(<span class="string">"a"</span>), queryBlock.findTableSource(<span class="string">"A"</span>));</span><br><span class="line"></span><br><span class="line">assertNull(queryBlock.findTableSourceWithColumn(<span class="string">"emp_id"</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用repository做column resolve</span></span><br><span class="line">repository.resolve(stmt);</span><br><span class="line"></span><br><span class="line">assertNotNull(queryBlock.findTableSourceWithColumn(<span class="string">"emp_id"</span>));</span><br><span class="line"></span><br><span class="line">SQLExprTableSource tableSource = (SQLExprTableSource) queryBlock.findTableSourceWithColumn(<span class="string">"emp_id"</span>);</span><br><span class="line">assertNotNull(tableSource.getSchemaObject());</span><br><span class="line"></span><br><span class="line">SQLCreateTableStatement createTableStmt = (SQLCreateTableStatement) tableSource.getSchemaObject().getStatement();</span><br><span class="line">assertNotNull(createTableStmt);</span><br><span class="line"></span><br><span class="line">SQLSelectItem selectItem = queryBlock.findSelectItem(<span class="string">"org_name"</span>);</span><br><span class="line">assertNotNull(selectItem);</span><br><span class="line">SQLPropertyExpr selectItemExpr = (SQLPropertyExpr) selectItem.getExpr();</span><br><span class="line">SQLColumnDefinition column = selectItemExpr.getResolvedColumn();</span><br><span class="line">assertNotNull(column);</span><br><span class="line">assertEquals(<span class="string">"name"</span>, column.getName().toString());</span><br><span class="line">assertEquals(<span class="string">"t_org"</span>, (((SQLCreateTableStatement)column.getParent()).getName().toString()));</span><br><span class="line"></span><br><span class="line">assertSame(queryBlock.findTableSource(<span class="string">"B"</span>), selectItemExpr.getResolvedTableSource());</span><br></pre></td></tr></table></figure><h2 id="4-SQL-Parser-Parameterize"><a href="#4-SQL-Parser-Parameterize" class="headerlink" title="4. SQL Parser Parameterize"></a>4. SQL Parser Parameterize</h2><h3 id="1-功能介绍"><a href="#1-功能介绍" class="headerlink" title="1. 功能介绍"></a>1. 功能介绍</h3><p>如果要对SQL做各种统计，通常需要对SQL进行参数化再做统计。比如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 原始SQL</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">id</span> = <span class="number">1</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">id</span> = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">// 参数化<span class="keyword">SQL</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">id</span> = ?</span><br></pre></td></tr></table></figure><h3 id="2-SQL参数化"><a href="#2-SQL参数化" class="headerlink" title="2. SQL参数化"></a>2. SQL参数化</h3><h4 id="2-1-SQL参数化API"><a href="#2-1-SQL参数化API" class="headerlink" title="2.1 SQL参数化API"></a>2.1 SQL参数化API</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.alibaba.druid.sql.visitor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ParameterizedOutputVisitorUtils</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">parameterize</span><span class="params">(String sql, String dbType)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-2-SQL参数化DEMO"><a href="#2-2-SQL参数化DEMO" class="headerlink" title="2.2 SQL参数化DEMO"></a>2.2 SQL参数化DEMO</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.druid.sql.visitor.ParameterizedOutputVisitorUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> String dbType = JdbcConstants.MYSQL;</span><br><span class="line"></span><br><span class="line">String sql = <span class="string">"select * from t where id = 1 or id = 2 or id = 3"</span>;</span><br><span class="line">String psql = ParameterizedOutputVisitorUtils.parameterize(sql, dbType);</span><br><span class="line">assertEquals(<span class="string">"SELECT *\n"</span> +</span><br><span class="line">        <span class="string">"FROM t\n"</span> +</span><br><span class="line">        <span class="string">"WHERE id = ?"</span>, psql);</span><br></pre></td></tr></table></figure><h4 id="3-获取具体参数化后的常量值"><a href="#3-获取具体参数化后的常量值" class="headerlink" title="3. 获取具体参数化后的常量值"></a>3. 获取具体参数化后的常量值</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> String dbType = JdbcConstants.MYSQL;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 参数化SQL是输出的参数保存在这个List中</span></span><br><span class="line">List&lt;Object&gt; outParameters = <span class="keyword">new</span> ArrayList&lt;Object&gt;();</span><br><span class="line"></span><br><span class="line">String sql = <span class="string">"select * from t where id = 101 and age = 102 or name = 'wenshao'"</span>;</span><br><span class="line">String psql = ParameterizedOutputVisitorUtils.parameterize(sql, dbType, outParameters);</span><br><span class="line">assertEquals(<span class="string">"SELECT *\n"</span> +</span><br><span class="line">        <span class="string">"FROM t\n"</span> +</span><br><span class="line">        <span class="string">"WHERE id = ?\n"</span> +</span><br><span class="line">        <span class="string">"\tAND age = ?\n"</span> +</span><br><span class="line">        <span class="string">"\tOR name = ?"</span>, psql);</span><br><span class="line"></span><br><span class="line">assertEquals(<span class="number">3</span>, outParameters.size());</span><br><span class="line">assertEquals(<span class="number">101</span>, outParameters.get(<span class="number">0</span>));</span><br><span class="line">assertEquals(<span class="number">102</span>, outParameters.get(<span class="number">1</span>));</span><br><span class="line">assertEquals(<span class="string">"wenshao"</span>, outParameters.get(<span class="number">2</span>));</span><br></pre></td></tr></table></figure><h2 id="5-Druid-SQL-AST"><a href="#5-Druid-SQL-AST" class="headerlink" title="5. Druid SQL AST"></a>5. Druid SQL AST</h2><h3 id="1-什么是AST"><a href="#1-什么是AST" class="headerlink" title="1. 什么是AST"></a>1. 什么是AST</h3><p>AST是abstract syntax tree的缩写，也就是抽象语法树。和所有的Parser一样，Druid Parser会生成一个抽象语法树。</p><h3 id="2-在Druid-SQL-Parser中有哪些AST节点类型"><a href="#2-在Druid-SQL-Parser中有哪些AST节点类型" class="headerlink" title="2. 在Druid SQL Parser中有哪些AST节点类型"></a>2. 在Druid SQL Parser中有哪些AST节点类型</h3><p>在Druid中，AST节点类型主要包括SQLObject、SQLExpr、SQLStatement三种抽象类型。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.alibaba.druid.sql.ast;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">SQLObject</span> </span>&#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">SQLExpr</span> <span class="keyword">extends</span> <span class="title">SQLObject</span> </span>&#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">SQLStatement</span> <span class="keyword">extends</span> <span class="title">SQLObject</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">SQLTableSource</span> <span class="keyword">extends</span> <span class="title">SQLObject</span> </span>&#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLSelect</span> <span class="keyword">extends</span> <span class="title">SQLObject</span> </span>&#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLSelectQueryBlock</span> <span class="keyword">extends</span> <span class="title">SQLObject</span> </span>&#123;&#125;</span><br></pre></td></tr></table></figure><h4 id="2-1-常用的SQLExpr有哪些"><a href="#2-1-常用的SQLExpr有哪些" class="headerlink" title="2.1. 常用的SQLExpr有哪些"></a>2.1. 常用的SQLExpr有哪些</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.alibaba.druid.sql.ast.expr;</span><br><span class="line"></span><br><span class="line"><span class="comment">// SQLName是一种的SQLExpr的Expr，包括SQLIdentifierExpr、SQLPropertyExpr等</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">SQLName</span> <span class="keyword">extends</span> <span class="title">SQLExpr</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 ID = 3 这里的ID是一个SQLIdentifierExpr</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLIdentifierExpr</span> <span class="keyword">implements</span> <span class="title">SQLExpr</span>, <span class="title">SQLName</span> </span>&#123;</span><br><span class="line">    String name;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 A.ID = 3 这里的A.ID是一个SQLPropertyExpr</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLPropertyExpr</span> <span class="keyword">implements</span> <span class="title">SQLExpr</span>, <span class="title">SQLName</span> </span>&#123;</span><br><span class="line">    SQLExpr owner;</span><br><span class="line">    String name;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 ID = 3 这是一个SQLBinaryOpExpr</span></span><br><span class="line"><span class="comment">// left是ID (SQLIdentifierExpr)</span></span><br><span class="line"><span class="comment">// right是3 (SQLIntegerExpr)</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLBinaryOpExpr</span> <span class="keyword">implements</span> <span class="title">SQLExpr</span> </span>&#123;</span><br><span class="line">    SQLExpr left;</span><br><span class="line">    SQLExpr right;</span><br><span class="line">    SQLBinaryOperator operator;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 select * from where id = ?，这里的?是一个SQLVariantRefExpr，name是'?'</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLVariantRefExpr</span> <span class="keyword">extends</span> <span class="title">SQLExprImpl</span> </span>&#123; </span><br><span class="line">    String name;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 ID = 3 这里的3是一个SQLIntegerExpr</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SQLIntegerExpr</span> <span class="keyword">extends</span> <span class="title">SQLNumericLiteralExpr</span> <span class="keyword">implements</span> <span class="title">SQLValuableExpr</span> </span>&#123; </span><br><span class="line">    Number number;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 所有实现了SQLValuableExpr接口的SQLExpr都可以直接调用这个方法求值</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">getValue</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.number;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 NAME = 'jobs' 这里的'jobs'是一个SQLCharExpr</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SQLCharExpr</span> <span class="keyword">extends</span> <span class="title">SQLTextLiteralExpr</span> <span class="keyword">implements</span> <span class="title">SQLValuableExpr</span></span>&#123;</span><br><span class="line">    String text;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-2-常用的SQLStatemment"><a href="#2-2-常用的SQLStatemment" class="headerlink" title="2.2. 常用的SQLStatemment"></a>2.2. 常用的SQLStatemment</h4><p>最常用的Statement当然是SELECT/UPDATE/DELETE/INSERT，他们分别是</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.alibaba.druid.sql.ast.statement;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLSelectStatement</span> <span class="keyword">implements</span> <span class="title">SQLStatement</span> </span>&#123;</span><br><span class="line">    SQLSelect select;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLUpdateStatement</span> <span class="keyword">implements</span> <span class="title">SQLStatement</span> </span>&#123;</span><br><span class="line">    SQLExprTableSource tableSource;</span><br><span class="line">     List&lt;SQLUpdateSetItem&gt; items;</span><br><span class="line">     SQLExpr where;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLDeleteStatement</span> <span class="keyword">implements</span> <span class="title">SQLStatement</span> </span>&#123;</span><br><span class="line">    SQLTableSource tableSource; </span><br><span class="line">    SQLExpr where;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLInsertStatement</span> <span class="keyword">implements</span> <span class="title">SQLStatement</span> </span>&#123;</span><br><span class="line">    SQLExprTableSource tableSource;</span><br><span class="line">    List&lt;SQLExpr&gt; columns;</span><br><span class="line">    SQLSelect query;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-3-SQLTableSource"><a href="#2-3-SQLTableSource" class="headerlink" title="2.3. SQLTableSource"></a>2.3. SQLTableSource</h4><p>常见的SQLTableSource包括SQLExprTableSource、SQLJoinTableSource、SQLSubqueryTableSource、SQLWithSubqueryClause.Entry</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLTableSourceImpl</span> <span class="keyword">extends</span> <span class="title">SQLObjectImpl</span> <span class="keyword">implements</span> <span class="title">SQLTableSource</span> </span>&#123; </span><br><span class="line">    String alias;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 select * from emp where i = 3，这里的from emp是一个SQLExprTableSource</span></span><br><span class="line"><span class="comment">// 其中expr是一个name=emp的SQLIdentifierExpr</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLExprTableSource</span> <span class="keyword">extends</span> <span class="title">SQLTableSourceImpl</span> </span>&#123;</span><br><span class="line">    SQLExpr expr;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 select * from emp e inner join org o on e.org_id = o.id</span></span><br><span class="line"><span class="comment">// 其中left 'emp e' 是一个SQLExprTableSource，right 'org o'也是一个SQLExprTableSource</span></span><br><span class="line"><span class="comment">// condition 'e.org_id = o.id'是一个SQLBinaryOpExpr</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLJoinTableSource</span> <span class="keyword">extends</span> <span class="title">SQLTableSourceImpl</span> </span>&#123;</span><br><span class="line">    SQLTableSource left;</span><br><span class="line">    SQLTableSource right;</span><br><span class="line">    JoinType joinType; <span class="comment">// INNER_JOIN/CROSS_JOIN/LEFT_OUTER_JOIN/RIGHT_OUTER_JOIN/...</span></span><br><span class="line">    SQLExpr condition;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 select * from (select * from temp) a，这里第一层from(...)是一个SQLSubqueryTableSource</span></span><br><span class="line">SQLSubqueryTableSource extends SQLTableSourceImpl &#123;</span><br><span class="line">    SQLSelect select;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* </span></span><br><span class="line"><span class="comment">例如</span></span><br><span class="line"><span class="comment">WITH RECURSIVE ancestors AS (</span></span><br><span class="line"><span class="comment">    SELECT *</span></span><br><span class="line"><span class="comment">    FROM org</span></span><br><span class="line"><span class="comment">    UNION</span></span><br><span class="line"><span class="comment">    SELECT f.*</span></span><br><span class="line"><span class="comment">    FROM org f, ancestors a</span></span><br><span class="line"><span class="comment">    WHERE f.id = a.parent_id</span></span><br><span class="line"><span class="comment">)</span></span><br><span class="line"><span class="comment">SELECT *</span></span><br><span class="line"><span class="comment">FROM ancestors;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">这里的ancestors AS (...) 是一个SQLWithSubqueryClause.Entry</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLWithSubqueryClause</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Entry</span> <span class="keyword">extends</span> <span class="title">SQLTableSourceImpl</span> </span>&#123; </span><br><span class="line">         SQLSelect subQuery;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-4-SQLSelect-amp-SQLSelectQuery"><a href="#2-4-SQLSelect-amp-SQLSelectQuery" class="headerlink" title="2.4. SQLSelect &amp; SQLSelectQuery"></a>2.4. SQLSelect &amp; SQLSelectQuery</h4><p>SQLSelectStatement包含一个SQLSelect，SQLSelect包含一个SQLSelectQuery，都是组成的关系。SQLSelectQuery有主要的两个派生类，分别是SQLSelectQueryBlock和SQLUnionQuery。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLSelect</span> <span class="keyword">extends</span> <span class="title">SQLObjectImpl</span> </span>&#123; </span><br><span class="line">    SQLWithSubqueryClause withSubQuery;</span><br><span class="line">    SQLSelectQuery query;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">SQLSelectQuery</span> <span class="keyword">extends</span> <span class="title">SQLObject</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLSelectQueryBlock</span> <span class="keyword">implements</span> <span class="title">SQLSelectQuery</span> </span>&#123;</span><br><span class="line">    List&lt;SQLSelectItem&gt; selectList;</span><br><span class="line">    SQLTableSource from;</span><br><span class="line">    SQLExprTableSource into;</span><br><span class="line">    SQLExpr where;</span><br><span class="line">    SQLSelectGroupByClause groupBy;</span><br><span class="line">    SQLOrderBy orderBy;</span><br><span class="line">    SQLLimit limit;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLUnionQuery</span> <span class="keyword">implements</span> <span class="title">SQLSelectQuery</span> </span>&#123;</span><br><span class="line">    SQLSelectQuery left;</span><br><span class="line">    SQLSelectQuery right;</span><br><span class="line">    SQLUnionOperator operator; <span class="comment">// UNION/UNION_ALL/MINUS/INTERSECT</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-5-SQLCreateTableStatement"><a href="#2-5-SQLCreateTableStatement" class="headerlink" title="2.5. SQLCreateTableStatement"></a>2.5. SQLCreateTableStatement</h4><p>建表语句包含了一系列方法，用于方便各种操作</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SQLCreateTableStatement</span> <span class="keyword">extends</span> <span class="title">SQLStatementImpl</span> <span class="keyword">implements</span> <span class="title">SQLDDLStatement</span>, <span class="title">SQLCreateStatement</span> </span>&#123;</span><br><span class="line">    SQLExprTableSource tableSource;</span><br><span class="line">    List&lt;SQLTableElement&gt; tableElementList;</span><br><span class="line">    Select select;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 忽略大小写的查找SQLCreateTableStatement中的SQLColumnDefinition</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SQLColumnDefinition <span class="title">findColumn</span><span class="params">(String columName)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 忽略大小写的查找SQLCreateTableStatement中的column关联的索引</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SQLTableElement <span class="title">findIndex</span><span class="params">(String columnName)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 是否外键依赖另外一个表</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isReferenced</span><span class="params">(String tableName)</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-怎样产生AST"><a href="#3-怎样产生AST" class="headerlink" title="3. 怎样产生AST"></a>3. 怎样产生AST</h3><h4 id="3-1-通过SQLUtils产生List-lt-SQLStatement-gt"><a href="#3-1-通过SQLUtils产生List-lt-SQLStatement-gt" class="headerlink" title="3.1. 通过SQLUtils产生List&lt;SQLStatement&gt;"></a>3.1. 通过SQLUtils产生List&lt;SQLStatement&gt;</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.druid.util.JdbcConstants;</span><br><span class="line"></span><br><span class="line">String dbType = JdbcConstants.MYSQL;</span><br><span class="line">List&lt;SQLStatement&gt; statementList = SQLUtils.parseStatements(sql, dbType);</span><br></pre></td></tr></table></figure><h4 id="3-2-通过SQLUtils产生SQLExpr"><a href="#3-2-通过SQLUtils产生SQLExpr" class="headerlink" title="3.2. 通过SQLUtils产生SQLExpr"></a>3.2. 通过SQLUtils产生SQLExpr</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">String dbType = JdbcConstants.MYSQL;</span><br><span class="line">SQLExpr expr = SQLUtils.toSQLExpr(<span class="string">"id=3"</span>, dbType);</span><br></pre></td></tr></table></figure><h3 id="4-怎样打印AST节点"><a href="#4-怎样打印AST节点" class="headerlink" title="4. 怎样打印AST节点"></a>4. 怎样打印AST节点</h3><h4 id="4-1-通过SQLUtils工具类打印节点"><a href="#4-1-通过SQLUtils工具类打印节点" class="headerlink" title="4.1. 通过SQLUtils工具类打印节点"></a>4.1. 通过SQLUtils工具类打印节点</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.alibaba.druid.sql;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SQLUtils</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 可以将SQLExpr/SQLStatement打印为String类型</span></span><br><span class="line">    <span class="function"><span class="keyword">static</span> String <span class="title">toSQLString</span><span class="params">(SQLObject sqlObj, String dbType)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 可以将一个&amp;lt;SQLStatement&amp;gt;打印为String类型</span></span><br><span class="line">    <span class="function"><span class="keyword">static</span> String <span class="title">toSQLString</span><span class="params">(List&lt;SQLStatement&gt; statementList, String dbType)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="5-如何自定义遍历AST节点"><a href="#5-如何自定义遍历AST节点" class="headerlink" title="5. 如何自定义遍历AST节点"></a>5. 如何自定义遍历AST节点</h3><p>所有的AST节点都支持Visitor模式，需要自定义遍历逻辑，可以实现相应的ASTVisitorAdapter派生类，比如 <a href="https://github.com/alibaba/druid/wiki/SQL_Parser_Demo_visitor" target="_blank" rel="noopener">https://github.com/alibaba/druid/wiki/SQL_Parser_Demo_visitor</a></p><h3 id="6-相关阅读"><a href="#6-相关阅读" class="headerlink" title="6. 相关阅读"></a>6. 相关阅读</h3><ul><li><a href="https://github.com/alibaba/druid/wiki/SQL-Parser" target="_blank" rel="noopener">https://github.com/alibaba/druid/wiki/SQL-Parser</a></li><li><a href="https://github.com/alibaba/druid/wiki/SQL_Schema_Repository" target="_blank" rel="noopener">https://github.com/alibaba/druid/wiki/SQL_Schema_Repository</a></li><li><a href="https://github.com/alibaba/druid/wiki/SQL_RemoveCondition_demo" target="_blank" rel="noopener">https://github.com/alibaba/druid/wiki/SQL_RemoveCondition_demo</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> SQL </tag>
            
            <tag> Druid </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper 入门</title>
      <link href="/posts/a097aeed/"/>
      <url>/posts/a097aeed/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在使用kafka，Hbase等大数据组件时，发现很多开源项目都用到了Zookeeper。所以在这里简单研究一下Zookeeper</p><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><h2 id="Zookeeper-是什么"><a href="#Zookeeper-是什么" class="headerlink" title="Zookeeper 是什么"></a>Zookeeper 是什么</h2><p>Zookeeper是一个分布式协调框架，实现同步服务，配置维护和命名服务等分布式应用。是一个高性能的分布式数据一致性解决方案</p><h2 id="Zookeeper-能干什么"><a href="#Zookeeper-能干什么" class="headerlink" title="Zookeeper 能干什么"></a>Zookeeper 能干什么</h2><p>可以在分布式系统中共享配置，协调锁资源，提供命名服务</p><ol><li>分布式锁：利用Zookeeper的临时顺序节点，可以轻松实现分布式锁</li><li>服务注册与发现： 利用Znode和Watcher，可以实现分布式服务的注册与发现。如：Dubbo</li><li>共享配置与状态信息：如Redis的分布式Codis，利用Zookeeper存放数据路由表和codis-proxy节点的元信息，同时codis-config发起的命令都会通过Zookeeper同步到各个存活的codis-proxy。</li></ol><h3 id="Zookeeper-的数据模型"><a href="#Zookeeper-的数据模型" class="headerlink" title="Zookeeper 的数据模型"></a>Zookeeper 的数据模型</h3><p>Zookeeper的数据模型类似于数据结构中的树，也类似于Linux文件系统中的目录</p><p>树由多个节点构成，Zookeeper的数据存储同样基于节点。在 Zookeeper 中，这样的节点被称作为 Znode</p><p>Zookeeper的引用方式是路径引用，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/tree1/node1</span><br><span class="line">/tree2/node2</span><br></pre></td></tr></table></figure><p>这种层级结构可以让每一个Znode节点拥有唯一的路径，可以对不同信息做出清晰的隔离</p><h3 id="Znode-里有什么？"><a href="#Znode-里有什么？" class="headerlink" title="Znode 里有什么？"></a>Znode 里有什么？</h3><p>Znode包含了数据，子节点引用，访问权限等数据。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">|         data           |  ACL  |</span><br><span class="line">---------------------------------</span><br><span class="line">|child (znode1,znode2...)|  stat |</span><br><span class="line"></span><br><span class="line">data 负责存储Znode存储的数据信息</span><br><span class="line">ACL  记录Znode的访问权限，谁可以访问本节点</span><br><span class="line">stat 包含Znode的各种元数据，如：事务ID、版本号、时间戳、大小 等</span><br><span class="line">child当前节点的子节点引用，类似于二叉树的左右孩子</span><br></pre></td></tr></table></figure><p>需要注意的是Zookeeper是为了读多写少的场景所设计，Znode并非是用来存储大规模业务数据，而是用于存储少量的状态与配置信息，每个节点的数据最大不能超过 1MB！</p><h2 id="Zookeeper-运行原理是什么"><a href="#Zookeeper-运行原理是什么" class="headerlink" title="Zookeeper 运行原理是什么"></a>Zookeeper 运行原理是什么</h2><h3 id="什么是Watch？"><a href="#什么是Watch？" class="headerlink" title="什么是Watch？"></a>什么是Watch？</h3><p>可以理解为注册在特定Znode上的触发器，当这个Znode发生改变，也就是调用了create,delete,setData方法的时候，将会触发Znode上注册的对应事件，请求Watch的客户端将会收到异步通知</p><h4 id="Watch的交互过程"><a href="#Watch的交互过程" class="headerlink" title="Watch的交互过程"></a>Watch的交互过程</h4><p>这里借用程序猿小灰博文中的图：</p><ol><li>客户端调用getData方法，watch参数为 true 。服务端收到请求，返回节点数据，并且在对应的哈希表中插入被Watch的Znode路径。以及Watcher列表。</li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200804235728.jpeg" alt=""></p><ol start="2"><li>当被watch的Znode已删除，服务端会查找哈希表，找到该Znode对应的所有Watcher，异步通知客户端，并且删除hash表中对应的 K-V</li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200804235659.jpeg" alt=""></p><h3 id="Zookeeper-的一致性"><a href="#Zookeeper-的一致性" class="headerlink" title="Zookeeper 的一致性"></a>Zookeeper 的一致性</h3><p>如果Zookeeper自身挂掉了，它作为分布式的协调服务，应该怎么办？</p><p>为了防止Zookeeper单机挂掉的情况，Zookeeper维护了一个集群</p><p>这里还是借用小灰的图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200804235334.png" alt=""></p><p>Zookeeper服务的集群是一主多从的结构。</p><p>在更新数据时，首先更新到主节点（服务器，非Znode），再同步到从节点。</p><p>在读取数据时，直接读取任意从节点</p><p>为了保证主从节点的数据一致性，Zookeeper采用了自己的ZAB协议。类似于一致性算法Paxos与Raft</p><p>ZAB协议是：Zookeeper Atomic Broadcast。 有效解决Zookeeper的集群崩溃恢复，以及主从同步数据的问题。</p><h4 id="ZAB协议"><a href="#ZAB协议" class="headerlink" title="ZAB协议"></a>ZAB协议</h4><p>ZAB协议定义了三种节点状态</p><ul><li>Looking：选举状态</li><li>Following：从节点所处的状态</li><li>Leading： Leader节点所处的状态</li></ul><h4 id="最大ZXID"><a href="#最大ZXID" class="headerlink" title="最大ZXID"></a>最大ZXID</h4><p>最大ZXID也就是节点本地的最新事务编号，包含epoch与计数两部分。epoch是纪元的意思，相当于Raft算法选主时候的term</p><h4 id="Zookeeper集群崩溃恢复"><a href="#Zookeeper集群崩溃恢复" class="headerlink" title="Zookeeper集群崩溃恢复"></a>Zookeeper集群崩溃恢复</h4><p>假如Zookeeper当前主节点挂掉了，集群会进行崩溃恢复。ZAB的崩溃恢复分为三个阶段：</p><ol><li>Leader election</li></ol><p>选举阶段，此时集群中的节点处于Looking状态。他们会各自向其他节点发起投票，投票当中包含自己的服务器ID和最新事务ID（ZXID）</p><p>接下来，节点会用自身的ZXID和从其他节点接受到的ZXID做比较，如果发现其他结点的ZXID比自己大，也就是数据比自己新，那么就重新发起投票，投票给目前已知最大的ZXID所属节点</p><p>每次投票后，服务器会统计投票数量，判断是否有某个节点获得半数以上的投票。如果存在这样的节点，该节点将会成为准Leader，状态变为Leading。其他节点随之变为Following。</p><ol start="2"><li>Discovery</li></ol><p>发现阶段，用于在从节点中发现最新的ZXID与事务日志。这是为了防止因为某些意外情况，比如网络原因在上一阶段产生多个Leader的情况。</p><p>所以在此阶段，Leader接收所有Follower发来各自的最新epoch值。Leader从中选出最大的epoch，基于此值+1，生成新的epoch分发给各个Follower</p><p>各个Follow二收到全新的epoch后，返回ACK给Leader，带上各自最大的ZXID和历史事务日志。Leader选出最大的ZXID，并更新自身历史日志。</p><ol start="3"><li>Synchronization</li></ol><p>同步阶段，把Leader刚才收集到的最新历史事务日志，同步给集群中所有的Follower。只有当半数Follower同步成功，这个准Leader才能成为正式Leader</p><p>故障恢复结束</p><h4 id="ZAB如何写入数据？"><a href="#ZAB如何写入数据？" class="headerlink" title="ZAB如何写入数据？"></a>ZAB如何写入数据？</h4><p>在写入过程中，涉及到ZAB协议的Broadcast阶段</p><p>Broadcast是Zookeeper常规情况下更新数据的时候，由Leader广播到所有的Follower。其过程如下：</p><ol><li><p>客户端发出写入数据请求给任意Follower</p></li><li><p>Follower把写入数据请求转发给Leader</p></li><li><p>Leader采用二阶段提交方式，先发送Propose广播给Follower。</p></li><li><p>Follower接到Propose消息，写入日志成功后，返回ACK消息给leader</p></li><li><p>leader接到半数以上ACK消息，返回成功给客户端，并且广播Commit请求给Follower</p></li></ol><p>ZAB协议并非强一致性，也不是弱一致性，而是处于两者之间的单调一致性。它依靠事务ID和版本号，保证了数据的更新和读取是有序的。</p><h2 id="Zookeeper-怎么使用"><a href="#Zookeeper-怎么使用" class="headerlink" title="Zookeeper 怎么使用"></a>Zookeeper 怎么使用</h2><p>Zookeeper 为开发者们提供了一些简单的API，甚至提供了触发器机制。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create 创建节点</span><br><span class="line">delete 删除节点</span><br><span class="line">exist  判断节点是否存在（读操作）</span><br><span class="line">getData 获得一个节点的数据（读操作）</span><br><span class="line">setData 设置一个节点的数据</span><br><span class="line">getChildren 获取节点下的所有子节点（读操作）</span><br></pre></td></tr></table></figure><p>Zookeeper客户端在请求读操作的时候，可以选择是否设置Watch</p><h3 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h3><p>从官方网站下载zookeeper的最新安装包：<a href="https://zookeeper.apache.org/releases.html" target="_blank" rel="noopener">链接</a></p><h4 id="单机版"><a href="#单机版" class="headerlink" title="单机版"></a>单机版</h4><p>单机版很简单，直接解压zookeeper的压缩包，进入conf目录下，复制一份zoo_sample.cfg文件到conf目录下命名为zoo.cfg,根据自己的需要修改配置即可</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The number of milliseconds of each tick</span></span><br><span class="line"><span class="attr">tickTime</span>=<span class="string">2000</span></span><br><span class="line"><span class="comment"># The number of ticks that the initial </span></span><br><span class="line"><span class="comment"># synchronization phase can take</span></span><br><span class="line"><span class="attr">initLimit</span>=<span class="string">10</span></span><br><span class="line"><span class="comment"># The number of ticks that can pass between </span></span><br><span class="line"><span class="comment"># sending a request and getting an acknowledgement</span></span><br><span class="line"><span class="attr">syncLimit</span>=<span class="string">5</span></span><br><span class="line"><span class="comment"># the directory where the snapshot is stored.</span></span><br><span class="line"><span class="comment"># do not use /tmp for storage, /tmp here is just </span></span><br><span class="line"><span class="comment"># example sakes.</span></span><br><span class="line"><span class="attr">dataDir</span>=<span class="string">/tmp/zookeeper</span></span><br><span class="line"><span class="comment"># the port at which the clients will connect</span></span><br><span class="line"><span class="attr">clientPort</span>=<span class="string">2181</span></span><br><span class="line"><span class="comment"># the maximum number of client connections.</span></span><br><span class="line"><span class="comment"># increase this if you need to handle more clients</span></span><br><span class="line"><span class="comment">#maxClientCnxns=60</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Be sure to read the maintenance section of the </span></span><br><span class="line"><span class="comment"># administrator guide before turning on autopurge.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># The number of snapshots to retain in dataDir</span></span><br><span class="line"><span class="comment">#autopurge.snapRetainCount=3</span></span><br><span class="line"><span class="comment"># Purge task interval in hours</span></span><br><span class="line"><span class="comment"># Set to "0" to disable auto purge feature</span></span><br><span class="line"><span class="comment">#autopurge.purgeInterval=1</span></span><br></pre></td></tr></table></figure><p>然后运行bin目录下的zkServer.sh即可启动</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@bogon bin]# zkServer.sh start</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/apache-zookeeper-3.5.7-bin/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br></pre></td></tr></table></figure><h4 id="集群搭建"><a href="#集群搭建" class="headerlink" title="集群搭建"></a>集群搭建</h4><p>集群搭建也很简单，只需要在上述的zoo.cfg文件中加入一下配置</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">server.zk1</span>=<span class="string">xxx.xxx.x.xx:2888:3888</span></span><br><span class="line"><span class="meta">server.zk2</span>=<span class="string">xxx.xxx.x.xx:2888:3888</span></span><br><span class="line"><span class="meta">server.zk3</span>=<span class="string">xxx.xxx.x.xx:2888:3888</span></span><br></pre></td></tr></table></figure><p>其中2888为通信端口号，3888为选举端口号</p><p>然后分别启动三台Zookeeper的服务即可</p>]]></content>
      
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
            <tag> Java </tag>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 网络编程之 SSL加密连接</title>
      <link href="/posts/8662ab0e/"/>
      <url>/posts/8662ab0e/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>关于SSL加密连接方式的一切在这里就不再赘述，这里主要分享关于在Java编程中如何对SSL进行编码</p><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><h2 id="几个重要的类"><a href="#几个重要的类" class="headerlink" title="几个重要的类"></a>几个重要的类</h2><h3 id="KeyStore"><a href="#KeyStore" class="headerlink" title="KeyStore"></a>KeyStore</h3><p>表示密钥和证书的存储设施</p><p>主要用于存放证书，创建对象时，指定交换数字证书的加密标准</p><p>用法如下(以pkcs12为例)：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">InputStream stream=<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> Filel(<span class="string">"your file path"</span>));</span><br><span class="line"><span class="keyword">char</span>[] password=<span class="string">"your password"</span>.toCharArray();</span><br><span class="line">KeyStore keyStore=KeyStore.getInstance(<span class="string">"PKCS12"</span>);</span><br><span class="line">keyStore.load(stream, password);</span><br><span class="line">stream.close();</span><br></pre></td></tr></table></figure><h3 id="KeyManager"><a href="#KeyManager" class="headerlink" title="KeyManager"></a>KeyManager</h3><p>选择证书来证明自己的身份</p><p>这是用于 JSSE 密钥管理器的基接口。</p><p>KeyManager 负责管理用于验证到同位体的本地 SSLSocket 的密钥内容。如果没有密钥内容可以使用，则套接字将不能提供验证证书。</p><p>通过使用 KeyManagerFactory，或实现 KeyManager 子类之一来创建 KeyManager。</p><p>用法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这里的 keyStore、password 可以参考上方代码</span></span><br><span class="line">KeyManagerFactory keyManagerFactory=KeyManagerFactory.getInstance(<span class="string">"PKCS12"</span>);</span><br><span class="line">keyManagerFactory.init(keyStore,password);</span><br><span class="line">KeyManager[] keyManagers=keyManagerFactory.getKeyManagers();</span><br></pre></td></tr></table></figure><h3 id="TrustManager"><a href="#TrustManager" class="headerlink" title="TrustManager"></a>TrustManager</h3><p>决定是否信任对方的证书</p><p>这是用于 JSSE 信任管理器的基接口。</p><p>TrustManager 负责管理做出信任决定时使用的的信任材料，也负责决定是否接受同位体提供的证书。</p><p>通过使用 TrustManagerFactory，或实现 TrustManager 子类之一创建 TrustManager。</p><p>用法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这里的 keyStore 可以参考上方代码</span></span><br><span class="line">TrustManagerFactory trustManagerFactory=TrustManagerFactory.getInstance(<span class="string">"PKCS12"</span>);</span><br><span class="line">trustManagerFactory.init(keyStore);</span><br><span class="line">TrustManager[] trustManagers=trustManagerFactory.getTrustManagers();</span><br></pre></td></tr></table></figure><h3 id="SSLContext"><a href="#SSLContext" class="headerlink" title="SSLContext"></a>SSLContext</h3><p>此类的实例表示安全套接字协议的实现，它充当用于安全套接字工厂或 SSLEngine 的工厂。用可选的一组密钥和信任管理器及安全随机字节源初始化此类。</p><p>用法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SSLContext context=SSLContext.getInstance(<span class="string">"SSL"</span>);</span><br><span class="line">context.init(keyManagers, trustManagers, <span class="keyword">null</span>);</span><br></pre></td></tr></table></figure><h3 id="SSLEngine"><a href="#SSLEngine" class="headerlink" title="SSLEngine"></a>SSLEngine</h3><p>数据发送前wrap打包加密，数据接收时unwrap解包解密，这样一个tcp数据包通过SSLEngine的过程。如下图所示（来自JDK源码）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">                app data</span><br><span class="line">             |           ^</span><br><span class="line">             |     |     |</span><br><span class="line">             v     |     |</span><br><span class="line">        +----+-----|-----+----+</span><br><span class="line">        |          |          |</span><br><span class="line">        |       SSL|Engine    |</span><br><span class="line">wrap()  |          |          |  unwrap()</span><br><span class="line">        | OUTBOUND | INBOUND  |</span><br><span class="line">        |          |          |</span><br><span class="line">        +----+-----|-----+----+</span><br><span class="line">             |     |     ^</span><br><span class="line">             |     |     |</span><br><span class="line">             v           |</span><br><span class="line">                net data</span><br></pre></td></tr></table></figure><p>用法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 此context为上文提到的SSLContext</span></span><br><span class="line">SSLEngine engine = context.createSSLEngine();</span><br></pre></td></tr></table></figure><h2 id="证书互相转换"><a href="#证书互相转换" class="headerlink" title="证书互相转换"></a>证书互相转换</h2><h3 id="pem格式证书转为pkcs12格式"><a href="#pem格式证书转为pkcs12格式" class="headerlink" title="pem格式证书转为pkcs12格式"></a>pem格式证书转为pkcs12格式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl pkcs12 -export -in client.pem -out client.p12</span><br></pre></td></tr></table></figure><h3 id="pem格式证书导出x509格式"><a href="#pem格式证书导出x509格式" class="headerlink" title="pem格式证书导出x509格式"></a>pem格式证书导出x509格式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl x509 -outform der -in client.pem -out client.crt</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Java 编程相关 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> SSL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MongoDB 报文解读</title>
      <link href="/posts/c88df007/"/>
      <url>/posts/c88df007/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>由于工作和学习的需要，需要对 MongoDB 的报文进行分析和解读，故通过 Wireshark 进行 MongoDB 的抓包进行分析和学习</p><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>在抓包过程中，我们发现 MongoDB 在3.6之后引入了新的数据交换格式，与之前不同，但总体报文解析逻辑是相同的</p><p>话不多说，先上MongoDB数据包的正确打开方式</p><h2 id="配置MongoDB协议解码器"><a href="#配置MongoDB协议解码器" class="headerlink" title="配置MongoDB协议解码器"></a>配置MongoDB协议解码器</h2><ol><li><p>配置需要解码的端口号和协议<br><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200402145752.png" alt=""><br><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200402145814.png" alt="配置端口和协议"></p></li><li><p>过滤掉除MongoDB外的其他报文<br><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200402145842.png" alt="配置过滤规则"></p></li><li><p>打开一个已经解码好的报文<br><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200402145858.png" alt="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200402145858.png"><br><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200402145926.png" alt="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200402145926.png"></p></li></ol><p>这样，我们就可以很直观的看到数据包中都传递了那些数据</p><p>对于 MongoDB 的协议来说，OpCode是一个很重要的东西，根据OpCode，MongoDB区分了不同版本的报文结构。我们在Wireshark中看到的报文结构，都是经过完全解码后的数据。</p><p>官方文档中也有对协议内容的一个大致说明：<a href="https://docs.mongodb.com/manual/reference/mongodb-wire-protocol/" target="_blank" rel="noopener">官方的协议说明</a></p><p>在报文中有固定的一些字段，如下：</p><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">messageLength</td><td align="left">The total size of the message in bytes. This total includes the 4 bytes that holds the message length.</td></tr><tr><td align="center">requestID</td><td align="left">A client or database-generated identifier that uniquely identifies this message. For the case of client-generated messages (e.g. OP_QUERY and OP_GET_MORE), it will be returned in the responseTo field of the OP_REPLY message. Clients can use the requestID and the responseTo fields to associate query responses with the originating query.</td></tr><tr><td align="center">responseTo</td><td align="left">In the case of a message from the database, this will be the requestID taken from the OP_QUERY or OP_GET_MORE messages from the client. Clients can use the requestID and the responseTo fields to associate query responses with the originating query.</td></tr><tr><td align="center">opCode</td><td align="left">Type of message. See Request Opcodes for details.</td></tr></tbody></table><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">MsgHeader</span> &#123;</span></span><br><span class="line">    int32   messageLength; <span class="comment">// total message size, including this</span></span><br><span class="line">    int32   requestID;     <span class="comment">// identifier for this message</span></span><br><span class="line">    int32   responseTo;    <span class="comment">// requestID from the original request</span></span><br><span class="line">                           <span class="comment">//   (used in responses from db)</span></span><br><span class="line">    int32   opCode;        <span class="comment">// request type - see table below for details</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>messageLength：代表了MongoDB一次消息通讯中的消息总长度，位置在消息头部。</p><p>requestId：一般为请求发起方的消息包ID，此ID是自增长的，MongoDB会根据这个Id来返回这个ID对应的数据包</p><p>responseTo：一般为MongoDB返回的消息包ID，这个ID为请求包的requestId</p><p>opCode：代表了数据包中的消息类型，具体的OpCode的对应关系如下</p><p>OpCode编号与其含义对应如下：</p><blockquote><p>NOTE:<br>Starting with MongoDB 2.6 and maxWireVersion 3, MongoDB drivers use the database commands insert, update, and delete instead of OP_INSERT, OP_UPDATE, and OP_DELETE for acknowledged writes. Most drivers continue to use opcodes for unacknowledged writes.<br>In version 4.2, MongoDB removes the deprecated internal OP_COMMAND and OP_COMMANDREPLY protocol.</p></blockquote><table><thead><tr><th align="center">Opcode Name</th><th align="center">Value</th><th align="left">Comment</th></tr></thead><tbody><tr><td align="center">OP_REPLY</td><td align="center">1</td><td align="left">Reply to a client request. responseTo is set.</td></tr><tr><td align="center">OP_UPDATE</td><td align="center">2001</td><td align="left">Update document.</td></tr><tr><td align="center">OP_INSERT</td><td align="center">2002</td><td align="left">Insert new document.</td></tr><tr><td align="center">RESERVED</td><td align="center">2003</td><td align="left">Formerly used for OP_GET_BY_OID.</td></tr><tr><td align="center">OP_QUERY</td><td align="center">2004</td><td align="left">Query a collection.</td></tr><tr><td align="center">OP_GET_MORE</td><td align="center">2005</td><td align="left">Get more data from a query. See Cursors.</td></tr><tr><td align="center">OP_DELETE</td><td align="center">2006</td><td align="left">Delete documents.</td></tr><tr><td align="center">OP_KILL_CURSORS</td><td align="center">2007</td><td align="left">Notify database that the client has finished with the cursor.</td></tr><tr><td align="center">OP_MSG</td><td align="center">2013</td><td align="left">Send a message using the format introduced in MongoDB 3.6.</td></tr></tbody></table><h2 id="具体类型的-OP-CODE-格式解析"><a href="#具体类型的-OP-CODE-格式解析" class="headerlink" title="具体类型的 OP_CODE 格式解析"></a>具体类型的 OP_CODE 格式解析</h2><h3 id="OP-INSERT"><a href="#OP-INSERT" class="headerlink" title="OP_INSERT"></a>OP_INSERT</h3><p>OP_INSERT消息用于将一个或多个文档插入到集合中。OP_INSERT消息的格式为</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    MsgHeader header;             <span class="comment">// standard message header</span></span><br><span class="line">    int32     flags;              <span class="comment">// bit vector - see below</span></span><br><span class="line">    cstring   fullCollectionName; <span class="comment">// "dbname.collectionname"</span></span><br><span class="line">    document* documents;          <span class="comment">// one or more documents to insert into the collection</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">header</td><td align="left">消息头，参照上方标准消息头</td></tr><tr><td align="center">flags</td><td align="left">位向量，用于指定操作标志。如果为0，则数据库不会因为某条数据插入失败而停止插入。1-31为数据库保留</td></tr><tr><td align="center">fullCollectionName</td><td align="left">完整的集合名称，也被称为命名空间，一般格式为: &lt;数据库.集合名&gt;</td></tr><tr><td align="center">documents</td><td align="left">一个或多个要插入集合的文档。如果有多个，则依次将它们依次写入socket。</td></tr></tbody></table><p>OP_INSERT消息无响应。</p><h3 id="OP-DELETE"><a href="#OP-DELETE" class="headerlink" title="OP_DELETE"></a>OP_DELETE</h3><p>OP_DELETE消息用于从集合中删除一个或多个文档。OP_DELETE消息的格式为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    MsgHeader header;             <span class="comment">// standard message header</span></span><br><span class="line">    int32     ZERO;               <span class="comment">// 0 - reserved for future use</span></span><br><span class="line">    cstring   fullCollectionName; <span class="comment">// "dbname.collectionname"</span></span><br><span class="line">    int32     flags;              <span class="comment">// bit vector - see below for details.</span></span><br><span class="line">    document  selector;           <span class="comment">// query object.  See below for details.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">header</td><td align="left">消息头，参照上方标准消息头</td></tr><tr><td align="center">ZERO</td><td align="left">整数值0。暂未使用，官方称保留以备将来使用</td></tr><tr><td align="center">numberOfCursorIDs</td><td align="left">消息中的游标ID的数量</td></tr><tr><td align="center">cursorIDs</td><td align="left">要删除的游标ID的“数组”。如果有多个，则依次将它们依次写入套接字</td></tr></tbody></table><p>如果游标被读取直到用尽（直到OP_QUERY 或OP_GET_MORE返回零作为游标ID），就没有必要终止游标</p><h3 id="OP-UPDATE"><a href="#OP-UPDATE" class="headerlink" title="OP_UPDATE"></a>OP_UPDATE</h3><p>OP_UPDATE消息用于更新集合中的文档。OP_UPDATE消息的格式如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">OP_UPDATE</span> &#123;</span></span><br><span class="line">    MsgHeader header;             <span class="comment">// standard message header</span></span><br><span class="line">    int32     ZERO;               <span class="comment">// 0 - reserved for future use</span></span><br><span class="line">    cstring   fullCollectionName; <span class="comment">// "dbname.collectionname"</span></span><br><span class="line">    int32     flags;              <span class="comment">// bit vector. see below</span></span><br><span class="line">    document  selector;           <span class="comment">// the query to select the document</span></span><br><span class="line">    document  update;             <span class="comment">// specification of the update to perform</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">header</td><td align="left">消息头，参照上方标准消息头</td></tr><tr><td align="center">ZERO</td><td align="left">整数值0。暂未使用，官方称保留以备将来使用</td></tr><tr><td align="center">fullCollectionName</td><td align="left">完整的集合名称，也被称为命名空间，一般格式为: &lt;数据库.集合名&gt;</td></tr><tr><td align="center">flags</td><td align="left">位向量，用于指定操作标志。0：对应于Upsert。如果设置，则如果找不到匹配的文档，数据库将把提供的对象插入集合中。1：对应于MultiUpdate。如果设置，数据库将更新集合中的所有匹配对象。否则，仅更新第一个匹配的文档。2- 31保留。必须设置为0。</td></tr><tr><td align="center">selector</td><td align="left">BSON文档，指定用于选择要更新的文档的查询。</td></tr><tr><td align="center">update</td><td align="left">BSON文档，指定要执行的更新</td></tr></tbody></table><p>OP_UPDATE消息无响应。</p><h3 id="OP-QUERY"><a href="#OP-QUERY" class="headerlink" title="OP_QUERY"></a>OP_QUERY</h3><p>OP_QUERY消息用于在数据库中查询集合中的文档。OP_QUERY消息的格式为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">OP_QUERY</span> &#123;</span></span><br><span class="line">    MsgHeader header;                 <span class="comment">// standard message header</span></span><br><span class="line">    int32     flags;                  <span class="comment">// bit vector of query options.  See below for details.</span></span><br><span class="line">    cstring   fullCollectionName ;    <span class="comment">// "dbname.collectionname"</span></span><br><span class="line">    int32     numberToSkip;           <span class="comment">// number of documents to skip</span></span><br><span class="line">    int32     numberToReturn;         <span class="comment">// number of documents to return</span></span><br><span class="line">                                      <span class="comment">//  in the first OP_REPLY batch</span></span><br><span class="line">    document  query;                  <span class="comment">// query object.  See below for details.</span></span><br><span class="line">  [ document  returnFieldsSelector; ] <span class="comment">// Optional. Selector indicating the fields</span></span><br><span class="line">                                      <span class="comment">//  to return.  See below for details.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">header</td><td align="left">消息头，参照上方标准消息头</td></tr><tr><td align="center">flags</td><td align="left">位向量，用于指定操作标志。</td></tr><tr><td align="center">fullCollectionName</td><td align="left">完整的集合名称，也被称为命名空间，一般格式为: &lt;数据库.集合名&gt;</td></tr><tr><td align="center">numberToSkip</td><td align="left">设置要跳过的文档数-从结果数据集中的第一个文档开始-返回查询结果时。</td></tr><tr><td align="center">numberToReturn</td><td align="left">将第一个OP_REPLY消息中的文档数限制为查询。但是，cursorID如果结果多于，数据库仍将建立游标并将其返回给客户端numberToReturn。如果客户端驱动程序提供了“限制”功能（例如SQL LIMIT关键字），则由客户端驱动程序来确保将不超过指定数量的文档返回给调用应用程序。如果numberToReturn为0，则数据库将使用默认的返回大小。如果数字为负，则数据库将返回该数字并关闭游标。无法获取该查询的其他结果。如果numberToReturn为， 1则服务器会将其视为-1（自动关闭光标）。</td></tr><tr><td align="center">query</td><td align="left">代表查询的BSON文档。该查询将包含一个或多个元素，所有这些元素都必须匹配才能使文档包含在结果集中。可能的因素包括 $query，$orderby，$hint，和$explain。</td></tr><tr><td align="center">returnFieldsSelector</td><td align="left">可选BSON文档，用于限制返回文档中的字段。所述returnFieldsSelector含有一种或多种元素，其中的每一个是应返回字段的名称，以及整数值1。</td></tr></tbody></table><p>对于上方flags字段，具体描述如下：</p><ul><li>0被预定了。必须设置为0。</li><li>1对应于TailableCursor。可拖尾表示检索到最后一个数据时光标未关闭。而是，光标标记最终对象的位置。如果收到更多数据，则可以稍后从光标所在的位置继续使用它。像任何“潜在游标”一样，游标可能会在某个时候失效（CursorNotFound）–例如，如果删除了它所引用的最终对象。</li><li>2对应于SlaveOk.Allow查询副本从属。通常，这些返回错误，但名称空间“ local”除外。</li><li>3对应于OplogReplay。仅供内部复制使用-不应设置驱动程序。</li><li>4对应于NoCursorTimeout。服务器通常在闲置时间（10分钟）后使空闲游标超时，以防止过多使用内存。设置此选项可以防止这种情况。</li><li>5对应于AwaitData。与TailableCursor一起使用。如果我们在数据的末尾，请阻塞一会儿，而不要返回任何数据。超时后，我们照常返回。</li><li>6对应于排气。假设客户端将完全读取所有查询的数据，则将数据以多个“更多”包的形式完整传输。当您提取大量数据并知道要全部提取时，速度更快。注意：除非客户端关闭连接，否则不允许客户端不读取所有数据。</li><li>7对应于部分。如果某些分片发生故障，则从mongos获得部分结果（而不是引发错误）</li><li>8-31保留。必须设置为0。</li></ul><p>数据库使用OP_REPLY消息来响应 OP_QUERY消息。</p><h3 id="OP-GET-MORE"><a href="#OP-GET-MORE" class="headerlink" title="OP_GET_MORE"></a>OP_GET_MORE</h3><p>OP_GET_MORE消息用于在数据库中查询集合中的文档。OP_GET_MORE消息的格式为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    MsgHeader header;             <span class="comment">// standard message header</span></span><br><span class="line">    int32     ZERO;               <span class="comment">// 0 - reserved for future use</span></span><br><span class="line">    cstring   fullCollectionName; <span class="comment">// "dbname.collectionname"</span></span><br><span class="line">    int32     numberToReturn;     <span class="comment">// number of documents to return</span></span><br><span class="line">    int64     cursorID;           <span class="comment">// cursorID from the OP_REPLY</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">header</td><td align="left">消息头，参照上方标准消息头</td></tr><tr><td align="center">ZERO</td><td align="left">整数值0。暂未使用，官方称保留以备将来使用</td></tr><tr><td align="center">fullCollectionName</td><td align="left">完整的集合名称，也被称为命名空间，一般格式为: &lt;数据库.集合名&gt;</td></tr><tr><td align="center">numberToReturn</td><td align="left">将第一个OP_REPLY消息中的文档数限制为查询。但是，cursorID如果结果多于，数据库仍将建立游标并将其返回给客户端numberToReturn。如果客户端驱动程序提供了“限制”功能（例如SQL LIMIT关键字），则由客户端驱动程序来确保将不超过指定数量的文档返回给调用应用程序。如果numberToReturn为0，则数据库将使用默认的返回大小。</td></tr><tr><td align="center">cursorID</td><td align="left">OP_REPLY中的光标标识符。这必须是来自数据库的值。</td></tr></tbody></table><p>数据库将以OP_REPLY消息响应 OP_GET_MORE消息。</p><h3 id="OP-KILL-CURSORS"><a href="#OP-KILL-CURSORS" class="headerlink" title="OP_KILL_CURSORS"></a>OP_KILL_CURSORS</h3><p>OP_KILL_CURSORS消息用于关闭数据库中的活动游标。这是确保查询结束时回收数据库资源所必需的。OP_KILL_CURSORS消息的格式为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    MsgHeader header;            <span class="comment">// standard message header</span></span><br><span class="line">    int32     ZERO;              <span class="comment">// 0 - reserved for future use</span></span><br><span class="line">    int32     numberOfCursorIDs; <span class="comment">// number of cursorIDs in message</span></span><br><span class="line">    int64*    cursorIDs;         <span class="comment">// sequence of cursorIDs to close</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">header</td><td align="left">消息头，参照上方标准消息头</td></tr><tr><td align="center">ZERO</td><td align="left">整数值0。暂未使用，官方称保留以备将来使用</td></tr><tr><td align="center">numberOfCursorIDs</td><td align="left">消息中的游标ID的数量。</td></tr><tr><td align="center">cursorIDs</td><td align="left">要关闭的游标ID的“数组”。如果有多个，则依次将它们依次写入socket。</td></tr><tr><td align="center">如果游标被读取直到用尽（直到OP_QUERY 或OP_GET_MORE返回零作为游标ID），就没有必要终止游标。</td><td align="left"></td></tr></tbody></table><h3 id="OP-MSG"><a href="#OP-MSG" class="headerlink" title="OP_MSG"></a>OP_MSG</h3><blockquote><p>MongoDB版本中的新功能： 3.6</p></blockquote><p>OP_MSG是一种可扩展的消息格式，旨在包含其他操作码的功能。OP_MSG消息的格式为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">OP_MSG &#123;</span><br><span class="line">    MsgHeader header;          <span class="comment">// standard message header</span></span><br><span class="line">    uint32 flagBits;           <span class="comment">// message flags</span></span><br><span class="line">    Sections[] sections;       <span class="comment">// data sections</span></span><br><span class="line">    optional&lt;uint32&gt; checksum; <span class="comment">// optional CRC-32C checksum</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">header</td><td align="left">消息头，参照上方标准消息头</td></tr><tr><td align="center">flagBits</td><td align="left">包含消息标志的整数位掩码</td></tr><tr><td align="center">sections</td><td align="left">消息主体部中，如所描述的章节</td></tr><tr><td align="center">checksum</td><td align="left">可选的CRC-32C校验和，如 Checksum中所述</td></tr></tbody></table><p>具体信息参照下方描述：</p><h4 id="flagBits"><a href="#flagBits" class="headerlink" title="flagBits"></a>flagBits</h4><p>该flagBits整数是编码修改的格式和行为的标志位掩码OP_MSG。</p><p>前16位（0-15）是必需的， 如果设置了一个位置的bit，则解析器务必出错。</p><p>最后16位（16-31）是可选的，解析器务必忽略任何未知的被设置的bit。代理和其他消息转发器必须在转发消息之前清除所有未知的可选位。</p><table><thead><tr><th align="center">Bit</th><th align="center">Name</th><th align="center">Request</th><th align="center">Response</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">checksumPresent</td><td align="center">✓</td><td align="center">✓</td><td align="left">该消息以4个字节结尾，其中包含CRC-32C [1] 校验和。</td></tr><tr><td align="center">1</td><td align="center">moreToCome</td><td align="center">✓</td><td align="center">✓</td><td align="left">另一条消息将跟随此消息，而无需接收者采取进一步措施。接收器必须不发送另一消息，直到接收到一个具有moreToCome设置为0作为发送可能阻塞，引起死锁。moreToCome 设置了该位的请求将不会收到答复。答复将仅在设置了该exhaustAllowed位的情况下响应此请求。</td></tr><tr><td align="center">16</td><td align="center">exhaustAllowed</td><td align="center">✓</td><td align="center">-</td><td align="left">客户端已准备好使用该moreToCome位对该请求进行多次答复。moreToCome除非请求设置了该位，否则服务器将永远不会产生设置了位的回复。这样可以确保仅在请求者的网络层已准备好多个答复时才发送它们。</td></tr></tbody></table><p>MongoDB 3.6会忽略此标志，并将以一条消息进行响应</p><h4 id="Sections"><a href="#Sections" class="headerlink" title="Sections"></a>Sections</h4><p>一条OP_MSG消息包含一个或多个部分。每个部分都以一个kind指示其类型的字节开头。kind 字节之后的所有内容均构成该节的有效负载。</p><p>可用的部分如下：</p><ul><li>Kind 0: Body</li></ul><p>正文部分被编码为单个 BSON对象。BSON对象中的大小也用作部分的大小。此部分类型是标准命令请求和答复正文。</p><p>所有顶级字段都必须具有唯一的名称。</p><ul><li>Kind 1: Document Sequence</li></ul><table><thead><tr><th align="center">Type</th><th>Description</th></tr></thead><tbody><tr><td align="center">int32</td><td>section的大小.</td></tr><tr><td align="center">C String</td><td>文档序列标识符。在所有当前命令中，此字段是从body section替换的（可能是嵌套的）字段。但是不得也存在于主体部分。</td></tr><tr><td align="center">Zero or more BSON objects</td><td>零个或多个BSON对象。对象不使用分隔符来背对背排序。</td></tr></tbody></table><p>对于Zero or more BSON objects来说，每个对象仅限于maxBSONObjectSize服务器的。所有对象的组合不限于 maxBSONObjSize。<br>一旦size消耗完字节，文档序列就结束。<br>转换为语言级对象时，解析器可以选择将这些对象作为数组合并到序列标识符指定的路径处的数组中。</p><h4 id="Checksum"><a href="#Checksum" class="headerlink" title="Checksum"></a>Checksum</h4><p>每条消息可以以CRC-32C [1]校验和结尾，该校验和覆盖消息中所有字节，校验和本身除外</p><p>从MongoDB 4.2开始：</p><ul><li>mongod如果不使用TLS / SSL连接mongos，则实例，实例和 mongo外壳程序实例将与校验和交换消息。</li><li>mongod如果使用TLS / SSL连接mongos，则实例，实例和 mongo外壳程序实例将跳过校验和。</li></ul><p>如果驱动程序和较旧的二进制文件带有带有校验和的消息，则它们将忽略校验和。</p><p>checksumPresent标志位指示存在校验和。</p><h3 id="OP-REPLY"><a href="#OP-REPLY" class="headerlink" title="OP_REPLY"></a>OP_REPLY</h3><p>该OP_REPLY消息由数据库发送，以响应 OP_QUERY或OP_GET_MORE消息。OP_REPLY消息的格式为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    MsgHeader header;         <span class="comment">// standard message header</span></span><br><span class="line">    int32     responseFlags;  <span class="comment">// bit vector - see details below</span></span><br><span class="line">    int64     cursorID;       <span class="comment">// cursor id if client needs to do get more's</span></span><br><span class="line">    int32     startingFrom;   <span class="comment">// where in the cursor this reply is starting</span></span><br><span class="line">    int32     numberReturned; <span class="comment">// number of documents in the reply</span></span><br><span class="line">    document* documents;      <span class="comment">// documents</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th>Description</th></tr></thead><tbody><tr><td align="center">header</td><td>消息头，参照上方标准消息头</td></tr><tr><td align="center">responseFlags</td><td>指定标志的bit向量</td></tr><tr><td align="center">cursorID</td><td>该cursorID 为 OP_REPLY的一部分。如果查询的结果集适合一个OP_REPLY消息， cursorID则将为0。cursorID必须在用于获取更多数据的任何 OP_GET_MORE消息中使用此值，并且当不再需要通过OP_KILL_CURSORS 消息将其关闭时，客户端也必须将其关闭。</td></tr><tr><td align="center">startingFrom</td><td>游标开始位置</td></tr><tr><td align="center">numberReturned</td><td>返回的文档数量.</td></tr><tr><td align="center">documents</td><td>返回的文档</td></tr></tbody></table><p>对于responseFlags的说明</p><ul><li>0对应于CursorNotFound。在getMore调用时设置，但光标ID在服务器上无效。返回结果为零。</li><li>1对应于QueryFailure。查询失败时设置。结果由一个文档组成，其中包含描述失败的“ $ err”字段。</li><li>2对应于ShardConfigStale。驱动应忽略这一点。只有mongos将看到此设置，在这种情况下，它需要从服务器更新配置。</li><li>3对应于AwaitCapable。当服务器支持AwaitData查询选项时设置。如果不是这样，则客户端应该在Tailable游标的getMore之间睡一会儿。Mongod 1.6版支持AwaitData，因此始终设置AwaitCapable。</li><li>4-31保留。忽视。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库相关 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MongoDB </tag>
            
            <tag> TCP </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
